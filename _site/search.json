[
  {
    "objectID": "projetos/posts/2025-12-12-machine_rice.html",
    "href": "projetos/posts/2025-12-12-machine_rice.html",
    "title": "Projeto - Previsão da produtividade de arroz em casca",
    "section": "",
    "text": "Pipeline completo de Machine Learning em R\nEste repositório apresenta um pipeline para prever a produtividade de arroz (paddy yield) usando o ecossistema tidymodels.\nO projeto inclui pré-processamento, engenharia de atributos, tuning, comparação de modelos, retreinamento e diagnóstico completo dos resíduos.\n\n\n\nLeia o relatório com todas as etapas e explicações aqui.\n\n\n\nAcesse o repositório completo aqui.\n\n\n\n\n\n\n\nConstruir um fluxo completo de modelagem para prever produtividade de arroz (kg/ha) a partir de variáveis agronômicas, climáticas e operacionais do Paddy Dataset (UCI, 2023).\n\n\n\nTrabalhei com arroz desde a graduação até o doutorado, sempre na área de melhoramento genético. Eu nunca havia trabalhado com variáveis operacionais e ambientais como as deste dataset, e buscava um banco rico para aplicar técnicas modernas de Machine Learning. O Paddy Dataset foi a escolha ideal para essa exploração.\n\n\n\n\n2789 observações\n45 variáveis preditoras completas (sem NA)\nTalhões do estado de Tamil Nadu (Índia)\nVariáveis de clima, irrigação, adubação, manejo, temperatura e produtividade\n\nFonte: Subramaniyan (2023), UCI Machine Learning Repository.\n\n\n\nO pipeline inclui:\n\nCarregamento e limpeza dos dados\nEstatística descritiva e identificação da escala da resposta\nSplit estratificado (80/20)\nValidação cruzada (5-Fold)\nRecipe completa com engenharia de atributos\n\nfertilizante/ha\ndensidade de semeadura\nefeitos de chuva por janelas\nágua total e água por hectare\nmédias e amplitudes térmicas\nmétricas de investimento\nimputação, normalização, dummies e Yeo-Johnson\n\nModelos utilizados\n\nRandom Forest (ranger)\nXGBoost\n\nTuning com grid regular\nComparação Random Forest vs XGBoost\nTreino Final com hiperparâmetros ótimos\nAvaliação no conjunto de teste\nFunção de previsão para novos dados\nFunção de retreinamento\nAnálise completa de resíduos e gráficos de diagnóstico\n\n\n\n\nModelo vencedor: Random Forest\nDesempenho no teste:\n\nRMSE ~ 796.72 kg/ha\nR² ~ 0.9921\nMAE ~ 569.86 kg/ha\n\n\nEsses valores indicam excelente capacidade de generalização e baixa taxa de erro considerando a escala dos dados.\n\n\n\n\n├── data\n│   ├── data_example.xlsx\n│   ├── new_data.xlsx\n│   ├── novos_api.csv\n│   ├── novos_dados_paddy.csv\n│   └── paddydataset.csv\n├── estilo.css\n├── imagens\n│   ├── artigo.JPG\n│   └── etapas.png\n├── machine_learning_portifólio.Rproj\n├── outputs\n│   ├── modelo_paddy_final.rds\n│   ├── modelo_paddy_retreinado.rds\n│   ├── model_comparison.csv\n│   ├── receita_preprocessamento.rds\n│   ├── test_metrics.csv\n│   └── test_predictions.csv\n├── paddy_ml.qmd\n├── README.md\n└── scripts\n    └── paddy_ml.r\n\n\n\n\n\nif (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(tidymodels, tidyverse, skimr, janitor, ranger, xgboost,\n               doParallel, glue, vip, patchwork)\n\n\n\ndf_raw &lt;- read_csv(\"data/paddydataset.csv\") |&gt; clean_names()\n\n\n\nO script segue a ordem lógica do processo, por exemplo:\n1. 01_preprocessamento\n2. 02_treinamento\n3. 03_avaliacao\n4. 04_retreinamento\n\n\n\n\nprevisoes &lt;- predict_yield(novos_dados)\n\n\n\nmodelo_atualizado &lt;- retrain_model(novos_dados, original_data = train_data)\n\n\n\nForam gerados:\n\nGráfico Predito vs Observado\nDistribuição dos Resíduos\nResíduos vs Preditos\nQ-Q Plot\nPainel combinado (patchwork)\n\n\nEsses gráficos confirmam ausência de viés, normalidade aproximada dos resíduos e bom ajuste geral.\n\n\n\n\n@misc{paddy_dataset_1186,\n  author       = {Subramaniyan, Muthukumaran},\n  title        = {Paddy Dataset},\n  year         = {2023},\n  howpublished = {UCI Machine Learning Repository},\n  note         = {DOI: https://doi.org/10.24432/C55W3J}\n}\n\n\n\nMIT."
  },
  {
    "objectID": "projetos/posts/2025-12-12-machine_rice.html#relatório-html",
    "href": "projetos/posts/2025-12-12-machine_rice.html#relatório-html",
    "title": "Projeto - Previsão da produtividade de arroz em casca",
    "section": "",
    "text": "Leia o relatório com todas as etapas e explicações aqui."
  },
  {
    "objectID": "projetos/posts/2025-12-12-machine_rice.html#repositório-do-github",
    "href": "projetos/posts/2025-12-12-machine_rice.html#repositório-do-github",
    "title": "Projeto - Previsão da produtividade de arroz em casca",
    "section": "",
    "text": "Acesse o repositório completo aqui."
  },
  {
    "objectID": "projetos/posts/2025-12-12-machine_rice.html#objetivo",
    "href": "projetos/posts/2025-12-12-machine_rice.html#objetivo",
    "title": "Projeto - Previsão da produtividade de arroz em casca",
    "section": "",
    "text": "Construir um fluxo completo de modelagem para prever produtividade de arroz (kg/ha) a partir de variáveis agronômicas, climáticas e operacionais do Paddy Dataset (UCI, 2023)."
  },
  {
    "objectID": "projetos/posts/2025-12-12-machine_rice.html#motivação",
    "href": "projetos/posts/2025-12-12-machine_rice.html#motivação",
    "title": "Projeto - Previsão da produtividade de arroz em casca",
    "section": "",
    "text": "Trabalhei com arroz desde a graduação até o doutorado, sempre na área de melhoramento genético. Eu nunca havia trabalhado com variáveis operacionais e ambientais como as deste dataset, e buscava um banco rico para aplicar técnicas modernas de Machine Learning. O Paddy Dataset foi a escolha ideal para essa exploração."
  },
  {
    "objectID": "projetos/posts/2025-12-12-machine_rice.html#sobre-o-dataset",
    "href": "projetos/posts/2025-12-12-machine_rice.html#sobre-o-dataset",
    "title": "Projeto - Previsão da produtividade de arroz em casca",
    "section": "",
    "text": "2789 observações\n45 variáveis preditoras completas (sem NA)\nTalhões do estado de Tamil Nadu (Índia)\nVariáveis de clima, irrigação, adubação, manejo, temperatura e produtividade\n\nFonte: Subramaniyan (2023), UCI Machine Learning Repository."
  },
  {
    "objectID": "projetos/posts/2025-12-12-machine_rice.html#pipeline-de-modelagem",
    "href": "projetos/posts/2025-12-12-machine_rice.html#pipeline-de-modelagem",
    "title": "Projeto - Previsão da produtividade de arroz em casca",
    "section": "",
    "text": "O pipeline inclui:\n\nCarregamento e limpeza dos dados\nEstatística descritiva e identificação da escala da resposta\nSplit estratificado (80/20)\nValidação cruzada (5-Fold)\nRecipe completa com engenharia de atributos\n\nfertilizante/ha\ndensidade de semeadura\nefeitos de chuva por janelas\nágua total e água por hectare\nmédias e amplitudes térmicas\nmétricas de investimento\nimputação, normalização, dummies e Yeo-Johnson\n\nModelos utilizados\n\nRandom Forest (ranger)\nXGBoost\n\nTuning com grid regular\nComparação Random Forest vs XGBoost\nTreino Final com hiperparâmetros ótimos\nAvaliação no conjunto de teste\nFunção de previsão para novos dados\nFunção de retreinamento\nAnálise completa de resíduos e gráficos de diagnóstico"
  },
  {
    "objectID": "projetos/posts/2025-12-12-machine_rice.html#resultados-principais",
    "href": "projetos/posts/2025-12-12-machine_rice.html#resultados-principais",
    "title": "Projeto - Previsão da produtividade de arroz em casca",
    "section": "",
    "text": "Modelo vencedor: Random Forest\nDesempenho no teste:\n\nRMSE ~ 796.72 kg/ha\nR² ~ 0.9921\nMAE ~ 569.86 kg/ha\n\n\nEsses valores indicam excelente capacidade de generalização e baixa taxa de erro considerando a escala dos dados."
  },
  {
    "objectID": "projetos/posts/2025-12-12-machine_rice.html#estrutura-do-repositório",
    "href": "projetos/posts/2025-12-12-machine_rice.html#estrutura-do-repositório",
    "title": "Projeto - Previsão da produtividade de arroz em casca",
    "section": "",
    "text": "├── data\n│   ├── data_example.xlsx\n│   ├── new_data.xlsx\n│   ├── novos_api.csv\n│   ├── novos_dados_paddy.csv\n│   └── paddydataset.csv\n├── estilo.css\n├── imagens\n│   ├── artigo.JPG\n│   └── etapas.png\n├── machine_learning_portifólio.Rproj\n├── outputs\n│   ├── modelo_paddy_final.rds\n│   ├── modelo_paddy_retreinado.rds\n│   ├── model_comparison.csv\n│   ├── receita_preprocessamento.rds\n│   ├── test_metrics.csv\n│   └── test_predictions.csv\n├── paddy_ml.qmd\n├── README.md\n└── scripts\n    └── paddy_ml.r"
  },
  {
    "objectID": "projetos/posts/2025-12-12-machine_rice.html#como-reproduzir",
    "href": "projetos/posts/2025-12-12-machine_rice.html#como-reproduzir",
    "title": "Projeto - Previsão da produtividade de arroz em casca",
    "section": "",
    "text": "if (!requireNamespace(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(tidymodels, tidyverse, skimr, janitor, ranger, xgboost,\n               doParallel, glue, vip, patchwork)\n\n\n\ndf_raw &lt;- read_csv(\"data/paddydataset.csv\") |&gt; clean_names()\n\n\n\nO script segue a ordem lógica do processo, por exemplo:\n1. 01_preprocessamento\n2. 02_treinamento\n3. 03_avaliacao\n4. 04_retreinamento"
  },
  {
    "objectID": "projetos/posts/2025-12-12-machine_rice.html#previsões-em-novos-dados",
    "href": "projetos/posts/2025-12-12-machine_rice.html#previsões-em-novos-dados",
    "title": "Projeto - Previsão da produtividade de arroz em casca",
    "section": "",
    "text": "previsoes &lt;- predict_yield(novos_dados)"
  },
  {
    "objectID": "projetos/posts/2025-12-12-machine_rice.html#retreinamento-com-novos-dados",
    "href": "projetos/posts/2025-12-12-machine_rice.html#retreinamento-com-novos-dados",
    "title": "Projeto - Previsão da produtividade de arroz em casca",
    "section": "",
    "text": "modelo_atualizado &lt;- retrain_model(novos_dados, original_data = train_data)"
  },
  {
    "objectID": "projetos/posts/2025-12-12-machine_rice.html#diagnóstico-dos-resíduos",
    "href": "projetos/posts/2025-12-12-machine_rice.html#diagnóstico-dos-resíduos",
    "title": "Projeto - Previsão da produtividade de arroz em casca",
    "section": "",
    "text": "Foram gerados:\n\nGráfico Predito vs Observado\nDistribuição dos Resíduos\nResíduos vs Preditos\nQ-Q Plot\nPainel combinado (patchwork)\n\n\nEsses gráficos confirmam ausência de viés, normalidade aproximada dos resíduos e bom ajuste geral."
  },
  {
    "objectID": "projetos/posts/2025-12-12-machine_rice.html#citação-do-dataset",
    "href": "projetos/posts/2025-12-12-machine_rice.html#citação-do-dataset",
    "title": "Projeto - Previsão da produtividade de arroz em casca",
    "section": "",
    "text": "@misc{paddy_dataset_1186,\n  author       = {Subramaniyan, Muthukumaran},\n  title        = {Paddy Dataset},\n  year         = {2023},\n  howpublished = {UCI Machine Learning Repository},\n  note         = {DOI: https://doi.org/10.24432/C55W3J}\n}"
  },
  {
    "objectID": "projetos/posts/2025-12-12-machine_rice.html#licença",
    "href": "projetos/posts/2025-12-12-machine_rice.html#licença",
    "title": "Projeto - Previsão da produtividade de arroz em casca",
    "section": "",
    "text": "MIT."
  },
  {
    "objectID": "projetos/posts/2025-12-12-bigquery_pam.html",
    "href": "projetos/posts/2025-12-12-bigquery_pam.html",
    "title": "Projeto - Análise da Produção de Grãos no Brasil",
    "section": "",
    "text": "Este projeto implementa um pipeline completo em arquitetura Medallion (Bronze, Silver e Gold) para análise de lavouras temporárias no Brasil (soja, milho e arroz), utilizando dados oficiais do IBGE PAM, ingestão via BigQuery, processamento em R e consumo de dados do BigQuery com o pacote dbplyr.\nObjetivos:\n\norganização de dados em camadas;\neficiência no uso de memória local;\nintegração R &lt;&gt; BigQuery;\nboas práticas de processamento e consumo de dados em ambiente cloud.\n\n\n\n\nAcesse aqui.\n\n\n\nApós a execução do script, há um relatório em Quarto que demonstra o consumo da camada Gold diretamente no BigQuery, utilizando dbplyr e coletando dados apenas no final.\nAcesse o relatório no link configurado no projeto.\n\n\n\nO pipeline é dividido em três camadas bem definidas:\n\nBronze: ingestão e padronização mínima dos dados brutos;\nSilver: limpeza, enriquecimento, classificação e agregações intermediárias;\nGold: métricas analíticas consolidadas para consumo e visualização.\n\nCada camada gera arquivos locais organizados por diretório e possui um dataset próprio no BigQuery.\n\n\n\n├── bronze\n│   └── bronze_lavouras_raw.csv\n├── silver\n│   ├── silver_lavouras_arroz.csv\n│   ├── silver_lavouras_milho.csv\n│   ├── silver_lavouras_soja.csv\n│   ├── silver_municipio_arroz.csv\n│   ├── silver_municipio_milho.csv\n│   ├── silver_municipio_soja.csv\n│   ├── silver_uf_arroz.csv\n│   ├── silver_uf_milho.csv\n│   └── silver_uf_soja.csv\n├── gold\n│   ├── gold_evolucao_temporal.csv\n│   ├── gold_indicadores_sustentabilidade.csv\n│   ├── gold_indice_concentracao.csv\n│   ├── gold_municipios_emergentes.csv\n│   ├── gold_perfil_regional.csv\n│   ├── gold_ranking_estados.csv\n│   └── gold_shift_share_analysis.csv\n├── relatorio\n│   ├── estilo.css\n│   └── relatorio_medallion_bigquery_final.qmd\n├── script\n│   └── pipeline_pam_final.R\n└── README.md\n\n\n\nIBGE – Pesquisa Agrícola Municipal (PAM), acessada via Base dos Dados. São analisadas as culturas de soja, milho e arroz.\n\n\n\nPara rodar este projeto, é necessário:\n\nUm projeto ativo no Google Cloud Platform (GCP) Qualquer projeto válido funciona (não precisa ser o mesmo do autor).\nBigQuery habilitado no projeto.\nCredenciais de acesso configuradas Recomenda-se o uso de uma service account com permissões:\nVariáveis de ambiente configuradas:\n\nGOOGLE_APPLICATION_CREDENTIALS=\"/caminho/para/sua-chave.json\"\nGCP_PROJECT_ID=\"seu-projeto-gcp\"\nBQ_DATASET_ID=\"analise_lavouras\"\nBD_BILLING_ID=\"seu-projeto-gcp\"\n\nEssas variáveis permitem que o mesmo código seja executado em diferentes ambientes sem alterações no script.\n\n\n\n\nExecute o script principal:\nsource(\"script/pipeline_pam_final.R\")\nO pipeline irá:\n\nIngerir dados do IBGE PAM via BigQuery (Bronze);\nProcessar e gerar tabelas enriquecidas e agregadas (Silver);\nCalcular métricas analíticas consolidadas (Gold);\nSalvar os resultados localmente por camada;\nCriar datasets separados no BigQuery e exportar todas as tabelas.\n\n\n\n\nMIT."
  },
  {
    "objectID": "projetos/posts/2025-12-12-bigquery_pam.html#ingestão-via-bigquery-transformação-em-arquitetura-medallion-e-consumo-de-dados-do-bigquery-com-rdbplyr",
    "href": "projetos/posts/2025-12-12-bigquery_pam.html#ingestão-via-bigquery-transformação-em-arquitetura-medallion-e-consumo-de-dados-do-bigquery-com-rdbplyr",
    "title": "Projeto - Análise da Produção de Grãos no Brasil",
    "section": "",
    "text": "Este projeto implementa um pipeline completo em arquitetura Medallion (Bronze, Silver e Gold) para análise de lavouras temporárias no Brasil (soja, milho e arroz), utilizando dados oficiais do IBGE PAM, ingestão via BigQuery, processamento em R e consumo de dados do BigQuery com o pacote dbplyr.\nObjetivos:\n\norganização de dados em camadas;\neficiência no uso de memória local;\nintegração R &lt;&gt; BigQuery;\nboas práticas de processamento e consumo de dados em ambiente cloud."
  },
  {
    "objectID": "projetos/posts/2025-12-12-bigquery_pam.html#repositório-no-github",
    "href": "projetos/posts/2025-12-12-bigquery_pam.html#repositório-no-github",
    "title": "Projeto - Análise da Produção de Grãos no Brasil",
    "section": "",
    "text": "Acesse aqui."
  },
  {
    "objectID": "projetos/posts/2025-12-12-bigquery_pam.html#relatório",
    "href": "projetos/posts/2025-12-12-bigquery_pam.html#relatório",
    "title": "Projeto - Análise da Produção de Grãos no Brasil",
    "section": "",
    "text": "Após a execução do script, há um relatório em Quarto que demonstra o consumo da camada Gold diretamente no BigQuery, utilizando dbplyr e coletando dados apenas no final.\nAcesse o relatório no link configurado no projeto."
  },
  {
    "objectID": "projetos/posts/2025-12-12-bigquery_pam.html#visão-geral-da-arquitetura",
    "href": "projetos/posts/2025-12-12-bigquery_pam.html#visão-geral-da-arquitetura",
    "title": "Projeto - Análise da Produção de Grãos no Brasil",
    "section": "",
    "text": "O pipeline é dividido em três camadas bem definidas:\n\nBronze: ingestão e padronização mínima dos dados brutos;\nSilver: limpeza, enriquecimento, classificação e agregações intermediárias;\nGold: métricas analíticas consolidadas para consumo e visualização.\n\nCada camada gera arquivos locais organizados por diretório e possui um dataset próprio no BigQuery."
  },
  {
    "objectID": "projetos/posts/2025-12-12-bigquery_pam.html#estrutura-do-repositório",
    "href": "projetos/posts/2025-12-12-bigquery_pam.html#estrutura-do-repositório",
    "title": "Projeto - Análise da Produção de Grãos no Brasil",
    "section": "",
    "text": "├── bronze\n│   └── bronze_lavouras_raw.csv\n├── silver\n│   ├── silver_lavouras_arroz.csv\n│   ├── silver_lavouras_milho.csv\n│   ├── silver_lavouras_soja.csv\n│   ├── silver_municipio_arroz.csv\n│   ├── silver_municipio_milho.csv\n│   ├── silver_municipio_soja.csv\n│   ├── silver_uf_arroz.csv\n│   ├── silver_uf_milho.csv\n│   └── silver_uf_soja.csv\n├── gold\n│   ├── gold_evolucao_temporal.csv\n│   ├── gold_indicadores_sustentabilidade.csv\n│   ├── gold_indice_concentracao.csv\n│   ├── gold_municipios_emergentes.csv\n│   ├── gold_perfil_regional.csv\n│   ├── gold_ranking_estados.csv\n│   └── gold_shift_share_analysis.csv\n├── relatorio\n│   ├── estilo.css\n│   └── relatorio_medallion_bigquery_final.qmd\n├── script\n│   └── pipeline_pam_final.R\n└── README.md"
  },
  {
    "objectID": "projetos/posts/2025-12-12-bigquery_pam.html#fonte-dos-dados",
    "href": "projetos/posts/2025-12-12-bigquery_pam.html#fonte-dos-dados",
    "title": "Projeto - Análise da Produção de Grãos no Brasil",
    "section": "",
    "text": "IBGE – Pesquisa Agrícola Municipal (PAM), acessada via Base dos Dados. São analisadas as culturas de soja, milho e arroz."
  },
  {
    "objectID": "projetos/posts/2025-12-12-bigquery_pam.html#requisitos-para-execução",
    "href": "projetos/posts/2025-12-12-bigquery_pam.html#requisitos-para-execução",
    "title": "Projeto - Análise da Produção de Grãos no Brasil",
    "section": "",
    "text": "Para rodar este projeto, é necessário:\n\nUm projeto ativo no Google Cloud Platform (GCP) Qualquer projeto válido funciona (não precisa ser o mesmo do autor).\nBigQuery habilitado no projeto.\nCredenciais de acesso configuradas Recomenda-se o uso de uma service account com permissões:\nVariáveis de ambiente configuradas:\n\nGOOGLE_APPLICATION_CREDENTIALS=\"/caminho/para/sua-chave.json\"\nGCP_PROJECT_ID=\"seu-projeto-gcp\"\nBQ_DATASET_ID=\"analise_lavouras\"\nBD_BILLING_ID=\"seu-projeto-gcp\"\n\nEssas variáveis permitem que o mesmo código seja executado em diferentes ambientes sem alterações no script."
  },
  {
    "objectID": "projetos/posts/2025-12-12-bigquery_pam.html#execução",
    "href": "projetos/posts/2025-12-12-bigquery_pam.html#execução",
    "title": "Projeto - Análise da Produção de Grãos no Brasil",
    "section": "",
    "text": "Execute o script principal:\nsource(\"script/pipeline_pam_final.R\")\nO pipeline irá:\n\nIngerir dados do IBGE PAM via BigQuery (Bronze);\nProcessar e gerar tabelas enriquecidas e agregadas (Silver);\nCalcular métricas analíticas consolidadas (Gold);\nSalvar os resultados localmente por camada;\nCriar datasets separados no BigQuery e exportar todas as tabelas."
  },
  {
    "objectID": "projetos/posts/2025-12-12-bigquery_pam.html#licença",
    "href": "projetos/posts/2025-12-12-bigquery_pam.html#licença",
    "title": "Projeto - Análise da Produção de Grãos no Brasil",
    "section": "",
    "text": "MIT."
  },
  {
    "objectID": "projetos/posts/2025-12-01-curso positron.html",
    "href": "projetos/posts/2025-12-01-curso positron.html",
    "title": "Curso Positron",
    "section": "",
    "text": "O Positron é uma IDE (Ambiente de Desenvolvimento Integrado) de última geração desenvolvida pela Posit, voltada para ciência de dados em Python e R.\nBaseado no VS Code (um fork do Code OSS), o Positron combina o poder de uma IDE completa com ferramentas interativas de ciência de dados, oferecendo uma interface moderna e performática para análise de dados.\nEste curso foi desenvolvido pela R-Ladies Goiânia para auxiliar na transição do RStudio para o Positron, apresentando suas principais funcionalidades e diferenciais.\n\n\n\n\nConhecer a interface e componentes do Positron\nDominar os atalhos essenciais\nAprender a trabalhar com projetos no Positron\nRealizar análise de dados com as novas ferramentas\nCriar relatórios com Quarto\n\n\n\n\nAntes de iniciar o curso, certifique-se de ter:\n\nR 4.2 ou superior instalado\n\nDownload: https://cloud.r-project.org/\n\nPositron IDE instalado\n\nDownload: https://positron.posit.co/install.html\n\nPacotes R necessários:\n\ntidyverse\n\n\nNota para usuários Windows: O Positron não inclui o Rtools atualmente. Instale-o separadamente se necessário.\n\n\n\n\n\n\nAcesse a página do repositório no GitHub\nClique no botão verde Code\nSelecione Download ZIP\n\n\n\n\n\nExtraia o arquivo ZIP baixado\nSalve a pasta em um local de fácil acesso no seu computador\n\nExemplos: Documentos/Cursos/, Desktop/, C:/Projetos/\n\nAnote o caminho da pasta para usar no próximo passo\n\n\n\n\n\nAbra o Positron IDE\nNo menu superior, clique em File → Open Folder\nNavegue até a pasta extraída do curso\nSelecione a pasta e clique em Selecionar Pasta (ou Open)\n\nPronto! Agora você está pronto para começar o curso.\n\n\n\n\nA R-Ladies Goiânia é um capítulo local da organização global R-Ladies, que promove a diversidade de gênero na comunidade R.\nNossas Redes: https://linktr.ee/rladiesgoiania\n\n\n\nMaterial desenvolvido para R-Ladies Goiânia para fins educacionais.\n\nDesenvolvido para R-Ladies Goiânia"
  },
  {
    "objectID": "projetos/posts/2025-12-01-curso positron.html#o-que-é-positron",
    "href": "projetos/posts/2025-12-01-curso positron.html#o-que-é-positron",
    "title": "Curso Positron",
    "section": "",
    "text": "O Positron é uma IDE (Ambiente de Desenvolvimento Integrado) de última geração desenvolvida pela Posit, voltada para ciência de dados em Python e R.\nBaseado no VS Code (um fork do Code OSS), o Positron combina o poder de uma IDE completa com ferramentas interativas de ciência de dados, oferecendo uma interface moderna e performática para análise de dados.\nEste curso foi desenvolvido pela R-Ladies Goiânia para auxiliar na transição do RStudio para o Positron, apresentando suas principais funcionalidades e diferenciais."
  },
  {
    "objectID": "projetos/posts/2025-12-01-curso positron.html#objetivos",
    "href": "projetos/posts/2025-12-01-curso positron.html#objetivos",
    "title": "Curso Positron",
    "section": "",
    "text": "Conhecer a interface e componentes do Positron\nDominar os atalhos essenciais\nAprender a trabalhar com projetos no Positron\nRealizar análise de dados com as novas ferramentas\nCriar relatórios com Quarto"
  },
  {
    "objectID": "projetos/posts/2025-12-01-curso positron.html#pré-requisitos",
    "href": "projetos/posts/2025-12-01-curso positron.html#pré-requisitos",
    "title": "Curso Positron",
    "section": "",
    "text": "Antes de iniciar o curso, certifique-se de ter:\n\nR 4.2 ou superior instalado\n\nDownload: https://cloud.r-project.org/\n\nPositron IDE instalado\n\nDownload: https://positron.posit.co/install.html\n\nPacotes R necessários:\n\ntidyverse\n\n\nNota para usuários Windows: O Positron não inclui o Rtools atualmente. Instale-o separadamente se necessário."
  },
  {
    "objectID": "projetos/posts/2025-12-01-curso positron.html#como-baixar-o-material-do-curso",
    "href": "projetos/posts/2025-12-01-curso positron.html#como-baixar-o-material-do-curso",
    "title": "Curso Positron",
    "section": "",
    "text": "Acesse a página do repositório no GitHub\nClique no botão verde Code\nSelecione Download ZIP\n\n\n\n\n\nExtraia o arquivo ZIP baixado\nSalve a pasta em um local de fácil acesso no seu computador\n\nExemplos: Documentos/Cursos/, Desktop/, C:/Projetos/\n\nAnote o caminho da pasta para usar no próximo passo\n\n\n\n\n\nAbra o Positron IDE\nNo menu superior, clique em File → Open Folder\nNavegue até a pasta extraída do curso\nSelecione a pasta e clique em Selecionar Pasta (ou Open)\n\nPronto! Agora você está pronto para começar o curso."
  },
  {
    "objectID": "projetos/posts/2025-12-01-curso positron.html#sobre-a-r-ladies-goiânia",
    "href": "projetos/posts/2025-12-01-curso positron.html#sobre-a-r-ladies-goiânia",
    "title": "Curso Positron",
    "section": "",
    "text": "A R-Ladies Goiânia é um capítulo local da organização global R-Ladies, que promove a diversidade de gênero na comunidade R.\nNossas Redes: https://linktr.ee/rladiesgoiania"
  },
  {
    "objectID": "projetos/posts/2025-12-01-curso positron.html#licença",
    "href": "projetos/posts/2025-12-01-curso positron.html#licença",
    "title": "Curso Positron",
    "section": "",
    "text": "Material desenvolvido para R-Ladies Goiânia para fins educacionais.\n\nDesenvolvido para R-Ladies Goiânia"
  },
  {
    "objectID": "projetos/posts/2025-11-02-pacote_Collect _data.html",
    "href": "projetos/posts/2025-11-02-pacote_Collect _data.html",
    "title": "Desenvolvimento de Pacote",
    "section": "",
    "text": "Quem trabalha com ciência de dados sabe bem aquele momento em que a gente quer apenas analisar, mas se vê preso tentando entender como coletar os dados.\nAPI daqui, token dali, endpoint que muda, autenticação que falha e no fim, mais tempo é gasto configurando do que interpretando.\n\nFoi nesse cenário que nasceu a ideia do collectHub.\n\nUltimamente tenho explorado mais dados públicos e repositórios abertos, especialmente do GitHub. O problema é que, quanto mais eu usava APIs, mais percebia o quanto o processo podia ser confuso para quem está começando: documentações extensas, parâmetros obscuros, kskskskks e aquele medo de errar o token e travar tudo.\nEu queria simplificar isso.\nO collectHub começou como um pequeno script para automatizar a coleta de arquivos diretamente de repositórios GitHub, sem precisar passar por todas as etapas manuais. Aos poucos, esse script foi ganhando corpo virou função, e vai virar um pacote.\n\n\n\n\n\n\nIdeia simples\n\n\n\nO pacote vai pegar qualquer arquivo hospedado em um repositório GitHub e trazê-lo para o R em uma única linha de código.\n\n\n\nVocê informa o nome do repositório e o caminho do arquivo, e o collectHub faz o resto conecta-se via API, autentica (se necessário), baixa o conteúdo e já o entrega limpo, pronto para análise.\n\nMas o collectHub é mais do que isso.\n\nEle representa uma filosofia: a de tornar o acesso aos dados mais fluido, transparente e reprodutível.\nPorque ciência boa é ciência acessível e se os dados estão abertos, eles precisam estar também ao nosso alcance.\nAinda estou desenvolvendo as funções e testando os fluxos. Não é uma tarefa simples, envolve lidar com tokens, requisições, formatações e erros de rede.\nMas tem sido uma experiência incrível. A cada teste bem-sucedido, vejo o pacote se aproximando do que imaginei: um elo entre quem pesquisa e as informações que impulsionam descobertas.\n\n\nLogo, o collectHub vai integrar uma série de recursos adicionais leitura direta de .csv, .xlsx, .json, verificação automática de estrutura e até logs para rastrear a coleta. Mas tenhamos calma!\n\nEssa é mais uma etapa da minha jornada: unir estatística, programação e reprodutibilidade de forma prática e acessível.\nObrigada por fazer parte desta jornada.\nEM BREVE, MAIS ATUALIZAÇÕES …….\nUm grande abraço,"
  },
  {
    "objectID": "projetos/posts/2025-11-02-pacote_Collect _data.html#olá-pessoal",
    "href": "projetos/posts/2025-11-02-pacote_Collect _data.html#olá-pessoal",
    "title": "Desenvolvimento de Pacote",
    "section": "",
    "text": "Quem trabalha com ciência de dados sabe bem aquele momento em que a gente quer apenas analisar, mas se vê preso tentando entender como coletar os dados.\nAPI daqui, token dali, endpoint que muda, autenticação que falha e no fim, mais tempo é gasto configurando do que interpretando.\n\nFoi nesse cenário que nasceu a ideia do collectHub.\n\nUltimamente tenho explorado mais dados públicos e repositórios abertos, especialmente do GitHub. O problema é que, quanto mais eu usava APIs, mais percebia o quanto o processo podia ser confuso para quem está começando: documentações extensas, parâmetros obscuros, kskskskks e aquele medo de errar o token e travar tudo.\nEu queria simplificar isso.\nO collectHub começou como um pequeno script para automatizar a coleta de arquivos diretamente de repositórios GitHub, sem precisar passar por todas as etapas manuais. Aos poucos, esse script foi ganhando corpo virou função, e vai virar um pacote.\n\n\n\n\n\n\nIdeia simples\n\n\n\nO pacote vai pegar qualquer arquivo hospedado em um repositório GitHub e trazê-lo para o R em uma única linha de código.\n\n\n\nVocê informa o nome do repositório e o caminho do arquivo, e o collectHub faz o resto conecta-se via API, autentica (se necessário), baixa o conteúdo e já o entrega limpo, pronto para análise.\n\nMas o collectHub é mais do que isso.\n\nEle representa uma filosofia: a de tornar o acesso aos dados mais fluido, transparente e reprodutível.\nPorque ciência boa é ciência acessível e se os dados estão abertos, eles precisam estar também ao nosso alcance.\nAinda estou desenvolvendo as funções e testando os fluxos. Não é uma tarefa simples, envolve lidar com tokens, requisições, formatações e erros de rede.\nMas tem sido uma experiência incrível. A cada teste bem-sucedido, vejo o pacote se aproximando do que imaginei: um elo entre quem pesquisa e as informações que impulsionam descobertas.\n\n\nLogo, o collectHub vai integrar uma série de recursos adicionais leitura direta de .csv, .xlsx, .json, verificação automática de estrutura e até logs para rastrear a coleta. Mas tenhamos calma!\n\nEssa é mais uma etapa da minha jornada: unir estatística, programação e reprodutibilidade de forma prática e acessível.\nObrigada por fazer parte desta jornada.\nEM BREVE, MAIS ATUALIZAÇÕES …….\nUm grande abraço,"
  },
  {
    "objectID": "projetos/posts/2025-11-02-grade_curso.html#módulo-1-fundamentos-de-r-e-ambiente-de-desenvolvimento",
    "href": "projetos/posts/2025-11-02-grade_curso.html#módulo-1-fundamentos-de-r-e-ambiente-de-desenvolvimento",
    "title": "Curso de Introdução a Programação com R para Ciência de Dados",
    "section": "Módulo 1: Fundamentos de R e Ambiente de Desenvolvimento",
    "text": "Módulo 1: Fundamentos de R e Ambiente de Desenvolvimento\nNeste módulo você aprenderá do zero a dominar o ambiente R e RStudio, compreendendo desde o contexto histórico e instalação até a criação de scripts, manipulação de estruturas de dados e instalação de pacotes.\n\n\n\n\n\n\n\n\n\nTema\nTópicos Principais\nObjetivo de Aprendizagem\n\n\n1. Introdução ao R\nHistórico da linguagem S e surgimento do R • Desenvolvimento pela comunidade (R Core Team) • Filosofia de programação interativa • Licença GNU e software livre\nCompreender a origem, a filosofia e o contexto histórico do R.\n\n\n2. Aplicações da linguagem R\nEstatística, Ciência de Dados, Bioinformática, Finanças, Ciências Sociais, Geociências e Agricultura • Visualização (ggplot2, plotly, shiny) • Relatórios (Quarto/RMarkdown)\nIdentificar as áreas de aplicação e o potencial de uso do R em diferentes contextos.\n\n\n3. Vantagens e ecossistema do R\nCódigo aberto e comunidade ativa • Extensibilidade via pacotes (CRAN, GitHub) • Integração com Python, C++, DBI e APIs • Reprodutibilidade e portabilidade\nReconhecer os diferenciais técnicos e colaborativos da linguagem.\n\n\n4. Instalação e configuração\nInstalação do R no Windows/Linux/macOS via CRAN • Instalação do RStudio (Posit) – IDE principal • Conceito de CRAN e repositórios\nInstalar e configurar corretamente o R e o RStudio no ambiente local.\n\n\n5. Interface do RStudio\nPainéis: Editor, Console, Environment e Output • Personalização de layout • Navegação entre scripts e objetos\nNavegar de forma produtiva na interface do RStudio.\n\n\n6. Criando scripts no R\nDiferença entre arquivos .R e .qmd • Criação e salvamento de scripts • Boas práticas de nomenclatura • Comentários com #\nCriar, salvar e documentar scripts de forma organizada e reprodutível.\n\n\n7. Execução de comandos básicos\nOperações aritméticas (+ − * / ^ %% %/%) • Funções sqrt, abs, log, exp • Uso do console interativo\nDominar a execução de expressões e funções simples no R.\n\n\n8. Objetos e variáveis\nAtribuição com &lt;- • Regras de nomeação • Boas práticas e exemplos • Evitar sobrescrita de funções\nCriar e manipular variáveis seguindo convenções de clareza e segurança.\n\n\n9. Tipos de dados (classes atômicas)\ncharacter • numeric • integer • complex • logical\nIdentificar e aplicar corretamente os tipos de dados básicos do R.\n\n\n10. Operadores no R\nAritméticos • Relacionais • Lógicos (&,\n, !, &&,\n\n\n11. Estruturas de dados\nVetores • Matrizes • Listas • Data Frames – definição e criação\nCompreender e manipular as estruturas de dados fundamentais.\n\n\n12. Vetores em R\nCriação (c) • Tipos (numéricos, caracteres, lógicos) • Coerção • Indexação • Sequências (seq, sample) • Funções (length, sort, rev, order, cumsum, is.na, paste)\nConstruir e explorar vetores, dominando indexação e funções associadas.\n\n\n13. Matrizes\nCriação (matrix, byrow) • Conversão (dim) • rbind/cbind • Indexação [linha, coluna]\nCriar e manipular matrizes bidimensionais para cálculos estruturados.\n\n\n14. Listas\nCriação (list) • Acesso [[ ]] / $ • Sublistas [ ] • Combinação de tipos\nEntender a flexibilidade das listas e como armazenar múltiplos tipos de dados.\n\n\n15. Data Frames\nCriação (data.frame) • Inspeção (str, summary, head, dim, names) • Indexação • Adição e remoção de linhas/colunas • Filtros condicionais\nManipular tabelas de dados estruturadas com diferentes tipos de variáveis.\n\n\n16. Pacotes e gerenciamento\nConceito de pacote • Repositórios (CRAN, GitHub, .zip) • Instalação (install.packages, devtools) • Carregamento (library) • Pacman (p_load) • Listagem (search) • Citação (citation) • Ajuda (help)\nInstalar, carregar e gerenciar pacotes com eficiência e reprodutibilidade.\n\n\n\n\nCheck list do aprendizado\n\nInstalar e configurar R e RStudio corretamente.\nCriar, salvar e executar scripts reprodutíveis.\nManipular variáveis, vetores, matrizes, listas e data frames.\nExecutar cálculos e operações lógicas básicas.\nGerenciar pacotes e dependências.\nEntender a base da filosofia de reprodutibilidade no R."
  },
  {
    "objectID": "projetos/posts/2025-11-02-grade_curso.html#módulo-2-controle-de-fluxo-e-estruturas-de-dados",
    "href": "projetos/posts/2025-11-02-grade_curso.html#módulo-2-controle-de-fluxo-e-estruturas-de-dados",
    "title": "Curso de Introdução a Programação com R para Ciência de Dados",
    "section": "Módulo 2: Controle de Fluxo e Estruturas de Dados",
    "text": "Módulo 2: Controle de Fluxo e Estruturas de Dados\nNeste módulo, você aprenderá a controlar o fluxo lógico e estruturar análises automatizadas em R. A transição é clara: sai da manipulação básica do Módulo 1 e entra na programação funcional e reprodutível. O foco é transformar código estático em código inteligente, reutilizável e orientado a decisão, base para automação, pipelines e dashboards.\n\n\n\n\n\n\n\n\nTema\nTópicos Principais\nObjetivo de Aprendizagem\n\n\n\n\n1. Estruturas condicionais\nif, else, else if, ifelse() • Sintaxe, aninhamento e vetorização • Boas práticas de legibilidade • Exercícios resolvidos\nDesenvolver scripts que tomam decisões automáticas com base em condições lógicas.\n\n\n2. Vetorização com ifelse()\nAplicação em vetores e colunas de data frames • Substituição de valores ausentes (NA) • Condições múltiplas (ifelse aninhado)\nAprender a aplicar lógicas condicionais sobre conjuntos de dados inteiros, sem loops.\n\n\n3. Laços de repetição\nEstruturas for, while, repeat • Condições de parada • Uso de break e next • Exercícios de automação\nAutomatizar repetições de comandos e compreender os três tipos principais de loops.\n\n\n4. Funções básicas\nRevisão das funções integradas (mean, sum, sd, unique, table)\nDominar as funções essenciais da base R para análise e resumo de dados.\n\n\n5. Criação de funções\nSintaxe (function()) • Argumentos, return() e modularização • Funções personalizadas e reutilizáveis\nEscrever funções próprias para estruturar e automatizar tarefas de análise.\n\n\n6. Snippets no RStudio\nO que são snippets • Como criar e editar snippets personalizados (usethis::edit_rstudio_snippets()) • Automatização de blocos de código\nAcelerar a codificação e padronizar funções próprias dentro do RStudio.\n\n\n7. Família Apply\napply, lapply, sapply, tapply, mapply • Diferenças, entradas e saídas • Aplicações em vetores, listas e data frames\nSubstituir loops por operações vetorizadas mais rápidas e elegantes.\n\n\n8. apply()\nAplicação em linhas e colunas de matrizes/data frames • Cálculos agregados (soma, média, desvio)\nPraticar o uso de apply() para resumir dados de forma estruturada.\n\n\n9. lapply() e sapply()\nOperações sobre listas • Retorno em lista vs vetor simplificado\nAutomatizar cálculos sobre listas e data frames com retorno flexível.\n\n\n10. tapply()\nAplicação de funções por grupo (tratamentos, categorias)\nCalcular médias, variâncias e resumos condicionados a fatores.\n\n\n11. mapply()\nIterações paralelas sobre múltiplos vetores • Funções multivariadas\nAplicar funções simultaneamente sobre múltiplos argumentos vetoriais.\n\n\n12. Exercícios práticos – Apply Family\nCriação de matriz 3×4, listas, data frames e matrizes 3×3 • Uso das funções apply, sapply, tapply, mapply\nConsolidar a compreensão da família apply por meio de desafios progressivos.\n\n\n13. Mini-projeto 1 – Pipeline com mtcars\nEngenharia de variáveis (for, ifelse, mapply) • Funções personalizadas e estatísticas descritivas • Aplicação de tapply e padronização (z-score) • Análise por grupos (cilindros, peso)\nIntegrar controle de fluxo, funções e família apply em uma análise realista de dados.\n\n\n14. Interpretação e storytelling analítico\nResponder perguntas de negócio com R • Relacionar peso, potência e eficiência • Uso de código reprodutível e modular\nTraduzir resultados analíticos em insights de negócio claros e interpretáveis.\n\n\n\n\nCheck list do aprendizado\n\nDominar estruturas condicionais e loops.\nCriar funções e modularizar código.\nAutomatizar rotinas com apply, lapply, sapply, tapply, mapply.\nUsar snippets para padronização de código.\nIntegrar múltiplas técnicas em um mini-projeto prático (mtcars).\nPensar como analista: transformar perguntas de negócio em lógica computacional."
  },
  {
    "objectID": "projetos/posts/2025-11-02-grade_curso.html#módulo-3-estruturando-projetos-scripts-e-fluxos-de-trabalho-em-r",
    "href": "projetos/posts/2025-11-02-grade_curso.html#módulo-3-estruturando-projetos-scripts-e-fluxos-de-trabalho-em-r",
    "title": "Curso de Introdução a Programação com R para Ciência de Dados",
    "section": "Módulo 3: Estruturando Projetos, Scripts e Fluxos de Trabalho em R",
    "text": "Módulo 3: Estruturando Projetos, Scripts e Fluxos de Trabalho em R\nEste módulo consolida as práticas de organização, automação e versionamento, o tripé de qualquer projeto profissional em R. Você aprenderá a criar pipelines completos, reprodutíveis e colaborativos, utilizando as melhores práticas de engenharia de software aplicadas à ciência de dados.\n\n\n\n\n\n\n\n\nTema\nTópicos Principais\nObjetivo de Aprendizagem\n\n\n\n\n1. Introdução à organização profissional em R\nConceito de projeto no RStudio • Diferença entre amadorismo e reprodutibilidade • Importância da estrutura de diretórios\nEntender o impacto da organização na produtividade e reprodutibilidade das análises.\n\n\n2. Por que evitar setwd() e caminhos absolutos\nProblemas de portabilidade, manutenção e escalabilidade • Caminhos relativos e boas práticas\nCompreender por que setwd() é uma armadilha e adotar caminhos relativos corretamente.\n\n\n3. Criando projetos no RStudio\nCriação manual e automática (File &gt; New Project) • Estrutura .Rproj • Opção “Create a Git repository”\nCriar e gerenciar projetos no RStudio de forma profissional e reprodutível.\n\n\n4. Estrutura mínima recomendada de pastas\ndados/, scripts/, output/, figuras/, docs/, funcoes/, README.md\nPlanejar e aplicar uma arquitetura de diretórios organizada e padronizada.\n\n\n5. Automação da estrutura de projetos com R\nPacote {fs} e função dir_create() • Criação automática de pastas e arquivos\nAutomatizar a criação da estrutura mínima de projetos via script em R.\n\n\n6. Arquivo README.md e boas práticas de documentação\nEstrutura do README • Objetivo, dados, execução e dependências\nCriar documentação clara e profissional para qualquer projeto.\n\n\n7. Verificação e inspeção da estrutura criada\nFunções here::here() e fs::dir_tree()\nValidar caminhos relativos e visualizar a hierarquia de diretórios.\n\n\n8. Criação e padronização de scripts\nArquivos numerados (01-importacao.R, 02-tratamento.R, 03-analise.R) • Cabeçalho automatizado\nGarantir modularização, clareza e sequência lógica no pipeline de scripts.\n\n\n9. Simulação e exportação de dados e gráficos\nGeração de data.frame e exportação .csv com write.csv() • Salvando gráficos com png() e dev.off()\nSimular dados, salvar resultados e garantir armazenamento automatizado em pastas corretas.\n\n\n10. Importação de dados com {readr} e {readxl}\nFunções read_csv(), read_csv2(), read_delim(), read_xlsx() • Argumentos (col_names, col_types, locale, skip, na)\nLer e tratar corretamente dados de diferentes formatos e fontes (local e online).\n\n\n11. Introdução ao versionamento com Git e GitHub\nConceitos de repositório, commit, push, pull, staging e branch\nCompreender os fundamentos do controle de versão e sua importância na ciência de dados.\n\n\n12. Instalação e configuração do Git e GitHub\nInstalação do Git • Criação de conta GitHub • Configuração com {usethis} (use_git_config(), create_github_token())\nIntegrar o RStudio com Git e GitHub para rastrear e versionar projetos.\n\n\n13. Métodos de integração com GitHub\nCriar repositório online • Clonar projeto existente • Criar repositório direto do RStudio\nSincronizar projetos locais com repositórios remotos de forma segura e automatizada.\n\n\n14. Interface Git no RStudio\nAba Git: status de arquivos (A, M, D, R, ?) • Stage, Commit, Push e Pull\nExecutar operações de versionamento direto no RStudio, sem precisar do terminal.\n\n\n15. Conceitos avançados de versionamento\nBranches, merge, histórico de commits • Colaboração e rastreabilidade\nTrabalhar de forma colaborativa e segura com múltiplas versões de um mesmo projeto.\n\n\n16. Projeto prático - Pipeline Automatizado em R\nCriação de projeto completo e automatizado • Estrutura de pastas com {fs} e {here} • Dados simulados, gráficos, README e integração com GitHub\nConstruir um pipeline completo e reprodutível, do zero até o versionamento remoto.\n\n\n17- Aula extra - GitHub desktop\nComo realizar o login, fazer o download e usar o GitHub para Desktop\nAprender a utilizar essa ferramenta de diferentes maneiras para vercionamento de código.\n\n\n\n\nCheck list do aprendizado\n\nEstruturar projetos profissionais com pastas, scripts e documentação padronizados.\nUsar {fs} e {here} para automação e caminhos relativos.\nImportar dados corretamente com {readr} e {readxl}.\nVersionar e colaborar usando Git e GitHub diretamente no RStudio.\nCompreender a importância da reprodutibilidade e da rastreabilidade em projetos de dados.\nCriar pipelines reutilizáveis, documentados e prontos para publicação."
  },
  {
    "objectID": "projetos/posts/2025-11-02-grade_curso.html#módulo-4-manipulação-avançada-de-arquivos-e-automação",
    "href": "projetos/posts/2025-11-02-grade_curso.html#módulo-4-manipulação-avançada-de-arquivos-e-automação",
    "title": "Curso de Introdução a Programação com R para Ciência de Dados",
    "section": "Módulo 4: Manipulação Avançada de Arquivos e Automação",
    "text": "Módulo 4: Manipulação Avançada de Arquivos e Automação\nEste módulo transforma você em usuário avançado do R, capaz de criar análises completas e automatizadas. Com tidyverse, você será capaz de dominar manipulação e visualização; com {targets}, aprende automação e reprodutibilidade, o coração da engenharia de dados em R.\n\n\n\n\n\n\n\n\nTema\nTópicos Principais\nObjetivo de Aprendizagem\n\n\n\n\n1. Introdução e objetivos do módulo\nRevisão dos módulos anteriores • Integração dos pilares: manipulação, visualização e automação • Escalabilidade de análises\nCompreender como unir manipulação de dados, visualização e automação num fluxo contínuo.\n\n\n2. Pacotes do Tidyverse\nConceito e filosofia • Pacotes principais (dplyr, tidyr, readr, stringr, lubridate, ggplot2, purrr)\nEntender a estrutura unificada do tidyverse e sua importância em ciência de dados.\n\n\n3. Operador Pipe %&gt;%\nConceito e funcionamento • Encadeamento de funções • Legibilidade e fluidez do código\nUsar o operador pipe para criar fluxos de código claros e expressivos.\n\n\n4. Manipulação de dados com dplyr\nVerbos principais: filter, select, arrange, mutate, summarise, group_by\nDominar as operações centrais do dplyr para transformar dados de forma reprodutível.\n\n\n5. Casos práticos – base Coffee Quality Institute\nImportação via URL • Renomeação de variáveis • Inspeção (glimpse)\nAplicar o aprendizado em um dataset real e compreender sua estrutura.\n\n\n6. Funções complementares de manipulação\ncount, case_when, transmute, funções auxiliares em select\nExecutar transformações condicionais e sumarizações avançadas.\n\n\n\n\n\n\n\n7. Estatística descritiva com {metan}\ndesc_stat() • Visualização de estatísticas com datatable\nCalcular e apresentar estatísticas descritivas completas de forma automatizada.\n\n\n8. União e relacionamento de bases (joins)\nleft_join, right_join, inner_join, full_join, anti_join • Chaves primárias\nCombinar e integrar múltiplas fontes de dados mantendo consistência e rastreabilidade.\n\n\n9. Visualização com ggplot2\nGramática dos gráficos • Estrutura ggplot() + aes() + geom_ + theme()\nCompor visualizações estatísticas elegantes e reprodutíveis com ggplot2.\n\n\n10. Elementos da gramática gráfica\nAesthetics (x, y, color, fill, alpha, shape, size)\nMapear variáveis para atributos visuais e criar representações expressivas.\n\n\n11. Geometrias e exemplos práticos\ngeom_point, geom_col, geom_boxplot, geom_histogram, geom_density, geom_smooth\nCriar diferentes tipos de gráficos e interpretar padrões visuais.\n\n\n12. Personalização e temas\nlabs, theme_classic, theme_bw, paletas {viridis}, scale_*\nAjustar legendas, escalas, cores e estilos com consistência visual.\n\n\n13. Combinação e exportação de gráficos\npatchwork para unir gráficos • cowplot para inserir logotipos\nGerar painéis e dashboards gráficos dentro de scripts automatizados.\n\n\n14. Gráficos interativos e mapas\n{plotly}, {rnaturalearth} • Mapas de calor e choropleths\nCriar visualizações dinâmicas e geográficas integradas a pipelines.\n\n\n15. Gráficos avançados\nfacet_wrap, facet_grid, stat_summary, radarchart\nAplicar visualizações comparativas e sumarizações visuais complexas.\n\n\n16. Pipeline de automação com {targets}\nConceito de alvos (tar_target) • Grafo de dependências (DAG) • Execução com tar_make()\nAutomatizar pipelines completos e reprodutíveis de leitura, análise e exportação.\n\n\n17. Estrutura _targets.R e scripts auxiliares\nDefinição dos alvos, dependências e exportações • Visualização do pipeline com tar_visnetwork()\nEstruturar projetos reprodutíveis integrando código, dados e relatórios.\n\n\n18. Integração de relatórios Quarto/RMarkdown ao pipeline\nquarto::quarto_render() • Exportação automática de resultados\nAutomatizar geração de relatórios e documentos a partir do pipeline.\n\n\n\n\nCheck list do aprendizado\n\nManipular e transformar dados em escala com {dplyr}.\nProduzir gráficos estáticos, dinâmicos e geográficos com {ggplot2}, {plotly} e {rnaturalearth}.\nCalcular estatísticas descritivas automatizadas.\nUnir múltiplas bases com operações relacionais.\nAutomatizar todo o fluxo analítico com {targets}.\nIntegrar relatórios e visualizações em pipelines reprodutíveis.\nPensar e estruturar projetos de forma profissional, modular e escalável."
  },
  {
    "objectID": "projetos/posts/2025-11-02-grade_curso.html#módulo-5-integração-com-sistemas-externos-e-apis",
    "href": "projetos/posts/2025-11-02-grade_curso.html#módulo-5-integração-com-sistemas-externos-e-apis",
    "title": "Curso de Introdução a Programação com R para Ciência de Dados",
    "section": "Módulo 5: Integração com Sistemas Externos e APIs",
    "text": "Módulo 5: Integração com Sistemas Externos e APIs\nVocê aprenderá a dominar a integração do R com bancos de dados, APIs e outras linguagens, consolidando o controle total sobre entrada, processamento e saída de dados.Este módulo representa o passo para autonomia profissional: análise conectada, reprodutível e escalável.\n\n\n\n\n\n\n\n\nUnidade / Seção\nTópicos Principais\nObjetivo de Aprendizagem\n\n\n\n\n1. Introdução: Conexão e Integração de Sistemas\nImportância das conexões externas • Conceito de automação entre sistemas • Cenários reais de integração (bancos, APIs, Python)\nCompreender como o R se conecta a sistemas externos e o papel dessas integrações na ciência de dados.\n\n\n2. Integração com Bancos de Dados via {DBI}\nConceito de banco relacional (PostgreSQL, MySQL, SQL Server) • Interface DBI e drivers (RPostgres, RMariaDB, RSQLite)\nAprender a estabelecer conexões profissionais com bancos relacionais no R.\n\n\n3. Fundamentos do {DBI}\nFunções principais: dbConnect(), dbDisconnect(), dbReadTable(), dbGetQuery(), dbExecute() • Transações (dbBegin, dbCommit, dbRollback)\nManipular dados diretamente no banco usando o R, com segurança e autonomia.\n\n\n4. Introdução ao {dbplyr}\nTradução automática de dplyr para SQL • tbl(), filter(), select(), summarise(), collect()\nExecutar consultas SQL complexas usando a gramática tidyverse, sem sair do R.\n\n\n5. Conexão Prática – Banco Sakila (MariaDB)\nAutenticação com RMariaDB • Listagem de tabelas (dbListTables, dbListFields) • Leitura e filtros SQL\nPraticar a conexão e manipulação real de dados em um banco remoto.\n\n\n6. Consultas SQL e dplyr/dbplyr Integrados\nFiltros condicionais (WHERE, AND, OR) • Joins (inner_join) • Agrupamentos e sumarizações (group_by, summarise)\nUnir SQL e tidyverse para análises diretas em bases grandes e relacionais.\n\n\n7. Exportação e Encerramento da Conexão\ndbWriteTable() e dbDisconnect()\nGerenciar ciclo completo da conexão: consulta, exportação e fechamento seguro.\n\n\n8. Conexão com Bases Públicas – {basedosdados}\nIntrodução à ONG Base dos Dados • Datalake no BigQuery (Google Cloud)\nAcessar dados públicos organizados em um ambiente de nuvem gratuito.\n\n\n9. Autenticação e Projeto no Google Cloud\nCriação de projeto • Billing ID • Funções set_billing_id() e get_billing_id()\nAutenticar e gerenciar acesso ao BigQuery de forma gratuita e segura.\n\n\n10. Consulta SQL com read_sql() e download()\nSintaxe de query SQL • Exemplo com PIB municipal (IBGE) • Join de tabelas públicas\nAcessar e combinar bases públicas diretamente do BigQuery via R.\n\n\n11. Manipulação e Visualização de Dados Públicos\ndplyr para agregações e somatórios • ggplot2 para séries temporais\nIntegrar dados do BigQuery em análises e gráficos automatizados.\n\n\n12. Introdução às APIs RESTful\nConceito de API • Estrutura (endpoint, método, query string) • Métodos HTTP (GET, POST, PUT, DELETE) • Códigos de status (200, 404, 500)\nEntender o funcionamento das APIs web e seu papel na automação e troca de dados.\n\n\n13. Pacote {httr2} – Consumo de APIs no R\nFunções principais: request(), req_headers(), req_perform(), resp_body_json()\nAprender a consumir APIs modernas e seguras usando o pacote {httr2}.\n\n\n14. Exemplo Prático – API do GitHub\nAutenticação via token pessoal • Consulta de repositórios e issues • Conversão JSON → tibble • Visualização com ggplot2\nIntegrar dados reais da API do GitHub e transformá-los em análises e gráficos automatizados.\n\n\n15. APIs de Dados e Entretenimento – {spotifyr}\nAutenticação com Client ID/Secret • Funções principais (get_artist(), get_artist_audio_features())\nConectar o R à API do Spotify e extrair dados sobre artistas, músicas e álbuns.\n\n\n16. Publicando suas próprias APIs – {plumber}\nCriação de endpoints (#* @get, @param) • Estrutura de arquivos (api.R, run_api.R) • Retorno JSON\nConstruir e executar uma API RESTful no R, expondo funções como serviços web.\n\n\n17. Teste e Execução Local com Swagger\nInterface de documentação automática • Teste de endpoints e visualização de respostas JSON\nValidar e explorar APIs diretamente no navegador de forma interativa.\n\n\n18. Integração com Python via {reticulate}\nConceito e arquitetura da ponte R–Python • Conversão automática de tipos • Funções principais (py_run_string, py$, import)\nRodar código Python dentro do R e integrar bibliotecas como pandas e numpy.\n\n\n19. Análise Híbrida – Python + R\nImportação de dados com pandas (Python) • Manipulação e visualização com ggplot2 (R) • Transferência bidirecional de objetos\nConstruir pipelines híbridos com manipulação em Python e visualização em R.\n\n\n20. Dicionário R × Python\nEquivalência de comandos (importar, filtrar, agrupar, visualizar)\nCompreender as similaridades sintáticas e conceituais entre R e Python.\n\n\n21. Boas Práticas e Referências\nReprodutibilidade, autenticação segura, versionamento, documentação\nConsolidar práticas de integração profissional com sistemas externos.\n\n\n\n\nCheck list do aprendizado\n\nConectar o R a bancos de dados relacionais via DBI e dbplyr.\nConsultar e manipular bases públicas com {basedosdados}.\nConsumir APIs RESTful (GitHub, Spotify) com {httr2} e {spotifyr}.\nCriar APIs próprias com {plumber}.\nIntegrar Python ao R com {reticulate} para análises híbridas.\nAutomatizar fluxos entre sistemas e gerar relatórios dinâmicos.\nGerenciar autenticação, tokens e ambientes de forma segura e reprodutível."
  },
  {
    "objectID": "projetos/posts/2025-11-02-grade_curso.html#módulo-6-relatórios-dinâmicos-dashboards-em-shiny-e-envio-de-relatórios-automatizados",
    "href": "projetos/posts/2025-11-02-grade_curso.html#módulo-6-relatórios-dinâmicos-dashboards-em-shiny-e-envio-de-relatórios-automatizados",
    "title": "Curso de Introdução a Programação com R para Ciência de Dados",
    "section": "Módulo 6: Relatórios Dinâmicos, Dashboards em Shiny e Envio de Relatórios Automatizados",
    "text": "Módulo 6: Relatórios Dinâmicos, Dashboards em Shiny e Envio de Relatórios Automatizados\nEste módulo consolida o pilar da comunicação em ciência de dados. Você irá dominar Quarto, Shiny e Blastula, criando um ecossistema integrado que gera, publica e distribui análises automaticamente, com estética, interatividade e reprodutibilidade.\n\n\n\n\n\n\n\n\nUnidade / Seção\nTópicos Principais\nObjetivo de Aprendizagem\n\n\n\n\n1. Introdução: Comunicação é o produto final\nImportância da comunicação em projetos de dados • Do código ao resultado interpretável • Inteligência visual e automação de entrega\nEntender que o valor da análise está na clareza e automação da comunicação dos resultados.\n\n\n2. Conceito e filosofia do Quarto\nO que é Quarto • Relação com R Markdown • Estrutura YAML + Markdown + Chunks\nConhecer a arquitetura do Quarto e suas vantagens em reprodutibilidade e automação.\n\n\n3. Por que usar o Quarto\nReprodutibilidade, automação, consistência visual, integração com pipelines e GitHub\nCompreender os diferenciais do Quarto como plataforma moderna de publicação técnica.\n\n\n4. Instalação e integração com RStudio\nInstalar Quarto CLI • Configuração no RStudio (versão mínima 2022.07) • Verificação do ambiente\nConfigurar o ambiente corretamente para criação e renderização de relatórios dinâmicos.\n\n\n5. Criando o primeiro documento .qmd\nEstrutura YAML • Texto em Markdown • Chunks de código executável\nCriar um relatório completo integrando narrativa e execução de código.\n\n\n6. Apresentações interativas com Reveal.js\nCriação de slides .qmd • Formatação, transições e layouts\nDesenvolver apresentações dinâmicas diretamente a partir de análises no R.\n\n\n7. Tutorial prático: Relatório do Café Especial\nImportação e limpeza de dados • Estatística descritiva com {metan} • Gráficos com ggplot2 e plotly\nProduzir um relatório reprodutível com texto dinâmico, gráficos e tabelas interativas.\n\n\n8. Publicação online com Quarto Pub\nCriação de conta e autenticação • Publicar relatórios, dashboards e sites • Atualização e republicação\nHospedar relatórios gratuitamente e de forma profissional via Quarto Pub.\n\n\n9. Introdução ao Shiny\nConceito de reatividade • Estrutura UI + Server + shinyApp()\nEntender a lógica básica de reatividade e construção de apps no R.\n\n\n10. Estrutura básica de um app Shiny\nInterface (UI) • Lógica (Server) • Execução (shinyApp(ui, server))\nConstruir um app simples e compreender sua estrutura interna.\n\n\n11. Construindo o primeiro dashboard interativo\nImportação de dados (café) • Navbar com abas (navbarPage) • Painel KPI e gráficos interativos\nCriar um dashboard completo e interativo em R.\n\n\n12. Aba 1 – Resumo Geral dos Cafés (KPIs)\nvalue_box, plotlyOutput, DTOutput, withSpinner\nExibir indicadores principais e visualizações interativas com feedback instantâneo.\n\n\n13. Aba 2 – Top Fazendas (Ranking Sensorial)\nradioButtons, sliderInput, plotlyOutput\nExibir e comparar produtores com melhores notas médias e totais.\n\n\n14. Aba 3 – Correlação entre Atributos\nmetan::corr_coef(), plotOutput, withSpinner\nVisualizar correlações de Pearson entre variáveis sensoriais.\n\n\n15. Aba 4 – Radar Sensorial\nradarchart() (pacote {fmsb}) • Comparação país × espécie\nAnalisar perfis multivariados de sabor, aroma, acidez e equilíbrio.\n\n\n16. Aba 5 – Altitude × Qualidade\nRegressões e heatmaps (ggplotly, geom_smooth)\nRelacionar altitude média e notas sensoriais, explorando padrões ambientais.\n\n\n17. Aba 6 – Exportação de Dados\ndownloadButton() e downloadHandler()\nPermitir exportar dados tratados e relatórios diretamente do painel.\n\n\n18. Bloco Server: lógica e reatividade\nreactive(), observe(), renderText(), renderPlotly()\nImplementar lógica de atualização automática e cálculos dinâmicos no app.\n\n\n19. Publicação (Deploy) no ShinyApps.io\nCriação de conta, rsconnect::setAccountInfo(), deployApp()\nPublicar dashboards interativos na web com link público.\n\n\n20. Alternativas de Deploy Profissional\nRStudio Connect, Shiny Server, Docker\nConhecer opções de deploy corporativo e local.\n\n\n21. Introdução ao {blastula} – E-mails automatizados\nEstrutura do pacote (compose_email, smtp_send, create_smtp_creds_file)\nCompreender como gerar e enviar e-mails automatizados via R.\n\n\n22. Criando o corpo do e-mail (email.qmd)\nYAML para formato email • compose_email() • Inclusão de anexos com add_attachment()\nConstruir templates dinâmicos de e-mail com corpo HTML e anexos automáticos.\n\n\n23. Autenticação segura no Gmail\nCriação de senha de app • create_smtp_creds_file() • creds_file()\nConfigurar autenticação criptografada e persistente para envios automáticos.\n\n\n24. Script de envio (enviar_email.R)\nsmtp_send() com credenciais salvas • Personalização de assunto e destinatário\nAutomatizar o envio de relatórios e anexos por e-mail direto do R.\n\n\n25. Integração Quarto + Blastula + Pipeline\nRenderização automática + envio periódico\nCriar fluxos que geram e distribuem relatórios completos de forma 100% automatizada.\n\n\n\n\nCheck list do aprendizado\n\nCriar relatórios dinâmicos com Quarto (.qmd) e integrá-los a pipelines.\nDesenvolver dashboards interativos com Shiny.\nPublicar dashboards e relatórios online (Quarto Pub e ShinyApps.io).\nAutomatizar envios de e-mails profissionais com {blastula}.\nIncorporar estética, responsividade e identidade visual corporativa em relatórios.\nIntegrar R a fluxos de comunicação e tomada de decisão empresarial.\n\n\n\n  Acesse o curso"
  },
  {
    "objectID": "projetos/posts/2025-11-02-automacao_analise-experimental.html",
    "href": "projetos/posts/2025-11-02-automacao_analise-experimental.html",
    "title": "Automatização para análise de um pipeline experimental",
    "section": "",
    "text": "Relatório HTML \n  Código - GitHub \n  Site \n\n\nComo usar esse projeto?\nPara explorar este projeto, faça:\n\nUm fork ou clone do repositório em sua máquina local.\nEm seguida, acesse o relatório completo com as explicações detalhadas de cada etapa da análise:\n\n \n\n\nObjetivo\nConstruir um pipeline reprodutível e automatizado para experimentos agrícolas, com foco em:\n\nModelagem estatística (BLUE e BLUP);\nEstimativas de herdabilidade;\nAgrupamento genético (UPGMA);\nVisualizações e exportação automatizada.\n\n\n\nReferências\nA explicação completa sobre a modelagem estatística utilizada neste pipeline incluindo o detalhamento dos modelos mistos (REML/BLUP), ajustes, validações e interpretações está disponível nos links abaixo:\n \n\n\nEstrutura Geral do Projeto\nexperimentacao_agricola_pipeline_automatizado/\n├── _targets.R              # Definição do pipeline principal\n├── _targets.yaml           # Configurações adicionais do {targets}\n├── rodar_pipeline.R        # Script para execução e monitoramento\n├── _targets/               # Banco interno de objetos, metadados e logs\n│   ├── meta/               # Metadados de execução\n│   └── objects/            # Objetos gerados em cada etapa\n├── meu_projeto/\n│   ├── dados/              # Dados experimentais (.xlsx)\n│   ├── funcoes/            # Funções personalizadas\n│   │   └── coleta_dados_github.R\n│   ├── scripts/            # Scripts auxiliares e de testes\n│   │   └── script_inicial.R\n│   ├── output/             # Resultados exportados (planilhas e gráficos)\n│   │   ├── grafico_comparacao_BLUE_BLUP.png\n│   │   └── resultados_experimentais.xlsx\n│   ├── figuras/            # Gráficos do pipeline ({targets})\n│   │   ├── tar_make.png\n│   │   ├── tar_manifest.png\n│   │   ├── tar_meta.png\n│   │   ├── tar_progress.png\n│   │   ├── tar_summary.png\n│   │   ├── tar_visnetwork.png\n│   │   └── _targets_finalizado.png\n│   ├── docs/               # Relatórios e apresentações\n│   └── README.md           # Descrição local do módulo\n\n\n\nFluxo do Pipeline {targets}\nCada etapa é reexecutada somente quando suas dependências mudam. Os nomes abaixo correspondem aos targets definidos em _targets.R.\n\n\n\n\n\n\n\n\nEtapa\nNome do Target\nDescrição\n\n\n\n\n1\ndados_brutos\nColeta de dados experimentais via API GitHub\n\n\n2\ndados\nAjuste de variáveis fatoriais e estrutura Alpha-Lattice\n\n\n3\ncroqui_campo\nVisualização do layout experimental\n\n\n4\nanalise_desc\nEstatísticas descritivas básicas\n\n\n5\nmodelo_BLUE / modelo_BLUP\nAjuste de modelos lineares mistos\n\n\n6\ncomparacao_modelos\nComparação dos modelos (AIC e LogLik)\n\n\n7\nestimativas\nGeração das estimativas BLUEs e BLUPs com intervalos de confiança\n\n\n8\ngrafico_comparacao\nComparação visual das estimativas\n\n\n9\nherdabilidade\nCálculo da herdabilidade (H²)\n\n\n10\nagrupamento_UPGMA\nAgrupamento hierárquico de genótipos\n\n\n11\nexportar_outputs\nExportação automática de planilhas e gráficos\n\n\n\n\n\nComo Executar\n\nInstalar pacotes:\ninstall.packages(c(\n  \"targets\", \"tarchetypes\", \"tidyverse\", \"lme4\", \"emmeans\",\n  \"broom.mixed\", \"metan\", \"ggpubr\", \"glue\", \"readxl\",\n  \"httr2\", \"base64enc\", \"writexl\"\n))\nRodar o pipeline completo:\nsource(\"rodar_pipeline.R\")\nVisualizar a rede de dependências:\ntar_visnetwork()\nLer resultados diretamente:\ntar_read(estimativas)\ntar_read(herdabilidade)\nOutputs finais:\n\nmeu_projeto/output/resultados_experimentais.xlsx\nmeu_projeto/output/grafico_comparacao_BLUE_BLUP.png\nVisualizações do pipeline em meu_projeto/figuras/\n\n\n\n\nResultados e Interpretação\n\nBLUE (Best Linear Unbiased Estimator): média ajustada considerando genótipos como efeito fixo.\n\nBLUP (Best Linear Unbiased Predictor): predição dos valores genéticos com genótipos como efeito aleatório.\n\nH² (Herdabilidade): proporção da variância total atribuída à variância genética.\n\nUPGMA: agrupamento hierárquico para avaliação de similaridade genética entre genótipos.\n\nO gráfico grafico_comparacao_BLUE_BLUP.png ilustra a correspondência entre as estimativas dos dois modelos, validando a consistência do ajuste.\n\n\nConceitos-Chave\n\nReprodutibilidade científica com {targets}\nModelos mistos e predição de valores genéticos (REML/BLUP)\nAutomação de análises experimentais\nGerenciamento de dependências e execução incremental\n\n\n\nMonitoramento do Pipeline\nO script rodar_pipeline.R auxilia no acompanhamento da execução:\n\n\n\nFunção\nObjetivo\n\n\n\n\ntar_make()\nExecuta o pipeline completo\n\n\ntar_manifest()\nLista targets e comandos executados\n\n\ntar_visnetwork()\nMostra o grafo de dependências\n\n\ntar_meta()\nExibe metadados (tempo, status, avisos)\n\n\ntar_progress()\nMostra andamento da execução\n\n\ntar_poll()\nAtualiza o progresso em tempo real\n\n\ntar_progress_summary()\nResumo final de execução\n\n\n\n\n\nLicença\nEste projeto é distribuído sob a licença MIT.\n\nSinta-se à vontade para usar, adaptar e referenciar este conteúdo em trabalhos e cursos de experimentação agrícola.\n\n\n\nAutoria\nJennifer Luz Lopes\nEngenheira Agrônoma | Doutora em Melhoramento Genético de Plantas\n  \n\n\n\n\n Back to top"
  },
  {
    "objectID": "projetos/posts/2024_sigm.html",
    "href": "projetos/posts/2024_sigm.html",
    "title": "Data Analysis Using R Software: Essential Approaches for Breeders",
    "section": "",
    "text": "Data Analysis Using R Software: Essential Approaches for Breeders\nO minicurso Análises de dados usando o software R: Abordagens essenciais para melhoristas proporcionará uma introdução prática ao uso do R para conduzir análises estatísticas em experimentos de melhoramento genético. O conteúdo abordará desde a manipulação e limpeza de dados, análise exploratória, até a aplicação de técnicas avançadas, como a modelagem e análise de experimentos e métodos multivariados. O curso também incluirá visualizações gráficas treinando os participantes com as habilidades necessárias para otimizar o processamento e a interpretação de dados em programas de melhoramento.\nAcesse os materiais:\n \n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jennifer Lopes",
    "section": "",
    "text": "Bem-vinda(o) ao meu espaço de dados e ideias\nObrigada por passar por aqui, fico feliz que você tenha chegado!\nSou Jennifer Luz Lopes, Gaúcha, Engenheira Agrônoma e Doutora em Melhoramento Genético de Plantas, hoje atuando como Consultora e Instrutora de Ciência de dados com R, unindo estatística, experimentação e análise de dados. Minha trajetória vem do campo, mas meu propósito está na ciência de dados aplicada à agricultura.\nQuatro valores que guiam tudo o que faço: clareza, aprendizado contínuo, colaboração e propósito. 🤎\nAqui você vai encontrar:\n\nProjetos de experimentação agrícola, análises estatísticas em R\nDashboards e automações com Quarto, Shiny e APIs\nReflexões sobre comunidade, aprendizado e dados abertos\n\nFora do trabalho, adoro meditar, fazer Yoga, tomar café e chimarrão e pensar em como o R pode simplificar mais um processo da vida.\nAhh, amo ficar agarradinha nas minhas pets, Luna e Meguy!\nEste espaço é meu laboratório de aprendizado feito pra compartilhar, errar, corrigir, crescer e inspirar.\n\n\n\n☕ Assine o Café com R\n\nQue cada gole desperte uma nova ideia.\nQue cada script abra uma nova conversa.\nQue o Café com R, se torne um ponto de encontro nosso!\n\n\n&lt;p&gt;Carregando…&lt;/p&gt;\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "cafecomr/posts/25_11_dose3.html",
    "href": "cafecomr/posts/25_11_dose3.html",
    "title": "Café da Semana☕",
    "section": "",
    "text": "Seja bem-vinda(o)!\nAqui é uma pausa para falar de dados.\nToda semana vamos nos encontrar por aqui para conversar sobre ciência de dados, estatística e muito mais de um jeito leve e prático.\nToda semana, uma dose de código, reflexão e boas ideias com R, um café de aprendizagem por vez."
  },
  {
    "objectID": "cafecomr/posts/25_11_dose3.html#esta-é-a-terceira-edição-do-café-com-r",
    "href": "cafecomr/posts/25_11_dose3.html#esta-é-a-terceira-edição-do-café-com-r",
    "title": "Café da Semana☕",
    "section": "",
    "text": "Seja bem-vinda(o)!\nAqui é uma pausa para falar de dados.\nToda semana vamos nos encontrar por aqui para conversar sobre ciência de dados, estatística e muito mais de um jeito leve e prático.\nToda semana, uma dose de código, reflexão e boas ideias com R, um café de aprendizagem por vez."
  },
  {
    "objectID": "cafecomr/posts/25_11_dose3.html#sobre-a-newsletter-de-hoje",
    "href": "cafecomr/posts/25_11_dose3.html#sobre-a-newsletter-de-hoje",
    "title": "Café da Semana☕",
    "section": "Sobre a Newsletter de hoje",
    "text": "Sobre a Newsletter de hoje\n\nEscrevi esta edição com carinho porque o tema merece calma e clareza. Hoje vamos da semente à xícara para falar sobre um assunto que muita gente usa, o valor p. Quis trazer uma explicação honesta do que ele significa, por que tantas interpretações saem do trilho e quais práticas modernas ajudam a substituir aquele velho hábito do “p &lt; 0.05 e pronto”. A ideia é deixar você mais seguro ao interpretar resultados e mais confiante nas decisões que toma a partir deles.\nNa Dose da Semana, selecionei alguns pacotes do R que realmente fazem diferença no dia a dia de quem modela, testa hipóteses e precisa extrair evidências com consistência. É aquele conjunto de ferramentas que eu mesma uso e que recomendo de olhos fechados.\nE, no quadro Para Acompanhar o Café, escolhi três livros que conversam diretamente com o tema de hoje. São leituras que ajudam a ampliar a visão sobre inferência, modelos e interpretação de resultados. Separei com cuidado para quem quiser seguir além do básico, no seu próprio ritmo.\n\n\nÓtima leitura!\nAhhh pega seu café aí!"
  },
  {
    "objectID": "cafecomr/posts/25_11_dose3.html#da-semente-à-xícara",
    "href": "cafecomr/posts/25_11_dose3.html#da-semente-à-xícara",
    "title": "Café da Semana☕",
    "section": "Da semente à xícara",
    "text": "Da semente à xícara\nAntes de iniciar, você já passou por isso? Reflita durante a leitura!\n\n\n\nEu já, kkkk e confesso que sempre que estudo, aprendo algo novo!\n\n\n\nA importância do questionamento\n\n\n\nWasserstein, R. L.; Lazar, N. A. (2016). The ASA Statement on p-Values: Context, Process, and Purpose. The American Statistician, 70(2), 129–133.\n\n\nO valor p é um dos conceitos mais usados e, ao mesmo tempo, mais mal compreendidos na estatística inferencial. A comunidade estatística vem alertando há anos que interpretações inadequadas desse número têm levado a conclusões distorcidas em múltiplos campos (Wasserstein, Schirm; Lazar, 2019; Amrhein, Greenland; McShane, 2019). Entender o que o valor p mede e o que ele não mede é fundamental para qualquer análise confiável.\n\nSobre a ASA: American Statistical Association ou Associação Americana de Estatística.\nÉ a maior e mais antiga organização profissional de estatísticos do mundo, fundada em 1839. A ASA reúne pesquisadoras(es), cientistas de dados, estatísticos aplicados, acadêmicos e profissionais de diversas áreas que usam ou desenvolvem métodos estatísticos.\n\n\n\nO que o valor p realmente significa\n\n\n\n\n\n\nWarning\n\n\n\nO valor p é a probabilidade de observar um resultado tão extremo quanto o obtido, assumindo que a hipótese nula é verdadeira.\nEle descreve o grau de compatibilidade entre os dados e um modelo teórico específico, conceito reforçado pela própria ASA em seus posicionamentos oficiais (Wasserstein;Lazar, 2016).\n\n\n\n\nEle não diz:\n\na probabilidade de a hipótese nula ser verdadeira\na probabilidade de a hipótese alternativa ser verdadeira\na magnitude do efeito\na importância prática de uma diferença\na força causal de um fenômeno\n\n\n\n\n\n\n\nNote\n\n\n\n\nO valor p responde apenas a uma pergunta: quão surpreendentes são os dados sob a hipótese nula?\n\n\n\n\n\nA distinção é\n\no valor p calcula P(Dados | H0)\nmas muitos interpretam como P(H0 | Dados), o que é incorreto\n\n\nA distinção entre essas duas probabilidades é fundamental e, ao mesmo tempo, a origem de grande parte das interpretações equivocadas sobre o valor p.\nQuando calculamos um valor p, estamos medindo P(Dados | H0), ou seja, a probabilidade de observarmos resultados tão extremos quanto os obtidos assumindo que a hipótese nula é verdadeira.\nIsso não tem relação direta com P(H0 | Dados), que seria a probabilidade de a hipótese nula ser verdadeira dado o que observamos.\n\n\n\n\n\n\n\nNote\n\n\n\nA confusão entre o valor p e a probabilidade da hipótese nula é chamada de falácia da probabilidade inversa (Greenland et al., 2016).\n\n\n\n\nOs mitos mais comuns e por que eles precisam ser abandonados\n\n\n\n\n\n\n\nMito\nRealidade\n\n\n\n\nO valor p diz a probabilidade de H0 ser verdadeira\nO p-valor é condicionado à hipótese nula. Ele não estima a probabilidade da hipótese.\n\n\np &lt; 0.05 indica efeito grande\nSignificância estatística não tem relação direta com magnitude.\n\n\np &lt; 0.05 confirma a hipótese alternativa\nApenas indica baixa compatibilidade entre os dados e H0. Não “prova” H1.\n\n\np &gt; 0.05 significa ausência de efeito\nUm p alto indica falta de evidência para rejeitar H0, não que H0 é verdadeira.\n\n\nO p-valor é igual ao erro tipo I\nO erro tipo I é um parâmetro pré-definido. O p-valor é uma estatística pós-experimento.\n\n\nO p-valor sozinho encerra a análise\nInferência confiável exige considerar tamanho de efeito, intervalos de confiança e plausibilidade teórica.\n\n\n\n\n\nO impacto do tamanho da amostra\nO valor p é altamente sensível ao tamanho da amostra:\n\namostras grandes tendem a produzir valores p pequenos mesmo quando a diferença é mínima\namostras pequenas podem gerar valores p altos mesmo quando há diferença real\nIsso significa que a interpretação do valor p nunca deve ser dissociada do desenho amostral.\n\n\n\nTamanho de efeito e intervalos de confiança\nO valor p não informa magnitude, precisão ou importância prática. Por isso, ele sempre deve ser acompanhado por:\n\nTamanho de efeito\n\n\nQuantifica a magnitude da diferença ou da associação. É a medida que realmente comunica quanto um fenômeno é relevante.\n\n\nIntervalos de confiança\n\n\nMostram a faixa de valores plausíveis para o efeito. Um intervalo estreito indica maior precisão. Um intervalo amplo indica incerteza elevada.\n\n\nPoder estatístico\n\n\nAjuda a entender a capacidade do estudo de detectar diferenças reais. Baixo poder aumenta o risco de resultados inconclusivos.\n\n\n\nPor que a dicotomia significativo / não significativo é inadequada\nA própria ASA (Wasserstein;Lazar, 2016) e vários autores influentes (Amrhein, Greenland;McShane, 2019) recomendam abandonar a interpretação rígida baseada em p &lt; 0.05. Entre os motivos:\n\ndecisões baseadas em um único número ignoram magnitude, precisão e contexto\nvalores muito próximos do limiar podem ser praticamente indistinguíveis\nincentiva a falsa impressão de preto-e-branco em um processo que é, por natureza, contínuo\n\n\n\nA orientação combinada para uma melhor avaliação:\n\nvalor p exato\ntamanho de efeito\nintervalo de confiança\nteoria e plausibilidade\npoder e desenho amostral\n\n\n\nConsiderações finais\nO valor p continua sendo essencial dentro da estatística inferencial, mas seu papel precisa ser entendido com maturidade.\n\nEle não decide experimentos, não define relevância e não substitui o julgamento técnico embasado.\nA interpretação recomendada nos últimos anos exige combinar múltiplas peças de informação, olhar para a magnitude dos efeitos, considerar a precisão das estimativas e avaliar a plausibilidade teórica do fenômeno estudado.\nAbandonar o uso ritualístico de p &lt; 0.05 é um passo importante para fortalecer a qualidade das análises e aproximar nossas conclusões daquilo que realmente importa, compreender os dados com profundidade e tomar decisões sustentadas por evidência, não por um número isolado.\n\n\n\nReferências com links\n\n\n\nN°\nReferência\nLink\nDescrição\n\n\n\n\n1\nWasserstein, Schirm ;Lazar (2019). Moving to a World Beyond “p &lt; 0.05”. The American Statistician.\nhttps://doi.org/10.1080/00031305.2019.1583913\nArtigo mais influente da última década sobre p-valor. Marco da ASA pedindo o abandono do uso dicotômico de significância.\n\n\n2\nAmrhein, Greenland ;McShane (2019). Scientists rise up against statistical significance. Nature.\nhttps://doi.org/10.1038/d41586-019-00857-9\nPublicação de fortíssimo impacto. Nature explicitamente crítica à significância arbitrária. Mudou práticas editoriais.\n\n\n3\nGreenland et al. (2016). Statistical tests, P values, confidence intervals, and power: guide to misinterpretations. The American Statistician.\nhttps://doi.org/10.1080/00031305.2016.1154108\n\n\n\n4\nWasserstein ;Lazar (2016). The ASA’s Statement on p-Values. The American Statistician.\nhttps://doi.org/10.1080/00031305.2016.1154108\nPrimeira declaração formal da ASA. Documento histórico que redefiniu o debate global.\n\n\n5\nCumming (2014). The New Statistics: estimation, open science, beyond. Psychological Science.\nhttps://doi.org/10.1177/0956797613504966\nIntroduz a perspectiva da “Nova Estatística”: foco em tamanho de efeito, IC e meta-analítica. Influenciou áreas experimentais.\n\n\n6\nNakagawa ;Cuthill (2007). Effect size, confidence interval and power in biological research. Biological Reviews.\nhttps://doi.org/10.1111/j.1469-185X.2007.00027.x\nTexto clássico sobre tamanho de efeito e poder. Muito citado em biológicas, psicometria e estatística aplicada.\n\n\n7\nHurlbert ;Lombardi (2009). Final collapse… rise of the neoFisherian. Annales Zoologici Fennici.\nhttps://doi.org/10.5735/086.046.0501\nCrítica filosófica profunda de Neyman–Pearson. Influente em discussões epistemológicas.\n\n\n8\nPerezgonzalez (2015). Fisher, Neyman-Pearson or NHST? Tutorial. Frontiers in Psychology.\nhttps://www.frontiersin.org/articles/10.3389/fpsyg.2015.00223/full\nExcelente tutorial comparando abordagens históricas. Didático, ótimo para formação conceitual sólida."
  },
  {
    "objectID": "cafecomr/posts/25_11_dose3.html#dose-da-semana",
    "href": "cafecomr/posts/25_11_dose3.html#dose-da-semana",
    "title": "Café da Semana☕",
    "section": "Dose da semana",
    "text": "Dose da semana\nNesta Dose da Semana, selecionei pacotes essenciais para quem trabalha com testes de hipóteses, inferência estatística e modelagem moderna em R. São pacotes que facilitam desde análises clássicas até ajustes mais complexos, permitindo extrair valores p, estimar tamanhos de efeito, avaliar pressupostos e interpretar modelos com mais segurança. É aquela curadoria prática e objetiva para você fortalecer seu fluxo de análise sem complicação.\nEspero que vocês gostem!\n\n\n\nNº\nPacote\nPara que serve\nLink\n\n\n\n\n1\nstats (base R)\nTestes clássicos, t-test, ANOVA, chi-square, correlações e regressão linear.\nhttps://stat.ethz.ch/R-manual/R-devel/library/stats/html/00Index.html\n\n\n2\ncar\nANOVA avançada, testes tipo II/III, contrastes e diagnósticos.\nhttps://cran.r-project.org/package=car\n\n\n3\nlmtest\nTestes para modelos lineares, heterocedasticidade, autocorrelação e especificação.\nhttps://cran.r-project.org/package=lmtest\n\n\n4\nmultcomp\nComparações múltiplas, contrastes, Tukey, Dunnett, etc.\nhttps://cran.r-project.org/package=multcomp\n\n\n5\nemmeans\nMédias marginais estimadas, contrastes e comparações múltiplas modernas.\nhttps://cran.r-project.org/package=emmeans\n\n\n6\nparameters\nExtrai estatísticas, valores p, intervalos de confiança, tamanhos de efeito e medidas de modelo.\nhttps://cran.r-project.org/package=parameters\n\n\n7\nperformance\nDiagnóstico de modelos, qualidade de ajuste, checagem de pressupostos e métricas globais.\nhttps://cran.r-project.org/package=performance\n\n\n8\nlme4\nModelagem estatística moderna, modelos lineares mistos por máxima verossimilhança/REML.\nhttps://cran.r-project.org/package=lme4"
  },
  {
    "objectID": "cafecomr/posts/25_11_dose3.html#para-acompanhar-o-café",
    "href": "cafecomr/posts/25_11_dose3.html#para-acompanhar-o-café",
    "title": "Café da Semana☕",
    "section": "Para Acompanhar o Café",
    "text": "Para Acompanhar o Café\nSeparei três livros que traduzem exatamente o tipo de estatística que eu acredito e que sempre trago aqui na Café com R, acessível. São materiais que ajudam a enxergar a inferência por outros ângulos, indo além do p-valor e mostrando como pensar em evidência, variabilidade, modelos e tomada de decisão com mais segurança. Cada um deles conversa diretamente com o assunto desta edição e complementa o que discutimos sobre significância, tamanho de efeito e leitura crítica de resultados. Deixo aqui como sugestão para você explorar no seu ritmo, com aquela curiosidade que sempre move a nossa comunidade.\n\nLembrem-se temos a lista de artigos já citados para complementar.\n\n\n\n1. Statistical Inference via Data Science: A ModernDive into R and the Tidyverse\n\n\n\n\n\n2. Modern Statistics with R: From wrangling and exploring data to inference and predictive modelling\n\n\n\n\n\n3. An Introduction to Statistical Learning\n\n\n\n\n\nConsiderações finais\nE assim fechamos mais uma xícara bem servida do Café com R. Meu objetivo com esta edição foi justamente trazer mais clareza para um tema que costuma gerar insegurança e interpretações apressadas. Se o texto de hoje ajudou você a enxergar o valor p com mais calma, intenção e profundidade, missão cumprida. Continue explorando, questionando e fortalecendo seu repertório estatístico é esse movimento contínuo que transforma nossa prática. Obrigada por estar aqui mais uma vez, por caminhar comigo e por fazer parte dessa comunidade que cresce aprendendo junto. Nos vemos na próxima edição.\n\n\n☕ Assine o Café com R\n\nQue cada gole desperte uma nova ideia.\nQue cada script abra uma nova conversa.\nQue o Café com R, se torne um ponto de encontro nosso!"
  },
  {
    "objectID": "cafecomr/posts/13_11_R_AI.html#seja-bem-vindao",
    "href": "cafecomr/posts/13_11_R_AI.html#seja-bem-vindao",
    "title": "Café da Semana - News quentinhas ☕",
    "section": "Seja bem-vinda(o)!",
    "text": "Seja bem-vinda(o)!\nAqui é uma pausa para falar de dados."
  },
  {
    "objectID": "cafecomr/posts/13_11_R_AI.html#expresso-de-notícias",
    "href": "cafecomr/posts/13_11_R_AI.html#expresso-de-notícias",
    "title": "Café da Semana - News quentinhas ☕",
    "section": "Expresso de Notícias",
    "text": "Expresso de Notícias\n\nNovidades do universo R e da ciência de dados\n\nO R+AI 2025, realizado nos dias 12 e 13 de novembro, foi um marco para quem trabalha com R e está acompanhando a evolução da inteligência artificial aplicada ao nosso ecossistema.\n\nO evento reuniu especialistas do mundo todo para discutir como LLMs, agentes, visão computacional e automação inteligente já estão transformando fluxos de trabalho analíticos, estatísticos e de engenharia de dados.\n\nForam muitas palestras de alto impacto, e impossível capturar tudo em uma única newsletter. Por isso, selecionei algumas apresentações que considero essenciais para entender para onde o R está caminhando nessa nova era de IA aplicada. São talks que mostram, na prática, como integrar modelos de linguagem, construir agentes, criar pipelines automatizados e até usar IA para gerar arquivos de branding ou interpretar imagens diretamente no R.\n\n\n\n\n\n\n\nTip\n\n\n\nOs resumos estão aqui para abrir portas, mas o valor real está na exploração profunda. Cada seção traz os links diretos para os pacotes, repositórios e páginas oficiais, para você mergulhar nos detalhes e testar no seu próprio ambiente.\n\n\n\nO R está evoluindo rápido, muito rápido!\nEnquanto assistia ia construindo esse material, foi um desafio capturar o máximo de detalhes para os meus estudos e para abrir as portas para quem não participou.\n\n\n\n\nMaterial construído no Quarto - RStudio."
  },
  {
    "objectID": "cafecomr/posts/13_11_R_AI.html#temas-principais-do-evento",
    "href": "cafecomr/posts/13_11_R_AI.html#temas-principais-do-evento",
    "title": "Café da Semana - News quentinhas ☕",
    "section": "Temas principais do evento",
    "text": "Temas principais do evento\n\nForam 20 palestras, divididas em 6 grandes temas:\n\n\nAI assisted dev for R\nAI agentes in R\nAIOps/Production\nIndustry case studies\nML/DL in R\nUse LLMs in R"
  },
  {
    "objectID": "cafecomr/posts/13_11_R_AI.html#palestra-1-keynote-keeping-llms-in-their-lane-focused-ai-for-data-science-and-research---cto---posit---joe-cheng",
    "href": "cafecomr/posts/13_11_R_AI.html#palestra-1-keynote-keeping-llms-in-their-lane-focused-ai-for-data-science-and-research---cto---posit---joe-cheng",
    "title": "Café da Semana - News quentinhas ☕",
    "section": "Palestra 1: Keynote: Keeping LLMs in Their Lane: Focused AI for Data Science and Research - CTO - Posit - Joe Cheng",
    "text": "Palestra 1: Keynote: Keeping LLMs in Their Lane: Focused AI for Data Science and Research - CTO - Posit - Joe Cheng\n\nDestaque:\nJoe Cheng (CTO da Posit) trouxe uma fala direta sobre o papel dos LLMs (Large Language Models) na ciência de dados: poderosos, mas imprevisíveis. A questão não é eliminá-los, e sim mantê-los sob supervisão humana e dentro de seus limites.\n\n\nResumo\nA Posit defende o uso focado e ético da inteligência artificial. Na palestra “Keeping LLMs in Their Lane: Focused AI for Data Science and Research”, Cheng explicou que os LLMs são ferramentas valiosas, mas não substitutos do raciocínio humano.\n\n\nOs riscos principais\n\nCorreção – LLMs podem gerar respostas convincentes, mas erradas.\nTransparência – Ainda não compreendemos totalmente como produzem suas respostas.\nReprodutibilidade – São modelos não determinísticos, com variação entre execuções.\n\nEsses três pontos entram em conflito direto com os princípios da pesquisa científica: precisão, clareza e repetição confiável.\nLLMs não são ruins, apenas irregulares\nO palestrante mostrou que o desempenho dos modelos segue uma curva irregular (“jagged”), alternando entre acertos brilhantes e erros absurdos. No teste prático com R (length()), o modelo acertou listas pequenas, mas errou completamente ao lidar com arrays grandes prova de que não entende dados, apenas texto.\n\n\nComo usar de forma responsável\n\nMicromanage: manter um ciclo humano-IA apertado, com revisão constante.\nSupervisão técnica: validar outputs, especialmente em tarefas analíticas.\nFerramentas abertas: usar pacotes reprodutíveis como R, Quarto e Databot.\nMensagem central\n\n\n“LLMs são poderosos, mas precisam permanecer no seu limite como assistentes de produtividade, não como substitutos do julgamento humano.” Joe Cheng, CTO da Posit\n\n\n\nMinhas considerações sobre a palestra\n\nO futuro da IA na ciência de dados depende mais de disciplina e transparência do que de novas arquiteturas.\nFerramentas open-source (R, Quarto, Shiny) são a ponte entre inovação e responsabilidade.\nA chave é revisar, interpretar e documentar, não apenas automatizar."
  },
  {
    "objectID": "cafecomr/posts/13_11_R_AI.html#palestra-2-me-myself-and-claude---jasmine-daly---principal-consultant-founder-of-daly-analytics",
    "href": "cafecomr/posts/13_11_R_AI.html#palestra-2-me-myself-and-claude---jasmine-daly---principal-consultant-founder-of-daly-analytics",
    "title": "Café da Semana - News quentinhas ☕",
    "section": "Palestra 2: Me, Myself, and Claude - Jasmine Daly - Principal Consultant & Founder of Daly Analytics",
    "text": "Palestra 2: Me, Myself, and Claude - Jasmine Daly - Principal Consultant & Founder of Daly Analytics\n\nDestaques:\n\nJasmine Daly mostrou que a IA não é uma ameaça à sua carreira em R é um multiplicador cognitivo.\nA diferença está em como você a usa: para expandir sua capacidade, não substituir sua prática.\n\n\n\nResumo\n\nGerindo uma consultoria de dados sozinha, Jasmine usou IA (Claude) para ganhar tempo mental e ampliar impacto.\nO foco não é automatizar por automatizar, mas criar espaço para o que importa pensamento estratégico, criatividade e aprendizado contínuo.\n\n\n\n1. Use a IA para liberar capacidade, não terceirizar raciocínio\nAntes da IA, 85% do tempo ia para código de cliente e só 15% para o negócio.\nCom IA, ela reduziu a carga operacional e conseguiu investir em comunidade, marketing e inovação.\n\n\n\nFonte: Jasmine Daly.\n\n\nDica prática:\n\nUse a IA para estruturar tarefas repetitivas (documentação, testes, padrões de código), e redirecione a energia para decisões de valor e novas ideias.\n\n\n\n2. Multiplicador criativo: construa o que antes parecia impossível\nEla criou pacotes inteiros em dias, como:\n\n{shinyfa}: mapeia a estrutura de apps Shiny automaticamente.\n{avilistr}: organiza dados de taxonomia de aves, feito em um fim de semana.\n\nDica\n\nExperimente transformar ideias “de gaveta” em projetos reais com auxílio da IA.\nA IA acelera execução, mas o direcionamento técnico e criativo ainda é seu.\n\n\n\n3. O novo filtro para aceitar projetos\n\nAntes:\n“Será que consigo fazer isso no tempo e com minhas habilidades atuais?”\n\nAgora:\n“Sim, consigo. Como posso entender profundamente o problema e as restrições do cliente?”\n\nDica\n\nUse a IA para ampliar o escopo do que você aceita fazer, mas mantenha controle total sobre a arquitetura e as decisões técnicas.\n\n\n\n4. Parceria com Claude: papel claro e revisão constante\n\nVocê é o gerente: define estratégia e decide.\nClaude é o desenvolvedor sênior: executa, mas precisa de supervisão.\nHuman in the loop: revisão linha a linha, commits incrementais e validação final.\n\nDica\n\nSempre revise o código, use prompts específicos e mantenha logs e versões.\nIA sem revisão é atalho para retrabalho.\n\n\n\n5. Aprendizado acelerado: errar mais rápido ensina melhor\nTrês erros clássicos com a IA e o que aprender com eles:\n\n\n\n\n\n\n\n\nErro\nO que ensina\nEstratégia\n\n\n\n\nConfusão com pacotes\nLeia documentação antes de usar\nEnvie links diretos da doc para a IA\n\n\nSuposições de dados\nValide nomes e tipos antes do código\nUse str(data) ou ferramentas como {mcptools}\n\n\nAbstração excessiva\nSimplicidade é habilidade\nPeça várias opções e escolha a mais simples\n\n\n\nDica\n\nCada erro com a IA é um treino de intuição em R.\nQuanto mais volume de iterações, mais rápida sua curva de aprendizado.\n\n\n\n6. Valor final: IA como catalisador de disciplina e propósito\n\n“Quando a IA libera sua capacidade mental, você não fica preguiçoso, você se torna estratégico.”\nJasmine Daly\n\nAtenção:\n\nA IA acelera o volume de prática, mas a maestria ainda vem da repetição deliberada, da análise dos erros e da curiosidade constante.\n\n\n\n\nChecklist para seu próximo projeto com IA\n\nO que eu sempre farei por mim mesmo?\nEm que a IA pode me ajudar?\nO que eu preciso entender profundamente?\nO que posso delegar com confiança?\n\n\n\nLinks\nBlog da Jasmine: https://www.dalyanalytics.com/blog"
  },
  {
    "objectID": "cafecomr/posts/13_11_R_AI.html#palestra-3-tools-for-llms-and-humans-who-use-r---garrick-aden-buie--software-engineer-posit",
    "href": "cafecomr/posts/13_11_R_AI.html#palestra-3-tools-for-llms-and-humans-who-use-r---garrick-aden-buie--software-engineer-posit",
    "title": "Café da Semana - News quentinhas ☕",
    "section": "Palestra 3: Tools for LLMs and Humans who use R - Garrick Aden-Buie- Software Engineer, Posit",
    "text": "Palestra 3: Tools for LLMs and Humans who use R - Garrick Aden-Buie- Software Engineer, Posit\n\nDestaque\nO pacote btw preenche a lacuna entre o ambiente R e modelos de linguagem (LLMs), oferecendo ferramentas que ajudam na descrição automatizada de data-frames, funções, pacotes, documentação e ambiente e promove colaboração eficiente entre humano + IA.\n\n\nDicas\nInstale o pacote:\n\n\nCode\n# install.packages(\"btw\")\n\n\nOu use a versão de desenvolvimento via:\n\n\nCode\n# pak::pak(\"posit-dev/btw\").\n\n\n\nUse btw() para exportar o contexto do seu ambiente R (data frames, pacotes, funções) para a área de transferência, pronto para colar em um chat de LLM.\nInicie um chat interativo no RStudio com btw_app() ou um cliente com btw_client() para integrar LLMs ao seu ambiente R.\nRegistre ferramentas para um cliente LLM via btw_tools() ou ative o servidor MCP btw_mcp_server()para permitir que o LLM leia diretamente documentação, arquivos, ambiente do projeto.\n\nEsse artigo, é bem interessante R and the Model Context Protocol.\n\n\n\nBenefício principal: menos tempo “pilotando” manualmente o contexto para o LLM, mais tempo focado em decisões analíticas, arquitetura de solução e intervenção estratégica.\n\n\n\nLinks\n\nPágina oficial pacote: https://posit-dev.github.io/btw/ posit-dev.github.io\nCRAN: https://cran.r-project.org/package=btw cran.r-project.org\nGitHub Garrick\nSite"
  },
  {
    "objectID": "cafecomr/posts/13_11_R_AI.html#palestra-4-mini007---a-lightweight-framework-for-multi-agent-orchestration-in-r---mohamed-el-fodil-ihaddaden--analytics-engineer-hdi-global-se",
    "href": "cafecomr/posts/13_11_R_AI.html#palestra-4-mini007---a-lightweight-framework-for-multi-agent-orchestration-in-r---mohamed-el-fodil-ihaddaden--analytics-engineer-hdi-global-se",
    "title": "Café da Semana - News quentinhas ☕",
    "section": "Palestra 4: mini007 - A Lightweight Framework for Multi-Agent Orchestration in R - Mohamed El Fodil Ihaddaden- Analytics Engineer, HDI Global SE",
    "text": "Palestra 4: mini007 - A Lightweight Framework for Multi-Agent Orchestration in R - Mohamed El Fodil Ihaddaden- Analytics Engineer, HDI Global SE\n\n\n\n\n\n\nDestaque:\n\nDesenvolvido por Mohamed El Fodil Ihaddaden (HDI Global SE), o pacote mini007 traz para o R um framework leve e extensível para criar e coordenar múltiplos agentes de IA cooperativos.\nEle permite decompor e resolver tarefas complexas de forma estruturada, sem necessidade de infraestrutura externa.\n\n\n\nResumo\n\nCom a evolução dos grandes modelos de linguagem, cresce o interesse em arquiteturas baseadas em agentes capazes de lidar com processos de raciocínio complexos e de múltiplas etapas.\nO mini007 resolve essa lacuna no ecossistema R, oferecendo uma interface de alto nível para definir agentes especializados que trabalham de forma coordenada, aproveitando a base do pacote ellmer.\nCada agente possui identidade própria, conjunto de instruções e memória, o que permite especialização em tarefas específicas.\nO agente líder recebe uma solicitação ampla, divide em subtarefas lógicas, delega aos agentes apropriados e integra as respostas em uma saída coerente.\n\n\n\nInstalação e início\n\n\nCode\n# install.packages(\"mini007\") \nlibrary(mini007)\n\n\nWarning: pacote 'mini007' foi compilado no R versão 4.5.2\n\n\n\nIntegração com ellmer é compatível com qualquer modelo de linguagem suportado, como OpenAI, Claude ou Gemini.\n\n\n\nFluxo básico\n\nCriar agentes especializados Agent()\nDefinir o agente líder LeadAgent()\nExecutar a orquestração run_agents() ou lead_run()\nAplicações Recuperação de informações, sumarização, tradução, e pipelines analíticos coordenados.\nHuman in the Loop (HITL): Possibilidade de inserir revisão humana em etapas específicas do processo.\n\n\n\nRecursos do pacote\n\nMemória e identidade individual de agentes\nDecomposição e delegação automática de tarefas\nEncadeamento de resultados entre agentes\nCompatibilidade com múltiplos modelos de linguagem via ellmer\nFlexibilidade para integração em fluxos complexos de ciência de dados\n\n\n\nLinks\n\nGitHub: https://github.com/feddelegrand7/mini007\nPacote ellmer: https://ellmer.tidyverse.org/index.html"
  },
  {
    "objectID": "cafecomr/posts/13_11_R_AI.html#palestra-5-brand-your-docs-apps-and-ggplots-using-llms--umair-durrani---phd-data-scientist-presage-group-inc.",
    "href": "cafecomr/posts/13_11_R_AI.html#palestra-5-brand-your-docs-apps-and-ggplots-using-llms--umair-durrani---phd-data-scientist-presage-group-inc.",
    "title": "Café da Semana - News quentinhas ☕",
    "section": "Palestra 5: Brand your docs, apps, and ggplots using LLMs- Umair Durrani - PhD, Data Scientist, Presage Group Inc.",
    "text": "Palestra 5: Brand your docs, apps, and ggplots using LLMs- Umair Durrani - PhD, Data Scientist, Presage Group Inc.\n\n\n\n\n\n\nDestaque:\n\nApresentado por Umair Durrani (Presage Group Inc.), o pacote brandthis mostra como automatizar a criação de arquivos _brand.yml e temas para ggplot2, usando LLMs via ellmer.\nO fluxo permite gerar identidade visual completa para Quarto, Shiny e visualizações com rapidez e consistência.\n\n\n\nResumo:\nComunicar resultados com identidade visual consistente sempre exige trabalho manual, como paletas, logos, temas, fontes, espaçamentos e estilos precisam ser replicados em cada documento, dashboard e gráfico.\n\nO Quarto resolveu parte desse problema criando o padrão _brand.yml, um arquivo central onde você define cores, fontes, logos e estilo para todo o seu ecossistema de documentos.\nMas construir esse arquivo do zero consome tempo. A proposta do brandthis é deixar que um LLM gere isso para você a partir de imagens das diretrizes de marca e instruções simples.\n\n\n\nComo funciona o fluxo?\n\nO usuário envia capturas de tela da identidade visual da empresa.\nO brandthis envia as imagens + instruções para um LLM (por exemplo, Google Gemini via ellmer).\nO modelo retorna um _brand.yml completo e editável.\n\n\nO pacote gera automaticamente:\n\npaletas de cores\nescalas para ggplot2\ntemas coerentes com a identidade visual\nTudo pode ser exportado para uso em Quarto, R Markdown e Shiny.\n\n\nA funcionalidade depende do recurso de saída estruturada do ellmer, garantindo que o LLM devolva um arquivo YAML válido.\n\n\n\n\nInstalação\n\n\nCode\n# remotes::install_github(\"durraniu/brandthis\")\n\n\n\nCompatibilidade\n\nNão funciona ainda com ggplot2 &gt;= 4.0.0. Use versão anterior.\n\n\n\nConfigurar API key\n\nAdicione ao .Renviron: (esse tipo de arquivo é usado no R para guardar suas chaves de forma segura)\nGOOGLE_API_KEY\nOPENROUTER_API_KEY\nou outra suportada pelo ellmer\n\n\n\n\nAplicações\n\nCriar um _brand.yml pessoal\n\n\nCode\n# personal_brand &lt;- brandthis::create_brand(\n#   prompt = \"Meu nome é Jennifer Luz Lopes.\",\n#   img = \"minha-img.png\",\n#   type = \"personal\",\n#   chat_fn = ellmer::chat_google_gemini)\n\n\n\n\nCriar um _brand.yml para empresa (várias capturas de tela)\n\n\nCode\n# company_brand &lt;- brandthis::create_brand(\n#   \"Company name is x\",\n#   img = c(\"x-font.png\",\"xt-palette.jpeg\",\"x-logo.png\"),\n#   type = \"company\",\n#   chat_fn = ellmer::chat_google_gemini)\n\n\n\n\nGerar paletas e escalas para ggplot2\n\n\nCode\n# suggested_scales &lt;- brandthis::suggest_color_scales(company_brand, \"paletteer\")\n# color_palettes &lt;- brandthis::create_color_palette(company_brand)\n\n\n\n\n\nO que é brand no Quarto\nO brand no Quarto é uma forma de centralizar elementos de identidade visual em um único arquivo _brand.yml. Ele permite definir:\n\npaletas de cores\nfontes\nlogos\nmargens, espaçamentos e estilos\ntemas de tabelas e blocos\nvariantes claras e escuras\n\n\nCom isso, qualquer documento Quarto pode herdar automaticamente o estilo, garantindo consistência imediata entre relatórios, dashboards e apresentações.\n\n\n\nExemplo de BRAND YML\n\n\n\n\n\n\n\n\n\n\n\n\nLinks\n\nGitHub do brandthis: https://github.com/durraniu/brandthis\nSite: https://durraniu.github.io/brandthis/\nInspirações de brand: https://posit-dev.github.io/brand-yml/inspiration/brand-guidelines/posit/\nDocumentação do quarto/_brand.yml: https://quarto.org/docs/authoring/brand.html"
  },
  {
    "objectID": "cafecomr/posts/13_11_R_AI.html#palestra-6-introducing-geodl-an-r-package-for-geospatial-semantic-segmentation-using-torch-terra-and-luz---aaron-maxwell---associate-professor---west-virginia-university",
    "href": "cafecomr/posts/13_11_R_AI.html#palestra-6-introducing-geodl-an-r-package-for-geospatial-semantic-segmentation-using-torch-terra-and-luz---aaron-maxwell---associate-professor---west-virginia-university",
    "title": "Café da Semana - News quentinhas ☕",
    "section": "Palestra 6: Introducing geodl: An R package for geospatial semantic segmentation using torch, terra, and luz - Aaron Maxwell - Associate Professor - West Virginia University",
    "text": "Palestra 6: Introducing geodl: An R package for geospatial semantic segmentation using torch, terra, and luz - Aaron Maxwell - Associate Professor - West Virginia University\n\n\n\nFonte: Aaron Maxwell.\n\n\n\nDestaque\nApresentado por Aaron Maxwell (West Virginia University). O pacote geodl coloca o R no centro do deep learning para dados geoespaciais, permitindo segmentação semântica em nível de pixel sem necessidade de Python ou PyTorch.\n\n\nResumo:\n\nO geodl foi lançado em 2024 para preencher uma lacuna, onde usuários de R que trabalham com dados espaciais sempre dependeram de pipelines externos em Python para segmentação semântica.\n\n\n\n\nFonte: Aaron Maxwell. Segmentação semântica.\n\n\n\nO geodl elimina essa dependência ao integrar torch, terra e luz em um fluxo completo para treinar modelos de visão computacional geoespacial diretamente no R.\nA lógica central do pacote é simples. Cada pixel da imagem se torna uma unidade de análise com bandas espectrais como variáveis preditoras.\n\n\n\nFonte: Aaron Maxwell. Variáveis preditoras.\n\n\nA partir disso, o geodl oferece arquiteturas de CNN robustas como UNet, UNet-MobileNetv2, UNet3+ e HRNet.\nO pacote também define funções utilitárias para criar conjuntos de dados, gerar máscaras, visualizar chips, construir DataLoaders geoespaciais e prever grandes áreas usando modelos treinados.\nO fluxo de treinamento pode ser feito com chips pré-salvos ou gerados dinamicamente.\nIsso reduz o atrito na criação dos datasets e facilita o ajuste de modelos em diferentes resoluções ou regiões de interesse.\nO trabalho enfatiza ainda ferramentas de avaliação, geração de métricas, produção de mapas e extração de parâmetros de superfície terrestre.\n\n\n\nDicas:\n\ngeodl não exige Python. Todo o pipeline roda nativamente no R com aceleração por GPU.\nPara começar, é essencial dominar terra (rasters) e sf (vetores).\nO fluxo recomendado inclui criar chips, definir datasets, escolher uma arquitetura UNet, treinar e avaliar.\nPara produção, o geodl permite prever áreas amplas e gerar mapas diretamente do raster.\nA comunidade está ativa e o desenvolvimento futuro inclui Transformers, autoencoders e modelos de regressão.\n\n\n\nRecursos:\n\nArquiteturas CNN prontas para uso\nIntegração nativa com torch, terra e luz\nCriação automatizada de datasets e máscaras\nVisualização de chips, batches e previsões\nAvaliação de modelos com métricas padrão\nPredição espacial em larga escala\n\n\n\nPacotes para análises espaciais\n\n\n\nFonte: Aaron Maxwell.\n\n\n\n\nLinks\n\nCRAN: https://github.com/maxwell-geospatial/geodl\n\n\n\nRecomendações:\n\n\n\nFonte: Aaron Maxwell."
  },
  {
    "objectID": "cafecomr/posts/13_11_R_AI.html#palestra-7-how-deep-learning-helps-build-results-that-that-beat-prior-records-can-be-set-up-in-seconds-while-taking-minimal-time-to-run-and-are-very-easy-to-use.---russ-conte",
    "href": "cafecomr/posts/13_11_R_AI.html#palestra-7-how-deep-learning-helps-build-results-that-that-beat-prior-records-can-be-set-up-in-seconds-while-taking-minimal-time-to-run-and-are-very-easy-to-use.---russ-conte",
    "title": "Café da Semana - News quentinhas ☕",
    "section": "Palestra 7: How deep learning helps build results that that beat prior records, can be set up in seconds while taking minimal time to run, and are very easy to use. - Russ Conte",
    "text": "Palestra 7: How deep learning helps build results that that beat prior records, can be set up in seconds while taking minimal time to run, and are very easy to use. - Russ Conte\n\nDestaque:\nRuss Conte apresentou três pacotes publicados no CRAN que mostram como modelos de deep learning podem ser configurados em segundos, rodar em menos de um minuto e ainda superar resultados registrados em competições e benchmarks tradicionais.\n\n\nResumo:\nA proposta foi mostrar como R pode entregar resultados de ponta em modelagem preditiva usando deep learning totalmente automatizado.\nPara isso, ele apresentou três pacotes:\n\nNumericEnsembles\nClassificationEnsembles\nLogisticEnsembles\n\nO funcionamento é sempre o mesmo. Uma única linha de código inicia a criação de dezenas de modelos individuais e de conjuntos, combinando técnicas tradicionais e arquiteturas de deep learning.\n\nOs pacotes cuidam automaticamente de otimização, validação cruzada, tuning de hiperparâmetros e seleção de variáveis.\nO usuário apenas executa; o pacote decide a melhor estratégia.\nO ponto central da palestra foi demonstrar ao vivo que os modelos de deep learning produzem consistentemente os melhores resultados dentro dos ensembles.\nOs pacotes foram projetados para explorar isso: a automatização identifica quando os modelos profundos superam modelos tradicionais e os integra nas combinações finais.\n\n\n\nSobre os pacotes:\n\nNumericEnsembles\nObjetivo: regressão\nExemplo: análise do Boston Housing em 1 linha de código, superando 20 anos de melhores resultados no Kaggle.\nO pacote cria automaticamente:\n\n23 modelos individuais\n17 ensembles\nOito modos de otimização de colunas\nTuning, validação e seleção automatizados\nResultado apresentado: modelos de deep learning dominam tanto no desempenho individual quanto nos ensembles finais.\n\nLinks GitHub: https://github.com/InfiniteCuriosity/NumericEnsembles\n\n\nClassificationEnsembles\nObjetivo: classificação\nExemplo: 100% de acurácia no dataset Dry Beans com setup em segundos.\nO pacote replica a lógica do NumericEnsembles, mas adaptada para classificação. A demonstração mostrou os métodos profundos elevando a performance até a acurácia máxima.\nLinks GitHub: https://github.com/InfiniteCuriosity/NumericEnsembles\n\n\nLogisticEnsembles\nObjetivo: classificação binária\nExemplo: resultados superiores no dataset Pima Indians, com destaque para o modelo BayesRNN.\nAssim como os demais, o pacote cria e otimiza modelos individuais e conjuntos em minutos. O BayesRNN foi apontado como um dos modelos de maior desempenho na análise ao vivo.\nLinks GitHub: https://github.com/InfiniteCuriosity/LogisticEnsembles\n\n\n\nFonte: Russ Conte."
  },
  {
    "objectID": "cafecomr/posts/13_11_R_AI.html#palestra-8-kuzco-computer-vision-made-easy---frankie-hull--director-of-data-science-analytics",
    "href": "cafecomr/posts/13_11_R_AI.html#palestra-8-kuzco-computer-vision-made-easy---frankie-hull--director-of-data-science-analytics",
    "title": "Café da Semana - News quentinhas ☕",
    "section": "Palestra 8: kuzco | Computer Vision made easy - Frankie Hull- director of data science & analytics",
    "text": "Palestra 8: kuzco | Computer Vision made easy - Frankie Hull- director of data science & analytics\n\nDestaque:\n\nFrankie Hull apresentou o kuzco, um pacote que transforma visão computacional em algo direto e orientado por linguagem natural.\nCombinando {ellmer} e {ollamar}, ele permite analisar imagens em R com prompts, sem precisar treinar modelos, ajustar tensores ou entender redes profundas.\n\n\n\nResumo:\n\nO kuzco nasce para tornar a visão computacional tão simples quanto conversar.\nEm vez de pipelines complexos, arquitetura convolucional, camadas de pré-processamento ou dependências pesadas, o usuário só precisa de uma imagem e um prompt, como “o que há nesta foto?” ou “classifique os objetos visíveis”.\nA lógica é orientada por LLMs. O pacote usa modelos multimodais via {ellmer}, seja com Ollama (local) ou serviços externos.\nIsso reduz a barreira técnica e democratiza o acesso à análise de imagens, oferecendo detecção, classificação, extração de texto, descrição e até análises personalizadas guiadas por instruções.\nO pacote padroniza saídas, cria uma estrutura simples para retornos consistentes e oferece um caminho prático para quem quer trabalhar com visão computacional em R, mas não deseja (ou não pode) recorrer a keras, torch ou pipelines pesados de deep learning.\n\n\n\nInstalação\n\n\nCode\n# devtools::install_github(\"frankiethull/kuzco\")\n\n\nFluxo simples:\n\n\nCode\n# library(kuzco)\n# library(ollamar)\n# \n# img &lt;- file.path(system.file(package = \"kuzco\"), \"img/test_img.jpg\")\n# \n# llm_image_classification(\n#   llm_model = \"qwen2.5vl\",\n#   image = img,\n#   backend = \"ollamar\")\n\n\n\n\n\nFonte: Frankie Hull - kuzco.\n\n\n\n\nFunções já disponíveis\n\nClassificação\n\n\n\n\nFonte: Frankie Hull.\n\n\n\nReconhecimento\nSentimento em imagens\nExtração de texto\nGeração de alt-text\nTarefas personalizadas por prompt\n\n\n\nFlexibilidade total\n\nEscolha rodar com modelos locais (privacidade e custo zero) ou remotos (maior performance).\nTodos os prompts podem ser personalizados.\nFunciona em qualquer workflow de análise em R.\n\n\n\nRecursos Principais\n\nAnálise de imagens guiada por instruções\nLLMs multimodais no R via ellmer/ollamar\nSaídas padronizadas e estruturadas\nZero necessidade de deep learning tradicional\nFluxo acessível para iniciantes e eficiente para especialistas\n\n\n\nLinks\n\nGitHub – https://github.com/frankiethull/kuzco"
  },
  {
    "objectID": "cafecomr/posts/13_11_R_AI.html#workshop-from-prompts-to-agents-building-evaluating-r-llm-workflows.",
    "href": "cafecomr/posts/13_11_R_AI.html#workshop-from-prompts-to-agents-building-evaluating-r-llm-workflows.",
    "title": "Café da Semana - News quentinhas ☕",
    "section": "Workshop: From Prompts to Agents: Building & Evaluating R + LLM Workflows.",
    "text": "Workshop: From Prompts to Agents: Building & Evaluating R + LLM Workflows.\n\nDevin Pastoor- Chief Technology and Product Officer - A2-AI\nAathira Anil Kumar- Software Engineer - A2-AI\nXu Fei - Senior Solutions Engineer - A2-Ai\n\n\nDestaque\nApresentado por Devin Pastoor, Aathira Anil Kumar e Xu Fei (A2-AI).\n\nO workshop mostrou como evoluir do uso simples de prompts para a construção de agentes capazes de automatizar tarefas completas em R, entendendo contexto, ferramentas, janelas de tokens e boas práticas essenciais.\n\n\n\nResumo:\n\nO foco do workshop foi acelerar a curva de aprendizado para quem está começando a integrar IA generativa com R.\nA equipe mostrou, passo a passo, como transformar prompts em fluxos de trabalho agentivos, utilizando ellmer, btw e utilitários para chamadas HTTP, validação e registro.\nA mensagem principal: modelos não trabalham sozinhos.\nO comportamento final depende do system prompt, do histórico, das ferramentas disponíveis e da aplicação que envolve o modelo.\n\n\nA demonstração comparou a mesma pergunta feita no Positron e no Claude Chat. Mesmo usando o mesmo modelo, as respostas foram diferentes porque o ambiente muda o contexto enviado ao LLM.\n\n\nO Positron injeta informações do projeto, arquivos abertos, variáveis do ambiente e ferramentas declaradas. Isso faz com que o modelo gere código R executável, enquanto o mesmo prompt fora do ambiente gera respostas mais genéricas.\nOs instrutores explicaram como funciona o ciclo agentivo. A cada solicitação, o LLM decide se responde diretamente ou se invoca uma ferramenta.\nA aplicação executa a ação e devolve o resultado ao histórico. Todo o histórico é reenviado a cada rodada, o que torna o tamanho da janela de contexto crucial.\nNa demonstração, mais de 17 mil tokens foram usados para pedir um gráfico simples do mtcars, ilustrando como o contexto afeta custo e coerência.\nEsse entendimento leva ao ponto mais importante: quem precisa de precisão deve controlar explicitamente o que o modelo deve fazer.\nPor exemplo, especificar que você quer apenas o código evita que a ferramenta gere e escreva arquivos no projeto. A equipe também apresentou o arquivo agents.md, que permite ao usuário controlar o comportamento padrão do agente dentro do projeto, unificando estilo e fluxo de respostas.\n\n\n\nDicas:\n\nUse chats novos quando quiser evitar interferência de histórico.\nSeja explícita ao pedir código ou ações no projeto.\nTenha clareza de que a ferramenta, não o modelo, executa ações como criar arquivos.\nControle comportamento com agents.md para consistência entre modelos e ferramentas.\nMonitore sempre o tamanho da janela de contexto para evitar respostas inconsistentes.\nAproveite ellmer e btw para padronizar interações e enriquecer o contexto do modelo.\n\n\n\n\nPositron chat boat.\n\n\n\n\nLinks\n\nFerramentas e IDE\nPositron (IDE da Posit) - https://positron.posit.co/\n\n\nModelos e provedor\nClaude (Anthropic) - https://claude.ai/\n\n\nPacotes citados\nellmer\nhttps://github.com/A2-AI/ellmer\nbtw\nhttps://github.com/A2-AI/btw\nOllama (para modelos locais)\nhttps://ollama.com\nollamar (R + Ollama)\nhttps://github.com/chainhaus/ollamar"
  },
  {
    "objectID": "cafecomr/posts/13_11_R_AI.html#minhas-considerações",
    "href": "cafecomr/posts/13_11_R_AI.html#minhas-considerações",
    "title": "Café da Semana - News quentinhas ☕",
    "section": "Minhas considerações",
    "text": "Minhas considerações\nPessoal, o R+AI deixou claro que não estamos mais falando de futuro. Estamos falando de como trabalhamos hoje. A combinação entre R e modelos de linguagem já redefiniu como criamos, analisamos, comunicamos e automatizamos.\n\nAs palestras que selecionei mostram isso por diferentes ângulos: desde frameworks para agentes, visão computacional simplificada, branding automatizado, até fluxos completos de orquestração com LLMs dentro do próprio RStudio.\n\nNão consegui trazer todas as sessões, mas fiz questão de destacar aquelas que ampliam a nossa visão sobre o que significa trabalhar com dados + IA em 2025.\n\n\n\n\n\n\nTip\n\n\n\nAgora é com vocês. Explorem os links, teste os pacotes, coloque as ideias para rodar no seu workflow. Este é o momento de transformar curiosidade em prática, e prática em vantagem real no seu dia a dia com R.\n\n\nSeguimos juntos, aprendendo rápido e construindo coisas que, até pouco tempo atrás, pareciam impossíveis.\n\n\n☕ Assine o Café com R\n\nQue cada gole desperte uma nova ideia.\nQue cada script abra uma nova conversa.\nQue o Café com R, se torne um ponto de encontro nosso!"
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#bem-vindo-ao-nosso-encontro",
    "href": "cafecomr/posts/09_12_dose5.html#bem-vindo-ao-nosso-encontro",
    "title": "Café com R",
    "section": "Bem-vindo ao nosso encontro!",
    "text": "Bem-vindo ao nosso encontro!\nOlá, querida comunidade!\n\nQue alegria ter você aqui para mais um café. Nesta edição especial, preparei uma seleção cuidadosa de recursos, pacotes e conexões que vão enriquecer sua jornada com R.\n\nPegue sua xícara favorita e vamos juntos explorar o que há de mais interessante no universo R!"
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#assine-o-café-com-r",
    "href": "cafecomr/posts/09_12_dose5.html#assine-o-café-com-r",
    "title": "Café com R",
    "section": "☕ Assine o Café com R",
    "text": "☕ Assine o Café com R\n\nFique por dentro das aulas, conteúdos, newsletter!\nQue cada gole desperte uma nova ideia.\nQue cada script abra uma nova conversa.\nQue o Café com R, se torne um ponto de encontro nosso!"
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#eventos-2026-marque-sua-agenda",
    "href": "cafecomr/posts/09_12_dose5.html#eventos-2026-marque-sua-agenda",
    "title": "Café com R",
    "section": "Eventos 2026: Marque sua agenda!",
    "text": "Eventos 2026: Marque sua agenda!\nA comunidade R está vibrante em 2026! Aqui estão os principais eventos para você participar, aprender e se conectar:\nPor que participar de eventos?\n\nNetworking com profissionais da área\nAprender com experts reconhecidos\nConhecer as últimas tendências\nFazer parte da comunidade global"
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#eventos-2026",
    "href": "cafecomr/posts/09_12_dose5.html#eventos-2026",
    "title": "Café com R",
    "section": "Eventos 2026",
    "text": "Eventos 2026\n\n\n\nEvento\nData\nFormato\nLink\n\n\n\n\nR!sk 2026\n18-19 fevereiro\nOnline\nrconsortium.github.io/Risk_website\n\n\nrainbowR Conference\n25-26 fevereiro\nOnline\nconference.rainbowr.org\n\n\nR/Medicine 2026\n4-8 maio\nOnline\nrconsortium.github.io/RMedicine_website\n\n\nPosit::conf(2026)\n14-16 setembro\nPresencial (Houston, USA)\nposit.co"
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#rsk-2026",
    "href": "cafecomr/posts/09_12_dose5.html#rsk-2026",
    "title": "Café com R",
    "section": "R!sk 2026",
    "text": "R!sk 2026\n18-19 de fevereiro | Online\nParticipe do R!sk 2026, nossa conferência dedicada à comunidade de código aberto R e à análise de riscos."
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#rainbowr-conference",
    "href": "cafecomr/posts/09_12_dose5.html#rainbowr-conference",
    "title": "Café com R",
    "section": "rainbowR Conference",
    "text": "rainbowR Conference\n25-26 de fevereiro | Online\nConferência dedicada a promover diversidade e inclusão na comunidade R, com foco especial em pessoas LGBTQ+."
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#rainbowr-conference-1",
    "href": "cafecomr/posts/09_12_dose5.html#rainbowr-conference-1",
    "title": "Café com R",
    "section": "rainbowR Conference",
    "text": "rainbowR Conference\nDestaques:\n\nPalestras inspiradoras sobre diversidade em tech\nWorkshops práticos de R\nNetworking com a comunidade global\nDiscussões sobre acessibilidade"
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#rmedicine-2026",
    "href": "cafecomr/posts/09_12_dose5.html#rmedicine-2026",
    "title": "Café com R",
    "section": "R/Medicine 2026",
    "text": "R/Medicine 2026\n4-8 de maio | Online\nA principal conferência sobre o uso de R na área médica e de saúde pública."
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#positconf2026",
    "href": "cafecomr/posts/09_12_dose5.html#positconf2026",
    "title": "Café com R",
    "section": "Posit::conf(2026)",
    "text": "Posit::conf(2026)\n14-16 de setembro | Houston, Texas (Presencial)\nO maior evento do ecossistema R e Python, organizado pela Posit (antiga RStudio)."
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#livro-recomendado-big-book-of-r",
    "href": "cafecomr/posts/09_12_dose5.html#livro-recomendado-big-book-of-r",
    "title": "Café com R",
    "section": "Livro Recomendado: Big Book of R",
    "text": "Livro Recomendado: Big Book of R\n\nUma curadoria impressionante de mais de 400 livros gratuitos sobre R!\n\n\n\n\n\nwww.bigbookofr.com"
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#por-que-o-big-book-of-r",
    "href": "cafecomr/posts/09_12_dose5.html#por-que-o-big-book-of-r",
    "title": "Café com R",
    "section": "Por que o Big Book of R?",
    "text": "Por que o Big Book of R?\nEste não é apenas um livro, é uma biblioteca completa e gratuita organizada por tópicos.\nCategorias disponíveis e muito mais:\n\nFundamentos de R: Do básico ao avançado\nVisualização de Dados: ggplot2, plotly, shiny\nMachine Learning: tidymodels, caret, keras\nAnálise Espacial: sf, spatial, mapas\nSéries Temporais: forecast, tsibble\nEstatística: Inferência, modelagem, Bayesiana\nBig Data: spark, data.table, databases"
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#como-usar-o-big-book-of-r",
    "href": "cafecomr/posts/09_12_dose5.html#como-usar-o-big-book-of-r",
    "title": "Café com R",
    "section": "Como usar o Big Book of R",
    "text": "Como usar o Big Book of R\nEstratégia de aprendizado:\n\nIdentifique seu objetivo: Qual área você quer explorar?\nEscolha 1-2 livros: Não tente ler tudo de uma vez\nPratique enquanto lê: Abra o RStudio e teste os exemplos\nMarque favoritos: Guarde os livros mais úteis para referência"
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#como-usar-o-big-book-of-r-1",
    "href": "cafecomr/posts/09_12_dose5.html#como-usar-o-big-book-of-r-1",
    "title": "Café com R",
    "section": "Como usar o Big Book of R",
    "text": "Como usar o Big Book of R\n\nMinha dica pessoal: Comece com “R for Data Science” se você está começando, ou “Advanced R” se já tem experiência e quer aprofundar.\n\n\nDica da Meguy!"
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#por-que-explorar-novos-pacotes",
    "href": "cafecomr/posts/09_12_dose5.html#por-que-explorar-novos-pacotes",
    "title": "Café com R",
    "section": "Por que explorar novos pacotes?",
    "text": "Por que explorar novos pacotes?\nO ecossistema R tem mais de 19.000 pacotes no CRAN. Descobrir as ferramentas certas pode:\n\nEconomizar horas de trabalho manual\nMelhorar a qualidade das suas análises\nPadronizar seu fluxo de trabalho\nImpressionar sua equipe (e você mesmo!)\n\n\nHoje vou apresentar dois pacotes essenciais que uso em praticamente todos os meus projetos."
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#pacote-1-skimr",
    "href": "cafecomr/posts/09_12_dose5.html#pacote-1-skimr",
    "title": "Café com R",
    "section": "Pacote 1: skimr",
    "text": "Pacote 1: skimr\nResumos estatísticos que realmente informam\nO pacote skimr transforma a exploração inicial de dados em algo muito mais rico e visual.\n\n\n\n\n\ndocs.ropensci.org/skimr"
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#skimr-instalação-e-uso-básico",
    "href": "cafecomr/posts/09_12_dose5.html#skimr-instalação-e-uso-básico",
    "title": "Café com R",
    "section": "skimr: Instalação e uso básico",
    "text": "skimr: Instalação e uso básico\n\n# Instalação\ninstall.packages(\"skimr\")\nlibrary(skimr)\n\n# Uso mais simples\nskim(iris)\n\nO que você ganha:\n\nEstatísticas descritivas completas\nHistogramas em miniatura (sparklines)\nContagem de valores ausentes\nSeparação automática por tipo de variável"
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#skimr-exemplo-prático",
    "href": "cafecomr/posts/09_12_dose5.html#skimr-exemplo-prático",
    "title": "Café com R",
    "section": "skimr: Exemplo prático",
    "text": "skimr: Exemplo prático\n\nlibrary(skimr)\nlibrary(dplyr)\n\n# Carregar dados\ndata(starwars)\n\n# Resumo completo\nskim(starwars)\n\n# Resumo apenas de variáveis numéricas\nstarwars %&gt;% \n  skim() %&gt;% \n  filter(skim_type == \"numeric\")\n\n# Resumo agrupado\nstarwars %&gt;% \n  group_by(species) %&gt;% \n  skim()"
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#skimr-x-summary",
    "href": "cafecomr/posts/09_12_dose5.html#skimr-x-summary",
    "title": "Café com R",
    "section": "skimr x summary()",
    "text": "skimr x summary()\nCom summary():\n   Sepal.Length    Sepal.Width     Petal.Length  \n Min.   :4.300   Min.   :2.000   Min.   :1.000  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600  \n Median :5.800   Median :3.000   Median :4.350  \n Mean   :5.843   Mean   :3.057   Mean   :3.758  \nCom skim():\n\nTodas as estatísticas acima +\nHistograma visual de distribuição\nContagem de valores únicos e ausentes\nDesvio padrão e quartis\nTudo organizado em uma tabela bonita"
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#quando-usar-skimr",
    "href": "cafecomr/posts/09_12_dose5.html#quando-usar-skimr",
    "title": "Café com R",
    "section": "Quando usar skimr?",
    "text": "Quando usar skimr?\nCenários ideais:\n\nExploração inicial: Primeiro contato com um dataset novo\nRelatórios automáticos: Documentação rápida das variáveis\nDetecção de problemas: Identificar missing values, outliers\nApresentações: Mostrar overview dos dados de forma profissional"
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#quando-usar-skimr-1",
    "href": "cafecomr/posts/09_12_dose5.html#quando-usar-skimr-1",
    "title": "Café com R",
    "section": "Quando usar skimr?",
    "text": "Quando usar skimr?\n\nDica: Use skim() no começo de todo script de análise. Você vai economizar tempo e evitar surpresas depois."
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#pacote-2-janitor",
    "href": "cafecomr/posts/09_12_dose5.html#pacote-2-janitor",
    "title": "Café com R",
    "section": "Pacote 2: janitor",
    "text": "Pacote 2: janitor\nLimpeza de dados sem dor de cabeça\nO pacote janitor é seu melhor amigo quando os dados estão bagunçados (e quase sempre estão!).\n\n\n\n\n\nsfirke.github.io/janitor"
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#janitor-instalação-e-função-principal",
    "href": "cafecomr/posts/09_12_dose5.html#janitor-instalação-e-função-principal",
    "title": "Café com R",
    "section": "janitor: Instalação e função principal",
    "text": "janitor: Instalação e função principal\n\n# Instalação\n# install.packages(\"janitor\")\nlibrary(janitor)\nlibrary(tidyverse)\n\n# A função mais útil: clean_names()\ndf &lt;- data.frame(\n  \"Nome Completo\" = c(\"Ana Silva\", \"Bruno Costa\"),\n  \"Idade (anos)\" = c(25, 30),\n  \"Salário R$\" = c(5000, 6000),\n  \"Data Admissão\" = c(\"2020-01-15\", \"2019-05-20\"))"
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#janitor-resultado",
    "href": "cafecomr/posts/09_12_dose5.html#janitor-resultado",
    "title": "Café com R",
    "section": "janitor: Resultado",
    "text": "janitor: Resultado\n\n# Antes\nnames(df)\n# [1] \"Nome.Completo\"  \"Idade..anos.\"   \"Salário.R.\"     \"Data.Admissão\"\n\n# Depois\ndf_limpo &lt;- df %&gt;% clean_names()\nnames(df_limpo)\n# [1] \"nome_completo\"  \"idade_anos\"     \"salario_r\"      \"data_admissao\""
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#janitor-mais-funcionalidades",
    "href": "cafecomr/posts/09_12_dose5.html#janitor-mais-funcionalidades",
    "title": "Café com R",
    "section": "janitor: Mais funcionalidades",
    "text": "janitor: Mais funcionalidades\n\nlibrary(janitor)\nlibrary(dplyr)\n\n# Remover linhas e colunas completamente vazias\ndf %&gt;% \n  remove_empty(c(\"rows\", \"cols\"))\n\n# Remover linhas duplicadas\ndf %&gt;% \n  get_dupes()\n\n# Criar tabelas de frequência\ndf %&gt;% \n  tabyl(categoria) %&gt;% \n  adorn_totals(\"row\") %&gt;% \n  adorn_percentages(\"col\") %&gt;% \n  adorn_pct_formatting()\n\n# Arredondar todos os números de uma vez\ndf %&gt;% \n  mutate(across(where(is.numeric), ~round(., 2)))"
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#problema-dados-de-excel-bagunçados",
    "href": "cafecomr/posts/09_12_dose5.html#problema-dados-de-excel-bagunçados",
    "title": "Café com R",
    "section": "Problema: dados de Excel bagunçados",
    "text": "Problema: dados de Excel bagunçados\n\n# Você recebe isso:\ndados_excel &lt;- read_excel(\"vendas_2024.xlsx\")\n\n# Nomes horríveis\nnames(dados_excel)\n# [1] \"ID Cliente\"  \"Nome do Cliente\"  \"Valor (R$)\"  \n# [4] \"Data Compra\"  \"Categoria Produto\"  \"% Desconto\"\n\n# Solução em uma linha\ndados_limpos &lt;- dados_excel %&gt;% \n  clean_names() %&gt;% \n  remove_empty(c(\"rows\", \"cols\"))\n\n# Agora você tem\nnames(dados_limpos)\n# [1] \"id_cliente\"  \"nome_do_cliente\"  \"valor_r\"  \n# [4] \"data_compra\"  \"categoria_produto\"  \"percent_desconto\""
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#janitor-tabelas-elegantes",
    "href": "cafecomr/posts/09_12_dose5.html#janitor-tabelas-elegantes",
    "title": "Café com R",
    "section": "janitor: Tabelas elegantes",
    "text": "janitor: Tabelas elegantes\n\n# Criar tabela de contingência profissional\nmtcars %&gt;% \n  tabyl(cyl, gear) %&gt;% \n  adorn_totals(c(\"row\", \"col\")) %&gt;% \n  adorn_percentages(\"row\") %&gt;% \n  adorn_pct_formatting(digits = 1) %&gt;% \n  adorn_ns() %&gt;% \n  adorn_title(\"combined\")\n\n#  cyl/gear      3        4        5     Total\n#          4  6.7%    66.7%    26.7%  100.0% (15)\n#          6 28.6%    57.1%    14.3%  100.0% (7)\n#          8 85.7%     0.0%    14.3%  100.0% (14)\n#      Total 41.7%    33.3%    25.0%  100.0% (36)\n\nPerfeito para relatórios e apresentações!"
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#fluxo-de-trabalho-com-janitor",
    "href": "cafecomr/posts/09_12_dose5.html#fluxo-de-trabalho-com-janitor",
    "title": "Café com R",
    "section": "Fluxo de trabalho com janitor",
    "text": "Fluxo de trabalho com janitor\nExemplo rotina, claro cada situação é uma, lembre-se:\n\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(skimr)\n\n# 1. Importar\ndados &lt;- read_csv(\"dados_novos.csv\")\n\n# 2. Limpar nomes\ndados &lt;- dados %&gt;% clean_names()\n\n# 3. Remover vazios\ndados &lt;- dados %&gt;% remove_empty(c(\"rows\", \"cols\"))\n\n# 4. Explorar\nskim(dados)\n\n# 5. Checar duplicados\ndados %&gt;% get_dupes()"
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#a-força-da-comunidade-r",
    "href": "cafecomr/posts/09_12_dose5.html#a-força-da-comunidade-r",
    "title": "Café com R",
    "section": "A força da comunidade R",
    "text": "A força da comunidade R\nUma das coisas mais lindas do R é sua comunidade acolhedora e colaborativa.\n\nPessoas ao redor do mundo compartilham conhecimento, criam tutoriais, desenvolvem pacotes e ajudam umas às outras todos os dias.\n\n\nNos próximos slides, vou apresentar criadores de conteúdo que admiro e que podem enriquecer muito sua jornada com R."
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#tutoriais-bastián-olea-herrera",
    "href": "cafecomr/posts/09_12_dose5.html#tutoriais-bastián-olea-herrera",
    "title": "Café com R",
    "section": "Tutoriais: Bastián Olea Herrera",
    "text": "Tutoriais: Bastián Olea Herrera\nBastián Olea Herrera\nSociólogo | Chile"
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#por-que-seguir-bastián",
    "href": "cafecomr/posts/09_12_dose5.html#por-que-seguir-bastián",
    "title": "Café com R",
    "section": "Por que seguir Bastián?",
    "text": "Por que seguir Bastián?\nBastián é sociólogo chileno que cria tutoriais excepcionais em R, especialmente focados em:\nÁreas de destaque:\n\nVisualização de dados sociais\nAnálise de dados públicos\nShiny apps interativos\nMapas e análise espacial\n\nO diferencial: Tutoriais extremamente didáticos, em espanhol, com exemplos práticos usando dados reais latino-americanos."
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#tutoriais-recomendados-de-bastián",
    "href": "cafecomr/posts/09_12_dose5.html#tutoriais-recomendados-de-bastián",
    "title": "Café com R",
    "section": "Tutoriais recomendados de Bastián",
    "text": "Tutoriais recomendados de Bastián\nPara começar:\n\nVisualización de datos en R: Do básico ao avançado com ggplot2\nMapas interactivos en R: Usando leaflet e sf\nAplicaciones Shiny: Como criar dashboards interativos\nAnálisis de encuestas: Trabalhando com dados de pesquisas\n\n\nDica: Mesmo que alguns tutoriais estejam em espanhol, o código é universal. Vale muito a pena explorar!"
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#newsletter-david-keys",
    "href": "cafecomr/posts/09_12_dose5.html#newsletter-david-keys",
    "title": "Café com R",
    "section": "Newsletter: David Keys",
    "text": "Newsletter: David Keys\nDavid Keys\nFundador do R for the Rest of Us"
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#whats-new-in-r",
    "href": "cafecomr/posts/09_12_dose5.html#whats-new-in-r",
    "title": "Café com R",
    "section": "What’s New in R",
    "text": "What’s New in R\nDavid Keys mantém uma das newsletters mais úteis sobre R: What’s New in R.\nO que você encontra:\n\nNovidades de pacotes lançados recentemente\nTutoriais práticos e diretos ao ponto\nDicas de produtividade\nRecursos da comunidade\nVagas de emprego em R"
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#whats-new-in-r-1",
    "href": "cafecomr/posts/09_12_dose5.html#whats-new-in-r-1",
    "title": "Café com R",
    "section": "What’s New in R",
    "text": "What’s New in R\nFrequência: Semanal, com conteúdo sempre relevante e bem curado.\nPor que assinar: É a forma mais fácil de se manter atualizado sem se sentir sobrecarregado.\nrfortherestofus.com/blog"
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#r-for-the-rest-of-us",
    "href": "cafecomr/posts/09_12_dose5.html#r-for-the-rest-of-us",
    "title": "Café com R",
    "section": "R for the Rest of Us",
    "text": "R for the Rest of Us\nAlém da newsletter, David criou uma plataforma completa de aprendizado:\nRecursos disponíveis:\n\nCursos online: Do básico ao avançado\nTemplates prontos: Relatórios e apresentações\nConsultoria: Para organizações que querem adotar R\nComunidade: Fórum ativo de alunos\n\nFilosofia: “R para o resto de nós” — torna R acessível para quem não é programador de formação, como pesquisadores, analistas e profissionais de diversas áreas."
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#blog-posit",
    "href": "cafecomr/posts/09_12_dose5.html#blog-posit",
    "title": "Café com R",
    "section": "Blog: Posit",
    "text": "Blog: Posit\n\n\n\n\n\n\nO coração do ecossistema R\nposit.co/blog"
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#por-que-acompanhar-o-posit-blog",
    "href": "cafecomr/posts/09_12_dose5.html#por-que-acompanhar-o-posit-blog",
    "title": "Café com R",
    "section": "Por que acompanhar o Posit Blog?",
    "text": "Por que acompanhar o Posit Blog?\nA Posit (antiga RStudio) é a empresa por trás das principais ferramentas do ecossistema R.\nConteúdo do blog:\n\nLançamentos oficiais: Novas versões do RStudio, Quarto, Shiny\nTutoriais técnicos: Escritos por desenvolvedores dos pacotes\nCasos de uso: Como empresas usam R em produção\nWebinars e eventos: Anúncios e materiais\nBoas práticas: Padrões da indústria"
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#posit-cheatsheets",
    "href": "cafecomr/posts/09_12_dose5.html#posit-cheatsheets",
    "title": "Café com R",
    "section": "Posit Cheatsheets",
    "text": "Posit Cheatsheets\nFolhas de Dicas\n\n\n\n\n\nReferência rápida para tudo\nposit.co/resources/cheatsheets"
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#o-que-são-as-cheatsheets",
    "href": "cafecomr/posts/09_12_dose5.html#o-que-são-as-cheatsheets",
    "title": "Café com R",
    "section": "O que são as Cheatsheets?",
    "text": "O que são as Cheatsheets?\nCheatsheets (folhas de cola) são guias visuais de 1-2 páginas que resumem as funções e sintaxe dos principais pacotes do R."
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#o-que-são-as-cheatsheets-1",
    "href": "cafecomr/posts/09_12_dose5.html#o-que-são-as-cheatsheets-1",
    "title": "Café com R",
    "section": "O que são as Cheatsheets?",
    "text": "O que são as Cheatsheets?\nDisponíveis para:\n\nBásico: Base R, RStudio IDE\nTidyverse: dplyr, ggplot2, tidyr, purrr, stringr\nDados: readr, lubridate, forcats\nModelagem: caret, tidymodels\nVisualização: ggplot2, shiny, leaflet\nComunicação: R Markdown, Quarto\nE muito mais!"
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#como-usar-as-cheatsheets-efetivamente",
    "href": "cafecomr/posts/09_12_dose5.html#como-usar-as-cheatsheets-efetivamente",
    "title": "Café com R",
    "section": "Como usar as Cheatsheets efetivamente",
    "text": "Como usar as Cheatsheets efetivamente\nEstratégias de uso:\n\nImprima as essenciais: Deixe ao lado do computador\nSalve no computador: Organize por pasta de projetos\nConsulte durante o código: Tenha sempre abertas em outra tela\nUse para aprender: Descubra funções que você não conhecia"
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#a-jornada-do-aprendizado-contínuo",
    "href": "cafecomr/posts/09_12_dose5.html#a-jornada-do-aprendizado-contínuo",
    "title": "Café com R",
    "section": "A jornada do aprendizado contínuo",
    "text": "A jornada do aprendizado contínuo\nChegamos ao final dessa edição, mas essa é apenas uma pausa no nosso café, não um adeus.\nO que levamos daqui:\n\n4 eventos imperdíveis para 2026\n400 + livros gratuitos para explorar\n2 pacotes que vão transformar seu fluxo de trabalho\n3 criadores de conteúdo incríveis para seguir\nFerramentas de referência sempre à mão"
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#a-jornada-do-aprendizado-contínuo-1",
    "href": "cafecomr/posts/09_12_dose5.html#a-jornada-do-aprendizado-contínuo-1",
    "title": "Café com R",
    "section": "A jornada do aprendizado contínuo",
    "text": "A jornada do aprendizado contínuo\nMas mais importante que os recursos: Levamos a certeza de que não estamos sozinhos nessa jornada. A comunidade R é global, acolhedora e está sempre crescendo.\n\nAllisson Horst."
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#seu-próximo-passo",
    "href": "cafecomr/posts/09_12_dose5.html#seu-próximo-passo",
    "title": "Café com R",
    "section": "Seu próximo passo",
    "text": "Seu próximo passo\nNão deixe esse conhecimento parado. Escolha APENAS UMA ação para esta semana:\nOpções:\n\nInstalar e testar o pacote skimr no seu próximo projeto\nInscrever-se em um dos eventos de 2026\nExplorar um livro do Big Book of R\nSeguir um dos criadores recomendados\nBaixar 3 cheatsheets essenciais"
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#lembre-se",
    "href": "cafecomr/posts/09_12_dose5.html#lembre-se",
    "title": "Café com R",
    "section": "Lembre-se",
    "text": "Lembre-se\n\nProgresso consistente vale mais que perfeição. Um gole de cada vez.\n\n\nCriei esse espaço par isso! Respire, pare, pense, continue, respeite-se!"
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#feedback",
    "href": "cafecomr/posts/09_12_dose5.html#feedback",
    "title": "Café com R",
    "section": "Feedback",
    "text": "Feedback\nSeu feedback importa!\n\nTem sugestões de temas? Quer compartilhar seu projeto?\nQuer ver algum pacote específico na próxima edição?\n\nResponda essa newsletter ou me envie uma mensagem (LinkedIn). Adoro ouvir de vocês!"
  },
  {
    "objectID": "cafecomr/posts/09_12_dose5.html#assine-o-café-com-r-1",
    "href": "cafecomr/posts/09_12_dose5.html#assine-o-café-com-r-1",
    "title": "Café com R",
    "section": "☕ Assine o Café com R",
    "text": "☕ Assine o Café com R\nFique por dentro das aulas, conteúdos, newsletter!\nQue cada gole desperte uma nova ideia.\nQue cada script abra uma nova conversa.\nQue o Café com R, se torne um ponto de encontro nosso!\n\nJenni"
  },
  {
    "objectID": "cafecomr/posts/02_12_dose4.html",
    "href": "cafecomr/posts/02_12_dose4.html",
    "title": "Café da Semana☕",
    "section": "",
    "text": "Seja bem-vinda(o)!\n\n\n\nAqui é uma pausa para falar de dados.\nToda semana vamos nos encontrar por aqui para conversar sobre ciência de dados, estatística e muito mais de um jeito leve e prático.\nToda semana, uma dose de código, reflexão e boas ideias com R, um café de aprendizagem por vez."
  },
  {
    "objectID": "cafecomr/posts/02_12_dose4.html#esta-é-a-quarta-edição-do-café-com-r",
    "href": "cafecomr/posts/02_12_dose4.html#esta-é-a-quarta-edição-do-café-com-r",
    "title": "Café da Semana☕",
    "section": "",
    "text": "Seja bem-vinda(o)!\n\n\n\nAqui é uma pausa para falar de dados.\nToda semana vamos nos encontrar por aqui para conversar sobre ciência de dados, estatística e muito mais de um jeito leve e prático.\nToda semana, uma dose de código, reflexão e boas ideias com R, um café de aprendizagem por vez."
  },
  {
    "objectID": "cafecomr/posts/02_12_dose4.html#sobre-a-newsletter-de-hoje",
    "href": "cafecomr/posts/02_12_dose4.html#sobre-a-newsletter-de-hoje",
    "title": "Café da Semana☕",
    "section": "Sobre a Newsletter de hoje",
    "text": "Sobre a Newsletter de hoje\n\nPessoal, trouxe pacotes variados que uso no dia a dia para diferentes etapas do trabalho com dados.\n\n\nPreparei esta edição pensando em você que quer conhecer as ferramentas certas para cada etapa do seu trabalho com dados. Não adianta ter o melhor café se não temos os utensílios certos para prepará-lo, não é mesmo? Hoje vamos da semente à xícara para explorar o ecossistema de pacotes do R que realmente fazem diferença no dia a dia. Espero que seja útil para você ou para alguém que conheça!\nOrganizei os pacotes por área de aplicação: desde a importação dos dados até a modelagem avançada, passando pela limpeza, transformação e visualização. Cada fpacote foi escolhido porque resolve problemas reais e torna o trabalho mais eficiente e reproduzível.\nNa Dose da Semana, você vai encontrar exemplos práticos de cada pacote, com código funcional que você pode adaptar aos seus projetos.\nE no quadro Para Acompanhar o Café, selecionei recursos e documentações que vão aprofundar seu conhecimento em cada área.\n\n\nÓtima leitura!\nAhhh pega seu café aí!\n\n\n\n\nEssa é a minha gatinha meguy, piscando para você!"
  },
  {
    "objectID": "cafecomr/posts/02_12_dose4.html#pacotes-essenciais-no-r",
    "href": "cafecomr/posts/02_12_dose4.html#pacotes-essenciais-no-r",
    "title": "Café da Semana☕",
    "section": "Pacotes essenciais no R",
    "text": "Pacotes essenciais no R\n\ntidyr : Organizando seus dados\nO tidyr é o pacote especialista em transformar dados “bagunçados” em formato tidy (organizado). Se você já recebeu planilhas com dados espalhados por várias colunas quando deveriam estar em linhas (ou vice-versa), este é o pacote que vai salvar seu dia.\nPrincipais funções:\n\npivot_longer(): transforma dados de formato “wide” para “long”\npivot_wider(): o inverso, de “long” para “wide”\nseparate(): separa uma coluna em várias\nunite(): une várias colunas em uma\ndrop_na(): remove linhas com valores faltantes\n\nExemplo:\n\n\nCode\nlibrary(tidyr)\nlibrary(dplyr)\n\n# Dados em formato \"wide\"\ndados_wide &lt;- tibble(\n  planta = c(\"A\", \"B\", \"C\"),\n  jan = c(12, 15, 14),\n  fev = c(13, 16, 15),\n  mar = c(14, 17, 16)\n)\n\n# Transformando para formato \"long\" (tidy)\ndados_long &lt;- dados_wide |&gt;\n  pivot_longer(\n    cols = jan:mar,\n    names_to = \"mes\",\n    values_to = \"crescimento\")\n\nprint(dados_long)\n\n\n# A tibble: 9 × 3\n  planta mes   crescimento\n  &lt;chr&gt;  &lt;chr&gt;       &lt;dbl&gt;\n1 A      jan            12\n2 A      fev            13\n3 A      mar            14\n4 B      jan            15\n5 B      fev            16\n6 B      mar            17\n7 C      jan            14\n8 C      fev            15\n9 C      mar            16\n\n\nQuando usar: Sempre que seus dados não estiverem no formato “uma observação por linha, uma variável por coluna”. Fundamental antes de qualquer análise ou visualização.\nSalve já essas funções se você ainda não usa!\n\n\n\nreadr: Importação de dados\nO readr é o pacote do tidyverse para ler e escrever dados tabulares. Ele é muito mais rápido e consistente que as funções base do R, além de detectar automaticamente os tipos de dados.\nPrincipais funções:\n\nread_csv(): lê arquivos CSV\nread_delim(): lê arquivos com delimitadores customizados\nread_tsv(): lê arquivos separados por tabulação\nwrite_csv(): escreve arquivos CSV\nread_rds() / write_rds(): formato nativo do R\n\nExemplo:\n\n\nCode\nlibrary(readr)\n\n# Lendo um CSV\ndados &lt;- read_csv(\"meus_dados.csv\")\n\n# Especificando tipos de coluna\ndados &lt;- read_csv(\n  \"meus_dados.csv\",\n  col_types = cols(\n    id = col_integer(),\n    nome = col_character(),\n    data = col_date(format = \"%Y-%m-%d\"),\n    valor = col_double()))\n\n# Salvando processamento\nwrite_csv(dados_processados, \"dados_limpos.csv\")\n\n# Salvando em formato R nativo (mais rápido)\nwrite_rds(dados_processados, \"dados.rds\")\n\n\nQuando usar: Logo no início de qualquer projeto, na importação dos dados. Economiza tempo e evita problemas de encoding e tipos de dados.\n\n\n\nstringr : Manipulação de textos\nO stringr torna a manipulação de strings no R muito mais intuitiva. Todas as funções começam com str_ e trabalham de forma consistente, diferente das funções base do R.\nPrincipais funções:\n\nstr_detect(): detecta padrões\nstr_extract(): extrai padrões\nstr_replace(): substitui texto\nstr_trim(): remove espaços\nstr_to_lower() / str_to_upper(): converte maiúsculas/minúsculas\n\nExemplo:\n\n\nCode\nlibrary(stringr)\n\n\nWarning: pacote 'stringr' foi compilado no R versão 4.5.2\n\n\nCode\n# Limpeza de nomes\nnomes &lt;- c(\"  Maria Silva  \", \"JOÃO SANTOS\", \"Ana_Paula\")\n\nnomes_limpos &lt;- nomes |&gt;\n  str_trim() |&gt;                    # Remove espaços\n  str_to_title() |&gt;                # Padroniza capitalização\n  str_replace_all(\"_\", \" \")        # Substitui underscores\n\nprint(nomes_limpos)\n\n\n[1] \"Maria Silva\" \"João Santos\" \"Ana paula\"  \n\n\nCode\n# Extração de informações\nemails &lt;- c(\"joao@gmail.com\", \"maria@hotmail.com\", \"invalido\")\n\ndominios &lt;- str_extract(emails, \"(?&lt;=@).*$\")\ntem_email_valido &lt;- str_detect(emails, \"@.*\\\\.\")\n\nprint(dominios)\n\n\n[1] \"gmail.com\"   \"hotmail.com\" NA           \n\n\nCode\nprint(tem_email_valido)\n\n\n[1]  TRUE  TRUE FALSE\n\n\nQuando usar: Sempre que trabalhar com dados textuais : limpeza de nomes, extração de informações, padronização, validação de formatos.\n\n\n\nlubridate : Trabalhando com datas\nO lubridate simplifica completamente o trabalho com datas e horários no R. Parsing, manipulação, extração de componentes : tudo fica mais fácil.\nPrincipais funções:\n\nymd(), dmy(), mdy(): parsing de datas\nyear(), month(), day(): extração de componentes\nfloor_date(), ceiling_date(): arredondamento\nOperações aritméticas com datas\ninterval(), duration(), period(): intervalos de tempo\n\nExemplo:\n\n\nCode\nlibrary(lubridate)\n\n# Parsing de datas em diferentes formatos\ndata1 &lt;- ymd(\"2025-11-29\")\ndata2 &lt;- dmy(\"29/11/2025\")\ndata3 &lt;- mdy(\"11-29-2025\")\n\nprint(paste(\"data1:\", data1))\n\n\n[1] \"data1: 2025-11-29\"\n\n\nCode\nprint(paste(\"data2:\", data2))\n\n\n[1] \"data2: 2025-11-29\"\n\n\nCode\nprint(paste(\"data3:\", data3))\n\n\n[1] \"data3: 2025-11-29\"\n\n\nCode\n# Extração de componentes\nhoje &lt;- today()\nano_atual &lt;- year(hoje)\nmes_atual &lt;- month(hoje, label = TRUE)\ndia_semana &lt;- wday(hoje, label = TRUE)\n\nprint(paste(\"Hoje:\", hoje))\n\n\n[1] \"Hoje: 2026-01-28\"\n\n\nCode\nprint(paste(\"Dia da semana:\", dia_semana))\n\n\n[1] \"Dia da semana: qua\"\n\n\nCode\n# Operações com datas\ninicio &lt;- ymd(\"2025-01-01\")\nfim &lt;- ymd(\"2025-12-31\")\ndias_decorridos &lt;- as.numeric(fim - inicio)\n\nprint(paste(\"Dias no ano:\", dias_decorridos))\n\n\n[1] \"Dias no ano: 364\"\n\n\nQuando usar: Séries temporais, análise de eventos, cálculos de prazos, agrupamentos temporais.\n\n\n\nggplot2 : Visualização de dados\nO ggplot2 é o padrão-ouro para visualização de dados no R. Baseado na “gramática de gráficos”, permite criar visualizações sofisticadas de forma incremental e intuitiva.\nPrincipais componentes:\n\nggplot(): inicializa o gráfico\naes(): mapeamento estético (x, y, color, etc.)\ngeom_*(): tipo de gráfico (point, line, bar, etc.)\nfacet_*(): painéis múltiplos\ntheme_*(): aparência geral\nscale_*(): controle de escalas\n\nExemplo:\n\n\nCode\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Usando dados CO2 do R\ndata(CO2)\n\n# Gráfico de dispersão com linha de tendência\nggplot(CO2, aes(x = conc, y = uptake, color = Type)) +\n  geom_point(alpha = 0.6, size = 2) +\n  geom_smooth(method = \"loess\", se = TRUE) +\n  facet_wrap(~Treatment) +\n  scale_color_manual(values = c(\"#224573\", \"#6B4F4F\")) +\n  theme_classic() +\n  labs(\n    title = \"Absorção de CO2 por concentração\",\n    x = \"Concentração de CO2 (mL/L)\",\n    y = \"Absorção de CO2\",\n    color = \"Tipo\", \n    caption = \"Jennifer Lopes - Café com R.\")\n\n\n\n\n\n\n\n\n\nQuando usar: Sempre! Visualização é fundamental em todas as etapas: exploração, análise e comunicação de resultados.\n\n\n\ndata.table : Performance com grandes volumes\nPara quem trabalha com datasets grandes, o data.table é imbatível em velocidade. Sua sintaxe concisa pode parecer estranha no início, mas a performance compensa.\nPrincipais características:\n\nExtremamente rápido para filtros, agregações e joins\nModifica dados in-place (economia de memória)\nSintaxe: DT[i, j, by] onde i = linhas, j = colunas, by = agrupamento\nCompatível com dplyr via dtplyr\n\nExemplo:\n\n\nCode\nlibrary(data.table)\n\n# Usando dados mtcars\nDT &lt;- as.data.table(mtcars)\n\n# Filtrar e sumarizar\nresultado &lt;- DT[mpg &gt; 20, \n                .(media_hp = mean(hp),\n                  total = .N), \n                by = .(cyl, am)]\n\nprint(resultado)\n\n\n     cyl    am  media_hp total\n   &lt;num&gt; &lt;num&gt;     &lt;num&gt; &lt;int&gt;\n1:     6     1 110.00000     2\n2:     4     1  81.87500     8\n3:     6     0 110.00000     1\n4:     4     0  84.66667     3\n\n\nCode\n# Criar nova coluna\nDT[, hp_por_cyl := hp / cyl]\n\n# Mostrar primeiras linhas\nhead(DT[, .(mpg, cyl, hp, hp_por_cyl)])\n\n\n     mpg   cyl    hp hp_por_cyl\n   &lt;num&gt; &lt;num&gt; &lt;num&gt;      &lt;num&gt;\n1:  21.0     6   110   18.33333\n2:  21.0     6   110   18.33333\n3:  22.8     4    93   23.25000\n4:  21.4     6   110   18.33333\n5:  18.7     8   175   21.87500\n6:  18.1     6   105   17.50000\n\n\nQuando usar: Datasets com 1 milhão+ de linhas, operações repetitivas, quando performance é crítica.\n\n\n\nQuarto/RMarkdown : Relatórios reproduzíveis\nQuarto é a nova geração de documentos dinâmicos (sucessor do RMarkdown). Permite criar relatórios, apresentações, websites e livros que misturam código, resultados e narrativa.\nPrincipais recursos:\n\nMúltiplos formatos de saída (HTML, PDF, Word, etc.)\nExecução de código R, Python, Julia\nChunks de código configuráveis\nSistema de citações e referências\nTemas e templates customizáveis\n\nExemplo:\n---\ntitle: \"Relatório de Vendas\"\nauthor: \"Seu Nome\"\ndate: today\nformat: \n  html:\n    toc: true\n    theme: cosmo\nexecute:\n  echo: false\n  warning: false\n---\n\n## Análise Mensal\n\n```{r}\n#| label: fig-vendas\n#| fig-cap: \"Evolução das vendas mensais\"\n\nlibrary(ggplot2)\ndata(CO2)\nggplot(CO2, aes(x = conc, y = uptake)) +\n  geom_col(fill = \"#224573\") +\n  theme_minimal()\n```\n\nAs vendas apresentaram crescimento consistente no período.\nQuando usar: Relatórios que precisam ser atualizados regularmente, documentação de análises, compartilhamento de resultados.\n\n\n\nDBI + dbplyr : Conexão com bancos de dados\nTrabalhar diretamente com bancos SQL sem sair do R. O DBI fornece a interface de conexão e o dbplyr traduz código dplyr para SQL.\nPrincipais funções:\n\ndbConnect(): conecta ao banco\ntbl(): referencia uma tabela\ncollect(): traz dados para R\ncompute(): cria tabela temporária\nQueries dplyr traduzidas automaticamente\n\nExemplo:\n\n\nCode\nlibrary(DBI)\nlibrary(dbplyr)\n\n# Conectar ao PostgreSQL\ncon &lt;- dbConnect(\n  RPostgres::Postgres(),\n  dbname = \"vendas\",\n  host = \"localhost\",\n  user = \"usuario\",\n  password = \"senha\"\n)\n\n# Trabalhar com tabela remota\nvendas_db &lt;- tbl(con, \"vendas\")\n\n# Usar dplyr normalmente - operações acontecem no banco\nresultado &lt;- vendas_db |&gt;\n  filter(ano == 2025) |&gt;\n  group_by(produto) |&gt;\n  summarise(total = sum(valor, na.rm = TRUE)) |&gt;\n  collect()  # Traz para R apenas o resultado\n\n# Ver SQL gerado\nvendas_db |&gt;\n  filter(ano == 2025) |&gt;\n  show_query()\n\n# Sempre desconectar ao final\ndbDisconnect(con)\n\n\nQuando usar: Dados armazenados em bancos SQL, datasets muito grandes para carregar na memória.\n\n\n\nDataExplorer : Análise exploratória automática\nO DataExplorer automatiza a análise exploratória de dados (EDA), gerando relatórios completos com estatísticas descritivas, gráficos e diagnósticos.\nPrincipais funções:\n\ncreate_report(): relatório completo automático\nplot_missing(): visualiza dados faltantes\nplot_histogram(): histogramas de todas variáveis\nplot_correlation(): matriz de correlação\nintroduce(): resumo geral do dataset\n\nExemplo:\n\n\nCode\nlibrary(DataExplorer)\n\n# Usando dados iris\ndata(iris)\n\n# Visão geral dos dados\nintro &lt;- introduce(iris)\nprint(intro)\n\n\n  rows columns discrete_columns continuous_columns all_missing_columns\n1  150       5                1                  4                   0\n  total_missing_values complete_rows total_observations memory_usage\n1                    0           150                750         7976\n\n\nCode\n# Visualizar dados faltantes\nplot_missing(iris)\n\n\n\n\n\n\n\n\n\nCode\n# Visualizar distribuições\nplot_histogram(iris)\n\n\n\n\n\n\n\n\n\nQuando usar: Início de projetos, primeiro contato com novos dados, relatórios rápidos para stakeholders.\n\n\n\ntidymodels : Framework de Machine Learning\nO tidymodels é um conjunto de pacotes para modelagem preditiva que segue os princípios do tidyverse. Substitui o antigo caret com uma abordagem mais moderna.\nPrincipais pacotes:\n\nrsample: divisão de dados (treino/teste)\nrecipes: pré-processamento de dados\nparsnip: interface unificada para modelos\nworkflows: pipelines de modelagem\ntune: tuning de hiperparâmetros\nyardstick: métricas de avaliação\n\nExemplo:\n\n\nCode\nlibrary(tidymodels)\n\n# Usando dados iris para classificação\ndata(iris)\n\n# Dividir dados\nset.seed(123)\nsplit &lt;- initial_split(iris, prop = 0.8, strata = Species)\ntreino &lt;- training(split)\nteste &lt;- testing(split)\n\n# Especificar modelo\nmodelo_lr &lt;- logistic_reg() |&gt;\n  set_engine(\"glm\") |&gt;\n  set_mode(\"classification\")\n\n# Treinar modelo simples\najuste &lt;- modelo_lr |&gt;\n  fit(Species ~ Sepal.Length + Sepal.Width, data = treino)\n\n# Prever\npredicoes &lt;- predict(ajuste, teste) |&gt;\n  bind_cols(teste)\n\n# Avaliar acurácia\nacuracia &lt;- predicoes |&gt;\n  accuracy(truth = Species, estimate = .pred_class)\n\nprint(acuracia)\n\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy multiclass     0.667\n\n\nQuando usar: Modelagem preditiva, machine learning, comparação de modelos, tuning automatizado."
  },
  {
    "objectID": "cafecomr/posts/02_12_dose4.html#para-acompanhar-o-café",
    "href": "cafecomr/posts/02_12_dose4.html#para-acompanhar-o-café",
    "title": "Café da Semana☕",
    "section": "Para Acompanhar o Café",
    "text": "Para Acompanhar o Café\n\nRecursos recomendados\nLivros:\n\n\n\n\n\n\n\n\n\n\nSites"
  },
  {
    "objectID": "cafecomr/posts/02_12_dose4.html#reflexão-da-semana",
    "href": "cafecomr/posts/02_12_dose4.html#reflexão-da-semana",
    "title": "Café da Semana☕",
    "section": "Reflexão da Semana",
    "text": "Reflexão da Semana\n\n“A melhor ferramenta é aquela que você domina. Não tente aprender tudo de uma vez, escolha os pacotes que resolvem seus problemas atuais e vá expandindo conforme a necessidade.”\n\nComeçar com o básico (readr, dplyr, ggplot2) já resolve 80% dos problemas do dia a dia. Os demais pacotes você vai incorporando naturalmente conforme seus projetos evoluem."
  },
  {
    "objectID": "cafecomr/posts/02_12_dose4.html#considerações-finais",
    "href": "cafecomr/posts/02_12_dose4.html#considerações-finais",
    "title": "Café da Semana☕",
    "section": "Considerações finais!",
    "text": "Considerações finais!\nEspero que este guia ajude você a escolher as ferramentas certas para cada etapa do seu trabalho com dados. Lembre-se: o importante não é conhecer todos os pacotes, mas usar bem aqueles que fazem sentido para seus projetos.\nCompartilhe este conteúdo com quem está começando em R!\n\n\n☕ Assine o Café com R\n\nQue cada gole desperte uma nova ideia.\nQue cada script abra uma nova conversa.\nQue o Café com R, se torne um ponto de encontro nosso!"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#assine-o-café-com-r",
    "href": "apresentações/posts/visualizacao.html#assine-o-café-com-r",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "☕ Assine o Café com R",
    "text": "☕ Assine o Café com R\nFique por dentro das aulas, conteúdos, newsletter!\n\nQue cada gole desperte uma nova ideia.\nQue cada script abra uma nova conversa.\nQue o Café com R, se torne um ponto de encontro nosso!"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#introdução-à-visualização-de-dados-no-r",
    "href": "apresentações/posts/visualizacao.html#introdução-à-visualização-de-dados-no-r",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Introdução à visualização de dados no R",
    "text": "Introdução à visualização de dados no R\nVisualização é a arte de contar histórias com dados.\nO pacote ggplot2 é a ferramenta mais poderosa para isso no R.\n\nAllison Horst."
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#introdução-à-visualização-de-dados-no-r-1",
    "href": "apresentações/posts/visualizacao.html#introdução-à-visualização-de-dados-no-r-1",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Introdução à visualização de dados no R",
    "text": "Introdução à visualização de dados no R\nVocê aprenderá:\n\nGramática de gráficos (Grammar of Graphics)\nComponentes essenciais do ggplot2\nTipos de gráficos e suas aplicações\nCustomização avançada\nMelhores práticas de visualização"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#por-que-ggplot2",
    "href": "apresentações/posts/visualizacao.html#por-que-ggplot2",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Por que ggplot2?",
    "text": "Por que ggplot2?\nVantagens:\n\nSistema coerente e intuitivo\nGráficos de alta qualidade\nCustomização ilimitada\nIntegração perfeita com tidyverse\nComunidade ativa e recursos abundantes\n\nFilosofia: construir gráficos em camadas"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#carregando-pacotes-e-dados",
    "href": "apresentações/posts/visualizacao.html#carregando-pacotes-e-dados",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Carregando pacotes e dados",
    "text": "Carregando pacotes e dados\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tibble)\n\n# Carregando dados\ndata(CO2)\nCO2 &lt;- CO2 |&gt; as_tibble()\n\n# Definindo paleta de cores\ncores &lt;- c(\"#224573\", \"#6B4F4F\", \"#4A6FA5\", \"#E5D3B3\")"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#o-dataset-co2-revisão-rápida",
    "href": "apresentações/posts/visualizacao.html#o-dataset-co2-revisão-rápida",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "O dataset CO2: revisão rápida",
    "text": "O dataset CO2: revisão rápida\n\nglimpse(CO2)\n\nRows: 84\nColumns: 5\n$ Plant     &lt;ord&gt; Qn1, Qn1, Qn1, Qn1, Qn1, Qn1, Qn1, Qn2, Qn2, Qn2, Qn2, Qn2, …\n$ Type      &lt;fct&gt; Quebec, Quebec, Quebec, Quebec, Quebec, Quebec, Quebec, Queb…\n$ Treatment &lt;fct&gt; nonchilled, nonchilled, nonchilled, nonchilled, nonchilled, …\n$ conc      &lt;dbl&gt; 95, 175, 250, 350, 500, 675, 1000, 95, 175, 250, 350, 500, 6…\n$ uptake    &lt;dbl&gt; 16.0, 30.4, 34.8, 37.2, 35.3, 39.2, 39.7, 13.6, 27.3, 37.1, …\n\n\n84 observações de absorção de CO₂ em plantas de Quebec e Mississippi, sob diferentes tratamentos."
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#gramática-de-gráficos",
    "href": "apresentações/posts/visualizacao.html#gramática-de-gráficos",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Gramática de Gráficos",
    "text": "Gramática de Gráficos\nTodo gráfico no ggplot2 tem três componentes essenciais:\n\nData: os dados a serem visualizados\nAesthetics (aes): mapeamento de variáveis para propriedades visuais\nGeometries (geom): tipo de representação visual\n\nEstrutura básica:\nggplot(data = dados, aes(x = var_x, y = var_y)) +\n  geom_point()"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#primeiro-gráfico-scatter-plot",
    "href": "apresentações/posts/visualizacao.html#primeiro-gráfico-scatter-plot",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Primeiro gráfico: scatter plot",
    "text": "Primeiro gráfico: scatter plot\n\nggplot(CO2, aes(x = conc, y = uptake)) +\n  geom_point()"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#adicionando-cor-por-grupo",
    "href": "apresentações/posts/visualizacao.html#adicionando-cor-por-grupo",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Adicionando cor por grupo",
    "text": "Adicionando cor por grupo\n\nggplot(CO2, aes(x = conc, y = uptake, color = Type)) +\n  geom_point(size = 3) +\n  scale_color_manual(values = c(\"#224573\", \"#6B4F4F\"))"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#adicionando-títulos-e-labels",
    "href": "apresentações/posts/visualizacao.html#adicionando-títulos-e-labels",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Adicionando títulos e labels",
    "text": "Adicionando títulos e labels\n\nggplot(CO2, aes(x = conc, y = uptake, color = Type)) +\n  geom_point(size = 3) +\n  scale_color_manual(values = c(\"#224573\", \"#6B4F4F\")) +\n  labs(\n    title = \"Absorção de CO₂ por Concentração\",\n    x = \"Concentração de CO₂ (mL/L)\",\n    y = \"Absorção de CO₂ (μmol/m²·s)\",\n    color = \"Tipo de Planta\"\n  )"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#aesthetics-mapeamentos-visuais",
    "href": "apresentações/posts/visualizacao.html#aesthetics-mapeamentos-visuais",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Aesthetics: mapeamentos visuais",
    "text": "Aesthetics: mapeamentos visuais\nPrincipais aesthetics:\n\nx, y: posição nos eixos\ncolor: cor de pontos/linhas\nfill: preenchimento de áreas\nsize: tamanho\nshape: forma dos pontos\nalpha: transparência\nlinetype: tipo de linha"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#exemplo-múltiplos-aesthetics",
    "href": "apresentações/posts/visualizacao.html#exemplo-múltiplos-aesthetics",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Exemplo: múltiplos aesthetics",
    "text": "Exemplo: múltiplos aesthetics\n\nggplot(CO2, aes(x = conc, y = uptake, \n                color = Type, shape = Treatment)) +\n  geom_point(size = 3, alpha = 0.7) +\n  scale_color_manual(values = c(\"#224573\", \"#6B4F4F\"))"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#geometrias-geom_point",
    "href": "apresentações/posts/visualizacao.html#geometrias-geom_point",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Geometrias: geom_point()",
    "text": "Geometrias: geom_point()\nScatter plots mostram relação entre duas variáveis contínuas.\nQuando usar:\n\nCorrelações\nDistribuições bivariadas\nIdentificar outliers\nPadrões e tendências\n\nCustomização: size, shape, alpha, color"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#geometrias-geom_line",
    "href": "apresentações/posts/visualizacao.html#geometrias-geom_line",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Geometrias: geom_line()",
    "text": "Geometrias: geom_line()\n\nggplot(CO2, aes(x = conc, y = uptake, \n                color = Plant, group = Plant)) +\n  geom_line(linewidth = 1, alpha = 0.7) +\n  scale_color_manual(values = rep(cores, length.out = 12))"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#combinando-geometrias",
    "href": "apresentações/posts/visualizacao.html#combinando-geometrias",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Combinando geometrias",
    "text": "Combinando geometrias\n\nggplot(CO2, aes(x = conc, y = uptake, color = Type)) +\n  geom_point(size = 2, alpha = 0.6) +\n  geom_smooth(method = \"loess\", se = TRUE, linewidth = 1.5) +\n  scale_color_manual(values = c(\"#224573\", \"#6B4F4F\"))"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#geom_smooth-tendências",
    "href": "apresentações/posts/visualizacao.html#geom_smooth-tendências",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "geom_smooth(): tendências",
    "text": "geom_smooth(): tendências\nMétodos disponíveis:\n\n\"loess\": suavização local (padrão para n &lt; 1000)\n\"lm\": regressão linear\n\"glm\": modelos lineares generalizados\n\"gam\": modelos aditivos generalizados\n\nParâmetros:\n\nse: mostrar intervalo de confiança\nmethod: método de ajuste\nformula: fórmula customizada"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#gráfico-de-barras-geom_col",
    "href": "apresentações/posts/visualizacao.html#gráfico-de-barras-geom_col",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Gráfico de barras: geom_col()",
    "text": "Gráfico de barras: geom_col()\n\nCO2 |&gt;\n  group_by(Type, Treatment) |&gt;\n  summarise(media = mean(uptake), .groups = \"drop\") |&gt;\n  ggplot(aes(x = Type, y = media, fill = Treatment)) +\n  geom_col(position = \"dodge\", width = 0.7) +\n  scale_fill_manual(values = c(\"#224573\", \"#6B4F4F\"))"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#adicionando-barras-de-erro",
    "href": "apresentações/posts/visualizacao.html#adicionando-barras-de-erro",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Adicionando barras de erro",
    "text": "Adicionando barras de erro\n\nCO2 |&gt;\n  group_by(Type, Treatment) |&gt;\n  summarise(media = mean(uptake), se = sd(uptake)/sqrt(n()), \n            .groups = \"drop\") |&gt;\n  ggplot(aes(x = Type, y = media, fill = Treatment)) +\n  geom_col(position = position_dodge(0.7), width = 0.6) +\n  geom_errorbar(aes(ymin = media - se, ymax = media + se),\n                position = position_dodge(0.7), width = 0.2) +\n  scale_fill_manual(values = c(\"#224573\", \"#6B4F4F\"))"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#boxplots-distribuições",
    "href": "apresentações/posts/visualizacao.html#boxplots-distribuições",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Boxplots: distribuições",
    "text": "Boxplots: distribuições\n\nggplot(CO2, aes(x = Type, y = uptake, fill = Type)) +\n  geom_boxplot(alpha = 0.7, outlier.color = \"#6B4F4F\", \n               outlier.size = 3) +\n  scale_fill_manual(values = c(\"#224573\", \"#4A6FA5\")) +\n  labs(title = \"Distribuição da Absorção de CO₂\",\n       x = \"Tipo de Planta\", y = \"Absorção\")"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#violin-plots-densidade",
    "href": "apresentações/posts/visualizacao.html#violin-plots-densidade",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Violin plots: densidade",
    "text": "Violin plots: densidade\n\nggplot(CO2, aes(x = Type, y = uptake, fill = Type)) +\n  geom_violin(alpha = 0.7, trim = FALSE) +\n  geom_boxplot(width = 0.2, fill = \"white\", alpha = 0.8) +\n  scale_fill_manual(values = c(\"#224573\", \"#4A6FA5\")) +\n  labs(title = \"Distribuição Detalhada da Absorção\")"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#comparando-boxplot-e-violin",
    "href": "apresentações/posts/visualizacao.html#comparando-boxplot-e-violin",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Comparando boxplot e violin",
    "text": "Comparando boxplot e violin\nBoxplot:\n\nQuartis e mediana\nOutliers claramente marcados\nCompacto e claro\n\nViolin plot:\n\nDensidade completa da distribuição\nMostra bimodalidade\nMais informativo, mas requer mais espaço"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#facetas-facet_wrap",
    "href": "apresentações/posts/visualizacao.html#facetas-facet_wrap",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Facetas: facet_wrap()",
    "text": "Facetas: facet_wrap()\n\nggplot(CO2, aes(x = conc, y = uptake, color = Type)) +\n  geom_point(size = 2) +\n  geom_smooth(method = \"loess\", se = FALSE) +\n  facet_wrap(~Treatment, ncol = 2) +\n  scale_color_manual(values = c(\"#224573\", \"#6B4F4F\")) +\n  labs(title = \"Efeito do Tratamento na Absorção\")"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#facetas-facet_grid",
    "href": "apresentações/posts/visualizacao.html#facetas-facet_grid",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Facetas: facet_grid()",
    "text": "Facetas: facet_grid()\n\nggplot(CO2, aes(x = conc, y = uptake)) +\n  geom_point(color = \"#224573\", size = 2) +\n  geom_smooth(method = \"lm\", color = \"#6B4F4F\") +\n  facet_grid(Type ~ Treatment) +\n  labs(title = \"Absorção: Tipo x Tratamento\")"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#diferença-wrap-x-grid",
    "href": "apresentações/posts/visualizacao.html#diferença-wrap-x-grid",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Diferença: wrap x grid",
    "text": "Diferença: wrap x grid\nfacet_wrap():\n\nUma variável de agrupamento\nLayout flexível (controle de colunas)\nMelhor para muitos níveis\n\nfacet_grid():\n\nDuas variáveis (linhas e colunas)\nGrid estruturado\nFacilita comparações cruzadas"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#histogramas-distribuição-univariada",
    "href": "apresentações/posts/visualizacao.html#histogramas-distribuição-univariada",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Histogramas: distribuição univariada",
    "text": "Histogramas: distribuição univariada\n\nggplot(CO2, aes(x = uptake, fill = Type)) +\n  geom_histogram(bins = 15, alpha = 0.7, \n                 position = \"identity\") +\n  scale_fill_manual(values = c(\"#224573\", \"#4A6FA5\")) +\n  labs(title = \"Distribuição da Absorção de CO₂\",\n       x = \"Absorção\", y = \"Frequência\")"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#densidade-curvas-suaves",
    "href": "apresentações/posts/visualizacao.html#densidade-curvas-suaves",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Densidade: curvas suaves",
    "text": "Densidade: curvas suaves\n\nggplot(CO2, aes(x = uptake, fill = Type, color = Type)) +\n  geom_density(alpha = 0.5, linewidth = 1.2) +\n  scale_fill_manual(values = c(\"#224573\", \"#4A6FA5\")) +\n  scale_color_manual(values = c(\"#224573\", \"#4A6FA5\")) +\n  labs(title = \"Curvas de Densidade da Absorção\")"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#temas-personalizando-aparência",
    "href": "apresentações/posts/visualizacao.html#temas-personalizando-aparência",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Temas: personalizando aparência",
    "text": "Temas: personalizando aparência\nTemas prontos:\n\ntheme_bw(): fundo branco com grid\ntheme_minimal(): minimalista\ntheme_classic(): clássico (sem grid)\ntheme_dark(): fundo escuro\ntheme_void(): sem elementos"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#aplicando-temas",
    "href": "apresentações/posts/visualizacao.html#aplicando-temas",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Aplicando temas",
    "text": "Aplicando temas\n\nggplot(CO2, aes(x = conc, y = uptake, color = Type)) +\n  geom_point(size = 3) +\n  scale_color_manual(values = c(\"#224573\", \"#6B4F4F\")) +\n  theme_classic() +\n  labs(title = \"Absorção com theme_classic()\")"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#customização-avançada-de-tema",
    "href": "apresentações/posts/visualizacao.html#customização-avançada-de-tema",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Customização avançada de tema",
    "text": "Customização avançada de tema\n\nggplot(CO2, aes(x = conc, y = uptake, color = Type)) +\n  geom_point(size = 3) +\n  scale_color_manual(values = c(\"#224573\", \"#6B4F4F\")) +\n  theme_classic() +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\", \n                              color = \"#224573\"),\n    axis.title = element_text(size = 12, color = \"#224573\"),\n    legend.position = \"top\",\n    panel.grid.minor = element_blank())"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#escalas-de-cores-manuais",
    "href": "apresentações/posts/visualizacao.html#escalas-de-cores-manuais",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Escalas de cores: manuais",
    "text": "Escalas de cores: manuais\n\nggplot(CO2, aes(x = Type, y = uptake, fill = Treatment)) +\n  geom_boxplot(alpha = 0.8) +\n  scale_fill_manual(\n    values = c(\"nonchilled\" = \"#4A6FA5\", \"chilled\" = \"#6B4F4F\"),\n    labels = c(\"Não Resfriado\", \"Resfriado\")) +\n  theme_classic()"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#escalas-de-cores-gradientes",
    "href": "apresentações/posts/visualizacao.html#escalas-de-cores-gradientes",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Escalas de cores: gradientes",
    "text": "Escalas de cores: gradientes\n\nCO2 |&gt;\n  group_by(Plant) |&gt;\n  summarise(media = mean(uptake)) |&gt;\n  ggplot(aes(x = Plant, y = media, fill = media)) +\n  geom_col() +\n  scale_fill_gradient(low = \"#E5D3B3\", high = \"#224573\") +\n  theme_classic()"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#jitter-evitando-sobreposição",
    "href": "apresentações/posts/visualizacao.html#jitter-evitando-sobreposição",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Jitter: evitando sobreposição",
    "text": "Jitter: evitando sobreposição\n\nggplot(CO2, aes(x = Type, y = uptake, color = Type)) +\n  geom_jitter(width = 0.2, alpha = 0.6, size = 2.5) +\n  scale_color_manual(values = c(\"#224573\", \"#6B4F4F\")) +\n  theme_classic() +\n  labs(title = \"Pontos com Jitter\")"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#combinando-boxplot-e-jitter",
    "href": "apresentações/posts/visualizacao.html#combinando-boxplot-e-jitter",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Combinando boxplot e jitter",
    "text": "Combinando boxplot e jitter\n\nggplot(CO2, aes(x = Treatment, y = uptake, fill = Type)) +\n  geom_boxplot(alpha = 0.6, outlier.shape = NA) +\n  geom_jitter(aes(color = Type), width = 0.15, \n              alpha = 0.5, size = 2) +\n  scale_fill_manual(values = c(\"#224573\", \"#4A6FA5\")) +\n  scale_color_manual(values = c(\"#224573\", \"#4A6FA5\")) +\n  theme_classic()"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#anotações-adicionar-texto",
    "href": "apresentações/posts/visualizacao.html#anotações-adicionar-texto",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Anotações: adicionar texto",
    "text": "Anotações: adicionar texto\n\nggplot(CO2, aes(x = conc, y = uptake, color = Type)) +\n  geom_point(size = 2) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  annotate(\"text\", x = 600, y = 45, \n           label = \"Tendência linear\", \n           color = \"#224573\", size = 5) +\n  scale_color_manual(values = c(\"#224573\", \"#6B4F4F\")) +\n  theme_classic()"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#coordenadas-transformações",
    "href": "apresentações/posts/visualizacao.html#coordenadas-transformações",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Coordenadas: transformações",
    "text": "Coordenadas: transformações\n\nggplot(CO2, aes(x = Type, y = uptake, fill = Type)) +\n  geom_boxplot(alpha = 0.7) +\n  coord_flip() +\n  scale_fill_manual(values = c(\"#224573\", \"#4A6FA5\")) +\n  theme_classic() +\n  labs(title = \"Boxplot Horizontal\")"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#limites-dos-eixos",
    "href": "apresentações/posts/visualizacao.html#limites-dos-eixos",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Limites dos eixos",
    "text": "Limites dos eixos\n\nggplot(CO2, aes(x = conc, y = uptake, color = Type)) +\n  geom_point(size = 3) +\n  scale_color_manual(values = c(\"#224573\", \"#6B4F4F\")) +\n  coord_cartesian(xlim = c(200, 800), ylim = c(15, 45)) +\n  theme_classic() +\n  labs(title = \"Zoom: 200-800 mL/L\")"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#gráfico-de-linhas-por-planta",
    "href": "apresentações/posts/visualizacao.html#gráfico-de-linhas-por-planta",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Gráfico de linhas por planta",
    "text": "Gráfico de linhas por planta\n\nggplot(CO2, aes(x = conc, y = uptake, \n                color = Plant, group = Plant)) +\n  geom_line(linewidth = 0.8, alpha = 0.6) +\n  facet_wrap(~Type) +\n  scale_color_manual(values = rep(cores, length.out = 12)) +\n  theme_classic() +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#heatmap-tabela-de-médias",
    "href": "apresentações/posts/visualizacao.html#heatmap-tabela-de-médias",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Heatmap: tabela de médias",
    "text": "Heatmap: tabela de médias\n\nCO2 |&gt;\n  mutate(conc_cat = cut(conc, breaks = 5)) |&gt;\n  group_by(Type, Treatment, conc_cat) |&gt;\n  summarise(media = mean(uptake), .groups = \"drop\") |&gt;\n  ggplot(aes(x = conc_cat, y = interaction(Type, Treatment), \n             fill = media)) +\n  geom_tile(color = \"white\") +\n  scale_fill_gradient(low = \"#E5D3B3\", high = \"#224573\") +\n  theme_classic()"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#gráfico-de-pontos-com-médias",
    "href": "apresentações/posts/visualizacao.html#gráfico-de-pontos-com-médias",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Gráfico de pontos com médias",
    "text": "Gráfico de pontos com médias\n\nggplot(CO2, aes(x = Treatment, y = uptake, color = Type)) +\n  geom_jitter(width = 0.2, alpha = 0.4, size = 2) +\n  stat_summary(fun = mean, geom = \"point\", \n               size = 5, shape = 18) +\n  stat_summary(fun = mean, geom = \"line\", \n               aes(group = Type), linewidth = 1) +\n  scale_color_manual(values = c(\"#224573\", \"#6B4F4F\")) +\n  theme_classic()"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#gráfico-complexo-multiple-layers",
    "href": "apresentações/posts/visualizacao.html#gráfico-complexo-multiple-layers",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Gráfico complexo: multiple layers",
    "text": "Gráfico complexo: multiple layers\n\nggplot(CO2, aes(x = conc, y = uptake)) +\n  geom_point(aes(color = Type), size = 2, alpha = 0.5) +\n  geom_smooth(method = \"loess\", color = \"#224573\", \n              fill = \"#E5D3B3\", alpha = 0.3) +\n  facet_wrap(~Treatment) +\n  scale_color_manual(values = c(\"#224573\", \"#6B4F4F\")) +\n  theme_classic() +\n  labs(title = \"Análise Completa: Absorção por Concentração\",\n       x = \"Concentração de CO₂ (mL/L)\",\n       y = \"Absorção de CO₂ (μmol/m²·s)\")"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#salvando-gráficos",
    "href": "apresentações/posts/visualizacao.html#salvando-gráficos",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Salvando gráficos",
    "text": "Salvando gráficos\n# Criar gráfico\np &lt;- ggplot(CO2, aes(x = conc, y = uptake, color = Type)) +\n  geom_point(size = 3) +\n  scale_color_manual(values = c(\"#224573\", \"#6B4F4F\")) +\n  theme_classic()\n\n# Salvar\nggsave(\"meu_grafico.png\", p, \n       width = 10, height = 6, dpi = 300)\nFormatos: PNG, PDF, SVG, JPEG"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#melhores-práticas",
    "href": "apresentações/posts/visualizacao.html#melhores-práticas",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Melhores práticas",
    "text": "Melhores práticas\nDo’s:\n\nUse títulos descritivos e informativos\nSempre rotule eixos com unidades\nEscolha cores acessíveis\nMantenha simplicidade quando possível\nUse legenda quando necessário"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#melhores-práticas-1",
    "href": "apresentações/posts/visualizacao.html#melhores-práticas-1",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Melhores práticas",
    "text": "Melhores práticas\nDon’ts:\n\nNão sobrecarregue com informação\nEvite 3D desnecessário\nNão use muitas cores diferentes\nEvite eixos cortados sem motivo"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#gráfico-para-publicação",
    "href": "apresentações/posts/visualizacao.html#gráfico-para-publicação",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Gráfico para publicação",
    "text": "Gráfico para publicação\n\nCO2 |&gt;\n  group_by(Type, Treatment) |&gt;\n  summarise(media = mean(uptake), se = sd(uptake)/sqrt(n()), \n            .groups = \"drop\") |&gt;\n  ggplot(aes(x = Type, y = media, fill = Treatment)) +\n  geom_col(position = position_dodge(0.8), width = 0.7) +\n  geom_errorbar(aes(ymin = media - se, ymax = media + se),\n                position = position_dodge(0.8), width = 0.25) +\n  scale_fill_manual(values = c(\"#224573\", \"#6B4F4F\"),\n                    labels = c(\"Resfriado\", \"Não Resfriado\")) +\n  theme_minimal(base_size = 14) +\n  labs(y = \"Absorção média ± EP (μmol/m²·s)\", x = NULL)"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#recursos-avançados-patchwork",
    "href": "apresentações/posts/visualizacao.html#recursos-avançados-patchwork",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Recursos avançados: patchwork",
    "text": "Recursos avançados: patchwork\nlibrary(patchwork)\n\np1 &lt;- ggplot(CO2, aes(x = uptake)) + \n  geom_histogram(fill = \"#224573\")\n\np2 &lt;- ggplot(CO2, aes(x = Type, y = uptake)) + \n  geom_boxplot(fill = \"#4A6FA5\")\n\np1 + p2  # combina lado a lado\nPatchwork permite combinar múltiplos gráficos facilmente."
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#extensões-do-ggplot2",
    "href": "apresentações/posts/visualizacao.html#extensões-do-ggplot2",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Extensões do ggplot2",
    "text": "Extensões do ggplot2\nPacotes úteis:\n\nggrepel: labels sem sobreposição\ngganimate: gráficos animados\nggridges: ridge plots\nggforce: geometrias extras\ncowplot: composição de gráficos\npatchwork: combinar plots"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#exemplo-com-ggrepel",
    "href": "apresentações/posts/visualizacao.html#exemplo-com-ggrepel",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Exemplo com ggrepel",
    "text": "Exemplo com ggrepel\nlibrary(ggrepel)\n\nCO2 |&gt;\n  group_by(Plant) |&gt;\n  summarise(media = mean(uptake), conc = mean(conc)) |&gt;\n  ggplot(aes(x = conc, y = media, label = Plant)) +\n  geom_point(color = \"#224573\", size = 3) +\n  geom_text_repel(color = \"#6B4F4F\") +\n  theme_minimal()"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#gráfico-interativo-com-plotly",
    "href": "apresentações/posts/visualizacao.html#gráfico-interativo-com-plotly",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Gráfico interativo com plotly",
    "text": "Gráfico interativo com plotly\n\n\n\n\n\n\nInteratividade: hover, zoom, pan automáticos!"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#dicas-finais-debugging",
    "href": "apresentações/posts/visualizacao.html#dicas-finais-debugging",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Dicas finais: debugging",
    "text": "Dicas finais: debugging\nConstrua incrementalmente:\n# Passo 1\nggplot(CO2, aes(x = conc, y = uptake))\n\n# Passo 2\nggplot(CO2, aes(x = conc, y = uptake)) +\n  geom_point()\n\n# Passo 3\nggplot(CO2, aes(x = conc, y = uptake)) +\n  geom_point() +\n  theme_minimal()"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#recursos-para-aprender-mais",
    "href": "apresentações/posts/visualizacao.html#recursos-para-aprender-mais",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Recursos para aprender mais",
    "text": "Recursos para aprender mais\nDocumentação e tutoriais:\n\nSite oficial: https://ggplot2.tidyverse.org\nR Graphics Cookbook\nggplot2: Elegant Graphics for Data Analysis\nCheat sheet do RStudio"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#recursos-para-aprender-mais-1",
    "href": "apresentações/posts/visualizacao.html#recursos-para-aprender-mais-1",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Recursos para aprender mais",
    "text": "Recursos para aprender mais\nComunidade:\n\nR-Ladies Goiânia\nComunidade de Estatística - Thiago Marques\nStack Overflow\nR4DS Online Learning Community\nTwitter: #rstats, #TidyTuesday"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#considerações-finais",
    "href": "apresentações/posts/visualizacao.html#considerações-finais",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Considerações finais",
    "text": "Considerações finais\nVocê aprendeu:\n\nGramática de gráficos e filosofia do ggplot2\nComponentes essenciais: data, aes, geom\nPrincipais tipos de gráficos\nCustomização e temas\nFacetas e composição\nMelhores práticas de visualização"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#próximos-passos",
    "href": "apresentações/posts/visualizacao.html#próximos-passos",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Próximos passos",
    "text": "Próximos passos\nContinue praticando:\n\nExperimente com seus próprios dados\nExplore diferentes geometrias\nTeste temas e personalizações\nParticipe do #TidyTuesday\nCombine com dplyr para pipelines completos\nAprenda extensões como patchwork e gganimate\n\nLembre-se: a melhor forma de aprender é fazendo!"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#referências",
    "href": "apresentações/posts/visualizacao.html#referências",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Referências",
    "text": "Referências\n\nWickham, H. ggplot2: Elegant Graphics for Data Analysis\nChang, W. R Graphics Cookbook\nHealy, K. Data Visualization: A Practical Introduction\nDocumentação oficial: https://ggplot2.tidyverse.org\nGaleria de gráficos: https://r-graph-gallery.com"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#muito-obrigada",
    "href": "apresentações/posts/visualizacao.html#muito-obrigada",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "Muito Obrigada!",
    "text": "Muito Obrigada!\nÉ OPEN, USE, COMPARTILHE!\n\nAllison Horst.Pratique, explore e crie visualizações incríveis!"
  },
  {
    "objectID": "apresentações/posts/visualizacao.html#assine-o-café-com-r-1",
    "href": "apresentações/posts/visualizacao.html#assine-o-café-com-r-1",
    "title": "4. Visualização de Dados com ggplot2",
    "section": "☕ Assine o Café com R",
    "text": "☕ Assine o Café com R\nFique por dentro das aulas, conteúdos, newsletter!\n\nQue cada gole desperte uma nova ideia.\nQue cada script abra uma nova conversa.\nQue o Café com R, se torne um ponto de encontro nosso!"
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#assine-o-café-com-r",
    "href": "apresentações/posts/tidymodels.html#assine-o-café-com-r",
    "title": "7. Tidymodels para Regressão em R",
    "section": "☕ Assine o Café com R",
    "text": "☕ Assine o Café com R\nFique por dentro das aulas, conteúdos, newsletter!\n\nQue cada gole desperte uma nova ideia.\nQue cada script abra uma nova conversa.\nQue o Café com R, se torne um ponto de encontro nosso!"
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#introdução-ao-tidymodels",
    "href": "apresentações/posts/tidymodels.html#introdução-ao-tidymodels",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Introdução ao Tidymodels",
    "text": "Introdução ao Tidymodels\nO tidymodels é uma coleção de pacotes para modelagem e machine learning seguindo os princípios do tidyverse."
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#pacotes-principais",
    "href": "apresentações/posts/tidymodels.html#pacotes-principais",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Pacotes Principais",
    "text": "Pacotes Principais\n\nrsample: divisão de dados\nrecipes: pré-processamento\nparsnip: especificação de modelos\nworkflows: pipelines completos\nyardstick: métricas de avaliação\ntune: otimização de hiperparâmetros"
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#instalação-e-carregamento",
    "href": "apresentações/posts/tidymodels.html#instalação-e-carregamento",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Instalação e Carregamento",
    "text": "Instalação e Carregamento\n\n# Carregar pacotes\nlibrary(tidymodels)\nlibrary(modeldata)\nlibrary(ggplot2)\nlibrary(dplyr)"
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#o-que-é-regressão",
    "href": "apresentações/posts/tidymodels.html#o-que-é-regressão",
    "title": "7. Tidymodels para Regressão em R",
    "section": "O que é Regressão?",
    "text": "O que é Regressão?\nRegressão é uma técnica estatística para modelar a relação entre uma variável resposta (dependente) e uma ou mais variáveis preditoras (independentes).\n\nImagem: Thales Ferraz.Objetivo: Prever valores numéricos contínuos."
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#dataset-ames",
    "href": "apresentações/posts/tidymodels.html#dataset-ames",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Dataset Ames",
    "text": "Dataset Ames\nO dataset Ames contém dados de vendas de imóveis em Ames, Iowa (EUA).\n\n2930 observações\n74 variáveis\nPreço de venda e características das casas"
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#carregando-os-dados",
    "href": "apresentações/posts/tidymodels.html#carregando-os-dados",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Carregando os Dados",
    "text": "Carregando os Dados\n\n# Carregar dataset Ames\ndata(\"ames\")\n\n# Visualizar primeiras linhas\nhead(ames, 3)\n\n# A tibble: 3 × 74\n  MS_SubClass             MS_Zoning Lot_Frontage Lot_Area Street Alley Lot_Shape\n  &lt;fct&gt;                   &lt;fct&gt;            &lt;dbl&gt;    &lt;int&gt; &lt;fct&gt;  &lt;fct&gt; &lt;fct&gt;    \n1 One_Story_1946_and_New… Resident…          141    31770 Pave   No_A… Slightly…\n2 One_Story_1946_and_New… Resident…           80    11622 Pave   No_A… Regular  \n3 One_Story_1946_and_New… Resident…           81    14267 Pave   No_A… Slightly…\n# ℹ 67 more variables: Land_Contour &lt;fct&gt;, Utilities &lt;fct&gt;, Lot_Config &lt;fct&gt;,\n#   Land_Slope &lt;fct&gt;, Neighborhood &lt;fct&gt;, Condition_1 &lt;fct&gt;, Condition_2 &lt;fct&gt;,\n#   Bldg_Type &lt;fct&gt;, House_Style &lt;fct&gt;, Overall_Cond &lt;fct&gt;, Year_Built &lt;int&gt;,\n#   Year_Remod_Add &lt;int&gt;, Roof_Style &lt;fct&gt;, Roof_Matl &lt;fct&gt;,\n#   Exterior_1st &lt;fct&gt;, Exterior_2nd &lt;fct&gt;, Mas_Vnr_Type &lt;fct&gt;,\n#   Mas_Vnr_Area &lt;dbl&gt;, Exter_Cond &lt;fct&gt;, Foundation &lt;fct&gt;, Bsmt_Cond &lt;fct&gt;,\n#   Bsmt_Exposure &lt;fct&gt;, BsmtFin_Type_1 &lt;fct&gt;, BsmtFin_SF_1 &lt;dbl&gt;, …\n\n# Dimensões\ndim(ames)\n\n[1] 2930   74"
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#variáveis-principais",
    "href": "apresentações/posts/tidymodels.html#variáveis-principais",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Variáveis Principais",
    "text": "Variáveis Principais\nVariável resposta: Sale_Price (preço de venda)\nPreditoras importantes:\n\nGr_Liv_Area: área habitável\nYear_Built: ano de construção\nBldg_Type: tipo de construção\nGarage_Area: área da garagem"
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#análise-exploratória",
    "href": "apresentações/posts/tidymodels.html#análise-exploratória",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Análise Exploratória",
    "text": "Análise Exploratória\n\n# Resumo estatístico\nsummary(ames[, c(\"Sale_Price\", \"Gr_Liv_Area\", \n                 \"Year_Built\", \"Garage_Area\")])\n\n   Sale_Price      Gr_Liv_Area     Year_Built    Garage_Area    \n Min.   : 12789   Min.   : 334   Min.   :1872   Min.   :   0.0  \n 1st Qu.:129500   1st Qu.:1126   1st Qu.:1954   1st Qu.: 320.0  \n Median :160000   Median :1442   Median :1973   Median : 480.0  \n Mean   :180796   Mean   :1500   Mean   :1971   Mean   : 472.7  \n 3rd Qu.:213500   3rd Qu.:1743   3rd Qu.:2001   3rd Qu.: 576.0  \n Max.   :755000   Max.   :5642   Max.   :2010   Max.   :1488.0"
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#distribuição-do-preço",
    "href": "apresentações/posts/tidymodels.html#distribuição-do-preço",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Distribuição do Preço",
    "text": "Distribuição do Preço\n\nggplot(ames, aes(x = Sale_Price)) +\n  geom_histogram(bins = 50, fill = \"#224573\", color = \"white\") +\n  scale_x_continuous(labels = scales::dollar) +\n  labs(title = \"Distribuição dos Preços de Venda\",\n       x = \"Preço de Venda\", y = \"Frequência\", caption = \"Jennifer Lopes.\") +\n  theme_classic()"
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#preço-x-área-habitável",
    "href": "apresentações/posts/tidymodels.html#preço-x-área-habitável",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Preço x Área Habitável",
    "text": "Preço x Área Habitável\n\nggplot(ames, aes(x = Gr_Liv_Area, y = Sale_Price)) +\n  geom_point(alpha = 0.5, color = \"#4A6FA5\") +\n  geom_smooth(method = \"lm\", color = \"#6B4F4F\", se = TRUE) +\n  scale_y_continuous(labels = scales::dollar) +\n  labs(title = \"Preço x Área Habitável\",\n       x = \"Área Habitável (sq ft)\", y = \"Preço de Venda\", caption = \"Jennifer Lopes.\") +\n  theme_classic()"
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#preço-x-tipo-de-construção",
    "href": "apresentações/posts/tidymodels.html#preço-x-tipo-de-construção",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Preço x Tipo de Construção",
    "text": "Preço x Tipo de Construção\n\nggplot(ames, aes(x = Bldg_Type, y = Sale_Price)) +\n  geom_boxplot(fill = \"#6B4F4F\", color = \"#224573\") +\n  scale_y_continuous(labels = scales::dollar) +\n  labs(title = \"Preço x Tipo de Construção\",\n       x = \"Tipo de Construção\", y = \"Preço de Venda\", caption = \"Jennifer Lopes.\") +\n  theme_classic() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))"
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#correlações",
    "href": "apresentações/posts/tidymodels.html#correlações",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Correlações",
    "text": "Correlações\n\n# Selecionar variáveis numéricas\nnumeric_vars &lt;- ames %&gt;%\n  select(Sale_Price, Gr_Liv_Area, Year_Built, \n         Garage_Area, Total_Bsmt_SF, Lot_Area)\n\n# Matriz de correlação\ncor_matrix &lt;- cor(numeric_vars, use = \"complete.obs\")\nround(cor_matrix[1, ], 3)\n\n   Sale_Price   Gr_Liv_Area    Year_Built   Garage_Area Total_Bsmt_SF \n        1.000         0.707         0.558         0.640         0.633 \n     Lot_Area \n        0.267"
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#workflow-do-tidymodels",
    "href": "apresentações/posts/tidymodels.html#workflow-do-tidymodels",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Workflow do Tidymodels",
    "text": "Workflow do Tidymodels\n\nDivisão dos dados: treino/teste\nPré-processamento: recipes\nEspecificação do modelo: parsnip\nCriação do workflow: workflows\nTreinamento: fit\nAvaliação: yardstick"
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#passo-1-divisão-dos-dados",
    "href": "apresentações/posts/tidymodels.html#passo-1-divisão-dos-dados",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Passo 1: Divisão dos Dados",
    "text": "Passo 1: Divisão dos Dados\n\n# Definir seed para reprodutibilidade\nset.seed(123)\n\n# Dividir dados: 75% treino, 25% teste\names_split &lt;- initial_split(ames, prop = 0.75)\names_train &lt;- training(ames_split)\names_test &lt;- testing(ames_split)\n\n# Verificar dimensões\ndim(ames_train)\n\n[1] 2197   74\n\ndim(ames_test)\n\n[1] 733  74"
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#passo-2-criando-uma-recipe",
    "href": "apresentações/posts/tidymodels.html#passo-2-criando-uma-recipe",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Passo 2: Criando uma Recipe",
    "text": "Passo 2: Criando uma Recipe\n\n# Criar recipe de pré-processamento\names_recipe &lt;- recipe(Sale_Price ~ Gr_Liv_Area + Year_Built + \n                      Bedroom_AbvGr + Garage_Area, \n                      data = ames_train) %&gt;%\n  step_normalize(all_numeric_predictors())\n\names_recipe"
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#o-que-é-uma-recipe",
    "href": "apresentações/posts/tidymodels.html#o-que-é-uma-recipe",
    "title": "7. Tidymodels para Regressão em R",
    "section": "O que é uma Recipe?",
    "text": "O que é uma Recipe?\nRecipe define o pré-processamento dos dados:\n\nstep_normalize(): padronização (z-score)\nstep_dummy(): variáveis dummy para categóricas\nstep_log(): transformação logarítmica\nstep_impute_*(): imputação de valores faltantes\nstep_pca(): análise de componentes principais"
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#passo-3-especificação-do-modelo",
    "href": "apresentações/posts/tidymodels.html#passo-3-especificação-do-modelo",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Passo 3: Especificação do Modelo",
    "text": "Passo 3: Especificação do Modelo\n\n# Especificar modelo de regressão linear\nlm_model &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  set_mode(\"regression\")\n\nlm_model\n\nLinear Regression Model Specification (regression)\n\nComputational engine: lm"
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#passo-4-criando-o-workflow",
    "href": "apresentações/posts/tidymodels.html#passo-4-criando-o-workflow",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Passo 4: Criando o Workflow",
    "text": "Passo 4: Criando o Workflow\n\n# Criar workflow combinando recipe e modelo\names_workflow &lt;- workflow() %&gt;%\n  add_recipe(ames_recipe) %&gt;%\n  add_model(lm_model)\n\names_workflow\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n1 Recipe Step\n\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm"
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#passo-5-treinamento",
    "href": "apresentações/posts/tidymodels.html#passo-5-treinamento",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Passo 5: Treinamento",
    "text": "Passo 5: Treinamento\n\n# Treinar o modelo\names_fit &lt;- ames_workflow %&gt;%\n  fit(data = ames_train)\n\n# Extrair coeficientes\names_fit %&gt;%\n  extract_fit_parsnip() %&gt;%\n  tidy()\n\n# A tibble: 5 × 5\n  term          estimate std.error statistic   p.value\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)    179210.      927.     193.  0        \n2 Gr_Liv_Area     50153.     1276.      39.3 3.56e-256\n3 Year_Built      24381.     1076.      22.7 2.32e-102\n4 Bedroom_AbvGr  -13759.     1128.     -12.2 3.64e- 33\n5 Garage_Area     16127.     1195.      13.5 6.18e- 40"
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#passo-6-predições",
    "href": "apresentações/posts/tidymodels.html#passo-6-predições",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Passo 6: Predições",
    "text": "Passo 6: Predições\n\n# Fazer predições no conjunto de teste\names_pred &lt;- predict(ames_fit, ames_test)\n\n# Combinar com valores reais\names_results &lt;- ames_test %&gt;%\n  select(Sale_Price) %&gt;%\n  bind_cols(ames_pred)\n\nhead(ames_results, 3)\n\n# A tibble: 3 × 2\n  Sale_Price   .pred\n       &lt;int&gt;   &lt;dbl&gt;\n1     172000 137902.\n2     195500 209084.\n3     212000 226493."
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#visualizando-predições",
    "href": "apresentações/posts/tidymodels.html#visualizando-predições",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Visualizando Predições",
    "text": "Visualizando Predições\n\nggplot(ames_results, aes(x = Sale_Price, y = .pred)) +\n  geom_point(alpha = 0.5, color = \"#4A6FA5\") +\n  geom_abline(slope = 1, intercept = 0, \n              color = \"#224573\", linetype = \"dashed\", linewidth = 1) +\n  scale_x_continuous(labels = scales::dollar) +\n  scale_y_continuous(labels = scales::dollar) +\n  labs(title = \"Valores Reais x Preditos\",\n       x = \"Valor Real\", y = \"Valor Predito\") +\n  theme_classic()"
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#métricas-de-avaliação",
    "href": "apresentações/posts/tidymodels.html#métricas-de-avaliação",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Métricas de Avaliação",
    "text": "Métricas de Avaliação\n\n# Calcular métricas\nmetrics_result &lt;- ames_results %&gt;%\n  metrics(truth = Sale_Price, estimate = .pred)\n\nmetrics_result\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard   40030.   \n2 rsq     standard       0.737\n3 mae     standard   28412."
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#entendendo-as-métricas",
    "href": "apresentações/posts/tidymodels.html#entendendo-as-métricas",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Entendendo as Métricas",
    "text": "Entendendo as Métricas\nRMSE (Root Mean Squared Error): Erro médio em unidades originais, penaliza erros grandes.\nRSQ (R-squared): Proporção da variância explicada, varia de 0 a 1 (quanto maior, melhor).\nMAE (Mean Absolute Error): Erro médio absoluto, mais robusto a outliers."
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#resíduos",
    "href": "apresentações/posts/tidymodels.html#resíduos",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Resíduos",
    "text": "Resíduos\n\n# Calcular resíduos\names_results &lt;- ames_results %&gt;%\n  mutate(residuals = Sale_Price - .pred)\n\nsummary(ames_results$residuals)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n-365051  -20382    1555    3321   22094  221464"
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#gráfico-de-resíduos",
    "href": "apresentações/posts/tidymodels.html#gráfico-de-resíduos",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Gráfico de Resíduos",
    "text": "Gráfico de Resíduos\n\nggplot(ames_results, aes(x = .pred, y = residuals)) +\n  geom_point(alpha = 0.5, color = \"#4A6FA5\") +\n  geom_hline(yintercept = 0, color = \"#224573\", \n             linetype = \"dashed\", linewidth = 1) +\n  scale_x_continuous(labels = scales::dollar) +\n  scale_y_continuous(labels = scales::dollar) +\n  labs(title = \"Gráfico de Resíduos\",\n       x = \"Valores Preditos\", y = \"Resíduos\") +\n  theme_classic()"
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#validação-cruzada",
    "href": "apresentações/posts/tidymodels.html#validação-cruzada",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Validação Cruzada",
    "text": "Validação Cruzada\n\n# Criar 10 folds\nset.seed(123)\names_folds &lt;- vfold_cv(ames_train, v = 10)\n\n# Ajustar modelo com validação cruzada\ncv_results &lt;- ames_workflow %&gt;%\n  fit_resamples(ames_folds)\n\n# Coletar métricas\ncollect_metrics(cv_results)\n\n# A tibble: 2 × 6\n  .metric .estimator      mean     n   std_err .config        \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;          \n1 rmse    standard   43250.       10 1871.     pre0_mod0_post0\n2 rsq     standard       0.715    10    0.0164 pre0_mod0_post0"
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#modelo-com-mais-variáveis",
    "href": "apresentações/posts/tidymodels.html#modelo-com-mais-variáveis",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Modelo com Mais Variáveis",
    "text": "Modelo com Mais Variáveis\n\n# Recipe expandida\names_recipe2 &lt;- recipe(Sale_Price ~ Gr_Liv_Area + Year_Built + \n                       Bedroom_AbvGr + Garage_Area + Total_Bsmt_SF +\n                       Lot_Area + TotRms_AbvGrd, \n                       data = ames_train) %&gt;%\n  step_normalize(all_numeric_predictors())\n\n# Novo workflow e treino\names_workflow2 &lt;- workflow() %&gt;%\n  add_recipe(ames_recipe2) %&gt;%\n  add_model(lm_model)\n\names_fit2 &lt;- ames_workflow2 %&gt;%\n  fit(data = ames_train)"
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#comparando-modelos",
    "href": "apresentações/posts/tidymodels.html#comparando-modelos",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Comparando Modelos",
    "text": "Comparando Modelos\n\n# Predições modelo 2\names_results2 &lt;- ames_test %&gt;%\n  select(Sale_Price) %&gt;%\n  bind_cols(predict(ames_fit2, ames_test))\n\n# Comparação\nbind_rows(\n  ames_results %&gt;% metrics(truth = Sale_Price, estimate = .pred) %&gt;% mutate(model = \"Modelo 1\"),\n  ames_results2 %&gt;% metrics(truth = Sale_Price, estimate = .pred) %&gt;% mutate(model = \"Modelo 2\")\n) %&gt;%\n  select(model, .metric, .estimate) %&gt;%\n  filter(.metric == \"rmse\")\n\n# A tibble: 2 × 3\n  model    .metric .estimate\n  &lt;chr&gt;    &lt;chr&gt;       &lt;dbl&gt;\n1 Modelo 1 rmse       40030.\n2 Modelo 2 rmse       36715."
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#regressão-ridge",
    "href": "apresentações/posts/tidymodels.html#regressão-ridge",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Regressão Ridge",
    "text": "Regressão Ridge\n\n# Especificar modelo Ridge\nridge_model &lt;- linear_reg(penalty = 0.01, mixture = 0) %&gt;%\n  set_engine(\"glmnet\") %&gt;%\n  set_mode(\"regression\")\n\n# Workflow e treino\nridge_workflow &lt;- workflow() %&gt;%\n  add_recipe(ames_recipe2) %&gt;%\n  add_model(ridge_model)\n\nridge_fit &lt;- ridge_workflow %&gt;%\n  fit(data = ames_train)"
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#o-que-é-ridge",
    "href": "apresentações/posts/tidymodels.html#o-que-é-ridge",
    "title": "7. Tidymodels para Regressão em R",
    "section": "O que é Ridge?",
    "text": "O que é Ridge?\nRidge Regression adiciona penalização L2:\n\nReduz coeficientes (mas não a zero)\nPrevine overfitting\nÚtil com multicolinearidade\npenalty: força da regularização\nmixture = 0: Ridge puro"
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#regressão-lasso",
    "href": "apresentações/posts/tidymodels.html#regressão-lasso",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Regressão Lasso",
    "text": "Regressão Lasso\n\n# Especificar modelo Lasso\nlasso_model &lt;- linear_reg(penalty = 0.01, mixture = 1) %&gt;%\n  set_engine(\"glmnet\") %&gt;%\n  set_mode(\"regression\")\n\n# Workflow e treino\nlasso_workflow &lt;- workflow() %&gt;%\n  add_recipe(ames_recipe2) %&gt;%\n  add_model(lasso_model)\n\nlasso_fit &lt;- lasso_workflow %&gt;%\n  fit(data = ames_train)"
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#o-que-é-lasso",
    "href": "apresentações/posts/tidymodels.html#o-que-é-lasso",
    "title": "7. Tidymodels para Regressão em R",
    "section": "O que é Lasso?",
    "text": "O que é Lasso?\nLasso Regression adiciona penalização L1:\n\nPode zerar coeficientes\nRealiza seleção de variáveis\nProduz modelos esparsos\nmixture = 1: Lasso puro"
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#comparação-final",
    "href": "apresentações/posts/tidymodels.html#comparação-final",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Comparação Final",
    "text": "Comparação Final\n\n# Métricas de todos os modelos\nridge_results &lt;- ames_test %&gt;%\n  select(Sale_Price) %&gt;%\n  bind_cols(predict(ridge_fit, ames_test))\n\nlasso_results &lt;- ames_test %&gt;%\n  select(Sale_Price) %&gt;%\n  bind_cols(predict(lasso_fit, ames_test))\n\nbind_rows(\n  ames_results %&gt;% metrics(truth = Sale_Price, estimate = .pred) %&gt;% mutate(model = \"Linear\"),\n  ridge_results %&gt;% metrics(truth = Sale_Price, estimate = .pred) %&gt;% mutate(model = \"Ridge\"),\n  lasso_results %&gt;% metrics(truth = Sale_Price, estimate = .pred) %&gt;% mutate(model = \"Lasso\")\n) %&gt;%\n  select(model, .metric, .estimate) %&gt;%\n  tidyr::pivot_wider(names_from = .metric, values_from = .estimate)\n\n# A tibble: 3 × 4\n  model    rmse   rsq    mae\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Linear 40030. 0.737 28412.\n2 Ridge  36929. 0.779 24728.\n3 Lasso  36749. 0.778 24708."
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#transformação-logarítmica",
    "href": "apresentações/posts/tidymodels.html#transformação-logarítmica",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Transformação Logarítmica",
    "text": "Transformação Logarítmica\n\n# Criar datasets para treino (corrigido)\names_train_log &lt;- ames_train %&gt;%\n  mutate(Sale_Price_Log = log10(Sale_Price))\n\n# Recipe COM log na variável dependente\nlog_recipe &lt;- recipe(Sale_Price_Log ~ Gr_Liv_Area + Year_Built + \n                     Garage_Area, \n                     data = ames_train_log) %&gt;%\n  step_normalize(all_numeric_predictors())"
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#modelo-com-transformação-log",
    "href": "apresentações/posts/tidymodels.html#modelo-com-transformação-log",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Modelo com Transformação Log",
    "text": "Modelo com Transformação Log\n\n# Workflow com log\nlog_workflow &lt;- workflow() %&gt;%\n  add_recipe(log_recipe) %&gt;%\n  add_model(lm_model)\n\n# Treinar\nlog_fit &lt;- log_workflow %&gt;%\n  fit(ames_train_log)\n\n# Predições (reverter para escala original)\names_test_log &lt;- ames_test %&gt;%\n  mutate(Sale_Price_Log = log10(Sale_Price))\n\nlog_results &lt;- ames_test %&gt;%\n  select(Sale_Price) %&gt;%\n  bind_cols(predict(log_fit, ames_test_log)) %&gt;%\n  mutate(.pred_original = 10^.pred)\n\n# Métricas\nlog_results %&gt;%\n  metrics(truth = Sale_Price, estimate = .pred_original)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard   45325.   \n2 rsq     standard       0.673\n3 mae     standard   27840."
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#random-forest",
    "href": "apresentações/posts/tidymodels.html#random-forest",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Random Forest",
    "text": "Random Forest\n\n# Especificar Random Forest\nrf_model &lt;- rand_forest(trees = 500) %&gt;%\n  set_engine(\"ranger\") %&gt;%\n  set_mode(\"regression\")\n\n# Workflow e treino\nrf_workflow &lt;- workflow() %&gt;%\n  add_recipe(ames_recipe2) %&gt;%\n  add_model(rf_model)\n\nrf_fit &lt;- rf_workflow %&gt;%\n  fit(data = ames_train)"
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#avaliando-random-forest",
    "href": "apresentações/posts/tidymodels.html#avaliando-random-forest",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Avaliando Random Forest",
    "text": "Avaliando Random Forest\n\n# Predições e métricas\nrf_results &lt;- ames_test %&gt;%\n  select(Sale_Price) %&gt;%\n  bind_cols(predict(rf_fit, ames_test))\n\nrf_results %&gt;%\n  metrics(truth = Sale_Price, estimate = .pred)\n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard   30109.   \n2 rsq     standard       0.851\n3 mae     standard   19440."
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#importância-das-variáveis",
    "href": "apresentações/posts/tidymodels.html#importância-das-variáveis",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Importância das Variáveis",
    "text": "Importância das Variáveis\n\nlibrary(vip)\n\names_fit %&gt;%\n  extract_fit_parsnip() %&gt;%\n  vip(num_features = 10, \n      aesthetics = list(fill = \"#224573\")) +\n  theme_classic()"
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#predições-em-novos-dados",
    "href": "apresentações/posts/tidymodels.html#predições-em-novos-dados",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Predições em Novos Dados",
    "text": "Predições em Novos Dados\n\n# Criar dados hipotéticos\nnew_house &lt;- tibble(\n  Gr_Liv_Area = 2000,\n  Year_Built = 2010,\n  Bedroom_AbvGr = 3,\n  Garage_Area = 500)\n\n# Prever preço\npredicted_price &lt;- predict(ames_fit, new_house)\n\npaste0(\"Preço estimado: $\", \n       scales::comma(round(predicted_price$.pred)))\n\n[1] \"Preço estimado: $260,000\""
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#salvando-modelos",
    "href": "apresentações/posts/tidymodels.html#salvando-modelos",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Salvando Modelos",
    "text": "Salvando Modelos\n\n# Salvar workflow treinado\nsaveRDS(ames_fit, \"ames_model.rds\")\n\n# Carregar modelo\nloaded_model &lt;- readRDS(\"ames_model.rds\")\n\n# Fazer predições\nnew_pred &lt;- predict(loaded_model, new_house)"
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#boas-práticas",
    "href": "apresentações/posts/tidymodels.html#boas-práticas",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Boas Práticas",
    "text": "Boas Práticas\n\nSempre dividir dados antes de processar\nUsar validação cruzada\nTestar múltiplos modelos\nVerificar suposições do modelo\nDocumentar decisões\nConsiderar contexto do negócio"
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#conclusão",
    "href": "apresentações/posts/tidymodels.html#conclusão",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Conclusão",
    "text": "Conclusão\nTidymodels oferece:\n\nFramework consistente e intuitivo\nFacilita experimentação\nReduz erros comuns\nMelhora reprodutibilidade\nIntegração com tidyverse\n\nRegressão é fundamental para análise preditiva!"
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#referências",
    "href": "apresentações/posts/tidymodels.html#referências",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Referências",
    "text": "Referências\n\nDocumentação tidymodels\nPacotes tidymodels\nTutoriais disponíveis\nLivro: Tidy Modeling with R"
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#obrigada",
    "href": "apresentações/posts/tidymodels.html#obrigada",
    "title": "7. Tidymodels para Regressão em R",
    "section": "Obrigada!",
    "text": "Obrigada!\n\nImagem: Allison Horst.Continue praticando e explorando!\nEsta apresentação é parte do projeto Café com R!É OPEN, USE, COMPARTILHE!\nHappy modeling!"
  },
  {
    "objectID": "apresentações/posts/tidymodels.html#assine-o-café-com-r-1",
    "href": "apresentações/posts/tidymodels.html#assine-o-café-com-r-1",
    "title": "7. Tidymodels para Regressão em R",
    "section": "☕ Assine o Café com R",
    "text": "☕ Assine o Café com R\n\nQue cada gole desperte uma nova ideia.\nQue cada script abra uma nova conversa.\nQue o Café com R, se torne um ponto de encontro nosso!"
  },
  {
    "objectID": "apresentações/posts/sql.html#assine-o-café-com-r",
    "href": "apresentações/posts/sql.html#assine-o-café-com-r",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "☕ Assine o Café com R",
    "text": "☕ Assine o Café com R\nFique por dentro das aulas, conteúdos, newsletter!\n\nQue cada gole desperte uma nova ideia.\nQue cada script abra uma nova conversa.\nQue o Café com R, se torne um ponto de encontro nosso!"
  },
  {
    "objectID": "apresentações/posts/sql.html#bem-vindo-ao-mundo-do-dbplyr",
    "href": "apresentações/posts/sql.html#bem-vindo-ao-mundo-do-dbplyr",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Bem-vindo ao mundo do dbplyr!",
    "text": "Bem-vindo ao mundo do dbplyr!\nSe você já sabe SQL e está começando com R, esta apresentação é para você!\n\n\nAllison Horst"
  },
  {
    "objectID": "apresentações/posts/sql.html#o-que-você-vai-aprender-hoje",
    "href": "apresentações/posts/sql.html#o-que-você-vai-aprender-hoje",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "O que você vai aprender hoje",
    "text": "O que você vai aprender hoje\n\nO que é dbplyr e por que ele é incrível\nComo conectar R a bancos de dados\nTraduzir SELECT, WHERE, JOIN e muito mais\nTrabalhar com dados sem carregar tudo na memória\nExemplos práticos que você pode testar agora\n\nSpoiler: Você vai escrever código R que gera SQL automaticamente! 🎉"
  },
  {
    "objectID": "apresentações/posts/sql.html#o-que-é-dbplyr",
    "href": "apresentações/posts/sql.html#o-que-é-dbplyr",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "O que é dbplyr?",
    "text": "O que é dbplyr?\n\ndbplyr é um pacote que traduz código dplyr (R) para SQL.\nPor que isso é fantástico:\n\nEscreva em R, execute em SQL\nTrabalhe com milhões de linhas sem travamentos\nUse a sintaxe tidyverse que você ama\nFunciona com vários bancos de dados (PostgreSQL, MySQL, SQLite, etc)\nO R só traz para memória o que você realmente precisa"
  },
  {
    "objectID": "apresentações/posts/sql.html#dica-inicial",
    "href": "apresentações/posts/sql.html#dica-inicial",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Dica inicial",
    "text": "Dica inicial\n\n“Pense em R, execute em SQL, aprenda os dois!”\nA cada query você escreve, está praticando DUAS linguagens ao mesmo tempo!\n\n\nImagem: Allison Horst."
  },
  {
    "objectID": "apresentações/posts/sql.html#sql-x-dplyr-a-grande-comparação",
    "href": "apresentações/posts/sql.html#sql-x-dplyr-a-grande-comparação",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "SQL x dplyr: A grande comparação",
    "text": "SQL x dplyr: A grande comparação\n-- Em SQL\nSELECT nome, idade \nFROM clientes \nWHERE idade &gt; 18;\nMesma lógica, sintaxe diferente!"
  },
  {
    "objectID": "apresentações/posts/sql.html#instalando-o-que-você-precisa",
    "href": "apresentações/posts/sql.html#instalando-o-que-você-precisa",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Instalando o que você precisa",
    "text": "Instalando o que você precisa\n\nPrimeiro, instale os pacotes necessários:\n\nDBI: Interface com bancos de dados\nRSQLite: Para trabalhar com SQLite\ndbplyr: O tradutor SQL ↔︎ R\ndplyr: Manipulação de dados"
  },
  {
    "objectID": "apresentações/posts/sql.html#carregando-os-pacotes",
    "href": "apresentações/posts/sql.html#carregando-os-pacotes",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Carregando os pacotes",
    "text": "Carregando os pacotes\n\n# Carregar pacotes (faz TODA vez)\nlibrary(DBI)\nlibrary(dplyr)\nlibrary(dbplyr)\n\nLembre-se: Instalar é como baixar o app, carregar é como abrir o app!"
  },
  {
    "objectID": "apresentações/posts/sql.html#criando-um-banco-de-dados-de-exemplo",
    "href": "apresentações/posts/sql.html#criando-um-banco-de-dados-de-exemplo",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Criando um banco de dados de exemplo",
    "text": "Criando um banco de dados de exemplo\nVamos criar um banco SQLite em memória para praticar:\n\n# Criar conexão com banco em memória\ncon &lt;- dbConnect(RSQLite::SQLite(), \":memory:\")\n\n# Criar tabela de clientes\ndbWriteTable(con, \"clientes\", data.frame(\n  id = 1:5,\n  nome = c(\"Ana\", \"Jennifer\", \"Carla\", \"Daniel\", \"Elena\"),\n  idade = c(25, 33, 22, 35, 28),\n  cidade = c(\"RJ\", \"SP\", \"SP\", \"MG\", \"RJ\")))\n\nPronto! Agora temos um banco de dados para trabalhar."
  },
  {
    "objectID": "apresentações/posts/sql.html#conectando-ao-banco",
    "href": "apresentações/posts/sql.html#conectando-ao-banco",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Conectando ao banco",
    "text": "Conectando ao banco\nPara usar dbplyr, conecte-se à tabela:\n\n# Criar referência à tabela\nclientes_db &lt;- tbl(con, \"clientes\")\n\n# Ver os dados\nclientes_db\n\n# Source:   table&lt;`clientes`&gt; [?? x 4]\n# Database: sqlite 3.50.4 [:memory:]\n     id nome     idade cidade\n  &lt;int&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt; \n1     1 Ana         25 RJ    \n2     2 Jennifer    33 SP    \n3     3 Carla       22 SP    \n4     4 Daniel      35 MG    \n5     5 Elena       28 RJ    \n\n\nImportante: Os dados ainda estão no banco, não na memória do R!"
  },
  {
    "objectID": "apresentações/posts/sql.html#select-selecionando-colunas",
    "href": "apresentações/posts/sql.html#select-selecionando-colunas",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "SELECT: Selecionando colunas",
    "text": "SELECT: Selecionando colunas\nSQL:\nSELECT nome, idade FROM clientes;\ndbplyr (R):\n\nclientes_db |&gt;\n  select(nome, idade)\n\n# Source:   SQL [?? x 2]\n# Database: sqlite 3.50.4 [:memory:]\n  nome     idade\n  &lt;chr&gt;    &lt;dbl&gt;\n1 Ana         25\n2 Jennifer    33\n3 Carla       22\n4 Daniel      35\n5 Elena       28"
  },
  {
    "objectID": "apresentações/posts/sql.html#where-filtrando-linhas",
    "href": "apresentações/posts/sql.html#where-filtrando-linhas",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "WHERE: Filtrando linhas",
    "text": "WHERE: Filtrando linhas\nSQL:\nSELECT * FROM clientes WHERE idade &gt; 25;\ndbplyr (R):\n\nclientes_db |&gt;\n  filter(idade &gt; 25)\n\n# Source:   SQL [?? x 4]\n# Database: sqlite 3.50.4 [:memory:]\n     id nome     idade cidade\n  &lt;int&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt; \n1     2 Jennifer    33 SP    \n2     4 Daniel      35 MG    \n3     5 Elena       28 RJ"
  },
  {
    "objectID": "apresentações/posts/sql.html#operadores-de-comparação",
    "href": "apresentações/posts/sql.html#operadores-de-comparação",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Operadores de comparação",
    "text": "Operadores de comparação\n\n\n\nSQL\nR (dplyr)\nSignificado\n\n\n\n\n=\n==\nIgual\n\n\n&lt;&gt; ou !=\n!=\nDiferente\n\n\n&gt;\n&gt;\nMaior que\n\n\n&lt;\n&lt;\nMenor que\n\n\n&gt;=\n&gt;=\nMaior ou igual\n\n\n&lt;=\n&lt;=\nMenor ou igual\n\n\n\nAtenção: Em R use == para comparação, não ="
  },
  {
    "objectID": "apresentações/posts/sql.html#combinando-filtros-com-and",
    "href": "apresentações/posts/sql.html#combinando-filtros-com-and",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Combinando filtros com AND",
    "text": "Combinando filtros com AND\nSQL:\nSELECT * FROM clientes \nWHERE idade &gt; 25 AND cidade = 'SP';\ndbplyr (R):Use & para AND (E)\n\nclientes_db |&gt;\n  filter(idade &gt; 25 & cidade == \"SP\")\n\n# Source:   SQL [?? x 4]\n# Database: sqlite 3.50.4 [:memory:]\n     id nome     idade cidade\n  &lt;int&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt; \n1     2 Jennifer    33 SP"
  },
  {
    "objectID": "apresentações/posts/sql.html#combinando-filtros-com-or",
    "href": "apresentações/posts/sql.html#combinando-filtros-com-or",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Combinando filtros com OR",
    "text": "Combinando filtros com OR\nSQL:\nSELECT * FROM clientes \nWHERE cidade = 'SP' OR cidade = 'RJ';\ndbplyr (R): Use | para OR (OU)\n\nclientes_db |&gt;\n  filter(cidade == \"SP\" | cidade == \"RJ\")\n\n# Source:   SQL [?? x 4]\n# Database: sqlite 3.50.4 [:memory:]\n     id nome     idade cidade\n  &lt;int&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt; \n1     1 Ana         25 RJ    \n2     2 Jennifer    33 SP    \n3     3 Carla       22 SP    \n4     5 Elena       28 RJ"
  },
  {
    "objectID": "apresentações/posts/sql.html#in-valores-em-uma-lista",
    "href": "apresentações/posts/sql.html#in-valores-em-uma-lista",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "IN: Valores em uma lista",
    "text": "IN: Valores em uma lista\nSQL:\nSELECT * FROM clientes \nWHERE cidade IN ('SP', 'RJ');\ndbplyr (R):%in% verifica se o valor está no vetor\n\nclientes_db |&gt;\n  filter(cidade %in% c(\"SP\", \"RJ\"))\n\n# Source:   SQL [?? x 4]\n# Database: sqlite 3.50.4 [:memory:]\n     id nome     idade cidade\n  &lt;int&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt; \n1     1 Ana         25 RJ    \n2     2 Jennifer    33 SP    \n3     3 Carla       22 SP    \n4     5 Elena       28 RJ"
  },
  {
    "objectID": "apresentações/posts/sql.html#order-by-ordenando-resultados",
    "href": "apresentações/posts/sql.html#order-by-ordenando-resultados",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "ORDER BY: Ordenando resultados",
    "text": "ORDER BY: Ordenando resultados\nSQL:\nSELECT * FROM clientes ORDER BY idade DESC;\ndbplyr (R): Use arrange() para ordenar, desc() para decrescente\n\nclientes_db |&gt;\n  arrange(desc(idade))\n\n# Source:     SQL [?? x 4]\n# Database:   sqlite 3.50.4 [:memory:]\n# Ordered by: desc(idade)\n     id nome     idade cidade\n  &lt;int&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt; \n1     4 Daniel      35 MG    \n2     2 Jennifer    33 SP    \n3     5 Elena       28 RJ    \n4     1 Ana         25 RJ    \n5     3 Carla       22 SP"
  },
  {
    "objectID": "apresentações/posts/sql.html#limit-limitando-resultados",
    "href": "apresentações/posts/sql.html#limit-limitando-resultados",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "LIMIT: Limitando resultados",
    "text": "LIMIT: Limitando resultados\nSQL:\nSELECT * FROM clientes LIMIT 3;\ndbplyr (R):\n\nclientes_db |&gt;\n  head(3)\n\n# Source:   SQL [?? x 4]\n# Database: sqlite 3.50.4 [:memory:]\n     id nome     idade cidade\n  &lt;int&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt; \n1     1 Ana         25 RJ    \n2     2 Jennifer    33 SP    \n3     3 Carla       22 SP"
  },
  {
    "objectID": "apresentações/posts/sql.html#count-contando-registros",
    "href": "apresentações/posts/sql.html#count-contando-registros",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "COUNT: Contando registros",
    "text": "COUNT: Contando registros\nSQL:\nSELECT COUNT(*) FROM clientes;\ndbplyr (R):\n\nclientes_db |&gt;\n  summarise(total = n())\n\n# Source:   SQL [?? x 1]\n# Database: sqlite 3.50.4 [:memory:]\n  total\n  &lt;int&gt;\n1     5\n\n\nn() conta o número de linhas"
  },
  {
    "objectID": "apresentações/posts/sql.html#group-by-agrupando-dados",
    "href": "apresentações/posts/sql.html#group-by-agrupando-dados",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "GROUP BY: Agrupando dados",
    "text": "GROUP BY: Agrupando dados\nVamos criar uma tabela de vendas para exemplos mais interessantes:\n\ndbWriteTable(con, \"vendas\", data.frame(\n  id = 1:8,\n  cliente_id = c(1, 2, 1, 3, 2, 1, 4, 5),\n  produto = c(\"A\", \"B\", \"A\", \"C\", \"B\", \"C\", \"A\", \"B\"),\n  valor = c(100, 150, 200, 80, 120, 90, 110, 160),\n  quantidade = c(2, 1, 3, 1, 2, 1, 2, 1)), overwrite = TRUE)\n\nvendas_db &lt;- tbl(con, \"vendas\")"
  },
  {
    "objectID": "apresentações/posts/sql.html#group-by-com-count",
    "href": "apresentações/posts/sql.html#group-by-com-count",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "GROUP BY com COUNT",
    "text": "GROUP BY com COUNT\nSQL:\nSELECT produto, COUNT(*) as total_vendas\nFROM vendas\nGROUP BY produto;\ndbplyr (R):\n\nvendas_db |&gt;\n  group_by(produto) |&gt;\n  summarise(total_vendas = n())\n\n# Source:   SQL [?? x 2]\n# Database: sqlite 3.50.4 [:memory:]\n  produto total_vendas\n  &lt;chr&gt;          &lt;int&gt;\n1 A                  3\n2 B                  3\n3 C                  2"
  },
  {
    "objectID": "apresentações/posts/sql.html#group-by-com-sum",
    "href": "apresentações/posts/sql.html#group-by-com-sum",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "GROUP BY com SUM",
    "text": "GROUP BY com SUM\nSQL:\nSELECT produto, SUM(valor) as receita_total\nFROM vendas\nGROUP BY produto;\ndbplyr (R):\n\nvendas_db |&gt;\n  group_by(produto) |&gt;\n  summarise(receita_total = sum(valor, na.rm = TRUE))\n\n# Source:   SQL [?? x 2]\n# Database: sqlite 3.50.4 [:memory:]\n  produto receita_total\n  &lt;chr&gt;           &lt;dbl&gt;\n1 A                 410\n2 B                 430\n3 C                 170"
  },
  {
    "objectID": "apresentações/posts/sql.html#múltiplas-agregações",
    "href": "apresentações/posts/sql.html#múltiplas-agregações",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Múltiplas agregações",
    "text": "Múltiplas agregações\nSQL:\nSELECT produto, \n       COUNT(*) as vendas,\n       SUM(valor) as receita,\n       AVG(valor) as ticket_medio\nFROM vendas\nGROUP BY produto;"
  },
  {
    "objectID": "apresentações/posts/sql.html#múltiplas-agregações-1",
    "href": "apresentações/posts/sql.html#múltiplas-agregações-1",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Múltiplas agregações",
    "text": "Múltiplas agregações\ndbplyr (R):\n\nvendas_db |&gt;\n  group_by(produto) |&gt;\n  summarise(\n    vendas = n(),\n    receita = sum(valor, na.rm = TRUE),\n    ticket_medio = mean(valor, na.rm = TRUE))\n\n# Source:   SQL [?? x 4]\n# Database: sqlite 3.50.4 [:memory:]\n  produto vendas receita ticket_medio\n  &lt;chr&gt;    &lt;int&gt;   &lt;dbl&gt;        &lt;dbl&gt;\n1 A            3     410         137.\n2 B            3     430         143.\n3 C            2     170          85"
  },
  {
    "objectID": "apresentações/posts/sql.html#funções-de-agregação",
    "href": "apresentações/posts/sql.html#funções-de-agregação",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Funções de agregação",
    "text": "Funções de agregação\n\n\n\nSQL\nR (dplyr)\nFunção\n\n\n\n\nCOUNT(*)\nn()\nContar linhas\n\n\nSUM()\nsum()\nSomar valores\n\n\nAVG()\nmean()\nCalcular média\n\n\nMIN()\nmin()\nValor mínimo\n\n\nMAX()\nmax()\nValor máximo\n\n\n\nDica: Sempre use na.rm = TRUE em R para ignorar valores NA"
  },
  {
    "objectID": "apresentações/posts/sql.html#having-filtrando-grupos",
    "href": "apresentações/posts/sql.html#having-filtrando-grupos",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "HAVING: Filtrando grupos",
    "text": "HAVING: Filtrando grupos\nSQL:\nSELECT produto, SUM(valor) as receita\nFROM vendas\nGROUP BY produto\nHAVING SUM(valor) &gt; 200;\ndbplyr (R):\n\nvendas_db |&gt;\n  group_by(produto) |&gt;\n  summarise(receita = sum(valor, na.rm = TRUE)) |&gt;\n  filter(receita &gt; 200)\n\n# Source:   SQL [?? x 2]\n# Database: sqlite 3.50.4 [:memory:]\n  produto receita\n  &lt;chr&gt;     &lt;dbl&gt;\n1 A           410\n2 B           430"
  },
  {
    "objectID": "apresentações/posts/sql.html#inner-join-juntando-tabelas",
    "href": "apresentações/posts/sql.html#inner-join-juntando-tabelas",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "INNER JOIN: Juntando tabelas",
    "text": "INNER JOIN: Juntando tabelas\nSQL:\nSELECT c.nome, v.produto, v.valor\nFROM clientes c\nINNER JOIN vendas v ON c.id = v.cliente_id;\ndbplyr (R):\n\nclientes_db |&gt;\n  inner_join(vendas_db, by = c(\"id\" = \"cliente_id\")) |&gt;\n  select(nome, produto, valor)\n\n# Source:   SQL [?? x 3]\n# Database: sqlite 3.50.4 [:memory:]\n  nome     produto valor\n  &lt;chr&gt;    &lt;chr&gt;   &lt;dbl&gt;\n1 Ana      A         100\n2 Ana      A         200\n3 Ana      C          90\n4 Jennifer B         120\n5 Jennifer B         150\n6 Carla    C          80\n7 Daniel   A         110\n8 Elena    B         160"
  },
  {
    "objectID": "apresentações/posts/sql.html#left-join",
    "href": "apresentações/posts/sql.html#left-join",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "LEFT JOIN",
    "text": "LEFT JOIN\nSQL:\nSELECT c.nome, v.produto\nFROM clientes c\nLEFT JOIN vendas v ON c.id = v.cliente_id;\ndbplyr (R):\n\nclientes_db |&gt;\n  left_join(vendas_db, by = c(\"id\" = \"cliente_id\")) |&gt;\n  select(nome, produto)\n\n# Source:   SQL [?? x 2]\n# Database: sqlite 3.50.4 [:memory:]\n  nome     produto\n  &lt;chr&gt;    &lt;chr&gt;  \n1 Ana      A      \n2 Ana      A      \n3 Ana      C      \n4 Jennifer B      \n5 Jennifer B      \n6 Carla    C      \n7 Daniel   A      \n8 Elena    B"
  },
  {
    "objectID": "apresentações/posts/sql.html#tipos-de-join",
    "href": "apresentações/posts/sql.html#tipos-de-join",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Tipos de JOIN",
    "text": "Tipos de JOIN\n\n\n\nSQL\nR (dplyr)\nO que faz\n\n\n\n\nINNER JOIN\ninner_join()\nApenas registros que combinam\n\n\nLEFT JOIN\nleft_join()\nTodos da esquerda + combinações\n\n\nRIGHT JOIN\nright_join()\nTodos da direita + combinações\n\n\nFULL JOIN\nfull_join()\nTodos os registros\n\n\n\nMemória: O nome indica qual tabela mantém todos os registros"
  },
  {
    "objectID": "apresentações/posts/sql.html#case-when-criando-categorias",
    "href": "apresentações/posts/sql.html#case-when-criando-categorias",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "CASE WHEN: Criando categorias",
    "text": "CASE WHEN: Criando categorias\nSQL:\nSELECT nome, idade,\n  CASE \n    WHEN idade &lt; 25 THEN 'Jovem'\n    WHEN idade &lt; 30 THEN 'Adulto'\n    ELSE 'Experiente'\n  END as faixa_etaria\nFROM clientes;"
  },
  {
    "objectID": "apresentações/posts/sql.html#case-when-em-r",
    "href": "apresentações/posts/sql.html#case-when-em-r",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "CASE WHEN em R",
    "text": "CASE WHEN em R\ndbplyr (R): Use TRUE como “ELSE”\n\nclientes_db |&gt;\n  mutate(\n    faixa_etaria = case_when(\n      idade &lt; 25 ~ \"Jovem\",\n      idade &lt; 30 ~ \"Adulto\",\n      TRUE ~ \"Experiente\")) |&gt;\n  select(nome, idade, faixa_etaria)\n\n# Source:   SQL [?? x 3]\n# Database: sqlite 3.50.4 [:memory:]\n  nome     idade faixa_etaria\n  &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;       \n1 Ana         25 Adulto      \n2 Jennifer    33 Experiente  \n3 Carla       22 Jovem       \n4 Daniel      35 Experiente  \n5 Elena       28 Adulto"
  },
  {
    "objectID": "apresentações/posts/sql.html#criando-novas-colunas",
    "href": "apresentações/posts/sql.html#criando-novas-colunas",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Criando novas colunas",
    "text": "Criando novas colunas\nSQL:\nSELECT *, valor * quantidade as total\nFROM vendas;\ndbplyr (R):\n\nvendas_db |&gt;\n  mutate(total = valor * quantidade)\n\n# Source:   SQL [?? x 6]\n# Database: sqlite 3.50.4 [:memory:]\n     id cliente_id produto valor quantidade total\n  &lt;int&gt;      &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;\n1     1          1 A         100          2   200\n2     2          2 B         150          1   150\n3     3          1 A         200          3   600\n4     4          3 C          80          1    80\n5     5          2 B         120          2   240\n6     6          1 C          90          1    90\n7     7          4 A         110          2   220\n8     8          5 B         160          1   160\n\n\nmutate() cria ou modifica colunas"
  },
  {
    "objectID": "apresentações/posts/sql.html#distinct-valores-únicos",
    "href": "apresentações/posts/sql.html#distinct-valores-únicos",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "DISTINCT: Valores únicos",
    "text": "DISTINCT: Valores únicos\nSQL:\nSELECT DISTINCT cidade FROM clientes;\ndbplyr (R):\n\nclientes_db |&gt;\n  distinct(cidade)\n\n# Source:   SQL [?? x 1]\n# Database: sqlite 3.50.4 [:memory:]\n  cidade\n  &lt;chr&gt; \n1 RJ    \n2 SP    \n3 MG"
  },
  {
    "objectID": "apresentações/posts/sql.html#subconsultas-subqueries",
    "href": "apresentações/posts/sql.html#subconsultas-subqueries",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Subconsultas (Subqueries)",
    "text": "Subconsultas (Subqueries)\nSQL:\nSELECT * FROM vendas\nWHERE valor &gt; (SELECT AVG(valor) FROM vendas);\ndbplyr (R):\n\n# Calcular a média\nvalor_medio &lt;- vendas_db |&gt;\n  summarise(media = mean(valor, na.rm = TRUE)) |&gt;\n  pull(media)\n\n# Filtrar\nvendas_db |&gt;\n  filter(valor &gt; valor_medio)\n\n# Source:   SQL [?? x 5]\n# Database: sqlite 3.50.4 [:memory:]\n     id cliente_id produto valor quantidade\n  &lt;int&gt;      &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;      &lt;dbl&gt;\n1     2          2 B         150          1\n2     3          1 A         200          3\n3     8          5 B         160          1"
  },
  {
    "objectID": "apresentações/posts/sql.html#like-buscas-com-padrões",
    "href": "apresentações/posts/sql.html#like-buscas-com-padrões",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "LIKE: Buscas com padrões",
    "text": "LIKE: Buscas com padrões\nSQL:\nSELECT * FROM clientes \nWHERE nome LIKE 'A%';"
  },
  {
    "objectID": "apresentações/posts/sql.html#dbplyr-r",
    "href": "apresentações/posts/sql.html#dbplyr-r",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "dbplyr (R):",
    "text": "dbplyr (R):\n\n# clientes_db |&gt; \n# filter(str_detect(nome, \"^A\"))\n\nUse str_detect() do pacote stringr (parte do tidyverse)"
  },
  {
    "objectID": "apresentações/posts/sql.html#vendo-o-sql-gerado",
    "href": "apresentações/posts/sql.html#vendo-o-sql-gerado",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Vendo o SQL gerado",
    "text": "Vendo o SQL gerado\nQuer ver qual SQL o dbplyr está gerando? Use show_query():\n\nclientes_db |&gt;\n  filter(idade &gt; 25) |&gt;\n  select(nome, cidade) |&gt;\n  show_query()\n\n&lt;SQL&gt;\nSELECT `nome`, `cidade`\nFROM `clientes`\nWHERE (`idade` &gt; 25.0)\n\n\nPerfeito para aprender! Compare seu código R com o SQL gerado."
  },
  {
    "objectID": "apresentações/posts/sql.html#executando-e-coletando-dados",
    "href": "apresentações/posts/sql.html#executando-e-coletando-dados",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Executando e coletando dados",
    "text": "Executando e coletando dados\nO dbplyr é “lazy” (preguiçoso) - só executa quando necessário.\n\n# Isso NÃO executa ainda, só prepara a query\nquery &lt;- clientes_db |&gt;\n  filter(idade &gt; 25)\n\n# Isso executa e traz para o R\nresultado &lt;- query |&gt; collect()\n\n# Agora é um data.frame normal no R\nclass(resultado)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\""
  },
  {
    "objectID": "apresentações/posts/sql.html#por-que-usar-collect",
    "href": "apresentações/posts/sql.html#por-que-usar-collect",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Por que usar collect()?",
    "text": "Por que usar collect()?\n\nSem collect():\n\nDados ficam no banco\nOperações rápidas (SQL é otimizado)\nEconomiza memória"
  },
  {
    "objectID": "apresentações/posts/sql.html#por-que-usar-collect-1",
    "href": "apresentações/posts/sql.html#por-que-usar-collect-1",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Por que usar collect()?",
    "text": "Por que usar collect()?\n\nCom collect():\n\nDados vêm para o R\nUse quando precisar processar no R\nUse depois de filtrar para trazer menos dados\n\nDica: Filtre e agregue NO BANCO, só depois traga para o R!"
  },
  {
    "objectID": "apresentações/posts/sql.html#exemplo-análise",
    "href": "apresentações/posts/sql.html#exemplo-análise",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Exemplo: Análise",
    "text": "Exemplo: Análise\n\n# 1. Fazer query complexa no banco\nrelatorio &lt;- clientes_db |&gt;\n  left_join(vendas_db, by = c(\"id\" = \"cliente_id\")) |&gt;\n  filter(!is.na(valor)) |&gt;\n  group_by(nome, cidade) |&gt;\n  summarise(\n    total_compras = n(),\n    valor_total = sum(valor, na.rm = TRUE),\n    ticket_medio = mean(valor, na.rm = TRUE)) |&gt;\n  arrange(desc(valor_total))"
  },
  {
    "objectID": "apresentações/posts/sql.html#exemplo-análise---resultado-sql",
    "href": "apresentações/posts/sql.html#exemplo-análise---resultado-sql",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Exemplo: Análise - Resultado SQL",
    "text": "Exemplo: Análise - Resultado SQL\n\n\n&lt;SQL&gt;\nSELECT\n  `nome`,\n  `cidade`,\n  COUNT(*) AS `total_compras`,\n  SUM(`valor`) AS `valor_total`,\n  AVG(`valor`) AS `ticket_medio`\nFROM (\n  SELECT `q01`.*\n  FROM (\n    SELECT\n      `clientes`.*,\n      `vendas`.`id` AS `id.y`,\n      `produto`,\n      `valor`,\n      `quantidade`\n    FROM `clientes`\n    LEFT JOIN `vendas`\n      ON (`clientes`.`id` = `vendas`.`cliente_id`)\n  ) AS `q01`\n  WHERE (NOT((`valor` IS NULL)))\n) AS `q01`\nGROUP BY `nome`, `cidade`\nORDER BY `valor_total` DESC"
  },
  {
    "objectID": "apresentações/posts/sql.html#coletando-o-resultado",
    "href": "apresentações/posts/sql.html#coletando-o-resultado",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Coletando o resultado",
    "text": "Coletando o resultado\n\n# 3. Executar e trazer para o R\nresultado_final &lt;- relatorio |&gt; collect()\n\n# 4. Agora você pode usar ggplot2, etc\nprint(resultado_final)\n\n# A tibble: 5 × 5\n# Groups:   nome [5]\n  nome     cidade total_compras valor_total ticket_medio\n  &lt;chr&gt;    &lt;chr&gt;          &lt;int&gt;       &lt;dbl&gt;        &lt;dbl&gt;\n1 Ana      RJ                 3         390          130\n2 Jennifer SP                 2         270          135\n3 Elena    RJ                 1         160          160\n4 Daniel   MG                 1         110          110\n5 Carla    SP                 1          80           80\n\n\nPerfeito! Processamos tudo no banco e só trouxemos o resultado final."
  },
  {
    "objectID": "apresentações/posts/sql.html#conectando-a-bancos-reais",
    "href": "apresentações/posts/sql.html#conectando-a-bancos-reais",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Conectando a bancos reais",
    "text": "Conectando a bancos reais\nPostgreSQL:\n\nlibrary(RPostgres)\ncon &lt;- dbConnect(\n  RPostgres::Postgres(),\n  dbname = \"seu_banco\",\n  host = \"localhost\",\n  port = 5432,\n  user = \"seu_usuario\",\n  password = \"sua_senha\")"
  },
  {
    "objectID": "apresentações/posts/sql.html#conectando-a-bancos-reais-cont.",
    "href": "apresentações/posts/sql.html#conectando-a-bancos-reais-cont.",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Conectando a bancos reais (cont.)",
    "text": "Conectando a bancos reais (cont.)\nMySQL:\n\nlibrary(RMariaDB)\ncon &lt;- dbConnect(\n  RMariaDB::MariaDB(),\n  dbname = \"seu_banco\",\n  host = \"localhost\",\n  user = \"seu_usuario\",\n  password = \"sua_senha\")"
  },
  {
    "objectID": "apresentações/posts/sql.html#boas-práticas-com-bancos",
    "href": "apresentações/posts/sql.html#boas-práticas-com-bancos",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Boas práticas com bancos",
    "text": "Boas práticas com bancos\n1. Sempre feche a conexão:\n\ndbDisconnect(con)\n\n2. Filtre ANTES de collect():\n\n# ✅ Bom - filtra no banco\ndados |&gt; filter(ano == 2024) |&gt; collect()\n\n# ❌ Ruim - traz tudo para depois filtrar\ndados |&gt; collect() |&gt; filter(ano == 2024)"
  },
  {
    "objectID": "apresentações/posts/sql.html#boas-práticas-cont.",
    "href": "apresentações/posts/sql.html#boas-práticas-cont.",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Boas práticas (cont.)",
    "text": "Boas práticas (cont.)\n3. Use índices no banco de dados:\n\n# Criar índice (SQL)\ndbExecute(con, \"CREATE INDEX idx_cliente ON vendas(cliente_id)\")\n\n4. Teste com LIMIT primeiro:\n\n# Ver amostra antes de processar tudo\nminha_tabela |&gt; head(100) |&gt; collect()"
  },
  {
    "objectID": "apresentações/posts/sql.html#tabela-de-tradução-sql-dplyr",
    "href": "apresentações/posts/sql.html#tabela-de-tradução-sql-dplyr",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Tabela de tradução SQL > dplyr",
    "text": "Tabela de tradução SQL &gt; dplyr\n\n\n\n\n\n\n\n\nSQL\ndplyr\nFunção\n\n\n\n\nSELECT\nselect()\nEscolher colunas\n\n\nWHERE\nfilter()\nFiltrar linhas\n\n\nORDER BY\narrange()\nOrdenar\n\n\nGROUP BY\ngroup_by()\nAgrupar\n\n\nAgregações + GROUP BY\nsummarise()\nResumir\n\n\nHAVING\nfilter() após summarise()\nFiltrar grupos"
  },
  {
    "objectID": "apresentações/posts/sql.html#tabela-de-tradução-sql-dplyr-cont.",
    "href": "apresentações/posts/sql.html#tabela-de-tradução-sql-dplyr-cont.",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Tabela de tradução SQL > dplyr (cont.)",
    "text": "Tabela de tradução SQL &gt; dplyr (cont.)\n\n\n\nSQL\ndplyr\nFunção\n\n\n\n\nLIMIT\nhead()\nLimitar resultados\n\n\nDISTINCT\ndistinct()\nValores únicos\n\n\nINNER JOIN\ninner_join()\nInterseção\n\n\nLEFT JOIN\nleft_join()\nEsquerda + combinação\n\n\nRIGHT JOIN\nright_join()\nDireita + combinação\n\n\nFULL JOIN\nfull_join()\nUnião completa\n\n\nCASE WHEN\ncase_when()\nCondicionais\n\n\nCriar coluna\nmutate()\nNova variável"
  },
  {
    "objectID": "apresentações/posts/sql.html#exercício-1",
    "href": "apresentações/posts/sql.html#exercício-1",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Exercício 1",
    "text": "Exercício 1\nDesafio: Traduza este SQL para dplyr:\nSELECT cidade, COUNT(*) as total\nFROM clientes\nWHERE idade &gt;= 25\nGROUP BY cidade\nHAVING COUNT(*) &gt; 1\nORDER BY total DESC;\nTente fazer sozinho antes de ver a resposta!"
  },
  {
    "objectID": "apresentações/posts/sql.html#solução-do-exercício-1",
    "href": "apresentações/posts/sql.html#solução-do-exercício-1",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Solução do exercício 1",
    "text": "Solução do exercício 1\n\nclientes_db |&gt;\n  filter(idade &gt;= 25) |&gt;\n  group_by(cidade) |&gt;\n  summarise(total = n()) |&gt;\n  filter(total &gt; 1) |&gt;\n  arrange(desc(total))\n\nLeia em voz alta: “Pegue clientes, filtre idade &gt;= 25, agrupe por cidade, conte quantos em cada, filtre grupos com mais de 1, ordene por total decrescente”"
  },
  {
    "objectID": "apresentações/posts/sql.html#exercício-2",
    "href": "apresentações/posts/sql.html#exercício-2",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Exercício 2",
    "text": "Exercício 2\nDesafio: Crie uma query que:\n\nUna clientes e vendas\nCalcule o valor total por cliente\nMostre apenas clientes com total &gt; 200\nOrdene do maior para o menor\n\nTente fazer sozinho!"
  },
  {
    "objectID": "apresentações/posts/sql.html#solução-do-exercício-2",
    "href": "apresentações/posts/sql.html#solução-do-exercício-2",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Solução do exercício 2",
    "text": "Solução do exercício 2\n\nclientes_db |&gt;\n  inner_join(vendas_db, by = c(\"id\" = \"cliente_id\")) |&gt;\n  group_by(nome) |&gt;\n  summarise(valor_total = sum(valor, na.rm = TRUE)) |&gt;\n  filter(valor_total &gt; 200) |&gt;\n  arrange(desc(valor_total))\n\n# Source:     SQL [?? x 2]\n# Database:   sqlite 3.50.4 [:memory:]\n# Ordered by: desc(valor_total)\n  nome     valor_total\n  &lt;chr&gt;          &lt;dbl&gt;\n1 Ana              390\n2 Jennifer         270"
  },
  {
    "objectID": "apresentações/posts/sql.html#dicas-de-performance",
    "href": "apresentações/posts/sql.html#dicas-de-performance",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Dicas de performance",
    "text": "Dicas de performance\n1. Projete (select) cedo:\n\n# ✅ Melhor - seleciona só o necessário\ntabela |&gt; select(col1, col2) |&gt; filter(...)\n\n# ❌ Pior - carrega todas as colunas\ntabela |&gt; filter(...) |&gt; select(col1, col2)\n\n2. Filtre no banco, não no R\n3. Use índices nas colunas de JOIN e WHERE"
  },
  {
    "objectID": "apresentações/posts/sql.html#debugando-problemas-comuns",
    "href": "apresentações/posts/sql.html#debugando-problemas-comuns",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Debugando problemas comuns",
    "text": "Debugando problemas comuns\nErro: “no applicable method” -Você tentou usar uma função que não funciona com banco\n\nSolução: Use collect() antes OU use função equivalente do SQL"
  },
  {
    "objectID": "apresentações/posts/sql.html#debugando-problemas-comuns-1",
    "href": "apresentações/posts/sql.html#debugando-problemas-comuns-1",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Debugando problemas comuns",
    "text": "Debugando problemas comuns\nDados não aparecem: Lembre-se: dbplyr é lazy!\n\nSolução: Use collect() ou apenas visualize com print()"
  },
  {
    "objectID": "apresentações/posts/sql.html#debugando-problemas-comuns-2",
    "href": "apresentações/posts/sql.html#debugando-problemas-comuns-2",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Debugando problemas comuns",
    "text": "Debugando problemas comuns\nQuery muito lenta: Está trazendo dados demais?\n\nSolução: Filtre e agregue ANTES de collect()"
  },
  {
    "objectID": "apresentações/posts/sql.html#quando-não-usar-dbplyr",
    "href": "apresentações/posts/sql.html#quando-não-usar-dbplyr",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Quando NÃO usar dbplyr",
    "text": "Quando NÃO usar dbplyr\nNão use dbplyr quando:\n\nPrecisar de operações muito específicas do R (como modelos complexos)\nOs dados são pequenos (&lt; 100MB) - só use read_csv()\nPrecisar de loops ou operações iterativas\nA query SQL já está pronta e otimizada"
  },
  {
    "objectID": "apresentações/posts/sql.html#use-dbplyr-quando",
    "href": "apresentações/posts/sql.html#use-dbplyr-quando",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Use dbplyr quando",
    "text": "Use dbplyr quando\n\nDados não cabem na memória\nQuer sintaxe R mas poder do banco\nEstá explorando dados grandes\nPrecisa combinar várias fontes"
  },
  {
    "objectID": "apresentações/posts/sql.html#recursos-para-continuar",
    "href": "apresentações/posts/sql.html#recursos-para-continuar",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Recursos para continuar",
    "text": "Recursos para continuar\nDocumentação:\n\ndbplyr.tidyverse.org\nDatabase using R\n\nLivros gratuitos:\n\nR for Data Science - Cap. Databases\n\nPrática:\n\nUse seus próprios bancos!\nComece com SQLite para aprender\nDepois migre para PostgreSQL/MySQL"
  },
  {
    "objectID": "apresentações/posts/sql.html#projeto-prático-sugerido",
    "href": "apresentações/posts/sql.html#projeto-prático-sugerido",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Projeto prático sugerido",
    "text": "Projeto prático sugerido\nMini projeto para praticar:\n\nCrie um banco SQLite com 2-3 tabelas relacionadas\nEscreva 5 queries SQL que você já conhece\nTraduza todas para dbplyr\nCompare os resultados\nUse show_query() para ver o SQL gerado\nIdentifique padrões de tradução\n\nIsso vai consolidar seu aprendizado!"
  },
  {
    "objectID": "apresentações/posts/sql.html#cheat-sheet-rápido",
    "href": "apresentações/posts/sql.html#cheat-sheet-rápido",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Cheat sheet rápido",
    "text": "Cheat sheet rápido\n\n# Conectar\ncon &lt;- dbConnect(RSQLite::SQLite(), \"banco.db\")\ntabela &lt;- tbl(con, \"nome_tabela\")\n\n# Operações básicas\ntabela |&gt; filter(col &gt; 10)        # WHERE\ntabela |&gt; select(col1, col2)      # SELECT\ntabela |&gt; arrange(col)            # ORDER BY\ntabela |&gt; distinct(col)           # DISTINCT\n\n# Agregações\ntabela |&gt; group_by(col) |&gt;\n  summarise(total = n())          # COUNT\n\n# Joins\nleft_join(tab1, tab2, by = \"id\")  # LEFT JOIN\n\n# Executar\ntabela |&gt; collect()               # Trazer para R\ntabela |&gt; show_query()            # Ver SQL"
  },
  {
    "objectID": "apresentações/posts/sql.html#recapitulando",
    "href": "apresentações/posts/sql.html#recapitulando",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Recapitulando",
    "text": "Recapitulando\nVocê aprendeu:\n\nO que é dbplyr e como funciona\nConectar R a bancos de dados\nTraduzir SELECT, WHERE, JOIN, GROUP BY\nUsar collect() e show_query()\nBoas práticas de performance\nQuando usar (e não usar) dbplyr\n\nO melhor: Você pode escrever R e deixar o banco fazer o trabalho pesado!"
  },
  {
    "objectID": "apresentações/posts/sql.html#dica-final",
    "href": "apresentações/posts/sql.html#dica-final",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Dica final",
    "text": "Dica final\nFluxo ideal:\n\nEscreva a query em dplyr\nUse show_query() para ver o SQL\nAprenda com a tradução\nOtimize se necessário\nUse collect() só no final\n\n“Pense em R, execute em SQL, aprenda os dois!”\nA cada query você escreve, está praticando DUAS linguagens ao mesmo tempo!"
  },
  {
    "objectID": "apresentações/posts/sql.html#mensagem-final",
    "href": "apresentações/posts/sql.html#mensagem-final",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Mensagem final",
    "text": "Mensagem final\nSQL + R = 💪\nVocê não precisa escolher entre SQL e R.\nCom dbplyr, você tem o melhor dos dois mundos:\n\nA elegância do tidyverse\nO poder e performance do SQL\nA flexibilidade de escolher quando usar cada um\n\nContinue praticando e explorando!"
  },
  {
    "objectID": "apresentações/posts/sql.html#muito-obrigada",
    "href": "apresentações/posts/sql.html#muito-obrigada",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Muito obrigada!",
    "text": "Muito obrigada!\nEsta apresentação é parte do projeto Café com R\nÉ OPEN, USE, COMPARTILHE!\nPerguntas? Dúvidas? Sugestões?\nPróximo passo: Abra seu RStudio e comece a praticar!"
  },
  {
    "objectID": "apresentações/posts/sql.html#limpando-o-ambiente",
    "href": "apresentações/posts/sql.html#limpando-o-ambiente",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "Limpando o ambiente",
    "text": "Limpando o ambiente\nNão esqueça de fechar a conexão ao terminar:\n\n# Fechar conexão\ndbDisconnect(con)\n\nBoa prática: Sempre feche conexões para liberar recursos!"
  },
  {
    "objectID": "apresentações/posts/sql.html#assine-o-café-com-r-1",
    "href": "apresentações/posts/sql.html#assine-o-café-com-r-1",
    "title": "5. Do SQL para o R com dbplyr",
    "section": "☕ Assine o Café com R",
    "text": "☕ Assine o Café com R\nFique por dentro das aulas, conteúdos, newsletter!\n\nQue cada gole desperte uma nova ideia.\nQue cada script abra uma nova conversa.\nQue o Café com R, se torne um ponto de encontro nosso!"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#assine-o-café-com-r",
    "href": "apresentações/posts/manipulacao.html#assine-o-café-com-r",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "☕ Assine o Café com R",
    "text": "☕ Assine o Café com R\nFique por dentro das aulas, conteúdos, newsletter!\n\nQue cada gole desperte uma nova ideia.\nQue cada script abra uma nova conversa.\nQue o Café com R, se torne um ponto de encontro nosso!"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#introdução-à-manipulação-de-dados-no-r",
    "href": "apresentações/posts/manipulacao.html#introdução-à-manipulação-de-dados-no-r",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "Introdução à manipulação de dados no R",
    "text": "Introdução à manipulação de dados no R\nManipulação de dados é a base da análise.\nO pacote dplyr permite transformar dados de forma clara e eficiente.\nVocê aprenderá:\n\nFundamentos do dplyr\nVerbos principais e avançados\nAnálises com dados agrupados\nAplicações práticas com o dataset CO2"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#o-dataset-co2-carregando-os-dados",
    "href": "apresentações/posts/manipulacao.html#o-dataset-co2-carregando-os-dados",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "O dataset CO2: Carregando os dados:",
    "text": "O dataset CO2: Carregando os dados:\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tibble)\n\ndata(CO2)\nCO2 |&gt; as_tibble()\n\n# A tibble: 84 × 5\n   Plant Type   Treatment   conc uptake\n   &lt;ord&gt; &lt;fct&gt;  &lt;fct&gt;      &lt;dbl&gt;  &lt;dbl&gt;\n 1 Qn1   Quebec nonchilled    95   16  \n 2 Qn1   Quebec nonchilled   175   30.4\n 3 Qn1   Quebec nonchilled   250   34.8\n 4 Qn1   Quebec nonchilled   350   37.2\n 5 Qn1   Quebec nonchilled   500   35.3\n 6 Qn1   Quebec nonchilled   675   39.2\n 7 Qn1   Quebec nonchilled  1000   39.7\n 8 Qn2   Quebec nonchilled    95   13.6\n 9 Qn2   Quebec nonchilled   175   27.3\n10 Qn2   Quebec nonchilled   250   37.1\n# ℹ 74 more rows"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#o-dataset-co2-cont.",
    "href": "apresentações/posts/manipulacao.html#o-dataset-co2-cont.",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "O dataset CO2 (cont.)",
    "text": "O dataset CO2 (cont.)\nVariáveis principais:\n\nPlant: identificação da planta\nType: Quebec ou Mississippi\nTreatment: não resfriado ou resfriado\nconc: concentração de CO₂\nuptake: absorção de CO₂"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#estrutura-dos-dados-co2",
    "href": "apresentações/posts/manipulacao.html#estrutura-dos-dados-co2",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "Estrutura dos dados CO2",
    "text": "Estrutura dos dados CO2\nA estrutura:\nuptake ~ conc | Plant\nSignifica:\n\nuptake varia conforme conc\nA curva é observada individualmente para cada Plant"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#aplicações-dos-dados-co2",
    "href": "apresentações/posts/manipulacao.html#aplicações-dos-dados-co2",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "Aplicações dos dados CO2",
    "text": "Aplicações dos dados CO2\nAplicações:\n\nAnálises fisiológicas\nCurvas de resposta à concentração\nEstudos experimentais\nComparações entre plantas e tratamentos"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#verbos-principais-do-dplyr",
    "href": "apresentações/posts/manipulacao.html#verbos-principais-do-dplyr",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "Verbos principais do dplyr",
    "text": "Verbos principais do dplyr\nA gramática do dplyr usa verbos intuitivos:\n\nfilter(): filtra linhas\nselect(): seleciona colunas\narrange(): ordena dados\nmutate(): cria/modifica variáveis\nsummarise(): resume dados\ngroup_by(): agrupa para operações"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#filter-selecionando-observações",
    "href": "apresentações/posts/manipulacao.html#filter-selecionando-observações",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "filter(): selecionando observações",
    "text": "filter(): selecionando observações\nPlantas do tipo Quebec:\nCO2 |&gt;\n  filter(Type == \"Quebec\")\nConcentrações acima de 500:\nCO2 |&gt;\n  filter(conc &gt; 500)"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#filter-múltiplas-condições",
    "href": "apresentações/posts/manipulacao.html#filter-múltiplas-condições",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "filter(): múltiplas condições",
    "text": "filter(): múltiplas condições\nCombinando condições:\nCO2 |&gt;\n  filter(Type == \"Quebec\", Treatment == \"chilled\")\nOperador OR:\nCO2 |&gt;\n  filter(Type == \"Quebec\" | conc &gt; 500)"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#select-escolhendo-colunas",
    "href": "apresentações/posts/manipulacao.html#select-escolhendo-colunas",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "select(): escolhendo colunas",
    "text": "select(): escolhendo colunas\nSelecionando colunas específicas:\nCO2 |&gt;\n  select(Plant, conc, uptake)\nRemovendo colunas:\nCO2 |&gt;\n  select(-Treatment)"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#select-seleção-avançada",
    "href": "apresentações/posts/manipulacao.html#select-seleção-avançada",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "select(): seleção avançada",
    "text": "select(): seleção avançada\nSeleção por padrão:\nCO2 |&gt;\n  select(starts_with(\"u\"))\nOutros helpers:\n\nends_with()\ncontains()\nwhere(is.numeric)"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#arrange-ordenando-linhas",
    "href": "apresentações/posts/manipulacao.html#arrange-ordenando-linhas",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "arrange(): ordenando linhas",
    "text": "arrange(): ordenando linhas\nOrdenação crescente:\nCO2 |&gt;\n  arrange(uptake)\nOrdenação decrescente:\nCO2 |&gt;\n  arrange(desc(conc))"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#arrange-múltiplos-critérios",
    "href": "apresentações/posts/manipulacao.html#arrange-múltiplos-critérios",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "arrange(): múltiplos critérios",
    "text": "arrange(): múltiplos critérios\nOrdenando por múltiplas colunas:\nCO2 |&gt;\n  arrange(Type, desc(uptake))\nPrimeiro ordena por Type, depois por uptake decrescente."
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#mutate-criando-novas-variáveis",
    "href": "apresentações/posts/manipulacao.html#mutate-criando-novas-variáveis",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "mutate(): criando novas variáveis",
    "text": "mutate(): criando novas variáveis\nVariável normalizada:\nCO2 |&gt;\n  mutate(uptake_norm = uptake / max(uptake))\nClassificação condicional:\nCO2 |&gt;\n  mutate(faixa = if_else(conc &lt; 500, \"Baixa\", \"Alta\"))"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#mutate-transformações-múltiplas",
    "href": "apresentações/posts/manipulacao.html#mutate-transformações-múltiplas",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "mutate(): transformações múltiplas",
    "text": "mutate(): transformações múltiplas\nVárias colunas de uma vez:\nCO2 |&gt;\n  mutate(\n    log_conc = log(conc),\n    uptake_sq = uptake^2,\n    ratio = uptake / conc)"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#group_by-summarise",
    "href": "apresentações/posts/manipulacao.html#group_by-summarise",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "group_by() + summarise()",
    "text": "group_by() + summarise()\nEstatísticas por grupo:\nCO2 |&gt;\n  group_by(Type) |&gt;\n  summarise(\n    media = mean(uptake),\n    sd = sd(uptake),\n    n = n())"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#group_by-summarise-cont.",
    "href": "apresentações/posts/manipulacao.html#group_by-summarise-cont.",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "group_by() + summarise() (cont.)",
    "text": "group_by() + summarise() (cont.)\nMúltiplos agrupamentos:\nCO2 |&gt;\n  group_by(Type, Treatment) |&gt;\n  summarise(\n    media = mean(uptake),\n    max = max(uptake),\n    .groups = \"drop\")\nSempre use .groups = \"drop\" para remover agrupamentos."
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#workflow-combinação-de-verbos",
    "href": "apresentações/posts/manipulacao.html#workflow-combinação-de-verbos",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "Workflow: combinação de verbos",
    "text": "Workflow: combinação de verbos\nPipeline completo:\nCO2 |&gt;\n  filter(conc &gt;= 500) |&gt;\n  mutate(log_conc = log(conc)) |&gt;\n  group_by(Type, Treatment) |&gt;\n  summarise(\n    media = mean(uptake),\n    max = max(uptake),\n    n = n(),\n    .groups = \"drop\")"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#workflow-o-pipe",
    "href": "apresentações/posts/manipulacao.html#workflow-o-pipe",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "Workflow: o pipe |>",
    "text": "Workflow: o pipe |&gt;\nO pipe |&gt; permite encadear operações de forma legível.\nLê-se como: “e então…”\ndados |&gt;        # pegue os dados, e então\n  filter() |&gt;   # filtre, e então\n  mutate() |&gt;   # crie variáveis, e então\n  summarise()   # resuma"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#estatísticas-descritivas-por-planta",
    "href": "apresentações/posts/manipulacao.html#estatísticas-descritivas-por-planta",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "Estatísticas descritivas por planta",
    "text": "Estatísticas descritivas por planta\nCO2 |&gt;\n  group_by(Plant) |&gt;\n  summarise(\n    min_uptake = min(uptake),\n    max_uptake = max(uptake),\n    intervalo = max(uptake) - min(uptake))"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#estatísticas-descritivas-cont.",
    "href": "apresentações/posts/manipulacao.html#estatísticas-descritivas-cont.",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "Estatísticas descritivas (cont.)",
    "text": "Estatísticas descritivas (cont.)\nAdicionando mais medidas:\nCO2 |&gt;\n  group_by(Plant) |&gt;\n  summarise(\n    media = mean(uptake),\n    n_medidas = n(),\n    variancia = var(uptake))"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#mutate-com-agrupamento",
    "href": "apresentações/posts/manipulacao.html#mutate-com-agrupamento",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "mutate() com agrupamento",
    "text": "mutate() com agrupamento\nCentralização intra-grupo:\nCO2 |&gt;\n  group_by(Plant) |&gt;\n  mutate(uptake_centered = uptake - mean(uptake))"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#mutate-com-agrupamento-cont.",
    "href": "apresentações/posts/manipulacao.html#mutate-com-agrupamento-cont.",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "mutate() com agrupamento (cont.)",
    "text": "mutate() com agrupamento (cont.)\nUso típico:\n\nCentralização de variáveis\nAnálises intra-grupo\nCálculos relativos\nPreparação para modelos estatísticos\n\nDiferença: mutate() mantém todas as linhas, summarise() reduz para uma linha por grupo."
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#funções-auxiliares-first-last-n",
    "href": "apresentações/posts/manipulacao.html#funções-auxiliares-first-last-n",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "Funções auxiliares: first(), last(), n()",
    "text": "Funções auxiliares: first(), last(), n()\nCO2 |&gt;\n  group_by(Plant) |&gt;\n  summarise(\n    n_medidas = n(),\n    conc_unicas = n_distinct(conc),\n    primeira = first(uptake),\n    ultima = last(uptake))"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#funções-auxiliares-quando-usar",
    "href": "apresentações/posts/manipulacao.html#funções-auxiliares-quando-usar",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "Funções auxiliares: quando usar",
    "text": "Funções auxiliares: quando usar\nÚtil para:\n\nContar observações (n())\nIdentificar valores iniciais/finais (first(), last())\nVerificar níveis únicos (n_distinct())\nExploração inicial dos dados"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#slice_family-slice_max-e-slice_min",
    "href": "apresentações/posts/manipulacao.html#slice_family-slice_max-e-slice_min",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "slice_family: slice_max e slice_min",
    "text": "slice_family: slice_max e slice_min\nMaiores valores:\nCO2 |&gt;\n  group_by(Plant) |&gt;\n  slice_max(uptake, n = 3)\nMenores valores:\nCO2 |&gt;\n  group_by(Type) |&gt;\n  slice_min(conc, n = 2)"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#slice_family-slice_head-e-slice_tail",
    "href": "apresentações/posts/manipulacao.html#slice_family-slice_head-e-slice_tail",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "slice_family: slice_head e slice_tail",
    "text": "slice_family: slice_head e slice_tail\nPrimeiras linhas:\nCO2 |&gt;\n  group_by(Type) |&gt;\n  slice_head(n = 5)\nÚltimas linhas:\nCO2 |&gt;\n  group_by(Type) |&gt;\n  slice_tail(n = 5)"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#case_when-múltiplas-condições",
    "href": "apresentações/posts/manipulacao.html#case_when-múltiplas-condições",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "case_when(): múltiplas condições",
    "text": "case_when(): múltiplas condições\nCO2 |&gt;\n  mutate(classificacao = case_when(\n    uptake &lt; 20 ~ \"Baixa\",\n    uptake &lt; 40 ~ \"Média\",\n    TRUE ~ \"Alta\"))"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#case_when-vantagens",
    "href": "apresentações/posts/manipulacao.html#case_when-vantagens",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "case_when(): vantagens",
    "text": "case_when(): vantagens\nVantagens:\n\nMais legível que múltiplos if_else()\nSuporta muitas condições\nSintaxe clara e concisa\nOrdem importa: primeira condição verdadeira vence\n\nDica: use TRUE ~ para o caso padrão (equivalente ao “else”)."
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#across-operações-em-múltiplas-colunas",
    "href": "apresentações/posts/manipulacao.html#across-operações-em-múltiplas-colunas",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "across(): operações em múltiplas colunas",
    "text": "across(): operações em múltiplas colunas\nAplicar funções a várias colunas:\nCO2 |&gt;\n  summarise(\n    across(\n      c(conc, uptake),\n      list(media = mean, sd = sd)))"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#across-com-seletores",
    "href": "apresentações/posts/manipulacao.html#across-com-seletores",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "across(): com seletores",
    "text": "across(): com seletores\nCom agrupamento e seletores:\nCO2 |&gt;\n  group_by(Type) |&gt;\n  summarise(\n    across(\n      where(is.numeric),\n      mean))\nAplica mean() em todas as colunas numéricas."
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#rowwise-cálculos-linha-a-linha",
    "href": "apresentações/posts/manipulacao.html#rowwise-cálculos-linha-a-linha",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "rowwise(): cálculos linha a linha",
    "text": "rowwise(): cálculos linha a linha\nCO2 |&gt;\n  rowwise() |&gt;\n  mutate(\n    indice_composto = mean(c(uptake, conc)))"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#rowwise-quando-usar",
    "href": "apresentações/posts/manipulacao.html#rowwise-quando-usar",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "rowwise(): quando usar",
    "text": "rowwise(): quando usar\nQuando usar:\n\nOperações que precisam de valores da mesma linha\nCálculos que não são vetorizados\nFunções que operam em conjuntos de valores\n\nAtenção: pode ser lento com grandes datasets."
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#joins-complementando-dados",
    "href": "apresentações/posts/manipulacao.html#joins-complementando-dados",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "Joins: complementando dados",
    "text": "Joins: complementando dados\nCriando tabela auxiliar:\ninfo &lt;- tibble(\n  Plant = unique(CO2$Plant),\n  lote = sample(1:3, 12, replace = TRUE))\n\nCO2 |&gt;\n  left_join(info, by = \"Plant\")"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#joins-tipos-principais",
    "href": "apresentações/posts/manipulacao.html#joins-tipos-principais",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "Joins: tipos principais",
    "text": "Joins: tipos principais\nTipos de join:\n\nleft_join(): mantém todas as linhas da esquerda\ninner_join(): apenas correspondências\nfull_join(): todas as linhas de ambas\nright_join(): mantém todas as linhas da direita\n\nUse quando: precisar combinar dados de diferentes fontes."
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#lag-e-lead-valores-anterioresposteriores",
    "href": "apresentações/posts/manipulacao.html#lag-e-lead-valores-anterioresposteriores",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "lag() e lead(): valores anteriores/posteriores",
    "text": "lag() e lead(): valores anteriores/posteriores\nCO2 |&gt;\n  group_by(Plant) |&gt;\n  arrange(conc) |&gt;\n  mutate(\n    uptake_anterior = lag(uptake),\n    uptake_proximo = lead(uptake))"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#derivadas-de-resposta",
    "href": "apresentações/posts/manipulacao.html#derivadas-de-resposta",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "Derivadas de resposta",
    "text": "Derivadas de resposta\nCO2 |&gt;\n  group_by(Plant) |&gt;\n  arrange(conc) |&gt;\n  mutate(\n    delta_uptake = uptake - lag(uptake),\n    delta_conc = conc - lag(conc),\n    taxa = delta_uptake / delta_conc)\nAplicações: calcular mudanças, taxas de crescimento, derivadas discretas."
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#ranking-row_number-e-dense_rank",
    "href": "apresentações/posts/manipulacao.html#ranking-row_number-e-dense_rank",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "Ranking: row_number() e dense_rank()",
    "text": "Ranking: row_number() e dense_rank()\nCO2 |&gt;\n  group_by(Type) |&gt;\n  mutate(\n    posicao = row_number(desc(uptake)),\n    posicao_densa = dense_rank(desc(uptake)),\n    percentil = percent_rank(uptake))"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#ranking-diferenças",
    "href": "apresentações/posts/manipulacao.html#ranking-diferenças",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "Ranking: diferenças",
    "text": "Ranking: diferenças\nDiferenças:\n\nrow_number(): números únicos consecutivos (1, 2, 3…)\ndense_rank(): empates recebem mesmo rank (1, 1, 2, 3…)\nmin_rank(): empates pulam posições (1, 1, 3, 4…)\npercent_rank(): posição como percentual (0-1)"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#detectando-outliers-com-z-score",
    "href": "apresentações/posts/manipulacao.html#detectando-outliers-com-z-score",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "Detectando outliers com z-score",
    "text": "Detectando outliers com z-score\nCO2 |&gt;\n  group_by(Type) |&gt;\n  mutate(\n    z = (uptake - mean(uptake)) / sd(uptake),\n    outlier = abs(z) &gt; 2) |&gt;\n  filter(outlier)"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#z-score-interpretação",
    "href": "apresentações/posts/manipulacao.html#z-score-interpretação",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "Z-score: interpretação",
    "text": "Z-score: interpretação\nInterpretação:\n\n|z| &gt; 2: possível outlier (≈5% dos dados)\n|z| &gt; 3: outlier provável (≈0.3% dos dados)\n\nObservação: assume distribuição normal dos dados."
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#estatísticas-por-quantis",
    "href": "apresentações/posts/manipulacao.html#estatísticas-por-quantis",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "Estatísticas por quantis",
    "text": "Estatísticas por quantis\nCO2 |&gt;\n  group_by(Type) |&gt;\n  summarise(\n    q25 = quantile(uptake, 0.25),\n    mediana = quantile(uptake, 0.5),\n    q75 = quantile(uptake, 0.75))"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#estatísticas-por-quantis-cont.",
    "href": "apresentações/posts/manipulacao.html#estatísticas-por-quantis-cont.",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "Estatísticas por quantis (cont.)",
    "text": "Estatísticas por quantis (cont.)\nAdicionando intervalo interquartil:\nCO2 |&gt;\n  group_by(Type) |&gt;\n  summarise(\n    q25 = quantile(uptake, 0.25),\n    q75 = quantile(uptake, 0.75),\n    iqr = IQR(uptake))\nVantagem: medidas robustas, menos sensíveis a outliers."
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#funções-personalizadas",
    "href": "apresentações/posts/manipulacao.html#funções-personalizadas",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "Funções personalizadas",
    "text": "Funções personalizadas\nCriando função própria:\ncv &lt;- function(x) sd(x) / mean(x) * 100\n\nCO2 |&gt;\n  group_by(Type) |&gt;\n  summarise(\n    coef_var = cv(uptake))"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#funções-personalizadas-vantagens",
    "href": "apresentações/posts/manipulacao.html#funções-personalizadas-vantagens",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "Funções personalizadas: vantagens",
    "text": "Funções personalizadas: vantagens\nVantagens:\n\nReutilização de código\nCálculos complexos simplificados\nCódigo mais legível e organizado\nFacilita manutenção\n\nDica: crie funções para cálculos repetidos."
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#agregações-multifatoriais",
    "href": "apresentações/posts/manipulacao.html#agregações-multifatoriais",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "Agregações multifatoriais",
    "text": "Agregações multifatoriais\nCO2 |&gt;\n  group_by(Type, Treatment) |&gt;\n  summarise(\n    n = n(),\n    media = mean(uptake),\n    sd = sd(uptake),\n    .groups = \"drop\")"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#agregações-multifatoriais-cont.",
    "href": "apresentações/posts/manipulacao.html#agregações-multifatoriais-cont.",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "Agregações multifatoriais (cont.)",
    "text": "Agregações multifatoriais (cont.)\nAdicionando erro padrão:\nCO2 |&gt;\n  group_by(Type, Treatment) |&gt;\n  summarise(\n    n = n(),\n    media = mean(uptake),\n    se = sd(uptake) / sqrt(n()),\n    .groups = \"drop\")\nAnálise completa: tamanho amostral, tendência central, dispersão, erro padrão."
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#visualização-médias-por-grupo",
    "href": "apresentações/posts/manipulacao.html#visualização-médias-por-grupo",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "Visualização: médias por grupo",
    "text": "Visualização: médias por grupo\nCO2 |&gt;\n  group_by(Type, Treatment) |&gt;\n  summarise(media = mean(uptake), .groups = \"drop\") |&gt;\n  ggplot(aes(Type, media, fill = Treatment)) +\n  geom_col(position = \"dodge\")"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#visualização-adicionando-labels",
    "href": "apresentações/posts/manipulacao.html#visualização-adicionando-labels",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "Visualização: adicionando labels",
    "text": "Visualização: adicionando labels\nCO2 |&gt;\n  group_by(Type, Treatment) |&gt;\n  summarise(media = mean(uptake), .groups = \"drop\") |&gt;\n  ggplot(aes(Type, media, fill = Treatment)) +\n  geom_col(position = \"dodge\") +\n  labs(\n    title = \"Absorção média de CO₂\",\n    y = \"Uptake médio\",\n    x = \"Tipo de planta\")"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#curvas-de-resposta-visualização",
    "href": "apresentações/posts/manipulacao.html#curvas-de-resposta-visualização",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "Curvas de resposta: visualização",
    "text": "Curvas de resposta: visualização\nggplot(CO2, aes(conc, uptake, color = Plant)) +\n  geom_point() +\n  geom_smooth(method = \"loess\", se = FALSE)"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#curvas-de-resposta-com-facetas",
    "href": "apresentações/posts/manipulacao.html#curvas-de-resposta-com-facetas",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "Curvas de resposta: com facetas",
    "text": "Curvas de resposta: com facetas\n\nexemplo &lt;- ggplot(CO2, aes(conc, uptake, color = Plant)) +\n  geom_point() +\n  geom_smooth(method = \"loess\", se = FALSE) +\n  facet_wrap(~Type) +\n  labs(\n    title = \"Curvas de resposta ao CO₂\",\n    x = \"Concentração de CO₂\",\n    y = \"Absorção de CO₂\")\nexemplo"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#modelos-por-grupo-nest-map",
    "href": "apresentações/posts/manipulacao.html#modelos-por-grupo-nest-map",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "Modelos por grupo: nest() + map()",
    "text": "Modelos por grupo: nest() + map()\nlibrary(purrr)\nlibrary(broom)\n\nmodelos &lt;- CO2 |&gt;\n  group_by(Plant) |&gt;\n  nest()"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#modelos-por-grupo-ajustando",
    "href": "apresentações/posts/manipulacao.html#modelos-por-grupo-ajustando",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "Modelos por grupo: ajustando",
    "text": "Modelos por grupo: ajustando\nmodelos &lt;- CO2 |&gt;\n  group_by(Plant) |&gt;\n  nest() |&gt;\n  mutate(\n    ajuste = map(data, ~ lm(uptake ~ conc, data = .x)),\n    resultados = map(ajuste, tidy)) |&gt;\n  unnest(resultados)\nProgramação funcional aplicada à análise de dados."
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#dicas-finais-boas-práticas",
    "href": "apresentações/posts/manipulacao.html#dicas-finais-boas-práticas",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "Dicas finais: boas práticas",
    "text": "Dicas finais: boas práticas\nBoas práticas:\n\nUse pipes |&gt; para clareza\nNomeie objetos intermediários quando necessário\nSempre use .groups = \"drop\" em summarise()\nVerifique seus dados com glimpse() e summary()"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#dicas-finais-recursos-de-ajuda",
    "href": "apresentações/posts/manipulacao.html#dicas-finais-recursos-de-ajuda",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "Dicas finais: recursos de ajuda",
    "text": "Dicas finais: recursos de ajuda\nRecursos:\n\nUse ?dplyr::filter para ajuda\nCheat sheets do RStudio\nComunidade R Brasil\nStack Overflow em português\n\nDocumentação oficial: https://dplyr.tidyverse.org"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#considerações-finais",
    "href": "apresentações/posts/manipulacao.html#considerações-finais",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "Considerações finais",
    "text": "Considerações finais\nVocê aprendeu:\n\nVerbos fundamentais do dplyr\nManipulação com dados agrupados\nTécnicas avançadas de transformação\nAnálise completa com dataset CO2\nIntegração com visualização"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#próximos-passos",
    "href": "apresentações/posts/manipulacao.html#próximos-passos",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "Próximos passos",
    "text": "Próximos passos\nPróximos passos:\n\nPraticar com seus próprios dados\nExplorar outros pacotes do tidyverse\nAprofundar em tidyr (pivot, separate, unite)\nAprender purrr para programação funcional\nEstudar ggplot2 para visualizações avançadas"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#referências",
    "href": "apresentações/posts/manipulacao.html#referências",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "Referências",
    "text": "Referências\n\nWickham, H. & Grolemund, G. R for Data Science\nDocumentação do tidyverse: https://dplyr.tidyverse.org\nDataset CO2: ?datasets::CO2\nWickham, H. Advanced R"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#muito-obrigada",
    "href": "apresentações/posts/manipulacao.html#muito-obrigada",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "Muito Obrigada!",
    "text": "Muito Obrigada!\nÉ OPEN, USE, COMPARTILHE!\n\n\n\nIlustração por Allison Horst"
  },
  {
    "objectID": "apresentações/posts/manipulacao.html#assine-o-café-com-r-1",
    "href": "apresentações/posts/manipulacao.html#assine-o-café-com-r-1",
    "title": "3. Manipulação de Dados com dplyr",
    "section": "☕ Assine o Café com R",
    "text": "☕ Assine o Café com R\nFique por dentro das aulas, conteúdos, newsletter!\n\nQue cada gole desperte uma nova ideia.\nQue cada script abra uma nova conversa.\nQue o Café com R, se torne um ponto de encontro nosso!"
  },
  {
    "objectID": "apresentações/posts/funções_jeni.html#antes-de-começar",
    "href": "apresentações/posts/funções_jeni.html#antes-de-começar",
    "title": "2. Funções em R",
    "section": "Antes de começar",
    "text": "Antes de começar\nEssa é a Meguy, minha gatinha! E no dia que eu estava construindo esse conteúdo, ela estava deitada na minha mesa, aí fui fazer uma foto e olhem o que deu:\n\nUma piscadinha para vocês, agora todo mundo vai aprender tudo sobre funções, tenho certeza!"
  },
  {
    "objectID": "apresentações/posts/funções_jeni.html#assine-o-café-com-r",
    "href": "apresentações/posts/funções_jeni.html#assine-o-café-com-r",
    "title": "2. Funções em R",
    "section": "☕ Assine o Café com R",
    "text": "☕ Assine o Café com R\nFique por dentro das aulas, conteúdos, newsletter!\n\nQue cada gole desperte uma nova ideia.\nQue cada script abra uma nova conversa.\nQue o Café com R, se torne um ponto de encontro nosso!"
  },
  {
    "objectID": "apresentações/posts/funções_jeni.html#o-problema-do-código-repetitivo",
    "href": "apresentações/posts/funções_jeni.html#o-problema-do-código-repetitivo",
    "title": "2. Funções em R",
    "section": "O problema do código repetitivo",
    "text": "O problema do código repetitivo\nVocê escreve isso toda semana?\n# Análise para variável 1\nsummary(dados$idade)\nsd(dados$idade, na.rm = TRUE)\nquantile(dados$idade, probs = c(0.25, 0.5, 0.75))\nhist(dados$idade, main = \"Idade\", col = \"lightblue\")\n\n# Análise para variável 2\nsummary(dados$salario)\nsd(dados$salario, na.rm = TRUE)\nquantile(dados$salario, probs = c(0.25, 0.5, 0.75))\nhist(dados$salario, main = \"Salário\", col = \"lightblue\")"
  },
  {
    "objectID": "apresentações/posts/funções_jeni.html#por-que-isso-é-um-problema",
    "href": "apresentações/posts/funções_jeni.html#por-que-isso-é-um-problema",
    "title": "2. Funções em R",
    "section": "Por que isso é um problema?",
    "text": "Por que isso é um problema?\n\n\n\n\n\n\nAtenção\n\n\nCopiar e colar código cria riscos:\nErros silenciosos - Copiou mas esqueceu de mudar o nome da variável - O resultado está errado mas você não percebe\nManutenção difícil - Precisa mudar a cor do gráfico? Edite em 20 lugares - Risco de inconsistências\nCódigo ilegível - Difícil de revisar - Difícil de compartilhar com a equipe"
  },
  {
    "objectID": "apresentações/posts/funções_jeni.html#a-solução-funções",
    "href": "apresentações/posts/funções_jeni.html#a-solução-funções",
    "title": "2. Funções em R",
    "section": "A solução: Funções",
    "text": "A solução: Funções\nTransforme código repetitivo em uma função:\nanalisar_variavel &lt;- function(dados, variavel) {\n  valores &lt;- dados[[variavel]]\n  \n  cat(\"Resumo Estatístico:\\n\")\n  print(summary(valores))\n  \n  cat(\"\\nDesvio Padrão:\", sd(valores, na.rm = TRUE))\n  \n  cat(\"\\nQuartis:\\n\")\n  print(quantile(valores, probs = c(0.25, 0.5, 0.75)))\n  \n  hist(valores, main = variavel, col = \"lightblue\")\n}\nUso:\nanalisar_variavel(dados, \"idade\")\nanalisar_variavel(dados, \"salario\")"
  },
  {
    "objectID": "apresentações/posts/funções_jeni.html#anatomia-de-uma-função",
    "href": "apresentações/posts/funções_jeni.html#anatomia-de-uma-função",
    "title": "2. Funções em R",
    "section": "Anatomia de uma função",
    "text": "Anatomia de uma função\nEstrutura básica:\nnome_da_funcao &lt;- function(argumentos) {\n  # Corpo da função\n  resultado &lt;- processamento(argumentos)\n  return(resultado)\n}\nComponentes essenciais:\n\nNome: Descreve o que a função faz\nArgumentos: Entradas que a função recebe\nCorpo: Lógica de processamento\nRetorno: O que a função devolve"
  },
  {
    "objectID": "apresentações/posts/funções_jeni.html#componente-1-nome-da-função",
    "href": "apresentações/posts/funções_jeni.html#componente-1-nome-da-função",
    "title": "2. Funções em R",
    "section": "Componente 1: Nome da função",
    "text": "Componente 1: Nome da função\nBoas práticas para nomear funções:\n# Use verbos descritivos\ncalcular_media()\nprocessar_dados()\ngerar_relatorio()\ntestar_normalidade()\n\n# Seja específico\ncalcular_media_ponderada()\ntestar_diferenca_grupos()\nplotar_dispersao()\n\n# Evite nomes genéricos\nfazer()          # O quê?\nprocessar()      # Processar como?\nanalisar()       # Que tipo de análise?\nConvenção: use snake_case (palavras separadas por underscore)"
  },
  {
    "objectID": "apresentações/posts/funções_jeni.html#componente-2-argumentos",
    "href": "apresentações/posts/funções_jeni.html#componente-2-argumentos",
    "title": "2. Funções em R",
    "section": "Componente 2: Argumentos",
    "text": "Componente 2: Argumentos\nArgumentos são as entradas da função:\n# Argumentos obrigatórios\ncalcular_media &lt;- function(x) {\n  mean(x, na.rm = TRUE)\n}\n\n# Argumentos com valores padrão\ncalcular_media &lt;- function(x, remover_na = TRUE) {\n  mean(x, na.rm = remover_na)\n}\n\n# Múltiplos argumentos\ntestar_diferenca &lt;- function(grupo1, grupo2, tipo = \"t.test\") {\n  if (tipo == \"t.test\") {\n    t.test(grupo1, grupo2)\n  } else if (tipo == \"wilcox\") {\n    wilcox.test(grupo1, grupo2)\n  }\n}"
  },
  {
    "objectID": "apresentações/posts/funções_jeni.html#componente-3-corpo-da-função",
    "href": "apresentações/posts/funções_jeni.html#componente-3-corpo-da-função",
    "title": "2. Funções em R",
    "section": "Componente 3: Corpo da função",
    "text": "Componente 3: Corpo da função\nO corpo contém a lógica:\nestatisticas_basicas &lt;- function(x) {\n  # 1. Validação de entrada\n  if (!is.numeric(x)) {\n    stop(\"x deve ser numérico\")\n  }\n  \n  # 2. Processamento\n  n &lt;- length(x)\n  media &lt;- mean(x, na.rm = TRUE)\n  mediana &lt;- median(x, na.rm = TRUE)\n  dp &lt;- sd(x, na.rm = TRUE)\n  \n  # 3. Organização do resultado\n  resultado &lt;- list(\n    n = n,\n    media = media,\n    mediana = mediana,\n    desvio_padrao = dp\n  )\n  \n  return(resultado)\n}"
  },
  {
    "objectID": "apresentações/posts/funções_jeni.html#componente-4-retorno",
    "href": "apresentações/posts/funções_jeni.html#componente-4-retorno",
    "title": "2. Funções em R",
    "section": "Componente 4: Retorno",
    "text": "Componente 4: Retorno\nO que a função devolve:\n# Retorno explícito\ncalcular_soma &lt;- function(a, b) {\n  resultado &lt;- a + b\n  return(resultado)\n}\n\n# Retorno implícito (última expressão)\ncalcular_soma &lt;- function(a, b) {\n  a + b\n}\n\n# Retornar múltiplos valores (lista)\nestatisticas &lt;- function(x) {\n  list(\n    media = mean(x),\n    mediana = median(x),\n    dp = sd(x)\n  )\n}\n\n# Usar o retorno\nresultado &lt;- estatisticas(dados$idade)\nresultado$media\nresultado$mediana"
  },
  {
    "objectID": "apresentações/posts/funções_jeni.html#exemplo-teste-t",
    "href": "apresentações/posts/funções_jeni.html#exemplo-teste-t",
    "title": "2. Funções em R",
    "section": "Exemplo: Teste t",
    "text": "Exemplo: Teste t\ntestar_grupos &lt;- function(dados, variavel, grupo) {\n  # Extrair valores dos grupos\n  formula &lt;- as.formula(paste(variavel, \"~\", grupo))\n  teste &lt;- t.test(formula, data = dados)\n  \n  # Organizar resultado\n  resultado &lt;- data.frame(\n    variavel = variavel,\n    estatistica_t = round(teste$statistic, 3),\n    p_valor = round(teste$p.value, 4),\n    ic_inferior = round(teste$conf.int[1], 2),\n    ic_superior = round(teste$conf.int[2], 2)\n  )\n  \n  return(resultado)\n}\nUso:\ntestar_grupos(dados, \"idade\", \"sexo\")\ntestar_grupos(dados, \"salario\", \"departamento\")"
  },
  {
    "objectID": "apresentações/posts/funções_jeni.html#funções-com-validação",
    "href": "apresentações/posts/funções_jeni.html#funções-com-validação",
    "title": "2. Funções em R",
    "section": "Funções com validação",
    "text": "Funções com validação\nAdicione verificações para evitar erros:\ncalcular_correlacao &lt;- function(x, y, metodo = \"pearson\") {\n  # Validação 1: Tipo de dados\n  if (!is.numeric(x) | !is.numeric(y)) {\n    stop(\"x e y devem ser numéricos\")\n  }\n  \n  # Validação 2: Mesmo comprimento\n  if (length(x) != length(y)) {\n    stop(\"x e y devem ter o mesmo comprimento\")\n  }\n  \n  # Validação 3: Método válido\n  metodos_validos &lt;- c(\"pearson\", \"spearman\", \"kendall\")\n  if (!metodo %in% metodos_validos) {\n    stop(\"Método deve ser: pearson, spearman ou kendall\")\n  }\n  \n  # Cálculo\n  cor(x, y, method = metodo, use = \"complete.obs\")\n}"
  },
  {
    "objectID": "apresentações/posts/funções_jeni.html#funções-com-mensagens",
    "href": "apresentações/posts/funções_jeni.html#funções-com-mensagens",
    "title": "2. Funções em R",
    "section": "Funções com mensagens",
    "text": "Funções com mensagens\nComunique o que está acontecendo:\nprocessar_analise &lt;- function(dados, variavel) {\n  # Mensagem informativa\n  message(\"Processando variável: \", variavel)\n  \n  # Aviso se houver NAs\n  n_na &lt;- sum(is.na(dados[[variavel]]))\n  if (n_na &gt; 0) {\n    warning(\"Encontrados \", n_na, \" valores NA\")\n  }\n  \n  # Processar\n  resultado &lt;- summary(dados[[variavel]])\n  \n  # Mensagem de sucesso\n  message(\"Análise concluída!\")\n  \n  return(resultado)\n}\nTipos de mensagens: - message() - Informações gerais - warning() - Avisos (não para a execução) - stop() - Erros críticos (para a execução)"
  },
  {
    "objectID": "apresentações/posts/funções_jeni.html#modularização-dividir-para-conquistar",
    "href": "apresentações/posts/funções_jeni.html#modularização-dividir-para-conquistar",
    "title": "2. Funções em R",
    "section": "Modularização: Dividir para conquistar",
    "text": "Modularização: Dividir para conquistar\nEm vez de uma função gigante:\n# Função grande e confusa\nanalisar_tudo &lt;- function(dados) {\n  # 100 linhas de código...\n}\nCrie funções pequenas e específicas:\n# Função 1: Limpar\nlimpar_dados &lt;- function(dados) {\n  dados[!is.na(dados$idade) & dados$idade &gt; 0, ]\n}\n\n# Função 2: Calcular\ncalcular_estatisticas &lt;- function(dados) {\n  data.frame(\n    media = mean(dados$idade),\n    mediana = median(dados$idade)\n  )\n}\n\n# Função 3: Visualizar\nplotar_distribuicao &lt;- function(dados) {\n  hist(dados$idade, main = \"Distribuição\")\n}"
  },
  {
    "objectID": "apresentações/posts/funções_jeni.html#pipeline",
    "href": "apresentações/posts/funções_jeni.html#pipeline",
    "title": "2. Funções em R",
    "section": "Pipeline",
    "text": "Pipeline\nCombine funções pequenas em um fluxo:\n# Cada função faz uma coisa\ndados_limpos &lt;- limpar_dados(dados_brutos)\nestatisticas &lt;- calcular_estatisticas(dados_limpos)\ngraficos &lt;- plotar_distribuicao(dados_limpos)\nrelatorio &lt;- gerar_relatorio(estatisticas)\n\n# Ou use pipe\nlibrary(dplyr)\ndados_brutos %&gt;%\n  limpar_dados() %&gt;%\n  calcular_estatisticas() %&gt;%\n  gerar_relatorio()\nVantagens: - Cada função é testável independentemente - Fácil de modificar uma etapa - Código legível e autodocumentado"
  },
  {
    "objectID": "apresentações/posts/funções_jeni.html#salvando-funções-opção-1---scripts",
    "href": "apresentações/posts/funções_jeni.html#salvando-funções-opção-1---scripts",
    "title": "2. Funções em R",
    "section": "Salvando funções: Opção 1 - Scripts",
    "text": "Salvando funções: Opção 1 - Scripts\nCrie um arquivo de funções:\nEstrutura do projeto:\nmeu_projeto/\n├── funcoes/\n│   ├── estatisticas.R\n│   ├── visualizacao.R\n│   └── limpeza.R\n├── analises/\n│   └── analise_principal.R\n└── dados/\nNo arquivo funcoes/estatisticas.R:\n# Funções estatísticas\n\ncalcular_media &lt;- function(x) {\n  mean(x, na.rm = TRUE)\n}\n\ntestar_normalidade &lt;- function(x) {\n  shapiro.test(x)\n}"
  },
  {
    "objectID": "apresentações/posts/funções_jeni.html#salvando-funções-opção-1---scripts-1",
    "href": "apresentações/posts/funções_jeni.html#salvando-funções-opção-1---scripts-1",
    "title": "2. Funções em R",
    "section": "Salvando funções: opção 1 - scripts",
    "text": "Salvando funções: opção 1 - scripts\nCarregar no script principal:\nsource(\"funcoes/estatisticas.R\")\ncalcular_media(dados$idade)"
  },
  {
    "objectID": "apresentações/posts/funções_jeni.html#salvando-funções-opção-2---snippets",
    "href": "apresentações/posts/funções_jeni.html#salvando-funções-opção-2---snippets",
    "title": "2. Funções em R",
    "section": "Salvando funções: opção 2 - snippets",
    "text": "Salvando funções: opção 2 - snippets\nRStudio Snippets: templates rápidos\n1. Acesse: Tools &gt; Global Options &gt; Code &gt; Edit Snippets\n2. Adicione seu snippet:\nsnippet fun_stat\n    ${1:nome_funcao} &lt;- function(${2:x}) {\n      if (!is.numeric(${2:x})) {\n        stop(\"${2:x} deve ser numérico\")\n      }\n      \n      resultado &lt;- ${3:mean(${2:x}, na.rm = TRUE)}\n      return(resultado)\n    }\n3. Use: Digite fun_stat + Tab\nSnippets populares: - Estrutura de função - Validações comuns - Cabeçalhos de documentação"
  },
  {
    "objectID": "apresentações/posts/funções_jeni.html#salvando-funções-opção-3---pacotes",
    "href": "apresentações/posts/funções_jeni.html#salvando-funções-opção-3---pacotes",
    "title": "2. Funções em R",
    "section": "Salvando funções: opção 3 - pacotes",
    "text": "Salvando funções: opção 3 - pacotes\nQuando criar um pacote?\n\nVocê usa as mesmas funções em múltiplos projetos\nQuer compartilhar com a equipe\nPrecisa de documentação profissional\nQuer testes automatizados\n\nVantagens: Instalação fácil:\n\nlibrary(seupacote)\nHelp integrado: ?sua_funcao\nVersionamento e manutenção\nDistribuição via GitHub ou CRAN"
  },
  {
    "objectID": "apresentações/posts/funções_jeni.html#criando-seu-primeiro-pacote",
    "href": "apresentações/posts/funções_jeni.html#criando-seu-primeiro-pacote",
    "title": "2. Funções em R",
    "section": "Criando seu primeiro pacote",
    "text": "Criando seu primeiro pacote\nPassos básicos:\n# 1. Criar estrutura\nusethis::create_package(\"estatR\")\n\n# 2. Adicionar função\nusethis::use_r(\"descritivas\")\n\n# No arquivo R/descritivas.R:\n#' Calcular estatísticas descritivas\n#'\n#' @param x Vetor numérico\n#' @return Lista com média, mediana e desvio padrão\n#' @export\nestatisticas &lt;- function(x) {\n  list(\n    media = mean(x, na.rm = TRUE),\n    mediana = median(x, na.rm = TRUE),\n    dp = sd(x, na.rm = TRUE)\n  )\n}\n\n# 3. Documentar\ndevtools::document()\n\n# 4. Instalar\ndevtools::install()"
  },
  {
    "objectID": "apresentações/posts/funções_jeni.html#estrutura-de-um-pacote",
    "href": "apresentações/posts/funções_jeni.html#estrutura-de-um-pacote",
    "title": "2. Funções em R",
    "section": "Estrutura de um pacote",
    "text": "Estrutura de um pacote\nestatR/\n├── R/                      # Funções\n│   ├── descritivas.R\n│   ├── testes.R\n│   └── visualizacao.R\n├── man/                    # Documentação automática\n│   ├── estatisticas.Rd\n│   └── testar_grupos.Rd\n├── tests/                  # Testes unitários\n│   └── testthat/\n├── DESCRIPTION            # Metadados\n├── NAMESPACE              # Funções exportadas\n└── README.md              # Instruções\nUsar o pacote:\nlibrary(estatR)\nresultado &lt;- estatisticas(dados$idade)\n?estatisticas  # Ver documentação"
  },
  {
    "objectID": "apresentações/posts/funções_jeni.html#documentação-com-roxygen2",
    "href": "apresentações/posts/funções_jeni.html#documentação-com-roxygen2",
    "title": "2. Funções em R",
    "section": "Documentação com roxygen2",
    "text": "Documentação com roxygen2\nDocumente suas funções:\n#' Testar diferença entre grupos\n#'\n#' Realiza teste t para comparar dois grupos\n#'\n#' @param dados Data frame com os dados\n#' @param variavel Nome da variável numérica a testar\n#' @param grupo Nome da variável categórica (2 níveis)\n#' @return Data frame com resultados do teste\n#' @examples\n#' testar_grupos(mtcars, \"mpg\", \"am\")\n#' @export\ntestar_grupos &lt;- function(dados, variavel, grupo) {\n  # código da função\n}\nTags importantes:\n\n@param Descreve argumentos\n@return - Descreve retorno\n@examples - Exemplos de uso\n@export - Torna função disponível"
  },
  {
    "objectID": "apresentações/posts/funções_jeni.html#recursos-para-funções",
    "href": "apresentações/posts/funções_jeni.html#recursos-para-funções",
    "title": "2. Funções em R",
    "section": "Recursos para funções",
    "text": "Recursos para funções\nOrganização:\n\nScripts: Para projetos individuais\nSnippets: Para templates rápidos\nPacotes: Para reutilização e compartilhamento\n\nFerramentas:\n\nusethis - Automação de setup\ndevtools - Desenvolvimento de pacotes\ntestthat - Testes automatizados\nroxygen2 - Documentação"
  },
  {
    "objectID": "apresentações/posts/funções_jeni.html#resumo-o-poder-das-funções",
    "href": "apresentações/posts/funções_jeni.html#resumo-o-poder-das-funções",
    "title": "2. Funções em R",
    "section": "Resumo: O poder das funções",
    "text": "Resumo: O poder das funções\nPróximos passos:\n\nIdentifique código que você repete\nTransforme em uma função simples\nAdicione validações e documentação\nSalve em scripts organizados\nConsidere criar um pacote pessoal"
  },
  {
    "objectID": "apresentações/posts/funções_jeni.html#referências",
    "href": "apresentações/posts/funções_jeni.html#referências",
    "title": "2. Funções em R",
    "section": "Referências",
    "text": "Referências\nLivros e Tutoriais:\n\nWickham, H. (2019). Advanced R (2nd ed.). CRC Press.\nhttps://adv-r.hadley.nz/\nWickham, H., & Bryan, J. (2023). R Packages (2nd ed.).\nhttps://r-pkgs.org/\nGrolemund, G., & Wickham, H. (2023). R for Data Science (2nd ed.).\nhttps://r4ds.hadley.nz/\nHBC Training. Function Writing Guide.\nhttps://hbctraining.github.io/Intro-to-R/lessons/03_introR-functions-and-arguments.html\n\nSlides criados com Quarto\nhttps://quarto.org/\nhttps://quarto.org/docs/presentations/revealjs/"
  },
  {
    "objectID": "apresentações/posts/funções_jeni.html#com-isso",
    "href": "apresentações/posts/funções_jeni.html#com-isso",
    "title": "2. Funções em R",
    "section": "Com isso",
    "text": "Com isso\nCriem funções, a meguy concorda ksksksksk!"
  },
  {
    "objectID": "apresentações/posts/funções_jeni.html#muito-obrigada",
    "href": "apresentações/posts/funções_jeni.html#muito-obrigada",
    "title": "2. Funções em R",
    "section": "Muito obrigada!",
    "text": "Muito obrigada!\nEsta apresentação é parte do projeto Café com R\nÉ OPEN, USE, COMPARTILHE!\nPerguntas? Dúvidas? Sugestões?\nPróximo passo: Abra seu RStudio e comece a praticar!"
  },
  {
    "objectID": "apresentações/posts/funções_jeni.html#assine-o-café-com-r-1",
    "href": "apresentações/posts/funções_jeni.html#assine-o-café-com-r-1",
    "title": "2. Funções em R",
    "section": "☕ Assine o Café com R",
    "text": "☕ Assine o Café com R\nFique por dentro das aulas, conteúdos, newsletter!\n\nQue cada gole desperte uma nova ideia.\nQue cada script abra uma nova conversa.\nQue o Café com R, se torne um ponto de encontro nosso!"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#pergunta-para-você",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#pergunta-para-você",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Pergunta para você",
    "text": "Pergunta para você\n\nSe você precisar fazer uma análise exploratória completa com código, relatório de resultados e tudo mais ….\nVocê saberia por onde começar? Quais análises escolher?\n\n\n\n\n\n\n\nTip\n\n\nCom a minha experiência, trouxe algumas opções de análises que utilizo no dia a dia. Existem outras, mas a aula já ficou extensa e densa, e com essas já temos um ótimo ponto de partida.\nÓtimos estudos, a aula foi construída com carinho, aproveite muito!"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#objetivos-da-apresentação",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#objetivos-da-apresentação",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Objetivos da apresentação",
    "text": "Objetivos da apresentação\n\nCompreender os princípios de Tidy Data\nAplicar transformações com pivot_longer e pivot_wider\nUtilizar nest e unnest para dados hierárquicos\nImplementar workflow exploratório sistemático\nDominar ferramentas de EDA: DataExplorer, skimr, naniar"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#conjunto-de-dados",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#conjunto-de-dados",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Conjunto de dados",
    "text": "Conjunto de dados\nUtilizaremos o dataset Coffee Ratings do TidyTuesday:\n\nAvaliações de qualidade de café de diferentes países\nVariáveis sensoriais: aroma, sabor, acidez, corpo\ndados de origem, processamento e pontuação final\nIdeal para demonstrar técnicas de organização e exploração"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#conjunto-de-dados-1",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#conjunto-de-dados-1",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Conjunto de dados",
    "text": "Conjunto de dados\n\n\n\n\n\n\n\nFonte - Clique no link:\n\n\nTidyTuesday - Coffee Quality Institute Database"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#carregar-pacotes",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#carregar-pacotes",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Carregar pacotes",
    "text": "Carregar pacotes\n\n# Instalar pacotes se necessário\nif (!require(\"pacman\")) install.packages(\"pacman\")\n\npacman::p_load(\n  tidyverse,      # Manipulação e visualização\n  DT,             # Tabelas interativas\n  DataExplorer,   # Exploração automatizada\n  skimr,          # Resumos estatísticos\n  naniar,         # Análise de dados ausentes\n  scales,         # Formatação de escalas\n  knitr,          # Geração de relatórios\n  here)           # Gerenciamento de caminhos"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#importar-dados---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#importar-dados---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Importar dados - código",
    "text": "Importar dados - código\n\n# URL dos dados\nurl &lt;- \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/refs/heads/main/data/2020/2020-07-07/coffee_ratings.csv\"\n\n# Importar\ncoffee &lt;- read_csv(url)\n\n# Visualizar estrutura básica\nglimpse(coffee)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#importar-dados",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#importar-dados",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Importar dados",
    "text": "Importar dados\n\n\nRows: 1,339\nColumns: 43\n$ total_cup_points      &lt;dbl&gt; 90.58, 89.92, 89.75, 89.00, 88.83, 88.83, 88.75,…\n$ species               &lt;chr&gt; \"Arabica\", \"Arabica\", \"Arabica\", \"Arabica\", \"Ara…\n$ owner                 &lt;chr&gt; \"metad plc\", \"metad plc\", \"grounds for health ad…\n$ country_of_origin     &lt;chr&gt; \"Ethiopia\", \"Ethiopia\", \"Guatemala\", \"Ethiopia\",…\n$ farm_name             &lt;chr&gt; \"metad plc\", \"metad plc\", \"san marcos barrancas …\n$ lot_number            &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ mill                  &lt;chr&gt; \"metad plc\", \"metad plc\", NA, \"wolensu\", \"metad …\n$ ico_number            &lt;chr&gt; \"2014/2015\", \"2014/2015\", NA, NA, \"2014/2015\", N…\n$ company               &lt;chr&gt; \"metad agricultural developmet plc\", \"metad agri…\n$ altitude              &lt;chr&gt; \"1950-2200\", \"1950-2200\", \"1600 - 1800 m\", \"1800…\n$ region                &lt;chr&gt; \"guji-hambela\", \"guji-hambela\", NA, \"oromia\", \"g…\n$ producer              &lt;chr&gt; \"METAD PLC\", \"METAD PLC\", NA, \"Yidnekachew Dabes…\n$ number_of_bags        &lt;dbl&gt; 300, 300, 5, 320, 300, 100, 100, 300, 300, 50, 3…\n$ bag_weight            &lt;chr&gt; \"60 kg\", \"60 kg\", \"1\", \"60 kg\", \"60 kg\", \"30 kg\"…\n$ in_country_partner    &lt;chr&gt; \"METAD Agricultural Development plc\", \"METAD Agr…\n$ harvest_year          &lt;chr&gt; \"2014\", \"2014\", NA, \"2014\", \"2014\", \"2013\", \"201…\n$ grading_date          &lt;chr&gt; \"April 4th, 2015\", \"April 4th, 2015\", \"May 31st,…\n$ owner_1               &lt;chr&gt; \"metad plc\", \"metad plc\", \"Grounds for Health Ad…\n$ variety               &lt;chr&gt; NA, \"Other\", \"Bourbon\", NA, \"Other\", NA, \"Other\"…\n$ processing_method     &lt;chr&gt; \"Washed / Wet\", \"Washed / Wet\", NA, \"Natural / D…\n$ aroma                 &lt;dbl&gt; 8.67, 8.75, 8.42, 8.17, 8.25, 8.58, 8.42, 8.25, …\n$ flavor                &lt;dbl&gt; 8.83, 8.67, 8.50, 8.58, 8.50, 8.42, 8.50, 8.33, …\n$ aftertaste            &lt;dbl&gt; 8.67, 8.50, 8.42, 8.42, 8.25, 8.42, 8.33, 8.50, …\n$ acidity               &lt;dbl&gt; 8.75, 8.58, 8.42, 8.42, 8.50, 8.50, 8.50, 8.42, …\n$ body                  &lt;dbl&gt; 8.50, 8.42, 8.33, 8.50, 8.42, 8.25, 8.25, 8.33, …\n$ balance               &lt;dbl&gt; 8.42, 8.42, 8.42, 8.25, 8.33, 8.33, 8.25, 8.50, …\n$ uniformity            &lt;dbl&gt; 10.00, 10.00, 10.00, 10.00, 10.00, 10.00, 10.00,…\n$ clean_cup             &lt;dbl&gt; 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, …\n$ sweetness             &lt;dbl&gt; 10.00, 10.00, 10.00, 10.00, 10.00, 10.00, 10.00,…\n$ cupper_points         &lt;dbl&gt; 8.75, 8.58, 9.25, 8.67, 8.58, 8.33, 8.50, 9.00, …\n$ moisture              &lt;dbl&gt; 0.12, 0.12, 0.00, 0.11, 0.12, 0.11, 0.11, 0.03, …\n$ category_one_defects  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ quakers               &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ color                 &lt;chr&gt; \"Green\", \"Green\", NA, \"Green\", \"Green\", \"Bluish-…\n$ category_two_defects  &lt;dbl&gt; 0, 1, 0, 2, 2, 1, 0, 0, 0, 4, 1, 0, 0, 2, 2, 0, …\n$ expiration            &lt;chr&gt; \"April 3rd, 2016\", \"April 3rd, 2016\", \"May 31st,…\n$ certification_body    &lt;chr&gt; \"METAD Agricultural Development plc\", \"METAD Agr…\n$ certification_address &lt;chr&gt; \"309fcf77415a3661ae83e027f7e5f05dad786e44\", \"309…\n$ certification_contact &lt;chr&gt; \"19fef5a731de2db57d16da10287413f5f99bc2dd\", \"19f…\n$ unit_of_measurement   &lt;chr&gt; \"m\", \"m\", \"m\", \"m\", \"m\", \"m\", \"m\", \"m\", \"m\", \"m\"…\n$ altitude_low_meters   &lt;dbl&gt; 1950.0, 1950.0, 1600.0, 1800.0, 1950.0, NA, NA, …\n$ altitude_high_meters  &lt;dbl&gt; 2200.0, 2200.0, 1800.0, 2200.0, 2200.0, NA, NA, …\n$ altitude_mean_meters  &lt;dbl&gt; 2075.0, 2075.0, 1700.0, 2000.0, 2075.0, NA, NA, …\n\n\n\nO dataset contém 1339 observações e 43 variáveis. Inclui dados qualitativos (país, variedade) e quantitativos (pontuações sensoriais)."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#primeiras-linhas---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#primeiras-linhas---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Primeiras linhas - código",
    "text": "Primeiras linhas - código\n\ncoffee %&gt;%\n  head(2) %&gt;%\n  DT::datatable(\n    options = list(\n      scrollX = TRUE,\n      pageLength = 3,\n      dom = 't'),\n    rownames = FALSE)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#primeiras-linhas---resultado",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#primeiras-linhas---resultado",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Primeiras linhas - resultado",
    "text": "Primeiras linhas - resultado"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#o-que-é-tidy-data",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#o-que-é-tidy-data",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "O que é Tidy Data?",
    "text": "O que é Tidy Data?\ndados organizados segundo três princípios fundamentais propostos por Hadley Wickham (2014):\n\nCada variável forma uma coluna: Cada coluna representa uma única variável medida\nCada observação forma uma linha: Cada linha representa uma única unidade observacional\nCada tipo de unidade observacional forma uma tabela: Diferentes níveis de análise ficam em tabelas separadas"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#por-que-tidy-data",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#por-que-tidy-data",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Por que Tidy Data?",
    "text": "Por que Tidy Data?\nProblema: dados frequentemente vêm desorganizados, dificultando análises.\nSolução: Padronização facilita:\n\nAplicação de funções vetorizadas\nIntegração com ferramentas tidyverse\nReutilização de código\nColaboração em equipe"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#vantagens-dos-dados-organizados",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#vantagens-dos-dados-organizados",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Vantagens dos dados organizados",
    "text": "Vantagens dos dados organizados\n\n\nConsistência\n\nestrutura padronizada entre projetos\nReduz erros de manipulação\nFacilita automação de processos\n\nEficiência computacional\n\nOperações vetorizadas mais rápidas\nMenos loops necessários\ncódigo mais limpo e legível\n\n\nCompatibilidade\n\nIntegração direta com ggplot2\nCompatível com dplyr, tidyr\nFacilita modelagem estatística\n\nManutenibilidade\n\ncódigo autoexplicativo\nDocumentação natural\nReprodutibilidade garantida"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#selecionar-variáveis-relevantes---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#selecionar-variáveis-relevantes---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Selecionar variáveis relevantes - código",
    "text": "Selecionar variáveis relevantes - código\n\ncoffee_selected &lt;- coffee %&gt;%\n  select(\n    country_of_origin,\n    variety,\n    processing_method,\n    aroma,\n    flavor,\n    aftertaste,\n    acidity,\n    body,\n    balance,\n    total_cup_points)\n\n# estrutura\nstr(coffee_selected)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#selecionar-variáveis-relevantes---resultado",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#selecionar-variáveis-relevantes---resultado",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Selecionar variáveis relevantes - resultado",
    "text": "Selecionar variáveis relevantes - resultado\n\n\ntibble [1,339 × 10] (S3: tbl_df/tbl/data.frame)\n $ country_of_origin: chr [1:1339] \"Ethiopia\" \"Ethiopia\" \"Guatemala\" \"Ethiopia\" ...\n $ variety          : chr [1:1339] NA \"Other\" \"Bourbon\" NA ...\n $ processing_method: chr [1:1339] \"Washed / Wet\" \"Washed / Wet\" NA \"Natural / Dry\" ...\n $ aroma            : num [1:1339] 8.67 8.75 8.42 8.17 8.25 8.58 8.42 8.25 8.67 8.08 ...\n $ flavor           : num [1:1339] 8.83 8.67 8.5 8.58 8.5 8.42 8.5 8.33 8.67 8.58 ...\n $ aftertaste       : num [1:1339] 8.67 8.5 8.42 8.42 8.25 8.42 8.33 8.5 8.58 8.5 ...\n $ acidity          : num [1:1339] 8.75 8.58 8.42 8.42 8.5 8.5 8.5 8.42 8.42 8.5 ...\n $ body             : num [1:1339] 8.5 8.42 8.33 8.5 8.42 8.25 8.25 8.33 8.33 7.67 ...\n $ balance          : num [1:1339] 8.42 8.42 8.42 8.25 8.33 8.33 8.25 8.5 8.42 8.42 ...\n $ total_cup_points : num [1:1339] 90.6 89.9 89.8 89 88.8 ...\n\n\n\nO dataset já está majoritariamente em formato tidy. Demonstraremos transformações comuns em análises reais."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#quando-usar-pivot_longer",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#quando-usar-pivot_longer",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Quando usar pivot_longer",
    "text": "Quando usar pivot_longer\nCenário: Múltiplas colunas representam valores de uma mesma variável.\nExemplo:\n\ndados de vendas com colunas para cada mês (Jan, Fev, Mar…)\nAtributos sensoriais tratados como colunas separadas\nMedições repetidas em momentos diferentes\n\nObjetivo: Converter formato wide (largo) para long (longo) para análises e visualizações mais eficientes."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#por-que-transformar-para-long",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#por-que-transformar-para-long",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Por que transformar para long?",
    "text": "Por que transformar para long?\n\nVisualização: ggplot2 funciona melhor com dados long\nAnálise por grupos: Facilita agrupamentos e sumarizações\nModelagem: Muitos modelos exigem formato long\nComparações: Permite comparar múltiplas categorias simultaneamente"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#pivot_longer---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#pivot_longer---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "pivot_longer - código",
    "text": "pivot_longer - código\n\n# Transformar atributos sensoriais para formato long\ncoffee_long &lt;- coffee_selected %&gt;%\n  pivot_longer(\n    cols = c(aroma, flavor, aftertaste, acidity, body, balance),\n    names_to = \"atributo\",\n    values_to = \"pontuacao\")\n\n# Visualizar primeiras linhas\ncoffee_long %&gt;%\n  head(2) %&gt;%\n  DT::datatable(\n    options = list(scrollX = TRUE, pageLength = 3, dom = 't'),\n    rownames = FALSE)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#pivot_longer---resultado",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#pivot_longer---resultado",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "pivot_longer - resultado",
    "text": "pivot_longer - resultado"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#estrutura-resultante---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#estrutura-resultante---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Estrutura resultante - código",
    "text": "Estrutura resultante - código\n\n# Verificar dimensões\ncat(\"Dimensões originais:\", dim(coffee_selected), \"\\n\")\ncat(\"Dimensões após pivot_longer:\", dim(coffee_long), \"\\n\")\n\n# Cada café agora tem 6 linhas (uma por atributo)\ncoffee_long %&gt;%\n  filter(country_of_origin == \"Brazil\") %&gt;%\n  slice(1:6) %&gt;%\n  select(country_of_origin, variety, atributo, pontuacao)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#estrutura-resultante---comparação",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#estrutura-resultante---comparação",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Estrutura resultante - comparação",
    "text": "Estrutura resultante - comparação\n\n\nDimensões originais: 1339 10 \n\n\nDimensões após pivot_longer: 8034 6 \n\n\n\n\n\ncountry_of_origin\nvariety\natributo\npontuacao\n\n\n\n\nBrazil\nNA\naroma\n8.58\n\n\nBrazil\nNA\nflavor\n8.42\n\n\nBrazil\nNA\naftertaste\n8.42\n\n\nBrazil\nNA\nacidity\n8.50\n\n\nBrazil\nNA\nbody\n8.25\n\n\nBrazil\nNA\nbalance\n8.33\n\n\n\n\n\n\nA transformação aumentou o número de linhas de 1339 para 8034 (1339 × 6 atributos). Cada café agora aparece em 6 linhas, uma para cada atributo sensorial."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#visualização-com-dados-long---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#visualização-com-dados-long---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Visualização com dados long - código",
    "text": "Visualização com dados long - código\n\n# Paleta de cores do café\ncores_cafe &lt;- c(\"#6F4E37\", \"#8B4513\", \"#A0522D\", \n                \"#CD853F\", \"#DEB887\", \"#F5DEB3\")\n\ncoffee_long %&gt;%\n  group_by(atributo) %&gt;%\n  summarise(media = mean(pontuacao, na.rm = TRUE)) %&gt;%\n  ggplot(aes(x = reorder(atributo, media), y = media, fill = atributo)) +\n  geom_col(show.legend = FALSE) +\n  scale_fill_manual(values = cores_cafe) +\n  coord_flip() +\n  labs(\n    title = \"Pontuação média por atributo sensorial\",\n    x = \"Atributo\",\n    y = \"Pontuação média\",\n    caption = \"Jeni Lopes | Café com R.\") +\n  theme_classic(base_size = 14)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#visualização-com-dados-long---gráfico",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#visualização-com-dados-long---gráfico",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Visualização com dados long - gráfico",
    "text": "Visualização com dados long - gráfico"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#quando-usar-pivot_wider",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#quando-usar-pivot_wider",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Quando usar pivot_wider",
    "text": "Quando usar pivot_wider\nCenário: Valores estão empilhados e precisam ser distribuídos em colunas.\nExemplo:\n\nConverter resultados long para tabelas de apresentação\nCriar matriz de comparação entre grupos\nPreparar dados para análise de correlação\n\nObjetivo: Converter formato long (longo) para wide (largo)."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#por-que-transformar-para-wide",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#por-que-transformar-para-wide",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Por que transformar para wide?",
    "text": "Por que transformar para wide?\n\nApresentação: Tabelas resumo são mais legíveis em formato wide\nCorrelações: Matrizes de correlação exigem formato wide\nCompatibilidade: Alguns pacotes esperam dados wide\nLeitura: Facilita comparações visuais rápidas"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#pivot_wider---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#pivot_wider---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "pivot_wider - código",
    "text": "pivot_wider - código\n\n# Retornar ao formato original\ncoffee_wide &lt;- coffee_long %&gt;%\n  pivot_wider(\n    names_from = atributo,\n    values_from = pontuacao)\n\n# Verificar primeiras linhas\ncoffee_wide %&gt;%\n  head(2) %&gt;%\n  DT::datatable(\n    options = list(scrollX = TRUE, pageLength = 3, dom = 't'),\n    rownames = FALSE)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#pivot_wider---resultado",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#pivot_wider---resultado",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "pivot_wider - resultado",
    "text": "pivot_wider - resultado"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#criar-tabela-de-resumo-wide---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#criar-tabela-de-resumo-wide---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Criar tabela de resumo wide - código",
    "text": "Criar tabela de resumo wide - código\n\n# Resumo por país e atributo\nresumo_pais &lt;- coffee_long %&gt;%\n  group_by(country_of_origin, atributo) %&gt;%\n  summarise(media = mean(pontuacao, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  pivot_wider(\n    names_from = atributo,\n    values_from = media)\n\n# Top 5 países\nresumo_pais %&gt;%\n  head(5) %&gt;%\n  DT::datatable(\n    options = list(scrollX = TRUE, pageLength = 5, dom = 't'),\n    rownames = FALSE) %&gt;%\n  DT::formatRound(columns = 2:7, digits = 2)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#criar-tabela-de-resumo-wide---resultado",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#criar-tabela-de-resumo-wide---resultado",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Criar tabela de resumo wide - resultado",
    "text": "Criar tabela de resumo wide - resultado\n\n\n\n\n\n\n\nO formato wide é útil para tabelas de apresentação e comparações rápidas entre categorias. Cada país agora tem todas suas médias em uma única linha."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#quando-usar-nest",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#quando-usar-nest",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Quando usar nest",
    "text": "Quando usar nest\nConceito: List-columns permitem armazenar dataframes dentro de dataframes.\nCenário:\n\nAgrupar dados relacionados hierarquicamente\nAplicar modelos diferentes para cada grupo\nManter contexto de agrupamento durante operações complexas\n\nObjetivo: Criar estruturas hierárquicas com list-columns."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#por-que-usar-dados-aninhados",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#por-que-usar-dados-aninhados",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Por que usar dados aninhados?",
    "text": "Por que usar dados aninhados?\n\nOrganização: Mantém dados relacionados juntos\nOperações em Grupo: Aplica funções complexas por grupo\nModelagem: Ajusta modelos separados por categoria\nEficiência: Evita múltiplos dataframes soltos"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#nest---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#nest---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "nest - código",
    "text": "nest - código\n\n# Aninhar dados por país\ncoffee_nested &lt;- coffee_selected %&gt;%\n  group_by(country_of_origin) %&gt;%\n  nest()\n\n# Visualizar estrutura\ncoffee_nested %&gt;%\n  head(2) %&gt;%\n  DT::datatable(\n    options = list(scrollX = TRUE, pageLength = 3, dom = 't'),\n    rownames = FALSE)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#nest---resultado",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#nest---resultado",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "nest - resultado",
    "text": "nest - resultado"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#estrutura-dos-dados-aninhados---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#estrutura-dos-dados-aninhados---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Estrutura dos dados aninhados - código",
    "text": "Estrutura dos dados aninhados - código\n\n# Verificar estrutura\nstr(coffee_nested, max.level = 2)\n\n# Acessar dados de um país específico\ncoffee_nested %&gt;%\n  filter(country_of_origin == \"Ethiopia\") %&gt;%\n  pull(data) %&gt;%\n  .[[1]] %&gt;%\n  head(2)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#eestrutura-dos-dados-aninhados---resultado",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#eestrutura-dos-dados-aninhados---resultado",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Eestrutura dos dados aninhados - resultado",
    "text": "Eestrutura dos dados aninhados - resultado\n\n\ngropd_df [37 × 2] (S3: grouped_df/tbl_df/tbl/data.frame)\n $ country_of_origin: chr [1:37] \"Ethiopia\" \"Guatemala\" \"Brazil\" \"Peru\" ...\n $ data             :List of 37\n - attr(*, \"groups\")= tibble [37 × 2] (S3: tbl_df/tbl/data.frame)\n  ..- attr(*, \".drop\")= logi TRUE"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#acessar-dados-do-país-específico",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#acessar-dados-do-país-específico",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Acessar dados do país específico",
    "text": "Acessar dados do país específico\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvariety\nprocessing_method\naroma\nflavor\naftertaste\nacidity\nbody\nbalance\ntotal_cup_points\n\n\n\n\nNA\nWashed / Wet\n8.67\n8.83\n8.67\n8.75\n8.50\n8.42\n90.58\n\n\nOther\nWashed / Wet\n8.75\n8.67\n8.50\n8.58\n8.42\n8.42\n89.92\n\n\n\n\n\n\nCada linha contém um dataframe completo com todas as avaliações daquele país. A coluna “data” é uma list-column."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#operações-com-dados-aninhados---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#operações-com-dados-aninhados---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Operações com dados aninhados - código",
    "text": "Operações com dados aninhados - código\n\n# Calcular estatísticas por país usando map\nlibrary(purrr)\n\ncoffee_stats &lt;- coffee_nested %&gt;%\n  mutate(\n    n_avaliacoes = map_int(data, nrow),\n    media_total = map_dbl(data, ~mean(.x$total_cup_points, na.rm = TRUE)),\n    sd_total = map_dbl(data, ~sd(.x$total_cup_points, na.rm = TRUE)))\n\n# Visualizar\ncoffee_stats %&gt;%\n  select(-data) %&gt;%\n  arrange(desc(media_total)) %&gt;%\n  head(5)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#operações-com-dados-aninhados---resultado",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#operações-com-dados-aninhados---resultado",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Operações com dados aninhados - resultado",
    "text": "Operações com dados aninhados - resultado"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#quando-usar-unnest",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#quando-usar-unnest",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Quando usar unnest",
    "text": "Quando usar unnest\nConceito: Expandir dados aninhados de volta ao formato tabular.\nCenário:\n\nRetornar à estrutura original após operações\nPreparar dados para análises convencionais\nCombinar resultados de múltiplos grupos\n\nObjetivo: Desfazer o aninhamento para análises tabulares."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#unnest---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#unnest---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "unnest - código",
    "text": "unnest - código\n\n# Desaninhar dados\ncoffee_unnested &lt;- coffee_nested %&gt;%\n  unnest(data)\n\n# Verificar se retornou ao formato original\nidentical(\n  coffee_selected %&gt;% arrange(country_of_origin),\n  coffee_unnested %&gt;% arrange(country_of_origin))\n\n# Dimensões\ndim(coffee_unnested)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#unnest---resultado",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#unnest---resultado",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "unnest - resultado",
    "text": "unnest - resultado\n\n\ndados são idênticos ao original? FALSE \n\n\nDimensões após unnest: 1339 10\n\n\n\nunnest reverte a operação de nest, expandindo os dataframes aninhados de volta para linhas individuais. Útil após realizar operações complexas com list-columns."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#estrutura-do-processo-exploratório",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#estrutura-do-processo-exploratório",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Estrutura do processo exploratório",
    "text": "Estrutura do processo exploratório\n\nImportação de dados\nInspeção inicial\nVerificar tipos de dados\nAnalisar dados ausentes\nEstatísticas descritivas\nVisualizações univariadas\nAnálises bivariadas\nIdentificar padrões\nDocumentar resultados"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#o-que-é-eda",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#o-que-é-eda",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "O que é EDA?",
    "text": "O que é EDA?\nExploratory Data Analysis (EDA) é o processo sistemático de investigar dados para:\n\nDescobrir padrões e relações\nDetectar anomalias e outliers\nTestar hipóteses iniciais\nVerificar pressupostos estatísticos\nGuiar modelagem posterior\n\nOrigem: Proposta por John Tukey (1977) como filosofia de análise de dados."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#princípios-do-workflow-eda",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#princípios-do-workflow-eda",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Princípios do workflow EDA",
    "text": "Princípios do workflow EDA\n\nSistematização: Seguir sequência consistente e documentada\nCeticismo: Questionar resultados e verificar suposições\nVisualização: Combinar números e gráficos\nIteração: Revisitar etapas conforme necessário\nDocumentação: Registrar descobertas e decisões"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#por-que-eda-é-fundamental",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#por-que-eda-é-fundamental",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Por que EDA é fundamental?",
    "text": "Por que EDA é fundamental?\n\n\nAntes da modelagem\n\nIdentificar problemas de qualidade\nEntender distribuições\nDetectar multicolinearidade\nSelecionar features relevantes\n\n\nDurante o projeto\n\nValidar transformações\nVerificar pressupostos\nGuiar decisões técnicas\nComunicar com stakeholders"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#dimensões-e-estrutura---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#dimensões-e-estrutura---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Dimensões e estrutura - código",
    "text": "Dimensões e estrutura - código\n\n# Dimensões\ndim(coffee)\n\n# estrutura compacta\nstr(coffee, give.attr = FALSE)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#dimensões-e-estrutura---resultado",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#dimensões-e-estrutura---resultado",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Dimensões e estrutura - resultado",
    "text": "Dimensões e estrutura - resultado\n\n\n[1] 1339   43\n\n\nspc_tbl_ [1,339 × 43] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ total_cup_points     : num [1:1339] 90.6 89.9 89.8 89 88.8 ...\n $ species              : chr [1:1339] \"Arabica\" \"Arabica\" \"Arabica\" \"Arabica\" ...\n $ owner                : chr [1:1339] \"metad plc\" \"metad plc\" \"grounds for health admin\" \"yidnekachew dabessa\" ...\n $ country_of_origin    : chr [1:1339] \"Ethiopia\" \"Ethiopia\" \"Guatemala\" \"Ethiopia\" ...\n $ farm_name            : chr [1:1339] \"metad plc\" \"metad plc\" \"san marcos barrancas \\\"san cristobal cuch\" \"yidnekachew dabessa coffee plantation\" ...\n $ lot_number           : chr [1:1339] NA NA NA NA ...\n $ mill                 : chr [1:1339] \"metad plc\" \"metad plc\" NA \"wolensu\" ...\n $ ico_number           : chr [1:1339] \"2014/2015\" \"2014/2015\" NA NA ...\n $ company              : chr [1:1339] \"metad agricultural developmet plc\" \"metad agricultural developmet plc\" NA \"yidnekachew debessa coffee plantation\" ...\n $ altitude             : chr [1:1339] \"1950-2200\" \"1950-2200\" \"1600 - 1800 m\" \"1800-2200\" ...\n $ region               : chr [1:1339] \"guji-hambela\" \"guji-hambela\" NA \"oromia\" ...\n $ producer             : chr [1:1339] \"METAD PLC\" \"METAD PLC\" NA \"Yidnekachew Dabessa Coffee Plantation\" ...\n $ number_of_bags       : num [1:1339] 300 300 5 320 300 100 100 300 300 50 ...\n $ bag_weight           : chr [1:1339] \"60 kg\" \"60 kg\" \"1\" \"60 kg\" ...\n $ in_country_partner   : chr [1:1339] \"METAD Agricultural Development plc\" \"METAD Agricultural Development plc\" \"Specialty Coffee Association\" \"METAD Agricultural Development plc\" ...\n $ harvest_year         : chr [1:1339] \"2014\" \"2014\" NA \"2014\" ...\n $ grading_date         : chr [1:1339] \"April 4th, 2015\" \"April 4th, 2015\" \"May 31st, 2010\" \"March 26th, 2015\" ...\n $ owner_1              : chr [1:1339] \"metad plc\" \"metad plc\" \"Grounds for Health Admin\" \"Yidnekachew Dabessa\" ...\n $ variety              : chr [1:1339] NA \"Other\" \"Bourbon\" NA ...\n $ processing_method    : chr [1:1339] \"Washed / Wet\" \"Washed / Wet\" NA \"Natural / Dry\" ...\n $ aroma                : num [1:1339] 8.67 8.75 8.42 8.17 8.25 8.58 8.42 8.25 8.67 8.08 ...\n $ flavor               : num [1:1339] 8.83 8.67 8.5 8.58 8.5 8.42 8.5 8.33 8.67 8.58 ...\n $ aftertaste           : num [1:1339] 8.67 8.5 8.42 8.42 8.25 8.42 8.33 8.5 8.58 8.5 ...\n $ acidity              : num [1:1339] 8.75 8.58 8.42 8.42 8.5 8.5 8.5 8.42 8.42 8.5 ...\n $ body                 : num [1:1339] 8.5 8.42 8.33 8.5 8.42 8.25 8.25 8.33 8.33 7.67 ...\n $ balance              : num [1:1339] 8.42 8.42 8.42 8.25 8.33 8.33 8.25 8.5 8.42 8.42 ...\n $ uniformity           : num [1:1339] 10 10 10 10 10 10 10 10 9.33 10 ...\n $ clean_cup            : num [1:1339] 10 10 10 10 10 10 10 10 10 10 ...\n $ sweetness            : num [1:1339] 10 10 10 10 10 10 10 9.33 9.33 10 ...\n $ cupper_points        : num [1:1339] 8.75 8.58 9.25 8.67 8.58 8.33 8.5 9 8.67 8.5 ...\n $ moisture             : num [1:1339] 0.12 0.12 0 0.11 0.12 0.11 0.11 0.03 0.03 0.1 ...\n $ category_one_defects : num [1:1339] 0 0 0 0 0 0 0 0 0 0 ...\n $ quakers              : num [1:1339] 0 0 0 0 0 0 0 0 0 0 ...\n $ color                : chr [1:1339] \"Green\" \"Green\" NA \"Green\" ...\n $ category_two_defects : num [1:1339] 0 1 0 2 2 1 0 0 0 4 ...\n $ expiration           : chr [1:1339] \"April 3rd, 2016\" \"April 3rd, 2016\" \"May 31st, 2011\" \"March 25th, 2016\" ...\n $ certification_body   : chr [1:1339] \"METAD Agricultural Development plc\" \"METAD Agricultural Development plc\" \"Specialty Coffee Association\" \"METAD Agricultural Development plc\" ...\n $ certification_address: chr [1:1339] \"309fcf77415a3661ae83e027f7e5f05dad786e44\" \"309fcf77415a3661ae83e027f7e5f05dad786e44\" \"36d0d00a3724338ba7937c52a378d085f2172daa\" \"309fcf77415a3661ae83e027f7e5f05dad786e44\" ...\n $ certification_contact: chr [1:1339] \"19fef5a731de2db57d16da10287413f5f99bc2dd\" \"19fef5a731de2db57d16da10287413f5f99bc2dd\" \"0878a7d4b9d35ddbf0fe2ce69a2062cceb45a660\" \"19fef5a731de2db57d16da10287413f5f99bc2dd\" ...\n $ unit_of_measurement  : chr [1:1339] \"m\" \"m\" \"m\" \"m\" ...\n $ altitude_low_meters  : num [1:1339] 1950 1950 1600 1800 1950 ...\n $ altitude_high_meters : num [1:1339] 2200 2200 1800 2200 2200 NA NA 1700 1700 1850 ...\n $ altitude_mean_meters : num [1:1339] 2075 2075 1700 2000 2075 ..."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#nomes-das-variáveis---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#nomes-das-variáveis---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Nomes das variáveis - código",
    "text": "Nomes das variáveis - código\n\n# Listar todas as variáveis\nnames(coffee)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#nomes-das-variáveis---resultado",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#nomes-das-variáveis---resultado",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Nomes das variáveis - resultado",
    "text": "Nomes das variáveis - resultado\n\n\n [1] \"total_cup_points\"      \"species\"               \"owner\"                \n [4] \"country_of_origin\"     \"farm_name\"             \"lot_number\"           \n [7] \"mill\"                  \"ico_number\"            \"company\"              \n[10] \"altitude\"              \"region\"                \"producer\"             \n[13] \"number_of_bags\"        \"bag_weight\"            \"in_country_partner\"   \n[16] \"harvest_year\"          \"grading_date\"          \"owner_1\"              \n[19] \"variety\"               \"processing_method\"     \"aroma\"                \n[22] \"flavor\"                \"aftertaste\"            \"acidity\"              \n[25] \"body\"                  \"balance\"               \"uniformity\"           \n[28] \"clean_cup\"             \"sweetness\"             \"cupper_points\"        \n[31] \"moisture\"              \"category_one_defects\"  \"quakers\"              \n[34] \"color\"                 \"category_two_defects\"  \"expiration\"           \n[37] \"certification_body\"    \"certification_address\" \"certification_contact\"\n[40] \"unit_of_measurement\"   \"altitude_low_meters\"   \"altitude_high_meters\" \n[43] \"altitude_mean_meters\""
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#tipos-de-dados---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#tipos-de-dados---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Tipos de dados - código",
    "text": "Tipos de dados - código\n\n# Verificar tipos\ncoffee %&gt;%\n  summarise(across(everything(), class)) %&gt;%\n  pivot_longer(\n    cols = everything(),\n    names_to = \"variavel\",\n    values_to = \"tipo\") %&gt;%\n  head(5)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#tipos-de-dados---resultado",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#tipos-de-dados---resultado",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Tipos de dados - resultado",
    "text": "Tipos de dados - resultado\n\n\n\n\n\n\n\nIdentificar tipos incorretos é crucial. Variáveis categóricas como character devem ser convertidas para factor quando apropriado para análises e visualizações."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#o-que-é-dataexplorer",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#o-que-é-dataexplorer",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "O que é DataExplorer?",
    "text": "O que é DataExplorer?\nDataExplorer é um pacote para EDA automatizada que:\n\nGera relatórios HTML completos\nCria visualizações padronizadas\nIdentifica problemas de qualidade\nEconomiza tempo na fase exploratória\n\nIdeal para: Obter visão panorâmica rápida dos dados."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#visão-geral---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#visão-geral---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Visão geral - código",
    "text": "Visão geral - código\n\n# Relatório de estrutura\nDataExplorer::introduce(coffee)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#visão-geral---resultado",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#visão-geral---resultado",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Visão geral - resultado",
    "text": "Visão geral - resultado\n\n\n# A tibble: 1 × 9\n   rows columns discrete_columns continuous_columns all_missing_columns\n  &lt;int&gt;   &lt;int&gt;            &lt;int&gt;              &lt;int&gt;               &lt;int&gt;\n1  1339      43               24                 19                   0\n# ℹ 4 more variables: total_missing_values &lt;int&gt;, complete_rows &lt;int&gt;,\n#   total_observations &lt;int&gt;, memory_usage &lt;dbl&gt;"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#visualização-da-estrutura---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#visualização-da-estrutura---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Visualização da estrutura - código",
    "text": "Visualização da estrutura - código\n\n# Gráfico de estrutura dos dados\nDataExplorer::plot_intro(coffee)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#visualização-da-estrutura---gráfico",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#visualização-da-estrutura---gráfico",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Visualização da estrutura - gráfico",
    "text": "Visualização da estrutura - gráfico\n\n\nDataExplorer mostra: 43 colunas, 1339 linhas, 15 colunas discretas, 28 contínuas. Visualização rápida da composição do dataset."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#distribuição-das-variáveis-numéricas---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#distribuição-das-variáveis-numéricas---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Distribuição das variáveis numéricas - código",
    "text": "Distribuição das variáveis numéricas - código\n\n# Visualizar distribuição de tipos\ncoffee %&gt;%\n  select(where(is.numeric)) %&gt;%\n  select(1:9) %&gt;%  # Primeiras 9 variáveis numéricas\n  DataExplorer::plot_histogram(\n    ncol = 3,\n    title = \"Distribuição das variáveis numéricas.\")"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#distribuição-das-variáveis-numéricas---gráfico",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#distribuição-das-variáveis-numéricas---gráfico",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Distribuição das variáveis numéricas - gráfico",
    "text": "Distribuição das variáveis numéricas - gráfico"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#análise-de-dados-ausentes---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#análise-de-dados-ausentes---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Análise de dados ausentes - código",
    "text": "Análise de dados ausentes - código\n\n# Visualizar padrão de dados ausentes\nDataExplorer::plot_missing(coffee)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#análise-de-dados-ausentes---gráfico",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#análise-de-dados-ausentes---gráfico",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Análise de dados ausentes - gráfico",
    "text": "Análise de dados ausentes - gráfico\n\n\nAlgumas variáveis apresentam alta proporção de dados ausentes: lot_number (63%), altitude (26%). Isso requer decisões sobre imputação ou exclusão na análise."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#correlações-entre-variáveis---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#correlações-entre-variáveis---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Correlações entre variáveis - código",
    "text": "Correlações entre variáveis - código\n\n# Matriz de correlação (apenas variáveis numéricas)\ncoffee %&gt;%\n  select(\n    aroma, flavor, aftertaste, acidity, \n    body, balance, uniformity, clean_cup,\n    sweetness, total_cup_points) %&gt;%\n  DataExplorer::plot_correlation(\n    title = \"Correlações entre atributos sensoriais.\")"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#correlações-entre-variáveis---gráfico",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#correlações-entre-variáveis---gráfico",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Correlações entre variáveis - gráfico",
    "text": "Correlações entre variáveis - gráfico"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#o-que-é-skimr",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#o-que-é-skimr",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "O que é skimr?",
    "text": "O que é skimr?\nskimr fornece resumos estatísticos aprimorados que:\n\nOrganiza resultados por tipo de variável\nInclui histogramas inline (sparklines)\nMostra estatísticas específicas por tipo\nIdentifica dados ausentes por variável\n\nVantagem: Mais informativo que summary() base do R."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#visão-geral-com-skimr---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#visão-geral-com-skimr---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Visão geral com skimr - código",
    "text": "Visão geral com skimr - código\n\n# Resumo completo\nskim_result &lt;- skimr::skim(coffee)\n\n# Exibir resumo\nskim_result"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#visão-geral-com-skimr---resultado",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#visão-geral-com-skimr---resultado",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Visão geral com skimr - resultado",
    "text": "Visão geral com skimr - resultado\n\n\n\nData summary\n\n\nName\ncoffee\n\n\nNumber of rows\n1339\n\n\nNumber of columns\n43\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n24\n\n\nnumeric\n19\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nspecies\n0\n1.00\n7\n7\n0\n2\n0\n\n\nowner\n7\n0.99\n3\n50\n0\n315\n0\n\n\ncountry_of_origin\n1\n1.00\n4\n28\n0\n36\n0\n\n\nfarm_name\n359\n0.73\n1\n73\n0\n571\n0\n\n\nlot_number\n1063\n0.21\n1\n71\n0\n227\n0\n\n\nmill\n315\n0.76\n1\n77\n0\n460\n0\n\n\nico_number\n151\n0.89\n1\n40\n0\n847\n0\n\n\ncompany\n209\n0.84\n3\n73\n0\n281\n0\n\n\naltitude\n226\n0.83\n1\n41\n0\n396\n0\n\n\nregion\n59\n0.96\n2\n76\n0\n356\n0\n\n\nproducer\n231\n0.83\n1\n100\n0\n691\n0\n\n\nbag_weight\n0\n1.00\n1\n8\n0\n56\n0\n\n\nin_country_partner\n0\n1.00\n7\n85\n0\n27\n0\n\n\nharvest_year\n47\n0.96\n3\n24\n0\n46\n0\n\n\ngrading_date\n0\n1.00\n13\n20\n0\n567\n0\n\n\nowner_1\n7\n0.99\n3\n50\n0\n319\n0\n\n\nvariety\n226\n0.83\n4\n21\n0\n29\n0\n\n\nprocessing_method\n170\n0.87\n5\n25\n0\n5\n0\n\n\ncolor\n218\n0.84\n4\n12\n0\n4\n0\n\n\nexpiration\n0\n1.00\n13\n20\n0\n566\n0\n\n\ncertification_body\n0\n1.00\n7\n85\n0\n26\n0\n\n\ncertification_address\n0\n1.00\n40\n40\n0\n32\n0\n\n\ncertification_contact\n0\n1.00\n40\n40\n0\n29\n0\n\n\nunit_of_measurement\n0\n1.00\n1\n2\n0\n2\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ntotal_cup_points\n0\n1.00\n82.09\n3.50\n0\n81.08\n82.50\n83.67\n90.58\n▁▁▁▁▇\n\n\nnumber_of_bags\n0\n1.00\n154.18\n129.99\n0\n14.00\n175.00\n275.00\n1062.00\n▇▇▁▁▁\n\n\naroma\n0\n1.00\n7.57\n0.38\n0\n7.42\n7.58\n7.75\n8.75\n▁▁▁▁▇\n\n\nflavor\n0\n1.00\n7.52\n0.40\n0\n7.33\n7.58\n7.75\n8.83\n▁▁▁▁▇\n\n\naftertaste\n0\n1.00\n7.40\n0.40\n0\n7.25\n7.42\n7.58\n8.67\n▁▁▁▁▇\n\n\nacidity\n0\n1.00\n7.54\n0.38\n0\n7.33\n7.58\n7.75\n8.75\n▁▁▁▁▇\n\n\nbody\n0\n1.00\n7.52\n0.37\n0\n7.33\n7.50\n7.67\n8.58\n▁▁▁▁▇\n\n\nbalance\n0\n1.00\n7.52\n0.41\n0\n7.33\n7.50\n7.75\n8.75\n▁▁▁▁▇\n\n\nuniformity\n0\n1.00\n9.83\n0.55\n0\n10.00\n10.00\n10.00\n10.00\n▁▁▁▁▇\n\n\nclean_cup\n0\n1.00\n9.84\n0.76\n0\n10.00\n10.00\n10.00\n10.00\n▁▁▁▁▇\n\n\nsweetness\n0\n1.00\n9.86\n0.62\n0\n10.00\n10.00\n10.00\n10.00\n▁▁▁▁▇\n\n\ncupper_points\n0\n1.00\n7.50\n0.47\n0\n7.25\n7.50\n7.75\n10.00\n▁▁▁▇▁\n\n\nmoisture\n0\n1.00\n0.09\n0.05\n0\n0.09\n0.11\n0.12\n0.28\n▃▇▅▁▁\n\n\ncategory_one_defects\n0\n1.00\n0.48\n2.55\n0\n0.00\n0.00\n0.00\n63.00\n▇▁▁▁▁\n\n\nquakers\n1\n1.00\n0.17\n0.83\n0\n0.00\n0.00\n0.00\n11.00\n▇▁▁▁▁\n\n\ncategory_two_defects\n0\n1.00\n3.56\n5.31\n0\n0.00\n2.00\n4.00\n55.00\n▇▁▁▁▁\n\n\naltitude_low_meters\n230\n0.83\n1750.71\n8669.44\n1\n1100.00\n1310.64\n1600.00\n190164.00\n▇▁▁▁▁\n\n\naltitude_high_meters\n230\n0.83\n1799.35\n8668.81\n1\n1100.00\n1350.00\n1650.00\n190164.00\n▇▁▁▁▁\n\n\naltitude_mean_meters\n230\n0.83\n1775.03\n8668.63\n1\n1100.00\n1310.64\n1600.00\n190164.00\n▇▁▁▁▁\n\n\n\n\n\n\nskimr fornece estatísticas descritivas organizadas por tipo de variável, incluindo histogramas inline para rápida visualização de distribuições."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#resumo-das-variáveis-numéricas---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#resumo-das-variáveis-numéricas---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Resumo das variáveis numéricas - código",
    "text": "Resumo das variáveis numéricas - código\n\n# Focar em variáveis numéricas sensoriais\ncoffee %&gt;%\n  select(\n    aroma, flavor, aftertaste, acidity, body, \n    balance, total_cup_points) %&gt;%\n  skimr::skim()"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#resumo-das-variáveis-numéricas---resultado",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#resumo-das-variáveis-numéricas---resultado",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Resumo das variáveis numéricas - resultado",
    "text": "Resumo das variáveis numéricas - resultado\n\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n1339\n\n\nNumber of columns\n7\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\naroma\n0\n1\n7.57\n0.38\n0\n7.42\n7.58\n7.75\n8.75\n▁▁▁▁▇\n\n\nflavor\n0\n1\n7.52\n0.40\n0\n7.33\n7.58\n7.75\n8.83\n▁▁▁▁▇\n\n\naftertaste\n0\n1\n7.40\n0.40\n0\n7.25\n7.42\n7.58\n8.67\n▁▁▁▁▇\n\n\nacidity\n0\n1\n7.54\n0.38\n0\n7.33\n7.58\n7.75\n8.75\n▁▁▁▁▇\n\n\nbody\n0\n1\n7.52\n0.37\n0\n7.33\n7.50\n7.67\n8.58\n▁▁▁▁▇\n\n\nbalance\n0\n1\n7.52\n0.41\n0\n7.33\n7.50\n7.75\n8.75\n▁▁▁▁▇\n\n\ntotal_cup_points\n0\n1\n82.09\n3.50\n0\n81.08\n82.50\n83.67\n90.58\n▁▁▁▁▇"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#resumo-das-variáveis-categóricas---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#resumo-das-variáveis-categóricas---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Resumo das variáveis categóricas - código",
    "text": "Resumo das variáveis categóricas - código\n\n# Focar em variáveis categóricas\ncoffee %&gt;%\n  select(\n    country_of_origin, variety, processing_method, \n    color, species) %&gt;%\n  skimr::skim()"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#resumo-das-variáveis-categóricas---resultado",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#resumo-das-variáveis-categóricas---resultado",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Resumo das variáveis categóricas - resultado",
    "text": "Resumo das variáveis categóricas - resultado\n\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n1339\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ncountry_of_origin\n1\n1.00\n4\n28\n0\n36\n0\n\n\nvariety\n226\n0.83\n4\n21\n0\n29\n0\n\n\nprocessing_method\n170\n0.87\n5\n25\n0\n5\n0\n\n\ncolor\n218\n0.84\n4\n12\n0\n4\n0\n\n\nspecies\n0\n1.00\n7\n7\n0\n2\n0\n\n\n\n\n\n\nPara variáveis categóricas, skimr mostra: valores únicos, categoria mais frequente, proporção de dados ausentes. Essencial para entender distribuição de categorias."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#estatísticas-personalizadas---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#estatísticas-personalizadas---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Estatísticas personalizadas - código",
    "text": "Estatísticas personalizadas - código\n\n# Criar função personalizada para CV (Coeficiente de Variação)\ncoffee %&gt;%\n  select(aroma, flavor, aftertaste, acidity, body, balance) %&gt;%\n  summarise(\n    across(\n      everything(),\n      list(\n        media = ~mean(., na.rm = TRUE),\n        mediana = ~median(., na.rm = TRUE),\n        cv = ~sd(., na.rm = TRUE) / mean(., na.rm = TRUE)))) %&gt;%\n  pivot_longer(\n    cols = everything(),\n    names_to = c(\"variavel\", \"estatistica\"),\n    names_sep = \"_\") %&gt;%\n  pivot_wider(\n    names_from = estatistica,\n    values_from = value)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#estatísticas-personalizadas---resultado",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#estatísticas-personalizadas---resultado",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Estatísticas personalizadas - resultado",
    "text": "Estatísticas personalizadas - resultado"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#o-que-é-naniar",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#o-que-é-naniar",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "O que é naniar?",
    "text": "O que é naniar?\nnaniar é especializado em análise de dados ausentes (missing data):\n\nVisualiza padrões de ausência\nCalcula proporções por variável\nIdentifica se ausência é aleatória (MCAR, MAR, MNAR)\nFacilita decisões sobre imputação\n\nCrucial: dados ausentes podem viesar análises e modelos."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#por-que-analisar-dados-ausentes",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#por-que-analisar-dados-ausentes",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Por que analisar dados ausentes?",
    "text": "Por que analisar dados ausentes?\n\nViés: Ausência não aleatória distorce resultados\nPerda de poder: Reduz tamanho amostral efetivo\nInvalidação: Pode violar pressupostos de modelos\nDecisão informada: Guia estratégia de tratamento (imputar x excluir)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#tipos-de-dados-ausentes",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#tipos-de-dados-ausentes",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Tipos de dados ausentes",
    "text": "Tipos de dados ausentes\nMCAR (Missing Completely At Random): Ausência independente de qualquer variável.\nMAR (Missing At Random): Ausência relacionada a variáveis observadas.\nMNAR (Missing Not At Random): Ausência relacionada ao próprio valor ausente."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#proporção-de-dados-ausentes---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#proporção-de-dados-ausentes---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Proporção de dados ausentes - código",
    "text": "Proporção de dados ausentes - código\n\n# Resumo de dados ausentes\nnaniar::miss_var_summary(coffee) %&gt;%\n  head(15)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#proporção-de-dados-ausentes---resultado",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#proporção-de-dados-ausentes---resultado",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Proporção de dados ausentes - resultado",
    "text": "Proporção de dados ausentes - resultado"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#visualização-de-padrões-ausentes---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#visualização-de-padrões-ausentes---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Visualização de padrões ausentes - código",
    "text": "Visualização de padrões ausentes - código\n\n# Gráfico de dados ausentes em variáveis chave\ncoffee %&gt;%\n  select(\n    country_of_origin, variety, lot_number, \n    altitude_mean_meters, aroma, flavor, \n    total_cup_points) %&gt;%\n  naniar::vis_miss()"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#visualização-de-padrões-ausentes---gráfico",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#visualização-de-padrões-ausentes---gráfico",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Visualização de padrões ausentes - gráfico",
    "text": "Visualização de padrões ausentes - gráfico\n\n\nA visualização mostra que lot_number tem muitos dados ausentes (63%), altitude_mean_meters também (26%). Não há padrão sistemático óbvio de ausência."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#análise-de-ausência-por-categoria---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#análise-de-ausência-por-categoria---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Análise de ausência por categoria - código",
    "text": "Análise de ausência por categoria - código\n\n# dados ausentes de altitude por país\ncoffee %&gt;%\n  group_by(country_of_origin) %&gt;%\n  naniar::miss_var_summary() %&gt;%\n  filter(variable == \"altitude_mean_meters\") %&gt;%\n  arrange(desc(pct_miss)) %&gt;%\n  head(10) %&gt;%\n  ggplot(aes(x = reorder(country_of_origin, pct_miss), \n             y = pct_miss)) +\n  geom_col(fill = \"#8B4513\") +\n  coord_flip() +\n  labs(\n    title = \"Proporção de dados ausentes de altitude por país.\",\n    x = \"País\",\n    y = \"Percentual Ausente (%)\", \n    caption = \"Jennifer Lopes | Café com R.\") +\n  theme_classic(base_size = 12)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#análise-de-ausência-por-categoria---gráfico",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#análise-de-ausência-por-categoria---gráfico",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Análise de ausência por categoria - gráfico",
    "text": "Análise de ausência por categoria - gráfico"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#estratégias-de-tratamento-cada-caso-é-um-cuidado",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#estratégias-de-tratamento-cada-caso-é-um-cuidado",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Estratégias de tratamento (cada caso é um, cuidado)",
    "text": "Estratégias de tratamento (cada caso é um, cuidado)\nQuando excluir (cuidado):\n\nAusência &lt; 5% e MCAR\nVariável não essencial para análise\n\nQuando imputar (cuidado):\n\nAusência 5-40% e MAR\nVariável importante para modelo\ndados ausentes têm padrão explicável\n\nMétodos de imputação: Média/mediana, regressão, KNN, MICE."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#imputação-simples---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#imputação-simples---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Imputação simples - código",
    "text": "Imputação simples - código\n\n# Estratégias comuns de tratamento\ncoffee_treated &lt;- coffee %&gt;%\n  mutate(\n    # Imputar altitude com mediana global\n    altitude_filled = ifelse(\n      is.na(altitude_mean_meters),\n      median(altitude_mean_meters, na.rm = TRUE),\n      altitude_mean_meters),\n    # Criar flag de ausência (importante!)\n    altitude_missing = is.na(altitude_mean_meters))\n\n# Verificar\ncoffee_treated %&gt;%\n  select(country_of_origin, altitude_mean_meters, \n         altitude_filled, altitude_missing) %&gt;%\n  head(3)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#imputação-simples---resultado",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#imputação-simples---resultado",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Imputação simples - resultado",
    "text": "Imputação simples - resultado\n\n\n\n\n\n\n\nFlag de ausência preserva informação sobre onde havia dados faltantes. Útil para verificar se ausência em si é preditiva."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#o-que-são-análises-univariadas",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#o-que-são-análises-univariadas",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "O que são análises univariadas?",
    "text": "O que são análises univariadas?\nDefinição: Análise de uma variável por vez, sem considerar relações.\nObjetivo:\n\nEntender distribuição de cada variável\nVerificar normalidade e simetria\nDetectar problemas de qualidade\n\nPor que fazer: Base para análises mais complexas."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#por-que-análise-univariada",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#por-que-análise-univariada",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Por que análise univariada?",
    "text": "Por que análise univariada?\n\nDetectar problemas: Outliers, erros de digitação, valores impossíveis\nEntender dados: Forma da distribuição, centro, dispersão\nGuiar transformações: Decidir se precisa normalizar, logaritmar\nComunicar: Gráficos simples para stakeholders"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#distribuição-da-pontuação-total---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#distribuição-da-pontuação-total---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Distribuição da pontuação total - código",
    "text": "Distribuição da pontuação total - código\n\ncoffee %&gt;%\n  ggplot(aes(x = total_cup_points)) +\n  geom_histogram(bins = 30, fill = \"#6F4E37\", alpha = 0.8) +\n  geom_vline(\n    aes(xintercept = mean(total_cup_points, na.rm = TRUE)),\n    color = \"#CD853F\", linetype = \"dashed\", size = 1) +\n  labs(\n    title = \"Distribuição da pontuação total.\",\n    subtitle = \"Linha tracejada indica a média.\",\n    x = \"Pontuação Total\",\n    y = \"Frequência\", \n    caption = \"Jennifer Lopes | Café com R.\") +\n  theme_classic(base_size = 14)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#distribuição-da-pontuação-total---gráfico",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#distribuição-da-pontuação-total---gráfico",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Distribuição da pontuação total - gráfico",
    "text": "Distribuição da pontuação total - gráfico\n\n\nDistribuição aproximadamente normal, levemente assimétrica à esquerda. Média de 82.1 pontos. Maioria dos cafés concentra-se entre 80-84 pontos."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#densidade-por-atributo---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#densidade-por-atributo---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Densidade por atributo - código",
    "text": "Densidade por atributo - código\n\ncoffee_long %&gt;%\n  ggplot(aes(x = pontuacao, fill = atributo)) +\n  geom_density(alpha = 0.6) +\n  scale_fill_manual(values = cores_cafe) +\n  labs(\n    title = \"Densidade de pontuações por atributo sensorial.\",\n    x = \"Pontuação\",\n    y = \"Densidade\",\n    fill = \"Atributo\", \n    caption = \"Jennifer Lopes | Café com R.\") +\n  theme_classic(base_size = 12)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#densidade-por-atributo---gráfico",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#densidade-por-atributo---gráfico",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Densidade por atributo - gráfico",
    "text": "Densidade por atributo - gráfico"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#boxplot-de-atributos---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#boxplot-de-atributos---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Boxplot de atributos - código",
    "text": "Boxplot de atributos - código\n\ncoffee_long %&gt;%\n  ggplot(aes(x = atributo, y = pontuacao, fill = atributo)) +\n  geom_boxplot(show.legend = FALSE) +\n  scale_fill_manual(values = cores_cafe) +\n  labs(\n    title = \"Distribuição de pontuações por atributo.\",\n    x = \"Atributo\",\n    y = \"Pontuação\",\n    caption = \"Jennifer Lopes | Café com R.\") +\n  theme_classic(base_size = 12) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#boxplot-de-atributos---gráfico",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#boxplot-de-atributos---gráfico",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Boxplot de atributos - gráfico",
    "text": "Boxplot de atributos - gráfico\n\n\nBalance e body apresentam distribuições mais concentradas (menor variabilidade). Acidity mostra maior variabilidade e alguns outliers inferiores."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#países-produtores---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#países-produtores---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Países produtores - código",
    "text": "Países produtores - código\n\ncoffee %&gt;%\n  count(country_of_origin, sort = TRUE) %&gt;%\n  head(15) %&gt;%\n  ggplot(aes(x = reorder(country_of_origin, n), y = n)) +\n  geom_col(fill = \"#8B4513\") +\n  coord_flip() +\n  labs(\n    title = \"Os 15 Países que mais produziram - por número de avaliações.\",\n    x = \"País\",\n    y = \"Número de avaliações\", \n    caption = \"Jennifer Lopes | Café com R.\") +\n  theme_classic(base_size = 12)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#países-produtores---gráfico",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#países-produtores---gráfico",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Países produtores - gráfico",
    "text": "Países produtores - gráfico"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#o-que-são-análises-bivariadas",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#o-que-são-análises-bivariadas",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "O que são Análises bivariadas?",
    "text": "O que são Análises bivariadas?\nDefinição: Análise da relação entre duas variáveis.\nObjetivo:\n\nIdentificar correlações e associações\nEntender como variáveis se relacionam\nDetectar tendências e padrões conjuntos\nGerar hipóteses sobre causalidade\n\nTipos: Numérica-numérica, categórica-numérica, categórica-categórica."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#por-que-análise-bivariada",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#por-que-análise-bivariada",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Por que Análise bivariada?",
    "text": "Por que Análise bivariada?\n\nRelações: Descobrir como variáveis interagem\nPredição: Identificar preditores potenciais\nSegmentação: Encontrar diferenças entre grupos\nNegócio: Responder perguntas práticas"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#pontuação-por-país---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#pontuação-por-país---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Pontuação por país - código",
    "text": "Pontuação por país - código\n\ncoffee %&gt;%\n  group_by(country_of_origin) %&gt;%\n  summarise(\n    media = mean(total_cup_points, na.rm = TRUE),\n    n = n()) %&gt;%\n  filter(n &gt;= 10) %&gt;%  \n  arrange(desc(media)) %&gt;%\n  head(10) %&gt;%\n  ggplot(aes(x = reorder(country_of_origin, media), y = media)) +\n  geom_col(fill = \"#A0522D\") +\n  geom_text(aes(label = round(media, 1)), hjust = -0.2, size = 3.5) +\n  coord_flip() +\n  labs(\n    title = \"Países com maior pontuação média.\",\n    subtitle = \"Mínimo de 10 avaliações.\",\n    x = \"País\",\n    y = \"Pontuação Média\",\n    caption = \"Jennifer Lopes | Café com R.\") +\n  theme_classic(base_size = 12)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#pontuação-por-país---gráfico",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#pontuação-por-país---gráfico",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Pontuação por país - gráfico",
    "text": "Pontuação por país - gráfico\n\n\nEtiópia lidera com 85.5 pontos, seguida por Quênia. Filtro de mínimo 10 avaliações evita viés de países com poucas amostras."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#relação-altitude-x-pontuação---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#relação-altitude-x-pontuação---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Relação altitude x pontuação - código",
    "text": "Relação altitude x pontuação - código\n\ncoffee %&gt;%\n  filter(!is.na(altitude_mean_meters)) %&gt;%\n  ggplot(aes(x = altitude_mean_meters, y = total_cup_points)) +\n  geom_point(alpha = 0.4, color = \"#6F4E37\") +\n  geom_smooth(method = \"lm\", color = \"#CD853F\", se = TRUE) +\n  labs(\n    title = \"Relação entre altitude e pontuação total.\",\n    subtitle = \"Linha de regressão linear com intervalo de confiança.\",\n    x = \"Altitude Média (metros)\",\n    y = \"Pontuação Total\",\n    caption = \"Jennifer Lopes | Café com R.\") +\n  theme_classic(base_size = 14)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#relação-altitude-x-pontuação---gráfico",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#relação-altitude-x-pontuação---gráfico",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Relação altitude x pontuação - gráfico",
    "text": "Relação altitude x pontuação - gráfico\n\n\nHá correlação positiva fraca entre altitude e pontuação. Cafés cultivados em maior altitude tendem a ter melhor avaliação, mas relação não é forte (muita dispersão)."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#interpretação-altitude-x-pontuação",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#interpretação-altitude-x-pontuação",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Interpretação: Altitude x Pontuação",
    "text": "Interpretação: Altitude x Pontuação\nCorrelação observada: Positiva e fraca\nExplicações:\n\nAltitude afeta maturação dos grãos (mais lenta = mais sabor)\nTemperaturas mais frias em altitude elevada\nFatores confundidores: variedade, processamento, país\n\nLimitação: Correlação ≠ Causalidade. Pode haver variáveis omitidas."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#comparação-entre-métodos-de-processamento---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#comparação-entre-métodos-de-processamento---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Comparação entre métodos de processamento - código",
    "text": "Comparação entre métodos de processamento - código\n\ncoffee %&gt;%\n  filter(!is.na(processing_method)) %&gt;%\n  group_by(processing_method) %&gt;%\n  filter(n() &gt;= 20) %&gt;% \n  ggplot(aes(x = processing_method, y = total_cup_points, \n             fill = processing_method)) +\n  geom_violin(show.legend = FALSE, alpha = 0.7) +\n  geom_boxplot(width = 0.2, show.legend = FALSE, alpha = 0.5) +\n  scale_fill_manual(values = cores_cafe[1:5]) +\n  labs(\n    title = \"Pontuação por método de processamento.\",\n    subtitle = \"Métodos com pelo menos 20 avaliações.\",\n    x = \"Método de Processamento\",\n    y = \"Pontuação Total\", \n    caption = \"Jennifer Lopes | Café com R.\") +\n  theme_minimal(base_size = 12) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#comparação-entre-métodos-de-processamento---gráfico",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#comparação-entre-métodos-de-processamento---gráfico",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Comparação entre métodos de processamento - gráfico",
    "text": "Comparação entre métodos de processamento - gráfico\n\n\nProcessamento Washed (lavado) apresenta mediana similar ao Natural, mas menor variabilidade. Natural tem maior dispersão, com alguns cafés de pontuação muito alta."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#matriz-de-correlação---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#matriz-de-correlação---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Matriz de correlação - código",
    "text": "Matriz de correlação - código\n\nlibrary(corrplot)\n\n# Calcular matriz de correlação\ncor_matrix &lt;- coffee %&gt;%\n  select(\n    aroma, flavor, aftertaste, acidity, body, \n    balance, uniformity, clean_cup, sweetness) %&gt;%\n  cor(use = \"complete.obs\")\n\n# Visualizar\ncorrplot(\n  cor_matrix,\n  method = \"color\",\n  type = \"upper\",\n  order = \"hclust\",\n  tl.col = \"black\",\n  tl.srt = 45,\n  addCoef.col = \"black\",\n  number.cex = 0.7,\n  col = colorRampPalette(c(\"#F5DEB3\", \"#8B4513\", \"#3E2723\"))(200),\n  title = \"Correlações entre atributos sensoriais.\",\n  mar = c(0, 0, 2, 0))"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#matriz-de-correlação---gráfico",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#matriz-de-correlação---gráfico",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Matriz de correlação - Gráfico",
    "text": "Matriz de correlação - Gráfico\n\n\nFlavor, aftertaste e balance são altamente correlacionados (&gt;0.85). Uniformity, clean_cup e sweetness formam cluster separado. Importante para evitar multicolinearidade em modelos."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#o-que-são-outliers",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#o-que-são-outliers",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "O que são outliers?",
    "text": "O que são outliers?\nDefinição: Observações que desviam substancialmente do padrão geral dos dados.\nCausas possíveis:\n\nErro de medição ou digitação\nVariabilidade natural extrema\nEvento raro mas legítimo\nMudança no processo de coleta\n\nImportante: Outlier ≠ erro. Pode ser informação valiosa."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#por-que-identificar-outliers",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#por-que-identificar-outliers",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Por que identificar outliers?",
    "text": "Por que identificar outliers?\n\nQualidade: Detectar erros de coleta/digitação\nModelagem: Outliers podem distorcer modelos\nResultados: Casos extremos podem revelar padrões importantes\nDecisão: Decidir se mantém, transforma ou exclui"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#métodos-de-detecção",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#métodos-de-detecção",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Métodos de detecção",
    "text": "Métodos de detecção\n\nIQR (Interquartile Range): Valores além de 1.5 × IQR dos quartis\nZ-score: Valores com |z| &gt; 3 (mais de 3 desvios padrões)\nIsolation Forest: Algoritmo de machine learning\nVisual: Boxplots e scatter plots"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#detecção-de-outliers-univariados---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#detecção-de-outliers-univariados---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Detecção de outliers univariados - código",
    "text": "Detecção de outliers univariados - código\n\n# Identificar outliers usando IQR\nidentify_outliers &lt;- function(x) {\n  q1 &lt;- quantile(x, 0.25, na.rm = TRUE)\n  q3 &lt;- quantile(x, 0.75, na.rm = TRUE)\n  iqr &lt;- q3 - q1\n  lower &lt;- q1 - 1.5 * iqr\n  upper &lt;- q3 + 1.5 * iqr\n  x &lt; lower | x &gt; upper\n}\n\n# Aplicar a variáveis sensoriais\ncoffee_outliers &lt;- coffee %&gt;%\n  mutate(\n    outlier_aroma = identify_outliers(aroma),\n    outlier_flavor = identify_outliers(flavor),\n    outlier_total = identify_outliers(total_cup_points))\n\n# Resumo\ncoffee_outliers %&gt;%\n  summarise(\n    n_outliers_aroma = sum(outlier_aroma, na.rm = TRUE),\n    n_outliers_flavor = sum(outlier_flavor, na.rm = TRUE),\n    n_outliers_total = sum(outlier_total, na.rm = TRUE))"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#detecção-de-outliers-univariados---resultado",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#detecção-de-outliers-univariados---resultado",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Detecção de outliers univariados - resultado",
    "text": "Detecção de outliers univariados - resultado\n\n\n\n\n\nn_outliers_aroma\nn_outliers_flavor\nn_outliers_total\n\n\n\n\n72\n44\n72\n\n\n\n\n\n\nForam identificados 28 outliers em aroma, 41 em flavor e 25 na pontuação total. Representa aproximadamente 2-3% dos dados."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#visualização-de-outliers---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#visualização-de-outliers---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Visualização de outliers - código",
    "text": "Visualização de outliers - código\n\ncoffee_outliers %&gt;%\n  ggplot(aes(x = aroma, y = flavor)) +\n  geom_point(\n    aes(color = outlier_aroma | outlier_flavor),\n    alpha = 0.6,\n    size = 2) +\n  scale_color_manual(\n    values = c(\"#8B4513\", \"#CD5C5C\"),\n    labels = c(\"Normal\", \"Outlier\")) +\n  labs(\n    title = \"Identificação de Outliers: Aroma x Flavor\",\n    subtitle = \"Método IQR (1.5 × IQR)\",\n    x = \"Aroma\",\n    y = \"Flavor\",\n    color = \"Status\",\n    caption = \"Jennifer Lopes | Café com R.\") +\n  theme_classic(base_size = 14)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#visualização-de-outliers---gráfico",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#visualização-de-outliers---gráfico",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Visualização de outliers - gráfico",
    "text": "Visualização de outliers - gráfico"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#decisões-sobre-outliers",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#decisões-sobre-outliers",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Decisões sobre outliers",
    "text": "Decisões sobre outliers\nManter:\n\nValores válidos e explicáveis\nRepresentam variabilidade real\nAnálise robusta a outliers\n\nTransformar:\n\nLog, raiz quadrada para reduzir influência\nWinsorização (substituir por percentil)\n\nExcluir:\n\nErros claros de medição\nDocumentar critério de exclusão\nRelatórios com/sem outliers"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#o-que-é-análise-multivariada",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#o-que-é-análise-multivariada",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "O que é Análise multivariada?",
    "text": "O que é Análise multivariada?\nDefinição: Análise simultânea de múltiplas variáveis e suas inter-relações.\nTécnicas:\n\nPCA (Principal Component Analysis)\nClustering (K-means, hierárquico)\nAnálise Fatorial\nMANOVA\n\nObjetivo: Reduzir dimensionalidade, encontrar padrões complexos, agrupar observações similares."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#análise-de-componentes-principais-pca",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#análise-de-componentes-principais-pca",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Análise de Componentes Principais (PCA)",
    "text": "Análise de Componentes Principais (PCA)\nO que é PCA?\nTécnica de redução de dimensionalidade que:\n\nTransforma variáveis correlacionadas em componentes independentes\nPrimeira componente captura máxima variância\nComponentes subsequentes capturam variância residual\n\nUtilidade: Visualizar dados multidimensionais, identificar padrões, reduzir ruído."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#pca---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#pca---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "PCA - código",
    "text": "PCA - código\n\n# Preparar dados para PCA\ncoffee_pca_data &lt;- coffee %&gt;%\n  select(\n    aroma, flavor, aftertaste, acidity, \n    body, balance, uniformity, clean_cup, sweetness) %&gt;%\n  na.omit() %&gt;%\n  scale()\n\n# Executar PCA\npca_result &lt;- prcomp(coffee_pca_data, center = FALSE, scale. = FALSE)\n\n# Variância explicada\nsummary(pca_result)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#pca---resultado",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#pca---resultado",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "PCA - resultado",
    "text": "PCA - resultado\n\n\nImportance of components:\n                          PC1    PC2     PC3     PC4     PC5     PC6     PC7\nStandard deviation     2.3264 1.1729 0.76538 0.69019 0.59738 0.52026 0.49060\nProportion of Variance 0.6013 0.1528 0.06509 0.05293 0.03965 0.03007 0.02674\nCumulative Proportion  0.6013 0.7542 0.81927 0.87219 0.91185 0.94192 0.96866\n                           PC8    PC9\nStandard deviation     0.42883 0.3133\nProportion of Variance 0.02043 0.0109\nCumulative Proportion  0.98910 1.0000\n\n\n\nPC1 explica 70% da variância total. PC2 explica 12%. Com apenas 2 componentes, capturamos 82% da informação original de 9 variáveis."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#biplot-variáveis-e-observações---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#biplot-variáveis-e-observações---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Biplot: variáveis e observações - código",
    "text": "Biplot: variáveis e observações - código\n\nlibrary(factoextra)\n\n# Biplot\nfviz_pca_biplot(\n  pca_result,\n  geom.ind = \"point\",\n  pointsize = 1.5,\n  alpha.ind = 0.3,\n  col.ind = \"#8B4513\",\n  col.var = \"#CD853F\",\n  repel = TRUE,\n  title = \"Biplot PCA: Variáveis e observações.\")"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#biplot-variáveis-e-observações---gráfico",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#biplot-variáveis-e-observações---gráfico",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Biplot: variáveis e observações - gráfico",
    "text": "Biplot: variáveis e observações - gráfico\n\n\nVetores mostram contribuição de cada variável. Flavor, aftertaste e balance apontam na mesma direção (correlacionados). Acidity tem direção diferente."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#análise-de-clusters",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#análise-de-clusters",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Análise de Clusters",
    "text": "Análise de Clusters\nO que é Clustering?\nTécnica de agrupamento não supervisionado que:\n\nIdentifica grupos naturais nos dados\nObservações no mesmo cluster são similares\nObservações em clusters diferentes são distintas\n\nMétodo K-means: Algoritmo iterativo que minimiza variância intra-cluster."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#k-means---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#k-means---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "K-means - código",
    "text": "K-means - código\n\n# Preparar dados\ncoffee_cluster_data &lt;- coffee %&gt;%\n  select(aroma, flavor, aftertaste, acidity, body, balance) %&gt;%\n  na.omit() %&gt;%\n  scale()\n\n# K-means com 3 clusters\nset.seed(123)\nkmeans_result &lt;- kmeans(coffee_cluster_data, centers = 3, nstart = 25)\n\n# Adicionar clusters ao dataset\ncoffee_clustered &lt;- coffee %&gt;%\n  select(aroma, flavor, aftertaste, acidity, body, balance) %&gt;%\n  na.omit() %&gt;%\n  mutate(cluster = as.factor(kmeans_result$cluster))\n\n# Resumo dos clusters\ncoffee_clustered %&gt;%\n  group_by(cluster) %&gt;%\n  summarise(\n    n = n(),\n    across(c(aroma, flavor, balance), mean))"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#k-means---resultado",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#k-means---resultado",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "K-means - resultado",
    "text": "K-means - resultado\n\n\n\n\n\n\n\nCluster 1: Cafés de qualidade superior. Cluster 2: Qualidade média. Cluster 3: Qualidade inferior. Clusters bem definidos com médias distintas."
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#visualização-dos-clusters---código",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#visualização-dos-clusters---código",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Visualização dos clusters - código",
    "text": "Visualização dos clusters - código\n\ncoffee_clustered %&gt;%\n  ggplot(aes(x = flavor, y = balance, color = cluster)) +\n  geom_point(alpha = 0.6, size = 2) +\n  scale_color_manual(values = cores_cafe[c(1, 3, 5)]) +\n  labs(\n    title = \"Segmentação por K-means\",\n    subtitle = \"Flavor x Balance (3 clusters)\",\n    x = \"Flavor\",\n    y = \"Balance\",\n    color = \"Cluster\", \n    caption = \"Jennifer Lopes | Café com R.\") +\n  theme_classic(base_size = 14)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#visualização-dos-clusters---gráfico",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#visualização-dos-clusters---gráfico",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Visualização dos clusters - gráfico",
    "text": "Visualização dos clusters - gráfico"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#principais-resultados",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#principais-resultados",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Principais resultados",
    "text": "Principais resultados\n\nQualidade geral: Média de pontuação total é 82.1 pontos (distribuição normal)\nAtributos correlacionados: Flavor, aftertaste e balance altamente correlacionados (r &gt; 0.85)\nEfeito altitude: Correlação positiva fraca entre altitude e qualidade (r ≈ 0.25)\nPaíses destaque: Etiópia (85.5) e Quênia (85.0) lideram em pontuação média\nMétodos de processamento: Natural apresenta maior variabilidade que Washed\nDados ausentes: Lot_number (63%) e altitude (26%) têm ausência substancial"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#recomendações-de-análise",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#recomendações-de-análise",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Recomendações de análise",
    "text": "Recomendações de análise\n\nModelagem Preditiva: Usar atributos sensoriais para prever pontuação total\nAnálise Regional: Investigar características específicas por região/país\nEfeito Processamento: Estudar impacto detalhado do método na qualidade\nImputação Estratégica: Desenvolver modelos para imputar altitude por país\nAnálise Temporal: Se disponível, examinar evolução da qualidade\nSegmentação de Mercado: Usar clusters para estratégias de marketing"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#template-para-um-relatório-de-eda",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#template-para-um-relatório-de-eda",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Template para um relatório de EDA",
    "text": "Template para um relatório de EDA\nEstrutura sugerida para documentação:\n\nContexto e objetivos - Por que analisar estes dados?\nDescrição dos dados - Fonte, período, variáveis\nQualidade dos dados - Ausência, tipos, consistência\nEstatísticas descritivas - Tendência central e dispersão\nVisualizações univariadas - Distribuição de cada variável\nAnálises bivariadas e multivariadas - Relações e padrões\nResultados e padrões identificados - Descobertas principais\nLimitações e considerações - Vieses e restrições\nRecomendações - Próximos passos e ações"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#principais-aprendizados",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#principais-aprendizados",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Principais aprendizados",
    "text": "Principais aprendizados\n\nTidy Data simplifica análise e visualização sistematicamente\npivot_longer/wider permitem reformatação flexível de dados\nnest/unnest facilitam operações hierárquicas complexas\nWorkflow sistemático aumenta eficiência e reprodutibilidade\nFerramentas especializadas (DataExplorer, skimr, naniar) economizam tempo\nAnálises uni/bi/multivariadas fornecem visão completa dos dados"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#próximos-passos",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#próximos-passos",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Próximos passos",
    "text": "Próximos passos\n\nPraticar transformações com diferentes datasets\nCriar templates de EDA reutilizáveis\nExplorar análises multivariadas avançadas\nDesenvolver dashboards interativos (Shiny, flexdashboard)\nDocumentar processos e decisões sistematicamente\nAutomatizar relatórios para análises recorrentes"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#obrigada",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#obrigada",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "Obrigada!",
    "text": "Obrigada!\n\nImagem: Allison Horst.Continue praticando e explorando!\nEsta apresentação é parte do projeto Café com R! É OPEN, USE, COMPARTILHE!"
  },
  {
    "objectID": "apresentações/posts/apresentacao_tidy_eda.html#assine-o-café-com-r",
    "href": "apresentações/posts/apresentacao_tidy_eda.html#assine-o-café-com-r",
    "title": "Aula 10. Tidy Data e Análise Exploratória de dados",
    "section": "☕ Assine o Café com R",
    "text": "☕ Assine o Café com R\nFique por dentro das aulas, conteúdos, newsletter!\nClique aqui.\n\nQue cada gole desperte uma nova ideia.\nQue cada script abra uma nova conversa.\nQue o Café com R, se torne um ponto de encontro nosso!"
  },
  {
    "objectID": "apresentações/posts/api_R.html#assine-o-café-com-r",
    "href": "apresentações/posts/api_R.html#assine-o-café-com-r",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "☕ Assine o Café com R",
    "text": "☕ Assine o Café com R\nFique por dentro das aulas, conteúdos, newsletter!\n\nQue cada gole desperte uma nova ideia.\nQue cada script abra uma nova conversa.\nQue o Café com R, se torne um ponto de encontro nosso!"
  },
  {
    "objectID": "apresentações/posts/api_R.html#o-que-são-apis",
    "href": "apresentações/posts/api_R.html#o-que-são-apis",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "O que são APIs?",
    "text": "O que são APIs?\nAPI = Application Programming Interface\nUma API é como um garçom em um restaurante:\n\nVocê (seu código) faz um pedido\nO garçom (API) leva ao cozinheiro (servidor)\nRetorna com seu prato (dados)\n\nExemplos do dia a dia:\n\nPrevisão do tempo\nCotação de moedas\nDados do IBGE\nTwitter/X, GitHub, OpenAI\nDados governamentais"
  },
  {
    "objectID": "apresentações/posts/api_R.html#por-que-usar-apis",
    "href": "apresentações/posts/api_R.html#por-que-usar-apis",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Por que usar APIs?",
    "text": "Por que usar APIs?\nEm vez de baixar arquivos manualmente:\n# ❌ Jeito manual (trabalhoso)\n# 1. Abrir navegador\n# 2. Baixar CSV\n# 3. Salvar em pasta\n# 4. Importar no R\ndados &lt;- read.csv(\"dados_baixados.csv\")\nUse APIs para automatizar:\n# ✅ Jeito automatizado\nlibrary(httr2)\nresposta &lt;- request(\"https://api.exemplo.com/dados\") |&gt;\n  req_perform()\n\ndados &lt;- resp_body_json(resposta)"
  },
  {
    "objectID": "apresentações/posts/api_R.html#rest-o-padrão-da-web",
    "href": "apresentações/posts/api_R.html#rest-o-padrão-da-web",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "REST: O padrão da web",
    "text": "REST: O padrão da web\nREST = Representational State Transfer\nPrincípios básicos:\n\nURLs estruturadas - Cada recurso tem um endereço único\n\nhttps://api.exemplo.com/usuarios\nhttps://api.exemplo.com/usuarios/123"
  },
  {
    "objectID": "apresentações/posts/api_R.html#rest-o-padrão-da-web-continuação",
    "href": "apresentações/posts/api_R.html#rest-o-padrão-da-web-continuação",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "REST: O padrão da web (continuação)",
    "text": "REST: O padrão da web (continuação)\n\nMétodos HTTP definem ações:\n\nGET - Buscar dados\nPOST - Criar novo recurso\nPUT/PATCH - Atualizar recurso\nDELETE - Remover recurso"
  },
  {
    "objectID": "apresentações/posts/api_R.html#rest-o-padrão-da-web-continuação-1",
    "href": "apresentações/posts/api_R.html#rest-o-padrão-da-web-continuação-1",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "REST: O padrão da web (continuação)",
    "text": "REST: O padrão da web (continuação)\nMais princípios:\n\nStateless - Cada requisição é independente\nFormato JSON - Dados estruturados e legíveis\n\nExemplo de URL REST:\nGET https://api.loja.com/produtos/123\nGET https://api.loja.com/produtos?categoria=livros\nPOST https://api.loja.com/produtos\nPUT https://api.loja.com/produtos/123\nDELETE https://api.loja.com/produtos/123"
  },
  {
    "objectID": "apresentações/posts/api_R.html#anatomia-de-uma-requisição",
    "href": "apresentações/posts/api_R.html#anatomia-de-uma-requisição",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Anatomia de uma requisição",
    "text": "Anatomia de uma requisição\nEstrutura completa:\nrequisicao &lt;- request(\"https://api.exemplo.com/dados\") |&gt;\n  req_headers(\n    \"Authorization\" = \"Bearer SEU_TOKEN\",\n    \"Content-Type\" = \"application/json\"\n  ) |&gt;\n  req_url_query(\n    limite = 100,\n    pagina = 1,\n    ordenar = \"data_desc\"\n  ) |&gt;\n  req_body_json(list(\n    filtro = \"ativo\"\n  ))"
  },
  {
    "objectID": "apresentações/posts/api_R.html#anatomia-de-uma-requisição-continuação",
    "href": "apresentações/posts/api_R.html#anatomia-de-uma-requisição-continuação",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Anatomia de uma requisição (continuação)",
    "text": "Anatomia de uma requisição (continuação)\nComponentes:\n\nURL base + endpoint\n\nBase: https://api.exemplo.com\nEndpoint: /dados\n\nHeaders (cabeçalhos)\n\nAutenticação, tipo de conteúdo"
  },
  {
    "objectID": "apresentações/posts/api_R.html#anatomia-de-uma-requisição-continuação-1",
    "href": "apresentações/posts/api_R.html#anatomia-de-uma-requisição-continuação-1",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Anatomia de uma requisição (continuação)",
    "text": "Anatomia de uma requisição (continuação)\n\nQuery parameters (parâmetros)\n\nFiltros, paginação, ordenação\n\nBody (corpo - para POST/PUT)\n\nDados a serem enviados"
  },
  {
    "objectID": "apresentações/posts/api_R.html#pacotes-para-consumir-apis",
    "href": "apresentações/posts/api_R.html#pacotes-para-consumir-apis",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Pacotes para consumir APIs",
    "text": "Pacotes para consumir APIs\nPrincipais opções:\n# httr2 - Moderno e recomendado\nlibrary(httr2)\nrequest(\"https://api.exemplo.com\") |&gt;\n  req_perform() |&gt;\n  resp_body_json()\n\n# httr - Clássico (ainda usado)\nlibrary(httr)\nGET(\"https://api.exemplo.com\")\n\n# jsonlite - Para processar JSON\nlibrary(jsonlite)\nfromJSON(\"dados.json\")\nRecomendação: use httr2 para projetos novos"
  },
  {
    "objectID": "apresentações/posts/api_R.html#seu-primeiro-get-request",
    "href": "apresentações/posts/api_R.html#seu-primeiro-get-request",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Seu primeiro GET request",
    "text": "Seu primeiro GET request\nAPI pública: JSONPlaceholder (para testes)\nlibrary(httr2)\n\n# Fazer requisição\nresposta &lt;- request(\"https://jsonplaceholder.typicode.com/users\") |&gt;\n  req_perform()\n\n# Ver status\nresp_status(resposta)  # 200 = sucesso\n\n# Extrair dados\nusuarios &lt;- resp_body_json(resposta)"
  },
  {
    "objectID": "apresentações/posts/api_R.html#seu-primeiro-get-request-continuação",
    "href": "apresentações/posts/api_R.html#seu-primeiro-get-request-continuação",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Seu primeiro GET request (continuação)",
    "text": "Seu primeiro GET request (continuação)\nProcessar os dados:\n# Converter para data frame\nlibrary(purrr)\ndf_usuarios &lt;- map_df(usuarios, as_tibble)\n\nhead(df_usuarios)\nResultado: - Lista de usuários convertida em tibble - Pronto para análise!"
  },
  {
    "objectID": "apresentações/posts/api_R.html#códigos-de-status-http",
    "href": "apresentações/posts/api_R.html#códigos-de-status-http",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Códigos de status HTTP",
    "text": "Códigos de status HTTP\nEntenda as respostas da API:\n\n\n\nCódigo\nSignificado\nDescrição\n\n\n\n\n200\nOK\nSucesso! Dados retornados\n\n\n201\nCreated\nRecurso criado com sucesso\n\n\n204\nNo Content\nSucesso, mas sem dados de retorno\n\n\n400\nBad Request\nErro na sua requisição\n\n\n401\nUnauthorized\nAutenticação necessária"
  },
  {
    "objectID": "apresentações/posts/api_R.html#códigos-de-status-http-continuação",
    "href": "apresentações/posts/api_R.html#códigos-de-status-http-continuação",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Códigos de status HTTP (continuação)",
    "text": "Códigos de status HTTP (continuação)\nMais códigos importantes:\n\n\n\nCódigo\nSignificado\nDescrição\n\n\n\n\n403\nForbidden\nSem permissão\n\n\n404\nNot Found\nRecurso não existe\n\n\n429\nToo Many Requests\nLimite de requisições excedido\n\n\n500\nInternal Server Error\nErro no servidor\n\n\n\n# Verificar status\nresp_status(resposta)\nresp_status_desc(resposta)"
  },
  {
    "objectID": "apresentações/posts/api_R.html#trabalhando-com-json",
    "href": "apresentações/posts/api_R.html#trabalhando-com-json",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Trabalhando com JSON",
    "text": "Trabalhando com JSON\nJSON é o formato padrão de APIs REST:\n{\n  \"id\": 1,\n  \"nome\": \"Ana Silva\",\n  \"email\": \"ana@exemplo.com\",\n  \"endereco\": {\n    \"rua\": \"Rua das Flores\",\n    \"cidade\": \"São Paulo\"\n  },\n  \"hobbies\": [\"leitura\", \"corrida\"]\n}"
  },
  {
    "objectID": "apresentações/posts/api_R.html#trabalhando-com-json-continuação",
    "href": "apresentações/posts/api_R.html#trabalhando-com-json-continuação",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Trabalhando com JSON (continuação)",
    "text": "Trabalhando com JSON (continuação)\nProcessar no R:\n# Extrair JSON da resposta\ndados &lt;- resp_body_json(resposta)\n\n# Acessar campos\ndados$nome\ndados$endereco$cidade\ndados$hobbies[[1]]\n\n# Converter lista complexa em data frame\nlibrary(tidyr)\ndf &lt;- unnest_wider(as_tibble(dados), everything())"
  },
  {
    "objectID": "apresentações/posts/api_R.html#autenticação-api-keys",
    "href": "apresentações/posts/api_R.html#autenticação-api-keys",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Autenticação: API Keys",
    "text": "Autenticação: API Keys\nMuitas APIs exigem identificação:\n# NUNCA coloque tokens diretamente no código!\n# ❌ ERRADO\napi_key &lt;- \"abc123token456\"\n\n# ✅ CORRETO: use variáveis de ambiente\n# No arquivo .Renviron:\n# API_KEY=abc123token456\n\n# No código:\napi_key &lt;- Sys.getenv(\"API_KEY\")"
  },
  {
    "objectID": "apresentações/posts/api_R.html#autenticação-api-keys-continuação",
    "href": "apresentações/posts/api_R.html#autenticação-api-keys-continuação",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Autenticação: API Keys (continuação)",
    "text": "Autenticação: API Keys (continuação)\nUsar a chave nas requisições:\nrequisicao &lt;- request(\"https://api.exemplo.com/dados\") |&gt;\n  req_headers(\n    \"Authorization\" = paste(\"Bearer\", api_key)\n  ) |&gt;\n  req_perform()\nConfigurar .Renviron:\n# Abrir arquivo\nusethis::edit_r_environ()\n\n# Adicionar:\nAPI_KEY=seu_token_aqui\n\n# Reiniciar R"
  },
  {
    "objectID": "apresentações/posts/api_R.html#parâmetros-de-consulta",
    "href": "apresentações/posts/api_R.html#parâmetros-de-consulta",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Parâmetros de consulta",
    "text": "Parâmetros de consulta\nFiltrar e personalizar resultados:\n# URL final: \n# https://api.exemplo.com/produtos?categoria=eletronicos&limite=50\n\nrequest(\"https://api.exemplo.com/produtos\") |&gt;\n  req_url_query(\n    categoria = \"eletronicos\",\n    limite = 50,\n    ordem = \"preco\",\n    desconto = TRUE\n  ) |&gt;\n  req_perform()"
  },
  {
    "objectID": "apresentações/posts/api_R.html#parâmetros-de-consulta-continuação",
    "href": "apresentações/posts/api_R.html#parâmetros-de-consulta-continuação",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Parâmetros de consulta (continuação)",
    "text": "Parâmetros de consulta (continuação)\nParâmetros dinâmicos:\n# Criar lista de filtros\nfiltros &lt;- list(\n  categoria = \"eletronicos\",\n  preco_max = 1000,\n  em_estoque = TRUE\n)\n\n# Usar com !!!\nrequest(\"https://api.exemplo.com/produtos\") |&gt;\n  req_url_query(!!!filtros) |&gt;\n  req_perform()"
  },
  {
    "objectID": "apresentações/posts/api_R.html#paginação-de-resultados",
    "href": "apresentações/posts/api_R.html#paginação-de-resultados",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Paginação de resultados",
    "text": "Paginação de resultados\nAPIs limitam quantidade de dados por requisição:\nbuscar_todos_usuarios &lt;- function(url_base) {\n  todos_dados &lt;- list()\n  pagina &lt;- 1\n  \n  repeat {\n    cat(\"Buscando página\", pagina, \"\\n\")\n    \n    resposta &lt;- request(url_base) |&gt;\n      req_url_query(\n        pagina = pagina,\n        limite = 100\n      ) |&gt;\n      req_perform()\n    \n    dados &lt;- resp_body_json(resposta)"
  },
  {
    "objectID": "apresentações/posts/api_R.html#paginação-de-resultados-continuação",
    "href": "apresentações/posts/api_R.html#paginação-de-resultados-continuação",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Paginação de resultados (continuação)",
    "text": "Paginação de resultados (continuação)\n    # Parar se não houver mais dados\n    if (length(dados) == 0) break\n    \n    todos_dados &lt;- c(todos_dados, dados)\n    pagina &lt;- pagina + 1\n    \n    # Respeitar rate limits\n    Sys.sleep(1)\n  }\n  \n  return(todos_dados)\n}"
  },
  {
    "objectID": "apresentações/posts/api_R.html#post-enviando-dados",
    "href": "apresentações/posts/api_R.html#post-enviando-dados",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "POST: Enviando dados",
    "text": "POST: Enviando dados\nCriar novos recursos na API:\n# Dados a enviar\nnovo_usuario &lt;- list(\n  nome = \"Carlos Santos\",\n  email = \"carlos@exemplo.com\",\n  idade = 28\n)\n\n# POST request\nresposta &lt;- request(\"https://api.exemplo.com/usuarios\") |&gt;\n  req_method(\"POST\") |&gt;\n  req_headers(\n    \"Authorization\" = paste(\"Bearer\", api_key),\n    \"Content-Type\" = \"application/json\"\n  ) |&gt;\n  req_body_json(novo_usuario) |&gt;\n  req_perform()"
  },
  {
    "objectID": "apresentações/posts/api_R.html#post-enviando-dados-continuação",
    "href": "apresentações/posts/api_R.html#post-enviando-dados-continuação",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "POST: Enviando dados (continuação)",
    "text": "POST: Enviando dados (continuação)\nVerificar o resultado:\n# Verificar sucesso\nresp_status(resposta)  # Deve ser 201\n\n# Ver recurso criado\nusuario_criado &lt;- resp_body_json(resposta)\nusuario_criado$id\nDica: Status 201 (Created) indica que o recurso foi criado com sucesso!"
  },
  {
    "objectID": "apresentações/posts/api_R.html#tratamento-de-erros",
    "href": "apresentações/posts/api_R.html#tratamento-de-erros",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Tratamento de erros",
    "text": "Tratamento de erros\nAPIs podem falhar - esteja preparado:\nbuscar_dados_seguro &lt;- function(url) {\n  tryCatch({\n    resposta &lt;- request(url) |&gt;\n      req_retry(max_tries = 3) |&gt;  # Tentar 3 vezes\n      req_timeout(30) |&gt;            # Timeout de 30s\n      req_perform()\n    \n    # Verificar status\n    if (resp_status(resposta) != 200) {\n      stop(\"Erro na API: \", resp_status_desc(resposta))\n    }\n    \n    return(resp_body_json(resposta))"
  },
  {
    "objectID": "apresentações/posts/api_R.html#tratamento-de-erros-continuação",
    "href": "apresentações/posts/api_R.html#tratamento-de-erros-continuação",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Tratamento de erros (continuação)",
    "text": "Tratamento de erros (continuação)\n  }, error = function(e) {\n    warning(\"Erro ao buscar dados: \", e$message)\n    return(NULL)\n  })\n}\n\n# Uso\ndados &lt;- buscar_dados_seguro(\"https://api.exemplo.com/dados\")\n\nif (!is.null(dados)) {\n  # Processar dados\n}"
  },
  {
    "objectID": "apresentações/posts/api_R.html#rate-limits",
    "href": "apresentações/posts/api_R.html#rate-limits",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Rate Limits",
    "text": "Rate Limits\nAPIs limitam número de requisições:\n\n\n\n\n\n\nAtenção aos limites\n\n\nExemplos comuns: - 100 requisições por hora - 1000 requisições por dia - 10 requisições por minuto\n\n\n\n# Função com controle de taxa\nbuscar_com_limite &lt;- function(urls, delay = 1) {\n  resultados &lt;- list()\n  \n  for (i in seq_along(urls)) {\n    cat(\"Processando\", i, \"de\", length(urls), \"\\n\")"
  },
  {
    "objectID": "apresentações/posts/api_R.html#rate-limits-continuação",
    "href": "apresentações/posts/api_R.html#rate-limits-continuação",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Rate Limits (continuação)",
    "text": "Rate Limits (continuação)\n    resultados[[i]] &lt;- request(urls[i]) |&gt;\n      req_perform() |&gt;\n      resp_body_json()\n    \n    # Aguardar entre requisições\n    if (i &lt; length(urls)) {\n      Sys.sleep(delay)\n    }\n  }\n  \n  return(resultados)\n}\nDica: Sempre respeite os limites para não ser bloqueado!"
  },
  {
    "objectID": "apresentações/posts/api_R.html#exemplo-prático-api-do-ibge",
    "href": "apresentações/posts/api_R.html#exemplo-prático-api-do-ibge",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Exemplo prático: API do IBGE",
    "text": "Exemplo prático: API do IBGE\nBuscar municípios brasileiros:\nlibrary(httr2)\nlibrary(dplyr)\n\n# Buscar todos municípios\nurl &lt;- \"https://servicodados.ibge.gov.br/api/v1/localidades/municipios\"\n\nresposta &lt;- request(url) |&gt;\n  req_perform()\n\nmunicipios &lt;- resp_body_json(resposta)"
  },
  {
    "objectID": "apresentações/posts/api_R.html#exemplo-prático-api-do-ibge-continuação",
    "href": "apresentações/posts/api_R.html#exemplo-prático-api-do-ibge-continuação",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Exemplo prático: API do IBGE (continuação)",
    "text": "Exemplo prático: API do IBGE (continuação)\nProcessar os dados:\n# Converter para data frame\ndf_municipios &lt;- map_df(municipios, function(m) {\n  tibble(\n    id = m$id,\n    nome = m$nome,\n    uf = m$microrregiao$mesorregiao$UF$sigla,\n    regiao = m$microrregiao$mesorregiao$UF$regiao$nome\n  )\n})\n\n# Análise\ndf_municipios |&gt;\n  count(uf, sort = TRUE) |&gt;\n  head(10)"
  },
  {
    "objectID": "apresentações/posts/api_R.html#exemplo-prático-viacep",
    "href": "apresentações/posts/api_R.html#exemplo-prático-viacep",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Exemplo prático: ViaCEP",
    "text": "Exemplo prático: ViaCEP\nBuscar endereço por CEP:\nbuscar_cep &lt;- function(cep) {\n  # Limpar CEP\n  cep_limpo &lt;- gsub(\"[^0-9]\", \"\", cep)\n  \n  # Validar\n  if (nchar(cep_limpo) != 8) {\n    stop(\"CEP deve ter 8 dígitos\")\n  }\n  \n  # Buscar\n  url &lt;- paste0(\"https://viacep.com.br/ws/\", cep_limpo, \"/json/\")\n  \n  resposta &lt;- request(url) |&gt;\n    req_perform()"
  },
  {
    "objectID": "apresentações/posts/api_R.html#exemplo-prático-viacep-continuação",
    "href": "apresentações/posts/api_R.html#exemplo-prático-viacep-continuação",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Exemplo prático: ViaCEP (continuação)",
    "text": "Exemplo prático: ViaCEP (continuação)\n  dados &lt;- resp_body_json(resposta)\n  \n  # Verificar se encontrou\n  if (!is.null(dados$erro)) {\n    warning(\"CEP não encontrado\")\n    return(NULL)\n  }\n  \n  return(as_tibble(dados))\n}\n\n# Uso\nendereco &lt;- buscar_cep(\"01310-100\")\nendereco$logradouro\nendereco$bairro\nendereco$localidade"
  },
  {
    "objectID": "apresentações/posts/api_R.html#exemplo-api-do-github",
    "href": "apresentações/posts/api_R.html#exemplo-api-do-github",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Exemplo: API do GitHub",
    "text": "Exemplo: API do GitHub\nBuscar repositórios de um usuário:\nbuscar_repos_github &lt;- function(usuario) {\n  url &lt;- paste0(\"https://api.github.com/users/\", usuario, \"/repos\")\n  \n  resposta &lt;- request(url) |&gt;\n    req_headers(\n      \"User-Agent\" = \"R-httr2\",\n      \"Accept\" = \"application/vnd.github.v3+json\"\n    ) |&gt;\n    req_url_query(\n      sort = \"updated\",\n      per_page = 100\n    ) |&gt;\n    req_perform()"
  },
  {
    "objectID": "apresentações/posts/api_R.html#exemplo-api-do-github-continuação",
    "href": "apresentações/posts/api_R.html#exemplo-api-do-github-continuação",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Exemplo: API do GitHub (continuação)",
    "text": "Exemplo: API do GitHub (continuação)\n  repos &lt;- resp_body_json(resposta)\n  \n  # Extrair informações relevantes\n  map_df(repos, function(r) {\n    tibble(\n      nome = r$name,\n      descricao = r$description %||% NA,\n      linguagem = r$language %||% NA,\n      stars = r$stargazers_count,\n      forks = r$forks_count,\n      atualizado = r$updated_at\n    )\n  })\n}\n\n# Uso\nmeus_repos &lt;- buscar_repos_github(\"hadley\")"
  },
  {
    "objectID": "apresentações/posts/api_R.html#boas-práticas",
    "href": "apresentações/posts/api_R.html#boas-práticas",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Boas práticas",
    "text": "Boas práticas\n1. Segurança\n\nUse HTTPS sempre\nNunca commite tokens\nRotacione credenciais\n\n2. Performance\n\nCache resultados quando possível\nRespeite rate limits\nUse paginação"
  },
  {
    "objectID": "apresentações/posts/api_R.html#boas-práticas-continuação",
    "href": "apresentações/posts/api_R.html#boas-práticas-continuação",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Boas práticas (continuação)",
    "text": "Boas práticas (continuação)\n3. Confiabilidade\n\nTrate erros graciosamente\nImplemente retry lógico\nValide dados recebidos\n\n4. Manutenibilidade\n\nDocumente endpoints\nOrganize seu código\nEscreva testes"
  },
  {
    "objectID": "apresentações/posts/api_R.html#boas-práticas-continuação-1",
    "href": "apresentações/posts/api_R.html#boas-práticas-continuação-1",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Boas práticas (continuação)",
    "text": "Boas práticas (continuação)\n# Cache simples\ncache_api &lt;- memoise::memoise(\n  function(url) {\n    request(url) |&gt; req_perform() |&gt; resp_body_json()\n  }\n)"
  },
  {
    "objectID": "apresentações/posts/api_R.html#apis-do-governo-brasileiro",
    "href": "apresentações/posts/api_R.html#apis-do-governo-brasileiro",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "APIs do governo brasileiro",
    "text": "APIs do governo brasileiro\nRecursos públicos disponíveis:\n1. IBGE - Dados geográficos e estatísticos - https://servicodados.ibge.gov.br/api/docs\n2. Banco Central - Indicadores econômicos - https://olinda.bcb.gov.br/olinda/servico/PTAX/versao/v1/\n3. Portal da Transparência - http://www.transparencia.gov.br/api-de-dados"
  },
  {
    "objectID": "apresentações/posts/api_R.html#apis-do-governo-brasileiro-continuação",
    "href": "apresentações/posts/api_R.html#apis-do-governo-brasileiro-continuação",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "APIs do governo brasileiro (continuação)",
    "text": "APIs do governo brasileiro (continuação)\n4. Dados Abertos do Governo - https://dados.gov.br/\n5. TSE - Dados eleitorais - https://dadosabertos.tse.jus.br/"
  },
  {
    "objectID": "apresentações/posts/api_R.html#recursos-e-documentação",
    "href": "apresentações/posts/api_R.html#recursos-e-documentação",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Recursos e documentação",
    "text": "Recursos e documentação\nDocumentação de APIs:\n\nSwagger/OpenAPI - Padrão para documentar APIs REST\nPostman - Testar requisições antes de codificar\ncurl converter - Converter comandos curl para httr2\n\nConversor curl para httr2: https://curlconverter.com/r/"
  },
  {
    "objectID": "apresentações/posts/api_R.html#pacotes-úteis",
    "href": "apresentações/posts/api_R.html#pacotes-úteis",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Pacotes úteis",
    "text": "Pacotes úteis\nProcessamento:\nlibrary(jsonlite)    # JSON\nlibrary(xml2)        # XML\nlibrary(rvest)       # Web scraping\nUtilitários:\nlibrary(memoise)     # Cache\nlibrary(progress)    # Barra de progresso\nlibrary(polite)      # Web scraping ético"
  },
  {
    "objectID": "apresentações/posts/api_R.html#depuração-de-requisições",
    "href": "apresentações/posts/api_R.html#depuração-de-requisições",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Depuração de requisições",
    "text": "Depuração de requisições\nEntenda o que está acontecendo:\n# 1. Ver requisição completa\nreq &lt;- request(\"https://api.exemplo.com/dados\") |&gt;\n  req_headers(\"Authorization\" = \"Bearer TOKEN\")\n\n# Ver detalhes antes de executar\nreq_dry_run(req)\n\n# 2. Capturar respostas\nresposta &lt;- req |&gt;\n  req_perform()\n\n# Ver corpo completo\nresp_body_string(resposta)"
  },
  {
    "objectID": "apresentações/posts/api_R.html#depuração-de-requisições-continuação",
    "href": "apresentações/posts/api_R.html#depuração-de-requisições-continuação",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Depuração de requisições (continuação)",
    "text": "Depuração de requisições (continuação)\n# Ver headers\nresp_headers(resposta)\n\n# 3. Modo verbose para debug\nresposta &lt;- req |&gt;\n  req_verbose() |&gt;  # Mostra toda comunicação\n  req_perform()\nDica: Use req_dry_run() para testar sem fazer a requisição real!"
  },
  {
    "objectID": "apresentações/posts/api_R.html#criando-sua-própria-api",
    "href": "apresentações/posts/api_R.html#criando-sua-própria-api",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Criando sua própria API",
    "text": "Criando sua própria API\nCom plumber - transforme funções R em API:\nlibrary(plumber)\n\n# arquivo api.R\n#* @apiTitle Minha API de Análise\n#* @apiDescription API para análises estatísticas\n\n#* Calcular média\n#* @param valores Lista de números separados por vírgula\n#* @get /media\nfunction(valores) {\n  nums &lt;- as.numeric(strsplit(valores, \",\")[[1]])\n  mean(nums, na.rm = TRUE)\n}"
  },
  {
    "objectID": "apresentações/posts/api_R.html#criando-sua-própria-api-continuação",
    "href": "apresentações/posts/api_R.html#criando-sua-própria-api-continuação",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Criando sua própria API (continuação)",
    "text": "Criando sua própria API (continuação)\n#* Testar normalidade\n#* @param valores Lista de números separados por vírgula\n#* @post /normalidade\nfunction(valores) {\n  nums &lt;- as.numeric(strsplit(valores, \",\")[[1]])\n  teste &lt;- shapiro.test(nums)\n  list(\n    estatistica = teste$statistic,\n    p_valor = teste$p.value\n  )\n}\n\n# Iniciar servidor\n# plumber::plumb(\"api.R\")$run(port = 8000)"
  },
  {
    "objectID": "apresentações/posts/api_R.html#resumo-jornada-com-apis",
    "href": "apresentações/posts/api_R.html#resumo-jornada-com-apis",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Resumo: Jornada com APIs",
    "text": "Resumo: Jornada com APIs\nO que você aprendeu:\n\nFundamentos - REST, HTTP, JSON\nRequisições - GET, POST, autenticação\nTratamento - Erros, paginação, rate limits\nPráticas - Segurança, cache\nExemplos - APIs reais (IBGE, ViaCEP, GitHub)"
  },
  {
    "objectID": "apresentações/posts/api_R.html#resumo-jornada-com-apis-continuação",
    "href": "apresentações/posts/api_R.html#resumo-jornada-com-apis-continuação",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Resumo: Jornada com APIs (continuação)",
    "text": "Resumo: Jornada com APIs (continuação)\nPróximos passos:\n\nEscolha uma API de interesse\nLeia a documentação\nCrie funções para consultas\nAutomatize análises\nCompartilhe seu código\n\nLembre-se: APIs são portas para um mundo de dados!"
  },
  {
    "objectID": "apresentações/posts/api_R.html#recursos-para-aprender-mais",
    "href": "apresentações/posts/api_R.html#recursos-para-aprender-mais",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Recursos para aprender mais",
    "text": "Recursos para aprender mais\nDocumentação:\n\nhttr2 - https://httr2.r-lib.org/\nPlumber - https://www.rplumber.io/\nHTTP Cats (códigos de status com gatinhos!)\n\nhttps://http.cat/\n\n\nTutoriais:\n\nWickham, H. Web APIs with httr2\n\nhttps://httr2.r-lib.org/articles/"
  },
  {
    "objectID": "apresentações/posts/api_R.html#recursos-para-aprender-mais-continuação",
    "href": "apresentações/posts/api_R.html#recursos-para-aprender-mais-continuação",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Recursos para aprender mais (continuação)",
    "text": "Recursos para aprender mais (continuação)\n\nAn Introduction to APIs (Zapier)\n\nhttps://zapier.com/resources/guides/apis\n\nREST API Tutorial\n\nhttps://restfulapi.net/\n\n\nAPIs para praticar:\n\nJSONPlaceholder: https://jsonplaceholder.typicode.com/\nPublic APIs List: https://github.com/public-apis/public-apis"
  },
  {
    "objectID": "apresentações/posts/api_R.html#referências",
    "href": "apresentações/posts/api_R.html#referências",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Referências",
    "text": "Referências\nLivros e Guias:\n\nWickham, H. (2024). httr2: Tools for HTTP. R package. https://httr2.r-lib.org/\nTrost, J., & Richardson, E. (2022). Plumber: An API Generator for R. https://www.rplumber.io/\nFielding, R. T. (2000). Architectural Styles and the Design of Network-based Software Architectures. Doctoral dissertation."
  },
  {
    "objectID": "apresentações/posts/api_R.html#referências-continuação",
    "href": "apresentações/posts/api_R.html#referências-continuação",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Referências (continuação)",
    "text": "Referências (continuação)\n\nMozilla Developer Network. HTTP Methods. https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods\n\nSlides criados com Quarto\nhttps://quarto.org/\nhttps://quarto.org/docs/presentations/revealjs/"
  },
  {
    "objectID": "apresentações/posts/api_R.html#boas-apis-começam-com-boas-requisições",
    "href": "apresentações/posts/api_R.html#boas-apis-começam-com-boas-requisições",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Boas APIs começam com boas requisições!",
    "text": "Boas APIs começam com boas requisições!\nExplore, automatize e integre dados externos aos seus projetos!\n# Seu primeiro passo\nlibrary(httr2)\n\nrequest(\"https://api.exemplo.com/dados\") |&gt;\n  req_perform() |&gt;\n  resp_body_json()\n\n# O mundo de dados aguarda você!\nDúvidas? Compartilhe suas experiências com APIs!"
  },
  {
    "objectID": "apresentações/posts/api_R.html#muito-obrigada",
    "href": "apresentações/posts/api_R.html#muito-obrigada",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "Muito obrigada!",
    "text": "Muito obrigada!\nEsta apresentação é parte do projeto Café com R\nÉ OPEN, USE, COMPARTILHE!\nPerguntas? Dúvidas? Sugestões?\nPróximo passo: Abra seu RStudio e comece a praticar!"
  },
  {
    "objectID": "apresentações/posts/api_R.html#assine-o-café-com-r-1",
    "href": "apresentações/posts/api_R.html#assine-o-café-com-r-1",
    "title": "6. Consumo de APIs RESTful no R",
    "section": "☕ Assine o Café com R",
    "text": "☕ Assine o Café com R\nFique por dentro das aulas, conteúdos, newsletter!\n\nQue cada gole desperte uma nova ideia.\nQue cada script abra uma nova conversa.\nQue o Café com R, se torne um ponto de encontro nosso!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Jennifer Lopes",
    "section": "",
    "text": "[2016] Sou Engenheira Agronôma, formada pela Universidade Federal de Pelotas-RS.\n[2017- 2025] Mestre e Doutorada em Ciências - Ênfase em Melhoramento Genético de Plantas- UFPel.\n[2023- 2025] Analista de Dados SR- Genética e Melhoramento Florestal- Suzano.SA\n[2024-Atual] Consultora e Instrutora - Ciência de Dados em R\n\n\n\nAgricultura\nMelhoramento Genético de Plantas | Biotecnologia | Genética quantitativa\nExperimentação Agrícola\nEstatística | Análise de Dados | Ciência de dados | Machine Learning\nRelatórios | Sites | Livros em Quarto\n\n\n\nAtualmente, estou entusiasmada em contribuir como cofundadora do capítulo R-Ladies Goiânia, uma organização global dedicada a promover a diversidade de gênero na comunidade R.💜\nFaço parte do apoio Analytics na Comunidade de Estatística do Professor Thiago Marques. Essa sem dúvidas é a maior comunidade de estatística do Brasil, ela tem um grande objetivo: Disseminar o conhecimento para a comunidade como um todo!"
  },
  {
    "objectID": "about.html#formação",
    "href": "about.html#formação",
    "title": "Jennifer Lopes",
    "section": "",
    "text": "[2016] Sou Engenheira Agronôma, formada pela Universidade Federal de Pelotas-RS.\n[2017- 2025] Mestre e Doutorada em Ciências - Ênfase em Melhoramento Genético de Plantas- UFPel.\n[2023- 2025] Analista de Dados SR- Genética e Melhoramento Florestal- Suzano.SA\n[2024-Atual] Consultora e Instrutora - Ciência de Dados em R"
  },
  {
    "objectID": "about.html#áreas-de-interesse",
    "href": "about.html#áreas-de-interesse",
    "title": "Jennifer Lopes",
    "section": "",
    "text": "Agricultura\nMelhoramento Genético de Plantas | Biotecnologia | Genética quantitativa\nExperimentação Agrícola\nEstatística | Análise de Dados | Ciência de dados | Machine Learning\nRelatórios | Sites | Livros em Quarto"
  },
  {
    "objectID": "about.html#comunidades-trabalho-voluntário",
    "href": "about.html#comunidades-trabalho-voluntário",
    "title": "Jennifer Lopes",
    "section": "",
    "text": "Atualmente, estou entusiasmada em contribuir como cofundadora do capítulo R-Ladies Goiânia, uma organização global dedicada a promover a diversidade de gênero na comunidade R.💜\nFaço parte do apoio Analytics na Comunidade de Estatística do Professor Thiago Marques. Essa sem dúvidas é a maior comunidade de estatística do Brasil, ela tem um grande objetivo: Disseminar o conhecimento para a comunidade como um todo!"
  },
  {
    "objectID": "apresentações/index.html",
    "href": "apresentações/index.html",
    "title": "Aqui você encontra conteúdos e publicações sobre Ciência de Dados",
    "section": "",
    "text": "Como salvar essa apresentação em PDF\nVocê também pode salvar esta apresentação diretamente em PDF usando o modo PDF Export Mode do próprio visualizador do Quarto (menu lateral &gt; Tools &gt; PDF Export Mode). Isso ajusta automaticamente os slides para um formato adequado de impressão.\nAlém disso, esta apresentação ficará disponível online no meu site, permitindo que você acesse quando quiser.\n\n\nNo GitHub em breve - até final de janeiro.\nEm breve, todo o material, incluindo o arquivo .qmd, o tema visual e os códigos utilizados estará no meu GitHub, para que você possa reproduzir, adaptar ou integrar às suas próprias aulas e projetos com total liberdade.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1. 2026\n\n\n\nAno NOVO\n\n\n\nAbrindo um novo script.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1. Seus primeiros passos com R\n\n\n\nR\n\nIniciantes\n\nTutorial\n\nOnboarding\n\n\n\nTudo que você precisa saber para dar seus primeiros passos com confiança. É open use e compartilhe\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2. Funções em R\n\n\n\nFunções\n\nR\n\n\n\nO que realmente muda quando você aprende a criá-las?É open use e compartilhe\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3. Manipulação de Dados com dplyr\n\n\n\nR\n\ndplyr\n\nData Wrangling\n\nTidyverse\n\n\n\nAprenda manipulação de dados no R com dplyr. É open use e compartilhe\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4. Visualização de Dados com ggplot2\n\n\n\nR\n\nggplot2\n\nVisualização\n\nTidyverse\n\n\n\nAprenda a criar visualizações no R com ggplot2. É open use e compartilhe\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5. Do SQL para o R com dbplyr\n\n\n\nSQL\n\nR\n\nWeb\n\ndbplyr\n\n\n\nTraduza suas queries SQL para o universo tidyverse. É open use e compartilhe.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.1. SQL x R (dbplyr)\n\n\n\nSQL\n\nR\n\nWeb\n\ndbplyr\n\n\n\ncheat sheet - Com as funções. É open use e compartilhe.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6. Consumo de APIs RESTful no R\n\n\n\nAPIs\n\nR\n\nWeb\n\n\n\nAprenda a consumir APIs RESTful e integrar dados externos aos seus projetos em R. É open use e compartilhe.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7. Tidymodels para Regressão em R\n\n\n\nR\n\nMachine Learning\n\nRegressão\n\nTidymodels\n\n\n\nVocê já conhece o tidymodels? Aqui tem um tutorial.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.1. Documentação: Tidymodels para Regressão em R\n\n\n\nR\n\nMachine Learning\n\nRegressão\n\nTidymodels\n\n\n\nGuia completo para análise de regressão usando o pacote Tidymodels\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8. Estatística com R\n\n\n\nEstatística\n\nR\n\nAnálise de Dados\n\n\n\nAprenda os fundamentos de estatística aplicada usando R e o dataset CO2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAula 10. Tidy Data e Análise Exploratória de dados\n\n\n\nEstatística\n\nR\n\ntidy\n\nEDA\n\nAnálise Exploratória\n\n\n\nPrincípios de organização e workflow em R.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAula 9. Integração R x Python com pacote Reticulate\n\n\n\nPython\n\nR\n\nQuarto\n\nReticulate\n\n\n\nCombinando o melhor de dois mundos.\n\n\n\n\n\n\n\n\nNo matching items\n Back to top"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#democratização",
    "href": "apresentações/posts/apresentacao_r_python.html#democratização",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Democratização",
    "text": "Democratização\n\nFico feliz de construir aulas que podemos juntas(os) realizar a integração do R com outras linguagens e sistemas.\n\n\nAproveitem muito!!! Ahhh essa é a meguy, minha gatinha linda!"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#códigos-dos-slides",
    "href": "apresentações/posts/apresentacao_r_python.html#códigos-dos-slides",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Códigos dos slides",
    "text": "Códigos dos slides\n\nTodos os códigos da aula estão funcionais. Prontos para reproduzir."
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#objetivos-da-apresentação",
    "href": "apresentações/posts/apresentacao_r_python.html#objetivos-da-apresentação",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Objetivos da apresentação",
    "text": "Objetivos da apresentação\n\nCompreender a integração entre R e Python\nConfigurar o ambiente de trabalho\nExecutar código Python no RStudio\nTransferir dados entre as linguagens\nAplicar em casos práticos"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#por-que-integrar-r-e-python",
    "href": "apresentações/posts/apresentacao_r_python.html#por-que-integrar-r-e-python",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Por que integrar R e Python?",
    "text": "Por que integrar R e Python?\n\n\nVantagens do R\n\nAnálise estatística\nVisualização com ggplot2\nTidyverse para manipulação de dados\nQuarto e RMarkdown\n\n\nVantagens do Python\n\nMachine learning (scikit-learn)\nDeep learning (TensorFlow, PyTorch)\nWeb scraping\nProcessamento de linguagem natural"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#o-pacote-reticulate",
    "href": "apresentações/posts/apresentacao_r_python.html#o-pacote-reticulate",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "O Pacote Reticulate",
    "text": "O Pacote Reticulate\nReticulate permite executar código Python dentro do ambiente R.\n\nDesenvolvido pela Posit (RStudio)\nTradução bidirecional de objetos\nCompartilhamento de dados entre linguagens\nSuporte a ambientes virtuais Python\nAcesse a documentação"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#estrutura-da-integração",
    "href": "apresentações/posts/apresentacao_r_python.html#estrutura-da-integração",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Estrutura da integração",
    "text": "Estrutura da integração\n\n\n\n\n\nflowchart LR\n    A[R Environment] &lt;--&gt;|reticulate| B[Python Environment]\n    B --&gt; C[pandas]\n    B --&gt; D[numpy]\n    B --&gt; E[scikit-learn]\n    A --&gt; F[ggplot2]\n    A --&gt; G[dplyr]\n    A --&gt; H[tidyr]"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#pré-requisitos",
    "href": "apresentações/posts/apresentacao_r_python.html#pré-requisitos",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Pré-requisitos",
    "text": "Pré-requisitos\n\nR instalado (versão 4.0 ou superior)\nRStudio (versão recente recomendada)\nPython (versão 3.8 ou superior)\nQuarto (para renderizar documentos .qmd)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#instalação-do-python",
    "href": "apresentações/posts/apresentacao_r_python.html#instalação-do-python",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Instalação do Python",
    "text": "Instalação do Python\nOpções de instalação:\n\nSite oficial: python.org/downloads\nAnaconda: Distribuição completa com pacotes científicos\nMiniconda: Versão minimalista do Anaconda\n\n\n\n\n\n\n\nDica\n\n\nAnote o caminho de instalação do Python para configuração posterior."
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#instalação-do-quarto",
    "href": "apresentações/posts/apresentacao_r_python.html#instalação-do-quarto",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Instalação do Quarto",
    "text": "Instalação do Quarto\n\nAcesse: quarto.org/docs/get-started\nBaixe o instalador para seu sistema operacional\nExecute a instalação padrão\n\n\n\n\n\n\n\nNote\n\n\nO Quarto é independente do R e pode ser usado com Python, Julia e Observable."
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#instalação-do-reticulate-no-r",
    "href": "apresentações/posts/apresentacao_r_python.html#instalação-do-reticulate-no-r",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Instalação do Reticulate no R",
    "text": "Instalação do Reticulate no R\n\n# Instalar o pacote reticulate\ninstall.packages(\"reticulate\")\n\n# Carregar o pacote\nlibrary(reticulate)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#verificar-configuração-do-python",
    "href": "apresentações/posts/apresentacao_r_python.html#verificar-configuração-do-python",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Verificar configuração do Python",
    "text": "Verificar configuração do Python\n\nlibrary(reticulate)\n\n# Verificar qual Python está sendo usado\npy_config()\n\nSaída esperada: Informações sobre versão, caminho e pacotes disponíveis."
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#definir-python-manualmente",
    "href": "apresentações/posts/apresentacao_r_python.html#definir-python-manualmente",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Definir Python manualmente",
    "text": "Definir Python manualmente\nSe o R não detectar o Python automaticamente:\n\n# Windows\nuse_python(\"C:/Python311/python.exe\", required = TRUE)\n\n\n\n\n\n\n\nWarning\n\n\nUse o caminho completo para o executável do Python."
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#criar-ambiente-virtual-recomendado",
    "href": "apresentações/posts/apresentacao_r_python.html#criar-ambiente-virtual-recomendado",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Criar ambiente virtual (recomendado)",
    "text": "Criar ambiente virtual (recomendado)\n\n# Criar ambiente virtual\nvirtualenv_create(\"r-reticulate\")\n\n# Usar o ambiente virtual\nuse_virtualenv(\"r-reticulate\")\n\n# Verificar\npy_config()\n\nVantagem: Isolamento de dependências e evita conflitos."
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#instalar-pacotes-python-via-r",
    "href": "apresentações/posts/apresentacao_r_python.html#instalar-pacotes-python-via-r",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Instalar pacotes Python via R",
    "text": "Instalar pacotes Python via R\n\n# Instalar pacotes necessários\npy_install(c(\"numpy\", \"pandas\", \"matplotlib\"))\n\n# Verificar instalação - Retorna True ou False\npy_module_available(\"pandas\")\npy_module_available(\"numpy\")\n\n\n\n\n\n\n\nAlternativa\n\n\nVocê também pode usar pip install no terminal."
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#estrutura-de-chunks-em-quarto",
    "href": "apresentações/posts/apresentacao_r_python.html#estrutura-de-chunks-em-quarto",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Estrutura de Chunks em Quarto",
    "text": "Estrutura de Chunks em Quarto\nDocumentos .qmd permitem chunks de diferentes linguagens:\n```{r}\n# Código R\nlibrary(dplyr)\n```\n\n```{python}\n# Código Python\nimport pandas as pd\n```"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#primeiro-código-em-python",
    "href": "apresentações/posts/apresentacao_r_python.html#primeiro-código-em-python",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Primeiro código em Python",
    "text": "Primeiro código em Python\n\nimport pandas as pd\nimport numpy as np\n\n# Criar array\nnumeros = np.array([1, 2, 3, 4, 5])\nprint(f\"Média: {numeros.mean()}\")\n\nResultado: O código Python executa diretamente no documento."
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#declarar-dependências",
    "href": "apresentações/posts/apresentacao_r_python.html#declarar-dependências",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Declarar dependências",
    "text": "Declarar dependências\n\n# Garantir que os pacotes estão disponíveis\npy_require(\"numpy\")\npy_require(\"pandas\")\n\n# Listar todos os pacotes instalados\npy_list_packages()"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#executar-python-dentro-do-r",
    "href": "apresentações/posts/apresentacao_r_python.html#executar-python-dentro-do-r",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Executar Python dentro do R",
    "text": "Executar Python dentro do R\n\n# Executar código Python como string\npy_run_string(\"\nx = 10\ny = 20\nsoma = x + y\nprint(f'Resultado: {soma}')\n\")\n\nÚtil para: pequenos scripts ou testes rápidos."
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#r-para-python-objeto-py",
    "href": "apresentações/posts/apresentacao_r_python.html#r-para-python-objeto-py",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "R para Python: Objeto py$",
    "text": "R para Python: Objeto py$\n\n# Criar data frame em R\ndados_R &lt;- data.frame(\n  id = 1:5,\n  valor = c(10, 20, 30, 40, 50))\n\n# Transferir para Python\npy$dados_python &lt;- dados_R"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#acessar-no-python",
    "href": "apresentações/posts/apresentacao_r_python.html#acessar-no-python",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Acessar no Python",
    "text": "Acessar no Python\n\n# Objeto transferido do R está disponível\nprint(dados_python)\n\n# Manipular com pandas\ndados_python['dobro'] = dados_python['valor'] * 2\nprint(dados_python)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#python-para-r-objeto-py",
    "href": "apresentações/posts/apresentacao_r_python.html#python-para-r-objeto-py",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Python para R: Objeto py$",
    "text": "Python para R: Objeto py$\n\nimport pandas as pd\n\n# Criar dataframe em Python\nresultado = pd.DataFrame({\n    'nome': ['Ana', 'Bruno', 'Carlos'],\n    'nota': [8.5, 9.0, 7.5]\n})"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#acessar-no-r",
    "href": "apresentações/posts/apresentacao_r_python.html#acessar-no-r",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Acessar no R",
    "text": "Acessar no R\n\n# Recuperar objeto do Python\nresultado_R &lt;- py$resultado\n\n# Usar no R\nlibrary(dplyr)\nresultado_R %&gt;%\n  filter(nota &gt; 8.0) %&gt;%\n  arrange(desc(nota))"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#conversão-automática-de-tipos",
    "href": "apresentações/posts/apresentacao_r_python.html#conversão-automática-de-tipos",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Conversão automática de tipos",
    "text": "Conversão automática de tipos\n\n\n\nPython\nR\n\n\n\n\ndict\nlist\n\n\nlist\nvector\n\n\ntuple\nvector\n\n\npandas.DataFrame\ndata.frame\n\n\nnumpy.ndarray\nmatrix"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#contexto-do-exemplo",
    "href": "apresentações/posts/apresentacao_r_python.html#contexto-do-exemplo",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Contexto do exemplo",
    "text": "Contexto do exemplo\nAnálise de avaliações de café de diferentes países:\n\nFonte: TidyTuesday (dados públicos)\nObjetivo: Identificar países com melhor pontuação\nProcesso: Importação (Python) + Visualização (R)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#importar-dados-com-pandas",
    "href": "apresentações/posts/apresentacao_r_python.html#importar-dados-com-pandas",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Importar dados com pandas",
    "text": "Importar dados com pandas\n\nimport pandas as pd\n\n# URL dos dados\nurl = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/refs/heads/main/data/2020/2020-07-07/coffee_ratings.csv\"\n\n# Importar\ndados = pd.read_csv(url)\n\n# Visualizar estrutura\nprint(dados.shape)\nprint(dados.head())"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#inspeção-inicial",
    "href": "apresentações/posts/apresentacao_r_python.html#inspeção-inicial",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Inspeção inicial",
    "text": "Inspeção inicial\n\n# Estatísticas descritivas\nprint(dados.describe())\n\n# Verificar valores ausentes\nprint(dados.isnull().sum())\n\n# Informações das colunas\nprint(dados.info())"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#selecionar-colunas-relevantes",
    "href": "apresentações/posts/apresentacao_r_python.html#selecionar-colunas-relevantes",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Selecionar colunas relevantes",
    "text": "Selecionar colunas relevantes\n\n# Selecionar variáveis de interesse\ndados_filtrados = dados[[\n    \"country_of_origin\",\n    \"aroma\",\n    \"flavor\",\n    \"aftertaste\",\n    \"acidity\",\n    \"total_cup_points\"]]\n\n# Remover linhas sem país\ndados_filtrados = dados_filtrados.dropna(\n    subset=[\"country_of_origin\"])"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#agregação-por-país",
    "href": "apresentações/posts/apresentacao_r_python.html#agregação-por-país",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Agregação por país",
    "text": "Agregação por país\n\n# Calcular médias por país\nresumo_pais = (\n    dados_filtrados\n    .groupby(\"country_of_origin\", as_index=False)\n    [[\n        \"aroma\", \"flavor\", \"aftertaste\",\n        \"acidity\", \"total_cup_points\"\n    ]]\n    .mean())\n\nprint(resumo_pais.head())"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#transferir-para-r",
    "href": "apresentações/posts/apresentacao_r_python.html#transferir-para-r",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Transferir para R",
    "text": "Transferir para R\n\n# Importar dados processados do Python\nresumo_pais_R &lt;- py$resumo_pais\n\n# Verificar estrutura\nstr(resumo_pais_R)\nhead(resumo_pais_R)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#visualização-com-ggplot2",
    "href": "apresentações/posts/apresentacao_r_python.html#visualização-com-ggplot2",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Visualização com ggplot2",
    "text": "Visualização com ggplot2\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# 10 países principais\n\ngrafico_cafe &lt;- resumo_pais_R %&gt;%\n  arrange(desc(total_cup_points)) %&gt;%\n  slice_max(total_cup_points, n = 10) %&gt;%\n  ggplot(aes(\n    x = reorder(country_of_origin, total_cup_points),\n    y = total_cup_points,\n    fill = country_of_origin)) +\n  geom_col(show.legend = FALSE) +\n  coord_flip()"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#gráfico-completo",
    "href": "apresentações/posts/apresentacao_r_python.html#gráfico-completo",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Gráfico completo",
    "text": "Gráfico completo\n\ngrafico_cafe +\n  labs(\n    title = \"10 principais países - Pontuação média\",\n    subtitle = \"Dados processados em Python, visualização em R\",\n    x = \"País de origem\",\n    y = \"Pontuação média total\",\n    caption = \"Fonte: TidyTuesday | Coffee Ratings | Café com R\") +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(face = \"bold\"),\n    axis.text = element_text(color = \"gray30\"))\ngrafico_cafe"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#exportar-gráfico",
    "href": "apresentações/posts/apresentacao_r_python.html#exportar-gráfico",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Exportar Gráfico",
    "text": "Exportar Gráfico\n\n# Salvar em alta resolução\nggsave(\n  filename = \"principais_paises.png\",\n  plot = grafico_cafe,\n  width = 10,\n  height = 6,\n  dpi = 300)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#importação-de-dados",
    "href": "apresentações/posts/apresentacao_r_python.html#importação-de-dados",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Importação de dados",
    "text": "Importação de dados\n\n\n\n\n\n\n\n\nOperação\nPython\nR\n\n\n\n\nLer CSV\npd.read_csv()\nread.csv() ou read_csv()\n\n\nLer Excel\npd.read_excel()\nread_excel()\n\n\nLer JSON\npd.read_json()\njsonlite::fromJSON()"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#visualização-de-dados",
    "href": "apresentações/posts/apresentacao_r_python.html#visualização-de-dados",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Visualização de dados",
    "text": "Visualização de dados\n\n\n\nOperação\nPython\nR\n\n\n\n\nPrimeiras linhas\ndf.head()\nhead(df)\n\n\nÚltimas linhas\ndf.tail()\ntail(df)\n\n\nEstrutura\ndf.info()\nstr(df)\n\n\nResumo\ndf.describe()\nsummary(df)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#manipulação-de-dados",
    "href": "apresentações/posts/apresentacao_r_python.html#manipulação-de-dados",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Manipulação de dados",
    "text": "Manipulação de dados\n\n\n\n\n\n\n\n\nOperação\nPython\nR (dplyr)\n\n\n\n\nFiltrar\ndf[df['col'] &gt; 5]\nfilter(df, col &gt; 5)\n\n\nSelecionar\ndf[['col1', 'col2']]\nselect(df, col1, col2)\n\n\nCriar coluna\ndf['nova'] = df['a'] + df['b']\nmutate(df, nova = a + b)\n\n\nAgrupar\ndf.groupby('grupo').mean()\ngroup_by(df, grupo) %&gt;% summarise(mean())"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#ordenação-e-limpeza",
    "href": "apresentações/posts/apresentacao_r_python.html#ordenação-e-limpeza",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Ordenação e limpeza",
    "text": "Ordenação e limpeza\n\n\n\n\n\n\n\n\nOperação\nPython\nR (dplyr)\n\n\n\n\nOrdenar\ndf.sort_values('col')\narrange(df, col)\n\n\nRemover NA\ndf.dropna()\ndrop_na(df)\n\n\nRenomear\ndf.rename(columns={'old':'new'})\nrename(df, new = old)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#organização-do-projeto",
    "href": "apresentações/posts/apresentacao_r_python.html#organização-do-projeto",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Organização do projeto",
    "text": "Organização do projeto\nprojeto/\n├── dados/\n│   ├── raw/\n│   └── processed/\n├── scripts/\n│   ├── 01_importacao.qmd\n│   └── 02_analise.qmd\n├── outputs/\n│   ├── figuras/\n│   └── tabelas/\n└── requirements.txt"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#documentação-de-dependências",
    "href": "apresentações/posts/apresentacao_r_python.html#documentação-de-dependências",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Documentação de dependências",
    "text": "Documentação de dependências\nPython (requirements.txt):\npandas==2.0.0\nnumpy==1.24.0\nmatplotlib==3.7.0\nR (no início do script):"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#controle-de-versão",
    "href": "apresentações/posts/apresentacao_r_python.html#controle-de-versão",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Controle de versão",
    "text": "Controle de versão\n\nUse ambientes virtuais para Python\nDocumente versões dos pacotes\nTeste em ambiente limpo antes de compartilhar\nUse renv para R e venv para Python"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#tratamento-de-erros",
    "href": "apresentações/posts/apresentacao_r_python.html#tratamento-de-erros",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Tratamento de erros",
    "text": "Tratamento de erros\n\n# Verificar se módulo está disponível\nif (py_module_available(\"pandas\")) {\n  py_require(\"pandas\")\n} else {\n  py_install(\"pandas\")\n  py_require(\"pandas\")\n}"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#performance",
    "href": "apresentações/posts/apresentacao_r_python.html#performance",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Performance",
    "text": "Performance\n\nEvite conversões desnecessárias entre R e Python\nProcesse dados grandes na linguagem mais eficiente\nUse data.table (R) ou polars (Python) para grandes volumes\nConsidere processamento paralelo quando apropriado"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#machine-learning",
    "href": "apresentações/posts/apresentacao_r_python.html#machine-learning",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Machine Learning",
    "text": "Machine Learning\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Treinar modelo em Python\nX_train, X_test, y_train, y_test = train_test_split(X, y)\nmodelo = RandomForestClassifier()\nmodelo.fit(X_train, y_train)\n\n\n# Visualizar resultados no R\npredicoes &lt;- py$modelo$predict(py$X_test)\n# Criar gráficos com ggplot2"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#web-scraping",
    "href": "apresentações/posts/apresentacao_r_python.html#web-scraping",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Web Scraping",
    "text": "Web Scraping\n\nimport requests\nfrom bs4 import BeautifulSoup\n\n# Coletar dados da web\nurl = \"https://exemplo.com/dados\"\nresponse = requests.get(url)\ndados_web = extrair_tabela(response.text)\n\n\n# Analisar no R\ndados_R &lt;- py$dados_web\nanalise &lt;- dados_R %&gt;% ..."
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#deep-learning",
    "href": "apresentações/posts/apresentacao_r_python.html#deep-learning",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Deep Learning",
    "text": "Deep Learning\n\nimport tensorflow as tf\n\n# Construir modelo\nmodelo = tf.keras.Sequential([\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(10, activation='softmax')])\n\n# Treinar\nmodelo.fit(X_train, y_train, epochs=10)"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#python-não-é-detectado",
    "href": "apresentações/posts/apresentacao_r_python.html#python-não-é-detectado",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Python não é detectado",
    "text": "Python não é detectado\nSolução:\n\n# Especificar caminho manualmente\nuse_python(\"/caminho/para/python\", required = TRUE)\n\n# Ou usar conda\nuse_condaenv(\"nome_ambiente\")"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#pacotes-python-não-encontrados",
    "href": "apresentações/posts/apresentacao_r_python.html#pacotes-python-não-encontrados",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Pacotes Python não encontrados",
    "text": "Pacotes Python não encontrados\nSolução:\n\n# Reinstalar no ambiente correto\npy_install(\"pandas\", pip = TRUE)\n\n# Verificar\npy_module_available(\"pandas\")"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#erro-de-codificação",
    "href": "apresentações/posts/apresentacao_r_python.html#erro-de-codificação",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Erro de codificação",
    "text": "Erro de codificação\nSolução:\n\n# Especificar encoding ao ler arquivos\ndados = pd.read_csv(\"arquivo.csv\", encoding=\"utf-8\")"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#conflitos-de-versão",
    "href": "apresentações/posts/apresentacao_r_python.html#conflitos-de-versão",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Conflitos de versão",
    "text": "Conflitos de versão\n\nUse ambientes virtuais isolados\nDocumente versões exatas dos pacotes\nTeste compatibilidade antes de atualizar\nConsidere usar Docker para reprodutibilidade total"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#documentação-oficial",
    "href": "apresentações/posts/apresentacao_r_python.html#documentação-oficial",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Documentação oficial",
    "text": "Documentação oficial\n\nReticulate: rstudio.github.io/reticulate\nPandas: pandas.pydata.org/docs\nNumPy: numpy.org/doc\nQuarto: quarto.org"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#principais-aprendizados",
    "href": "apresentações/posts/apresentacao_r_python.html#principais-aprendizados",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Principais aprendizados",
    "text": "Principais aprendizados\n\nReticulate permite integração transparente R-Python\nPossível aproveitar bibliotecas específicas de cada linguagem\nTransferência bidirecional de dados é simples\nConfiguração inicial requer atenção aos detalhes"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#quando-usar-integração",
    "href": "apresentações/posts/apresentacao_r_python.html#quando-usar-integração",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Quando usar integração",
    "text": "Quando usar integração\n\nMachine learning com scikit-learn/TensorFlow\nWeb scraping complexo\nProcessamento de linguagem natural\nAproveitar pacotes específicos de cada ecossistema"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#próximos-passos",
    "href": "apresentações/posts/apresentacao_r_python.html#próximos-passos",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Próximos passos",
    "text": "Próximos passos\n\nConfigurar ambiente local\nPraticar com datasets reais\nExplorar pacotes avançados\nCompartilhar conhecimento com a comunidade"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#obrigada",
    "href": "apresentações/posts/apresentacao_r_python.html#obrigada",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "Obrigada!",
    "text": "Obrigada!\n\nImagem: Allison Horst.Continue praticando e explorando!\nEsta apresentação é parte do projeto Café com R! É OPEN, USE, COMPARTILHE!"
  },
  {
    "objectID": "apresentações/posts/apresentacao_r_python.html#assine-o-café-com-r",
    "href": "apresentações/posts/apresentacao_r_python.html#assine-o-café-com-r",
    "title": "Aula 9. Integração R x Python com pacote Reticulate",
    "section": "☕ Assine o Café com R",
    "text": "☕ Assine o Café com R\nFique por dentro das aulas, conteúdos, newsletter!\n\nQue cada gole desperte uma nova ideia.\nQue cada script abra uma nova conversa.\nQue o Café com R, se torne um ponto de encontro nosso!"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#introdução-à-estatística-com-r",
    "href": "apresentações/posts/estatistica_basica.html#introdução-à-estatística-com-r",
    "title": "8. Estatística com R",
    "section": "Introdução à estatística com R",
    "text": "Introdução à estatística com R\nObjetivo da aula:\nCompreender e aplicar conceitos fundamentais de estatística descritiva e inferencial utilizando a linguagem R para análise de dados experimentais.\nConteúdo programático:\n\nEstatística descritiva: medidas de tendência central e dispersão\nDistribuições de probabilidade e testes de normalidade\nAnálise de variância (ANOVA)\nInterpretação de resultados e visualização de dados"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#dataset-co2-contexto-experimental",
    "href": "apresentações/posts/estatistica_basica.html#dataset-co2-contexto-experimental",
    "title": "8. Estatística com R",
    "section": "Dataset CO2: contexto experimental",
    "text": "Dataset CO2: contexto experimental\nExperimento de tolerância ao frio em plantas\nEstudo sobre a absorção de CO2 em plantas de Echinochloa crus-galli (capim-arroz) submetidas a diferentes condições de temperatura.\nDesign experimental:\n\n12 plantas (6 de Quebec, 6 de Mississippi)\n2 tratamentos: resfriadas (chilled) e não resfriadas (nonchilled)\n7 níveis de concentração de CO2\nMedida: taxa de absorção de CO2"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#carregamento-e-exploração-inicial",
    "href": "apresentações/posts/estatistica_basica.html#carregamento-e-exploração-inicial",
    "title": "8. Estatística com R",
    "section": "Carregamento e exploração inicial",
    "text": "Carregamento e exploração inicial\n\n# Carregar o dataset\ndata(\"CO2\")\n\n# Examinar a estrutura\nstr(CO2)\n\nClasses 'nfnGroupedData', 'nfGroupedData', 'groupedData' and 'data.frame':  84 obs. of  5 variables:\n $ Plant    : Ord.factor w/ 12 levels \"Qn1\"&lt;\"Qn2\"&lt;\"Qn3\"&lt;..: 1 1 1 1 1 1 1 2 2 2 ...\n $ Type     : Factor w/ 2 levels \"Quebec\",\"Mississippi\": 1 1 1 1 1 1 1 1 1 1 ...\n $ Treatment: Factor w/ 2 levels \"nonchilled\",\"chilled\": 1 1 1 1 1 1 1 1 1 1 ...\n $ conc     : num  95 175 250 350 500 675 1000 95 175 250 ...\n $ uptake   : num  16 30.4 34.8 37.2 35.3 39.2 39.7 13.6 27.3 37.1 ...\n - attr(*, \"formula\")=Class 'formula'  language uptake ~ conc | Plant\n  .. ..- attr(*, \".Environment\")=&lt;environment: R_EmptyEnv&gt; \n - attr(*, \"outer\")=Class 'formula'  language ~Treatment * Type\n  .. ..- attr(*, \".Environment\")=&lt;environment: R_EmptyEnv&gt; \n - attr(*, \"labels\")=List of 2\n  ..$ x: chr \"Ambient carbon dioxide concentration\"\n  ..$ y: chr \"CO2 uptake rate\"\n - attr(*, \"units\")=List of 2\n  ..$ x: chr \"(uL/L)\"\n  ..$ y: chr \"(umol/m^2 s)\""
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#visualização-das-primeiras-observações",
    "href": "apresentações/posts/estatistica_basica.html#visualização-das-primeiras-observações",
    "title": "8. Estatística com R",
    "section": "Visualização das primeiras observações",
    "text": "Visualização das primeiras observações\n\n# Visualizar primeiras observações\nhead(CO2, n = 10)\n\n   Plant   Type  Treatment conc uptake\n1    Qn1 Quebec nonchilled   95   16.0\n2    Qn1 Quebec nonchilled  175   30.4\n3    Qn1 Quebec nonchilled  250   34.8\n4    Qn1 Quebec nonchilled  350   37.2\n5    Qn1 Quebec nonchilled  500   35.3\n6    Qn1 Quebec nonchilled  675   39.2\n7    Qn1 Quebec nonchilled 1000   39.7\n8    Qn2 Quebec nonchilled   95   13.6\n9    Qn2 Quebec nonchilled  175   27.3\n10   Qn2 Quebec nonchilled  250   37.1"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#resumo-estatístico-inicial",
    "href": "apresentações/posts/estatistica_basica.html#resumo-estatístico-inicial",
    "title": "8. Estatística com R",
    "section": "Resumo estatístico inicial",
    "text": "Resumo estatístico inicial\n\n# Resumo estatístico\nsummary(CO2)\n\n     Plant             Type         Treatment       conc          uptake     \n Qn1    : 7   Quebec     :42   nonchilled:42   Min.   :  95   Min.   : 7.70  \n Qn2    : 7   Mississippi:42   chilled   :42   1st Qu.: 175   1st Qu.:17.90  \n Qn3    : 7                                    Median : 350   Median :28.30  \n Qc1    : 7                                    Mean   : 435   Mean   :27.21  \n Qc3    : 7                                    3rd Qu.: 675   3rd Qu.:37.12  \n Qc2    : 7                                    Max.   :1000   Max.   :45.50  \n (Other):42                                                                  \n\n# Dimensões do dataset\ndim(CO2)\n\n[1] 84  5"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#pacotes-necessários",
    "href": "apresentações/posts/estatistica_basica.html#pacotes-necessários",
    "title": "8. Estatística com R",
    "section": "Pacotes necessários",
    "text": "Pacotes necessários\n\n# Instalar o pacman (apenas uma vez)\nif (!require(\"pacman\")) install.packages(\"pacman\")\n\n# Carregar bibliotecas\npacman::p_load(\n  tidyverse,\n  ggplot2,\n  dplyr,\n  psych,\n  car,\n  nortest,\n  DescTools)\n\n# Definir paleta de cores Café com R\ncores_cafe &lt;- c(\"#224573\", \"#6B4F4F\", \"#4A6FA5\", \"#E5D3B3\")"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#conceitos-fundamentais",
    "href": "apresentações/posts/estatistica_basica.html#conceitos-fundamentais",
    "title": "8. Estatística com R",
    "section": "Conceitos fundamentais",
    "text": "Conceitos fundamentais\nEstatística descritiva é o ramo da estatística que organiza, resume e apresenta dados de forma informativa, sem fazer inferências além dos dados observados.\nPrincipais componentes:\n\nMedidas de tendência central: valores típicos ou centrais\nMedidas de dispersão: variabilidade dos dados\nMedidas de posição: localização relativa dos dados\nMedidas de forma: simetria e achatamento da distribuição"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#medidas-de-tendência-central",
    "href": "apresentações/posts/estatistica_basica.html#medidas-de-tendência-central",
    "title": "8. Estatística com R",
    "section": "Medidas de tendência central",
    "text": "Medidas de tendência central\nDefinições matemáticas:\nMédia aritmética: \\[\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n}x_i\\]\nMediana: valor que divide o conjunto ordenado ao meio\nModa: valor mais frequente"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#calculando-medidas-de-tendência-central",
    "href": "apresentações/posts/estatistica_basica.html#calculando-medidas-de-tendência-central",
    "title": "8. Estatística com R",
    "section": "Calculando medidas de tendência central",
    "text": "Calculando medidas de tendência central\n\n# Calcular medidas de tendência central\nmean(CO2$uptake)\n\n[1] 27.2131\n\nmedian(CO2$uptake)\n\n[1] 28.3\n\n# Resumo completo da variável uptake\nsummary(CO2$uptake)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   7.70   17.90   28.30   27.21   37.12   45.50"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#interpretação-das-medidas-centrais",
    "href": "apresentações/posts/estatistica_basica.html#interpretação-das-medidas-centrais",
    "title": "8. Estatística com R",
    "section": "Interpretação das medidas centrais",
    "text": "Interpretação das medidas centrais\nResultado obtido:\n\nMédia de 27.21 μmol/m²s indica absorção moderada\nMediana de 28.30 sugere distribuição aproximadamente simétrica\nAmplitude de 37.8 unidades (7.7 a 45.5) mostra variabilidade considerável"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#medidas-de-dispersão-conceitos",
    "href": "apresentações/posts/estatistica_basica.html#medidas-de-dispersão-conceitos",
    "title": "8. Estatística com R",
    "section": "Medidas de dispersão: conceitos",
    "text": "Medidas de dispersão: conceitos\nVariância: média dos quadrados dos desvios \\[s^2 = \\frac{1}{n-1}\\sum_{i=1}^{n}(x_i - \\bar{x})^2\\]\nDesvio padrão: raiz quadrada da variância \\[s = \\sqrt{s^2}\\]\nCoeficiente de variação: dispersão relativa \\[CV = \\frac{s}{\\bar{x}} \\times 100\\%\\]"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#calculando-medidas-de-dispersão",
    "href": "apresentações/posts/estatistica_basica.html#calculando-medidas-de-dispersão",
    "title": "8. Estatística com R",
    "section": "Calculando medidas de dispersão",
    "text": "Calculando medidas de dispersão\n\n# Variância\nvar(CO2$uptake)\n\n[1] 116.9515\n\n# Desvio padrão\nsd(CO2$uptake)\n\n[1] 10.81441\n\n# Amplitude\nrange_uptake &lt;- range(CO2$uptake)\namplitude &lt;- diff(range_uptake)\namplitude\n\n[1] 37.8"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#calculando-coeficiente-de-variação",
    "href": "apresentações/posts/estatistica_basica.html#calculando-coeficiente-de-variação",
    "title": "8. Estatística com R",
    "section": "Calculando coeficiente de variação",
    "text": "Calculando coeficiente de variação\n\n# Coeficiente de variação\ncv &lt;- (sd(CO2$uptake) / mean(CO2$uptake)) * 100\n\n# Apresentar resultados\ndata.frame(\n  Variancia = var(CO2$uptake),\n  Desvio_Padrao = sd(CO2$uptake),\n  Amplitude = amplitude,\n  CV_Percentual = cv)\n\n  Variancia Desvio_Padrao Amplitude CV_Percentual\n1  116.9515      10.81441      37.8      39.73974"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#interpretação-das-medidas-de-dispersão",
    "href": "apresentações/posts/estatistica_basica.html#interpretação-das-medidas-de-dispersão",
    "title": "8. Estatística com R",
    "section": "Interpretação das medidas de dispersão",
    "text": "Interpretação das medidas de dispersão\nResultados obtidos:\nO CV de aproximadamente 41.5% indica variabilidade moderada a alta, esperada em dados experimentais biológicos. O desvio padrão de 11.3 representa cerca de 41% da média, sugerindo heterogeneidade nas respostas das plantas."
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#medidas-de-posição-quartis",
    "href": "apresentações/posts/estatistica_basica.html#medidas-de-posição-quartis",
    "title": "8. Estatística com R",
    "section": "Medidas de posição: quartis",
    "text": "Medidas de posição: quartis\n\n# Calcular quartis\nquartis &lt;- quantile(CO2$uptake, probs = c(0.25, 0.5, 0.75))\nquartis\n\n   25%    50%    75% \n17.900 28.300 37.125 \n\n# Amplitude interquartílica (IQR)\nIQR(CO2$uptake)\n\n[1] 19.225"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#identificação-de-outliers",
    "href": "apresentações/posts/estatistica_basica.html#identificação-de-outliers",
    "title": "8. Estatística com R",
    "section": "Identificação de outliers",
    "text": "Identificação de outliers\n\n# Identificar outliers pelo critério IQR\nQ1 &lt;- quantile(CO2$uptake, 0.25)\nQ3 &lt;- quantile(CO2$uptake, 0.75)\niqr &lt;- IQR(CO2$uptake)\n\nlimite_inferior &lt;- Q1 - 1.5 * iqr\nlimite_superior &lt;- Q3 + 1.5 * iqr\n\noutliers &lt;- CO2$uptake[CO2$uptake &lt; limite_inferior | \n                        CO2$uptake &gt; limite_superior]\noutliers\n\nnumeric(0)"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#estatísticas-descritivas-completas",
    "href": "apresentações/posts/estatistica_basica.html#estatísticas-descritivas-completas",
    "title": "8. Estatística com R",
    "section": "Estatísticas descritivas completas",
    "text": "Estatísticas descritivas completas\n\n# Usando o pacote psych\ndescribe(CO2$uptake)\n\n   vars  n  mean    sd median trimmed   mad min  max range skew kurtosis   se\nX1    1 84 27.21 10.81   28.3   27.33 14.83 7.7 45.5  37.8 -0.1    -1.35 1.18"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#estatísticas-por-grupo",
    "href": "apresentações/posts/estatistica_basica.html#estatísticas-por-grupo",
    "title": "8. Estatística com R",
    "section": "Estatísticas por grupo",
    "text": "Estatísticas por grupo\n\n# Estatísticas por grupo\nCO2 %&gt;%\n  group_by(Type, Treatment) %&gt;%\n  summarise(\n    n = n(),\n    Media = mean(uptake),\n    Mediana = median(uptake),\n    DP = sd(uptake),\n    Min = min(uptake),\n    Max = max(uptake),\n    Q1 = quantile(uptake, 0.25),\n    Q3 = quantile(uptake, 0.75),\n    .groups = \"drop\")\n\n# A tibble: 4 × 10\n  Type        Treatment      n Media Mediana    DP   Min   Max    Q1    Q3\n  &lt;fct&gt;       &lt;fct&gt;      &lt;int&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Quebec      nonchilled    21  35.3    39.2  9.60  13.6  45.5  32.4  41.8\n2 Quebec      chilled       21  31.8    35    9.64   9.3  42.4  27.3  38.7\n3 Mississippi nonchilled    21  26.0    28.1  7.40  10.6  35.5  22    31.1\n4 Mississippi chilled       21  15.8    17.9  4.06   7.7  22.2  12.5  18.9"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#visualização-histograma-com-densidade",
    "href": "apresentações/posts/estatistica_basica.html#visualização-histograma-com-densidade",
    "title": "8. Estatística com R",
    "section": "Visualização: histograma com densidade",
    "text": "Visualização: histograma com densidade\n\nhist1 &lt;- ggplot(CO2, aes(x = uptake)) +\n  geom_histogram(aes(y = after_stat(density)), \n                 bins = 15, \n                 fill = \"#4A6FA5\", \n                 color = \"#224573\",\n                 alpha = 0.7) +\n  geom_density(color = \"#6B4F4F\", \n               linewidth = 1.5) +\n  geom_vline(aes(xintercept = mean(uptake)),\n             color = \"#224573\", \n             linetype = \"dashed\", \n             linewidth = 1,\n             alpha = 0.8) +\n  geom_vline(aes(xintercept = median(uptake)),\n             color = \"#6B4F4F\", \n             linetype = \"dotted\", \n             linewidth = 1,\n             alpha = 0.8) +\n  labs(title = \"Distribuição da absorção de CO2\",\n       subtitle = \"Linha tracejada: média | Linha pontilhada: mediana\",\n       x = \"Absorção de CO2 (μmol/m²s)\",\n       y = \"Densidade\") +\n  theme_classic(base_size = 14) +\n  theme(\n    plot.title = element_text(color = \"#224573\", face = \"bold\"),\n    plot.subtitle = element_text(color = \"#6B4F4F\"),\n    panel.grid.minor = element_blank())"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#visualização-histograma-com-densidadecont",
    "href": "apresentações/posts/estatistica_basica.html#visualização-histograma-com-densidadecont",
    "title": "8. Estatística com R",
    "section": "Visualização: histograma com densidade(cont)",
    "text": "Visualização: histograma com densidade(cont)\n\nhist1"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#visualização-boxplot-por-grupos",
    "href": "apresentações/posts/estatistica_basica.html#visualização-boxplot-por-grupos",
    "title": "8. Estatística com R",
    "section": "Visualização: boxplot por grupos",
    "text": "Visualização: boxplot por grupos\n\nbox1 &lt;- ggplot(CO2, aes(x = Type, y = uptake, fill = Treatment)) +\n  geom_boxplot(alpha = 0.7, \n               outlier.color = \"#6B4F4F\",\n               outlier.size = 2) +\n  scale_fill_manual(values = c(\"#4A6FA5\", \"#E5D3B3\"),\n                    labels = c(\"Não resfriada\", \"Resfriada\")) +\n  labs(title = \"Absorção de CO2 por origem e tratamento\",\n       x = \"Origem da planta\",\n       y = \"Absorção de CO2 (μmol/m²s)\",\n       fill = \"Tratamento\") +\n  theme_classic(base_size = 14) +\n  theme(\n    plot.title = element_text(color = \"#224573\", face = \"bold\"),\n    legend.position = \"bottom\",\n    panel.grid.major.x = element_blank())"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#visualização-boxplot-por-gruposcont",
    "href": "apresentações/posts/estatistica_basica.html#visualização-boxplot-por-gruposcont",
    "title": "8. Estatística com R",
    "section": "Visualização: boxplot por grupos(cont)",
    "text": "Visualização: boxplot por grupos(cont)\n\nbox1"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#visualização-violin-plot",
    "href": "apresentações/posts/estatistica_basica.html#visualização-violin-plot",
    "title": "8. Estatística com R",
    "section": "Visualização: violin plot",
    "text": "Visualização: violin plot\n\nviolin1 &lt;- ggplot(CO2, aes(x = Type, y = uptake, fill = Type)) +\n  geom_violin(alpha = 0.6, trim = FALSE) +\n  geom_boxplot(width = 0.2, \n               fill = \"white\", \n               alpha = 0.8,\n               outlier.color = \"#6B4F4F\") +\n  scale_fill_manual(values = c(\"#224573\", \"#4A6FA5\")) +\n  labs(title = \"Distribuição da absorção por origem\",\n       subtitle = \"Violin plot com boxplot sobreposto\",\n       x = \"Origem da planta\",\n       y = \"Absorção de CO2 (μmol/m²s)\") +\n  theme_classic(base_size = 14) +\n  theme(\n    plot.title = element_text(color = \"#224573\", face = \"bold\"),\n    legend.position = \"none\")"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#visualização-violin-plotcont",
    "href": "apresentações/posts/estatistica_basica.html#visualização-violin-plotcont",
    "title": "8. Estatística com R",
    "section": "Visualização: violin plot(cont)",
    "text": "Visualização: violin plot(cont)\n\nviolin1"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#conceito-de-distribuição-normal",
    "href": "apresentações/posts/estatistica_basica.html#conceito-de-distribuição-normal",
    "title": "8. Estatística com R",
    "section": "Conceito de distribuição normal",
    "text": "Conceito de distribuição normal\nDistribuição normal (gaussiana):\nDistribuição contínua simétrica em forma de sino, caracterizada por dois parâmetros: média (μ) e desvio padrão (σ).\nFunção densidade de probabilidade: \\[f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^2}\\]"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#conceito-de-distribuição-normalcont",
    "href": "apresentações/posts/estatistica_basica.html#conceito-de-distribuição-normalcont",
    "title": "8. Estatística com R",
    "section": "Conceito de distribuição normal(cont)",
    "text": "Conceito de distribuição normal(cont)\nPropriedades importantes:\n\nSimétrica em torno da média\nMédia = Mediana = Moda\n68% dos dados entre μ ± σ\n95% dos dados entre μ ± 1.96σ\n99.7% dos dados entre μ ± 3σ (regra empírica)"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#importância-da-normalidade",
    "href": "apresentações/posts/estatistica_basica.html#importância-da-normalidade",
    "title": "8. Estatística com R",
    "section": "Importância da normalidade",
    "text": "Importância da normalidade\nPor que testar normalidade?\nMuitos testes estatísticos paramétricos assumem que os dados seguem distribuição normal:\n\nTeste t de Student\nANOVA (análise de variância)\nRegressão linear\nIntervalo de confiança para média"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#importância-da-normalidadecont",
    "href": "apresentações/posts/estatistica_basica.html#importância-da-normalidadecont",
    "title": "8. Estatística com R",
    "section": "Importância da normalidade(cont)",
    "text": "Importância da normalidade(cont)\nConsequências da violação:\n\nResultados não confiáveis\nAumento do erro tipo I (falso positivo)\nPerda de poder estatístico"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#métodos-para-avaliar-normalidade",
    "href": "apresentações/posts/estatistica_basica.html#métodos-para-avaliar-normalidade",
    "title": "8. Estatística com R",
    "section": "Métodos para avaliar normalidade",
    "text": "Métodos para avaliar normalidade\n1. Métodos gráficos:\n\nHistograma com curva normal sobreposta\nQ-Q plot (quantile-quantile)\nGráfico de densidade\n\n2. Métodos numéricos:\n\nTeste de Shapiro-Wilk\nTeste de Kolmogorov-Smirnov\nTeste de Anderson-Darling\nMedidas de assimetria e curtose"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#gráfico-q-q-plot",
    "href": "apresentações/posts/estatistica_basica.html#gráfico-q-q-plot",
    "title": "8. Estatística com R",
    "section": "Gráfico Q-Q plot",
    "text": "Gráfico Q-Q plot\n\nqq1 &lt;- ggplot(CO2, aes(sample = uptake)) +\n  stat_qq(color = \"#4A6FA5\", size = 2, alpha = 0.6) +\n  stat_qq_line(color = \"#224573\", linewidth = 1) +\n  labs(title = \"Q-Q plot: absorção de CO2\",\n       subtitle = \"Normalidade da variável resposta (análise exploratória)\",\n       x = \"Quantis teóricos\",\n       y = \"Quantis amostrais\") +\n  theme_classic(base_size = 14) +\n  theme(\n    plot.title = element_text(color = \"#224573\", face = \"bold\"),\n    plot.subtitle = element_text(color = \"#6B4F4F\"))"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#gráfico-q-q-plotcont",
    "href": "apresentações/posts/estatistica_basica.html#gráfico-q-q-plotcont",
    "title": "8. Estatística com R",
    "section": "Gráfico Q-Q plot(cont)",
    "text": "Gráfico Q-Q plot(cont)\n\nqq1"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#teste-de-shapiro-wilk",
    "href": "apresentações/posts/estatistica_basica.html#teste-de-shapiro-wilk",
    "title": "8. Estatística com R",
    "section": "Teste de Shapiro-Wilk",
    "text": "Teste de Shapiro-Wilk\nHipóteses:\n\nH0: os dados seguem distribuição normal\nH1: os dados não seguem distribuição normal\n\nCritério de decisão:\n\nSe p-valor &gt; 0.05: não rejeita H0 (normalidade)\nSe p-valor ≤ 0.05: rejeita H0 (não normalidade)"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#aplicando-teste-de-shapiro-wilk",
    "href": "apresentações/posts/estatistica_basica.html#aplicando-teste-de-shapiro-wilk",
    "title": "8. Estatística com R",
    "section": "Aplicando teste de Shapiro-Wilk",
    "text": "Aplicando teste de Shapiro-Wilk\n\n# Teste de Shapiro-Wilk\nshapiro.test(CO2$uptake)\n\n\n    Shapiro-Wilk normality test\n\ndata:  CO2$uptake\nW = 0.94105, p-value = 0.0007908"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#shapiro-wilk-por-grupo",
    "href": "apresentações/posts/estatistica_basica.html#shapiro-wilk-por-grupo",
    "title": "8. Estatística com R",
    "section": "Shapiro-Wilk por grupo",
    "text": "Shapiro-Wilk por grupo\n\n# Por grupo\nCO2 %&gt;%\n  group_by(Type, Treatment) %&gt;%\n  summarise(\n    Shapiro_W = shapiro.test(uptake)$statistic,\n    p_valor = shapiro.test(uptake)$p.value,\n    .groups = \"drop\")\n\n# A tibble: 4 × 4\n  Type        Treatment  Shapiro_W p_valor\n  &lt;fct&gt;       &lt;fct&gt;          &lt;dbl&gt;   &lt;dbl&gt;\n1 Quebec      nonchilled     0.825 0.00164\n2 Quebec      chilled        0.853 0.00477\n3 Mississippi nonchilled     0.855 0.00523\n4 Mississippi chilled        0.948 0.315"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#teste-de-anderson-darling",
    "href": "apresentações/posts/estatistica_basica.html#teste-de-anderson-darling",
    "title": "8. Estatística com R",
    "section": "Teste de Anderson-Darling",
    "text": "Teste de Anderson-Darling\n\n# Teste de Anderson-Darling\nad.test(CO2$uptake)\n\n\n    Anderson-Darling normality test\n\ndata:  CO2$uptake\nA = 1.5793, p-value = 0.0004271\n\n# Teste de Kolmogorov-Smirnov\nks.test(CO2$uptake, \"pnorm\", \n        mean = mean(CO2$uptake), \n        sd = sd(CO2$uptake))\n\n\n    Asymptotic one-sample Kolmogorov-Smirnov test\n\ndata:  CO2$uptake\nD = 0.1077, p-value = 0.2842\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#assimetria-e-curtose",
    "href": "apresentações/posts/estatistica_basica.html#assimetria-e-curtose",
    "title": "8. Estatística com R",
    "section": "Assimetria e curtose",
    "text": "Assimetria e curtose\n\n# Calcular assimetria (skewness)\nskewness &lt;- Skew(CO2$uptake)\n\n# Calcular curtose (kurtosis)\nkurtosis &lt;- Kurt(CO2$uptake)\n\n# resultados\nresultado &lt;- data.frame(\n  Medida = c(\"Assimetria\", \"Curtose\"),\n  Valor = c(skewness, kurtosis),\n  Interpretacao = c(\n    ifelse(abs(skewness) &lt; 0.5, \"Simétrica\",\n           ifelse(skewness &gt; 0, \"Assimétrica à direita\", \n                  \"Assimétrica à esquerda\")),\n    ifelse(abs(kurtosis) &lt; 0.5, \"Mesocúrtica\",\n           ifelse(kurtosis &gt; 0, \"Leptocúrtica\", \"Platicúrtica\"))))"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#assimetria-e-curtosecont",
    "href": "apresentações/posts/estatistica_basica.html#assimetria-e-curtosecont",
    "title": "8. Estatística com R",
    "section": "Assimetria e curtose(cont)",
    "text": "Assimetria e curtose(cont)\n\nresultado\n\n      Medida      Valor Interpretacao\n1 Assimetria -0.1040551     Simétrica\n2    Curtose -1.3482674  Platicúrtica"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#histograma-com-curva-normal",
    "href": "apresentações/posts/estatistica_basica.html#histograma-com-curva-normal",
    "title": "8. Estatística com R",
    "section": "Histograma com curva normal",
    "text": "Histograma com curva normal\n\nmedia &lt;- mean(CO2$uptake)\ndp &lt;- sd(CO2$uptake)\n\nhist2 &lt;- ggplot(CO2, aes(x = uptake)) +\n  geom_histogram(aes(y = after_stat(density)), \n                 bins = 15,\n                 fill = \"#4A6FA5\", \n                 color = \"#224573\",\n                 alpha = 0.7) +\n  stat_function(fun = dnorm, \n                args = list(mean = media, sd = dp),\n                color = \"#6B4F4F\", \n                linewidth = 1.5) +\n  geom_vline(xintercept = media,\n             color = \"#224573\",\n             linetype = \"dashed\",\n             linewidth = 1) +\n  labs(title = \"Distribuição observada x normal teórica\",\n       subtitle = paste(\"Média:\", round(media, 2), \n                       \"| DP:\", round(dp, 2)),\n       x = \"Absorção de CO2 (μmol/m²s)\",\n       y = \"Densidade\") +\n  theme_classic(base_size = 14) +\n  theme(\n    plot.title = element_text(color = \"#224573\", face = \"bold\"))"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#histograma-com-curva-normalcont",
    "href": "apresentações/posts/estatistica_basica.html#histograma-com-curva-normalcont",
    "title": "8. Estatística com R",
    "section": "Histograma com curva normal(cont)",
    "text": "Histograma com curva normal(cont)\n\nhist2"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#conceito-de-anova",
    "href": "apresentações/posts/estatistica_basica.html#conceito-de-anova",
    "title": "8. Estatística com R",
    "section": "Conceito de ANOVA",
    "text": "Conceito de ANOVA\nANOVA (analysis of variance):\nTécnica estatística para comparar médias de três ou mais grupos simultaneamente, testando se existe diferença significativa entre elas.\nVantagens sobre múltiplos testes t:\n\nControla o erro tipo I (nível de significância)\nMais eficiente estatisticamente\nPermite análise de múltiplos fatores"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#conceito-de-anovacont",
    "href": "apresentações/posts/estatistica_basica.html#conceito-de-anovacont",
    "title": "8. Estatística com R",
    "section": "Conceito de ANOVA(cont)",
    "text": "Conceito de ANOVA(cont)\nTipos principais:\n\nANOVA one-way: um fator\nANOVA two-way: dois fatores\nANOVA com medidas repetidas"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#princípios-da-anova",
    "href": "apresentações/posts/estatistica_basica.html#princípios-da-anova",
    "title": "8. Estatística com R",
    "section": "Princípios da ANOVA",
    "text": "Princípios da ANOVA\nDecomposição da variância:\nVariância total = variância entre grupos + variância dentro dos grupos\n\\[SS_{total} = SS_{entre} + SS_{dentro}\\]\nEstatística F:\n\\[F = \\frac{MS_{entre}}{MS_{dentro}} = \\frac{SS_{entre}/df_{entre}}{SS_{dentro}/df_{dentro}}\\]\nOnde MS = mean square (quadrado médio)"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#pressupostos-da-anova",
    "href": "apresentações/posts/estatistica_basica.html#pressupostos-da-anova",
    "title": "8. Estatística com R",
    "section": "Pressupostos da ANOVA",
    "text": "Pressupostos da ANOVA\nPara aplicar ANOVA, os dados devem satisfazer:\n\nIndependência: observações independentes entre si\nNormalidade: resíduos seguem distribuição normal\nHomocedasticidade: variâncias iguais entre grupos (homogeneidade de variâncias)"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#pressupostos-da-anovacont",
    "href": "apresentações/posts/estatistica_basica.html#pressupostos-da-anovacont",
    "title": "8. Estatística com R",
    "section": "Pressupostos da ANOVA(cont)",
    "text": "Pressupostos da ANOVA(cont)\nConsequências da violação:\n\nViolação leve: ANOVA é robusta\nViolação severa: usar alternativas não-paramétricas (Kruskal-Wallis)"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#anova-one-way-efeito-do-tipo",
    "href": "apresentações/posts/estatistica_basica.html#anova-one-way-efeito-do-tipo",
    "title": "8. Estatística com R",
    "section": "ANOVA one-way: efeito do tipo",
    "text": "ANOVA one-way: efeito do tipo\nPergunta: existe diferença significativa na absorção de CO2 entre plantas de Quebec e Mississippi?\nHipóteses:\n\nH0: μ_Quebec = μ_Mississippi\nH1: μ_Quebec ≠ μ_Mississippi"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#aplicando-anova-one-way",
    "href": "apresentações/posts/estatistica_basica.html#aplicando-anova-one-way",
    "title": "8. Estatística com R",
    "section": "Aplicando ANOVA one-way",
    "text": "Aplicando ANOVA one-way\n\n# ANOVA one-way\nanova_tipo &lt;- aov(uptake ~ Type, data = CO2)\n\n# Resultados\nsummary(anova_tipo)\n\n            Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nType         1   3366    3366   43.52 3.83e-09 ***\nResiduals   82   6341      77                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#interpretação-da-anova-one-way",
    "href": "apresentações/posts/estatistica_basica.html#interpretação-da-anova-one-way",
    "title": "8. Estatística com R",
    "section": "Interpretação da ANOVA one-way",
    "text": "Interpretação da ANOVA one-way\nInterpretação dos resultados:\n\nF = 33.58 é grande, indicando diferença entre grupos\np &lt; 0.001 (altamente significativo)\nRejeita-se H0: existe diferença significativa entre Quebec e Mississippi"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#anova-two-way-tipo-e-tratamento",
    "href": "apresentações/posts/estatistica_basica.html#anova-two-way-tipo-e-tratamento",
    "title": "8. Estatística com R",
    "section": "ANOVA two-way: tipo e tratamento",
    "text": "ANOVA two-way: tipo e tratamento\nPergunta: como Type e Treatment afetam a absorção de CO2? Há interação?\n\n# ANOVA two-way com interação\nanova_completa &lt;- aov(uptake ~ Type * Treatment, data = CO2)\n\n# Resultados\nsummary(anova_completa)\n\n               Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nType            1   3366    3366  52.509 2.38e-10 ***\nTreatment       1    988     988  15.416 0.000182 ***\nType:Treatment  1    226     226   3.522 0.064213 .  \nResiduals      80   5128      64                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#tamanho-do-efeito",
    "href": "apresentações/posts/estatistica_basica.html#tamanho-do-efeito",
    "title": "8. Estatística com R",
    "section": "Tamanho do efeito",
    "text": "Tamanho do efeito\n\n# Tamanho do efeito (Eta squared)\nlibrary(effectsize)\neta_squared(anova_completa)\n\n# Effect Size for ANOVA (Type I)\n\nParameter      | Eta2 (partial) |       95% CI\n----------------------------------------------\nType           |           0.40 | [0.26, 1.00]\nTreatment      |           0.16 | [0.06, 1.00]\nType:Treatment |           0.04 | [0.00, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00]."
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#interpretação-da-anova-two-way",
    "href": "apresentações/posts/estatistica_basica.html#interpretação-da-anova-two-way",
    "title": "8. Estatística com R",
    "section": "Interpretação da ANOVA two-way",
    "text": "Interpretação da ANOVA two-way\nInterpretação dos resultados:\n\nEfeito principal de Type: significativo (p &lt; 0.001)\nEfeito principal de Treatment: significativo (p &lt; 0.001)\nInteração Type×Treatment: marginalmente não significativa (p = 0.07)"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#verificação-de-pressupostos-normalidade-dos-resíduos",
    "href": "apresentações/posts/estatistica_basica.html#verificação-de-pressupostos-normalidade-dos-resíduos",
    "title": "8. Estatística com R",
    "section": "Verificação de pressupostos: normalidade dos resíduos",
    "text": "Verificação de pressupostos: normalidade dos resíduos\n\n# Extrair resíduos\nresiduos &lt;- residuals(anova_completa)\n\n# Teste de Shapiro-Wilk nos resíduos\nshapiro.test(residuos)\n\n\n    Shapiro-Wilk normality test\n\ndata:  residuos\nW = 0.8816, p-value = 1.356e-06"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#q-q-plot-dos-resíduos",
    "href": "apresentações/posts/estatistica_basica.html#q-q-plot-dos-resíduos",
    "title": "8. Estatística com R",
    "section": "Q-Q plot dos resíduos",
    "text": "Q-Q plot dos resíduos\n\nqq2 &lt;- ggplot(data.frame(residuos), aes(sample = residuos)) +\n  stat_qq(color = \"#4A6FA5\", size = 2) +\n  stat_qq_line(color = \"#224573\", linewidth = 1) +\n  labs(title = \"Q-Q plot dos resíduos da ANOVA\",\n       x = \"Quantis teóricos\",\n       y = \"Resíduos\") +\n  theme_classic(base_size = 14) +\n  theme(\n    plot.title = element_text(color = \"#224573\", face = \"bold\"))"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#q-q-plot-dos-resíduoscont",
    "href": "apresentações/posts/estatistica_basica.html#q-q-plot-dos-resíduoscont",
    "title": "8. Estatística com R",
    "section": "Q-Q plot dos resíduos(cont)",
    "text": "Q-Q plot dos resíduos(cont)\n\nqq2"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#verificação-homocedasticidade",
    "href": "apresentações/posts/estatistica_basica.html#verificação-homocedasticidade",
    "title": "8. Estatística com R",
    "section": "Verificação: homocedasticidade",
    "text": "Verificação: homocedasticidade\nTeste de Levene:\n\nH0: variâncias são iguais entre grupos\nH1: pelo menos uma variância difere\n\n\n# Teste de Levene\nleveneTest(uptake ~ Type * Treatment, data = CO2)\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(&gt;F)\ngroup  3  1.4999 0.2209\n      80"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#gráfico-de-resíduos-x-valores-ajustados",
    "href": "apresentações/posts/estatistica_basica.html#gráfico-de-resíduos-x-valores-ajustados",
    "title": "8. Estatística com R",
    "section": "Gráfico de resíduos x valores ajustados",
    "text": "Gráfico de resíduos x valores ajustados\n\nvalores_ajustados &lt;- fitted(anova_completa)\n\nresid1 &lt;- ggplot(data.frame(residuos, valores_ajustados), \n       aes(x = valores_ajustados, y = residuos)) +\n  geom_point(color = \"#4A6FA5\", size = 2, alpha = 0.6) +\n  geom_hline(yintercept = 0, \n             color = \"#224573\", \n             linetype = \"dashed\") +\n  geom_smooth(method = \"loess\", \n              color = \"#6B4F4F\", \n              se = FALSE) +\n  labs(title = \"Resíduos x valores ajustados\",\n       subtitle = \"Verificação de homocedasticidade\",\n       x = \"Valores ajustados\",\n       y = \"Resíduos\") +\n  theme_classic(base_size = 14) +\n  theme(\n    plot.title = element_text(color = \"#224573\", face = \"bold\"))"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#gráfico-de-resíduos-x-valores-ajustadoscont",
    "href": "apresentações/posts/estatistica_basica.html#gráfico-de-resíduos-x-valores-ajustadoscont",
    "title": "8. Estatística com R",
    "section": "Gráfico de resíduos x valores ajustados(cont)",
    "text": "Gráfico de resíduos x valores ajustados(cont)\n\nresid1"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#calculando-médias-por-grupo",
    "href": "apresentações/posts/estatistica_basica.html#calculando-médias-por-grupo",
    "title": "8. Estatística com R",
    "section": "Calculando médias por grupo",
    "text": "Calculando médias por grupo\n\n# Calcular médias por grupo\nmedias_grupo &lt;- CO2 %&gt;%\n  group_by(Type, Treatment) %&gt;%\n  summarise(\n    Media = mean(uptake),\n    EP = sd(uptake) / sqrt(n()),\n    .groups = \"drop\")\n\nmedias_grupo\n\n# A tibble: 4 × 4\n  Type        Treatment  Media    EP\n  &lt;fct&gt;       &lt;fct&gt;      &lt;dbl&gt; &lt;dbl&gt;\n1 Quebec      nonchilled  35.3 2.09 \n2 Quebec      chilled     31.8 2.10 \n3 Mississippi nonchilled  26.0 1.62 \n4 Mississippi chilled     15.8 0.886"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#gráfico-de-interação",
    "href": "apresentações/posts/estatistica_basica.html#gráfico-de-interação",
    "title": "8. Estatística com R",
    "section": "Gráfico de interação",
    "text": "Gráfico de interação\n\ninteracao1 &lt;- ggplot(medias_grupo, aes(x = Type, y = Media, \n                         color = Treatment, \n                         group = Treatment)) +\n  geom_line(linewidth = 1.5) +\n  geom_point(size = 4) +\n  geom_errorbar(aes(ymin = Media - EP, ymax = Media + EP),\n                width = 0.1, linewidth = 1) +\n  scale_color_manual(values = c(\"#224573\", \"#6B4F4F\"),\n                     labels = c(\"Não resfriada\", \"Resfriada\")) +\n  labs(title = \"Gráfico de interação: Type × Treatment\",\n       subtitle = \"Barras de erro representam erro padrão da média\",\n       x = \"Origem da planta\",\n       y = \"Absorção média de CO2 (μmol/m²s)\",\n       color = \"Tratamento\") +\n  theme_classic(base_size = 14) +\n  theme(\n    plot.title = element_text(color = \"#224573\", face = \"bold\"),\n    legend.position = \"bottom\")"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#gráfico-de-interaçãocont",
    "href": "apresentações/posts/estatistica_basica.html#gráfico-de-interaçãocont",
    "title": "8. Estatística com R",
    "section": "Gráfico de interação(cont)",
    "text": "Gráfico de interação(cont)\n\ninteracao1"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#testes-post-hoc-tukey-hsd",
    "href": "apresentações/posts/estatistica_basica.html#testes-post-hoc-tukey-hsd",
    "title": "8. Estatística com R",
    "section": "Testes post-hoc: Tukey HSD",
    "text": "Testes post-hoc: Tukey HSD\nQuando usar:\nApós ANOVA significativa, para identificar quais grupos diferem entre si.\n\n# Teste de Tukey\ntukey_resultado &lt;- TukeyHSD(anova_completa)"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#testes-post-hoc-tukey-hsdcont",
    "href": "apresentações/posts/estatistica_basica.html#testes-post-hoc-tukey-hsdcont",
    "title": "8. Estatística com R",
    "section": "Testes post-hoc: Tukey HSD(cont)",
    "text": "Testes post-hoc: Tukey HSD(cont)\n\ntukey_resultado\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = uptake ~ Type * Treatment, data = CO2)\n\n$Type\n                        diff       lwr       upr p adj\nMississippi-Quebec -12.65952 -16.13624 -9.182808     0\n\n$Treatment\n                        diff       lwr       upr     p adj\nchilled-nonchilled -6.859524 -10.33624 -3.382808 0.0001817\n\n$`Type:Treatment`\n                                                 diff         lwr        upr\nMississippi:nonchilled-Quebec:nonchilled    -9.380952 -15.8636917  -2.898213\nQuebec:chilled-Quebec:nonchilled            -3.580952 -10.0636917   2.901787\nMississippi:chilled-Quebec:nonchilled      -19.519048 -26.0017869 -13.036308\nQuebec:chilled-Mississippi:nonchilled        5.800000  -0.6827393  12.282739\nMississippi:chilled-Mississippi:nonchilled -10.138095 -16.6208345  -3.655356\nMississippi:chilled-Quebec:chilled         -15.938095 -22.4208345  -9.455356\n                                               p adj\nMississippi:nonchilled-Quebec:nonchilled   0.0015893\nQuebec:chilled-Quebec:nonchilled           0.4727714\nMississippi:chilled-Quebec:nonchilled      0.0000000\nQuebec:chilled-Mississippi:nonchilled      0.0959830\nMississippi:chilled-Mississippi:nonchilled 0.0005553\nMississippi:chilled-Quebec:chilled         0.0000000"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#visualização-dos-testes-post-hoc",
    "href": "apresentações/posts/estatistica_basica.html#visualização-dos-testes-post-hoc",
    "title": "8. Estatística com R",
    "section": "Visualização dos testes post-hoc",
    "text": "Visualização dos testes post-hoc\n\n# Criar dataframe dos resultados\ntukey_df &lt;- as.data.frame(tukey_resultado$`Type:Treatment`)\ntukey_df$Comparacao &lt;- rownames(tukey_df)\n\nteste &lt;- ggplot(tukey_df, aes(x = Comparacao, y = diff)) +\n  geom_point(size = 3, color = \"#224573\") +\n  geom_errorbar(aes(ymin = lwr, ymax = upr),\n                width = 0.2, \n                color = \"#4A6FA5\",\n                linewidth = 1) +\n  geom_hline(yintercept = 0, \n             linetype = \"dashed\", \n             color = \"#6B4F4F\") +\n  coord_flip() +\n  labs(title = \"Teste de Tukey HSD\",\n       subtitle = \"Intervalos de confiança de 95% para diferenças\",\n       x = \"Comparação\",\n       y = \"Diferença entre médias\") +\n  theme_classic(base_size = 14) +\n  theme(\n    plot.title = element_text(color = \"#224573\", face = \"bold\"))"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#visualização-dos-testes-post-hoccont",
    "href": "apresentações/posts/estatistica_basica.html#visualização-dos-testes-post-hoccont",
    "title": "8. Estatística com R",
    "section": "Visualização dos testes post-hoc(cont)",
    "text": "Visualização dos testes post-hoc(cont)\n\nteste"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#anova-com-concentração-como-fator",
    "href": "apresentações/posts/estatistica_basica.html#anova-com-concentração-como-fator",
    "title": "8. Estatística com R",
    "section": "ANOVA com concentração como fator",
    "text": "ANOVA com concentração como fator\n\n# Converter concentração em fator\nCO2$conc_factor &lt;- as.factor(CO2$conc)\n\n# ANOVA: efeito da concentração\nanova_conc &lt;- aov(uptake ~ conc_factor, data = CO2)\nsummary(anova_conc)\n\n            Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nconc_factor  6   4069   678.1   9.261 1.24e-07 ***\nResiduals   77   5638    73.2                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#post-hoc-para-concentração",
    "href": "apresentações/posts/estatistica_basica.html#post-hoc-para-concentração",
    "title": "8. Estatística com R",
    "section": "Post-hoc para concentração",
    "text": "Post-hoc para concentração\n\n# Teste post-hoc\nTukeyHSD(anova_conc)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = uptake ~ conc_factor, data = CO2)\n\n$conc_factor\n               diff         lwr      upr     p adj\n175-95   10.0250000  -0.5518604 20.60186 0.0747914\n250-95   16.6166667   6.0398062 27.19353 0.0001775\n350-95   18.4083333   7.8314729 28.98519 0.0000244\n500-95   18.6166667   8.0398062 29.19353 0.0000193\n675-95   19.6916667   9.1148062 30.26853 0.0000056\n1000-95  21.3250000  10.7481396 31.90186 0.0000008\n250-175   6.5916667  -3.9851938 17.16853 0.4951218\n350-175   8.3833333  -2.1935271 18.96019 0.2128727\n500-175   8.5916667  -1.9851938 19.16853 0.1889506\n675-175   9.6666667  -0.9101938 20.24353 0.0958771\n1000-175 11.3000000   0.7231396 21.87686 0.0284907\n350-250   1.7916667  -8.7851938 12.36853 0.9986002\n500-250   2.0000000  -8.5768604 12.57686 0.9974074\n675-250   3.0750000  -7.5018604 13.65186 0.9744940\n1000-250  4.7083333  -5.8685271 15.28519 0.8270400\n500-350   0.2083333 -10.3685271 10.78519 1.0000000\n675-350   1.2833333  -9.2935271 11.86019 0.9997937\n1000-350  2.9166667  -7.6601938 13.49353 0.9804667\n675-500   1.0750000  -9.5018604 11.65186 0.9999267\n1000-500  2.7083333  -7.8685271 13.28519 0.9866675\n1000-675  1.6333333  -8.9435271 12.21019 0.9991720"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#análise-de-regressão-linear",
    "href": "apresentações/posts/estatistica_basica.html#análise-de-regressão-linear",
    "title": "8. Estatística com R",
    "section": "Análise de regressão linear",
    "text": "Análise de regressão linear\nAlternativa: tratar concentração como variável contínua\n\n# Modelo de regressão linear\nmodelo_linear &lt;- lm(uptake ~ conc, data = CO2)\nsummary(modelo_linear)\n\n\nCall:\nlm(formula = uptake ~ conc, data = CO2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-22.831  -7.729   1.483   7.748  16.394 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 19.500290   1.853080  10.523  &lt; 2e-16 ***\nconc         0.017731   0.003529   5.024 2.91e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.514 on 82 degrees of freedom\nMultiple R-squared:  0.2354,    Adjusted R-squared:  0.2261 \nF-statistic: 25.25 on 1 and 82 DF,  p-value: 2.906e-06"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#gráfico-com-linha-de-regressão",
    "href": "apresentações/posts/estatistica_basica.html#gráfico-com-linha-de-regressão",
    "title": "8. Estatística com R",
    "section": "Gráfico com linha de regressão",
    "text": "Gráfico com linha de regressão\n\nreg1 &lt;- ggplot(CO2, aes(x = conc, y = uptake)) +\n  geom_point(aes(color = Type), \n             size = 2.5, \n             alpha = 0.6) +\n  geom_smooth(method = \"lm\", \n              color = \"#224573\",\n              linewidth = 1.2,\n              se = TRUE,\n              fill = \"#E5D3B3\") +\n  scale_color_manual(values = c(\"#224573\", \"#6B4F4F\")) +\n  labs(title = \"Regressão linear: concentração x absorção\",\n       x = \"Concentração de CO2 (mL/L)\",\n       y = \"Absorção de CO2 (μmol/m²s)\",\n       color = \"Origem\") +\n  theme_classic(base_size = 14) +\n  theme(\n    plot.title = element_text(color = \"#224573\", face = \"bold\"),\n    legend.position = \"bottom\")"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#gráfico-com-linha-de-regressãocont",
    "href": "apresentações/posts/estatistica_basica.html#gráfico-com-linha-de-regressãocont",
    "title": "8. Estatística com R",
    "section": "Gráfico com linha de regressão(cont)",
    "text": "Gráfico com linha de regressão(cont)\n\nreg1"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#diagnóstico-do-modelo-linear",
    "href": "apresentações/posts/estatistica_basica.html#diagnóstico-do-modelo-linear",
    "title": "8. Estatística com R",
    "section": "Diagnóstico do modelo linear",
    "text": "Diagnóstico do modelo linear\n\n# Extrair resíduos e valores ajustados\nresiduos_lm &lt;- residuals(modelo_linear)\najustados_lm &lt;- fitted(modelo_linear)"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#diagnóstico-do-modelo-linearcont",
    "href": "apresentações/posts/estatistica_basica.html#diagnóstico-do-modelo-linearcont",
    "title": "8. Estatística com R",
    "section": "Diagnóstico do modelo linear(cont)",
    "text": "Diagnóstico do modelo linear(cont)\n\n# Criar dataframe para diagnóstico\ndiag_df &lt;- data.frame(\n  residuos = residuos_lm,\n  ajustados = ajustados_lm,\n  padronizados = rstandard(modelo_linear))\n\nhead(diag_df)\n\n   residuos ajustados padronizados\n1 -5.184696  21.18470   -0.5527064\n2  7.796857  22.60314    0.8283632\n3 10.867063  23.93294    1.1518530\n4 11.494005  25.70600    1.2160110\n5  6.934417  28.36558    0.7334750\n6  7.731564  31.46844    0.8208495"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#gráfico-de-resíduos-do-modelo-linear",
    "href": "apresentações/posts/estatistica_basica.html#gráfico-de-resíduos-do-modelo-linear",
    "title": "8. Estatística com R",
    "section": "Gráfico de resíduos do modelo linear",
    "text": "Gráfico de resíduos do modelo linear\n\nmod_linear &lt;- ggplot(diag_df, aes(x = ajustados, y = residuos)) +\n  geom_point(color = \"#4A6FA5\", size = 2, alpha = 0.6) +\n  geom_hline(yintercept = 0, \n             color = \"#224573\", \n             linetype = \"dashed\",\n             linewidth = 1) +\n  geom_smooth(se = FALSE, \n              color = \"#6B4F4F\",\n              linewidth = 1) +\n  labs(title = \"Diagnóstico de resíduos: modelo linear\",\n       x = \"Valores ajustados\",\n       y = \"Resíduos\") +\n  theme_classic(base_size = 14) +\n  theme(\n    plot.title = element_text(color = \"#224573\", face = \"bold\"))"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#gráfico-de-resíduos-do-modelo-linearcont",
    "href": "apresentações/posts/estatistica_basica.html#gráfico-de-resíduos-do-modelo-linearcont",
    "title": "8. Estatística com R",
    "section": "Gráfico de resíduos do modelo linear(cont)",
    "text": "Gráfico de resíduos do modelo linear(cont)\n\nmod_linear"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#modelo-não-linear-polinomial",
    "href": "apresentações/posts/estatistica_basica.html#modelo-não-linear-polinomial",
    "title": "8. Estatística com R",
    "section": "Modelo não-linear: polinomial",
    "text": "Modelo não-linear: polinomial\n\n# Ajustar modelo polinomial de grau 2\nmodelo_poly &lt;- lm(uptake ~ poly(conc, 2), data = CO2)\nsummary(modelo_poly)\n\n\nCall:\nlm(formula = uptake ~ poly(conc, 2), data = CO2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-21.4051  -5.9844  -0.0679   6.3711  15.8080 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     27.2131     0.9664  28.160  &lt; 2e-16 ***\npoly(conc, 2)1  47.8016     8.8569   5.397 6.58e-07 ***\npoly(conc, 2)2 -32.6790     8.8569  -3.690 0.000405 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.857 on 81 degrees of freedom\nMultiple R-squared:  0.3454,    Adjusted R-squared:  0.3292 \nF-statistic: 21.37 on 2 and 81 DF,  p-value: 3.521e-08"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#comparação-de-modelos",
    "href": "apresentações/posts/estatistica_basica.html#comparação-de-modelos",
    "title": "8. Estatística com R",
    "section": "Comparação de modelos",
    "text": "Comparação de modelos\n\n# Comparar modelos\nanova(modelo_linear, modelo_poly)\n\nAnalysis of Variance Table\n\nModel 1: uptake ~ conc\nModel 2: uptake ~ poly(conc, 2)\n  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    \n1     82 7422.0                                  \n2     81 6354.1  1    1067.9 13.614 0.0004054 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#preparando-predições-para-visualização",
    "href": "apresentações/posts/estatistica_basica.html#preparando-predições-para-visualização",
    "title": "8. Estatística com R",
    "section": "Preparando predições para visualização",
    "text": "Preparando predições para visualização\n\n# Criar predições para visualização\npred_df &lt;- data.frame(\n  conc = seq(min(CO2$conc), max(CO2$conc), length.out = 100))\npred_df$pred_linear &lt;- predict(modelo_linear, pred_df)\npred_df$pred_poly &lt;- predict(modelo_poly, pred_df)"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#preparando-predições-para-visualizaçãocont",
    "href": "apresentações/posts/estatistica_basica.html#preparando-predições-para-visualizaçãocont",
    "title": "8. Estatística com R",
    "section": "Preparando predições para visualização(cont)",
    "text": "Preparando predições para visualização(cont)\n\nhead(pred_df)\n\n      conc pred_linear pred_poly\n1  95.0000    21.18470  16.56952\n2 104.1414    21.34678  17.09685\n3 113.2828    21.50886  17.61666\n4 122.4242    21.67094  18.12893\n5 131.5657    21.83303  18.63366\n6 140.7071    21.99511  19.13087"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#visualização-comparação-de-modelos",
    "href": "apresentações/posts/estatistica_basica.html#visualização-comparação-de-modelos",
    "title": "8. Estatística com R",
    "section": "Visualização: comparação de modelos",
    "text": "Visualização: comparação de modelos\n\ncomparacao_modelos &lt;- ggplot(CO2, aes(x = conc, y = uptake)) +\n  geom_point(color = \"#4A6FA5\", size = 2, alpha = 0.5) +\n  geom_line(data = pred_df, \n            aes(y = pred_linear, color = \"Linear\"),\n            linewidth = 1.2) +\n  geom_line(data = pred_df, \n            aes(y = pred_poly, color = \"Polinomial\"),\n            linewidth = 1.2) +\n  scale_color_manual(values = c(\"Linear\" = \"#224573\", \n                                 \"Polinomial\" = \"#6B4F4F\")) +\n  labs(title = \"Comparação de modelos de regressão\",\n       x = \"Concentração de CO2 (mL/L)\",\n       y = \"Absorção de CO2 (μmol/m²s)\",\n       color = \"Modelo\") +\n  theme_classic(base_size = 14) +\n  theme(\n    plot.title = element_text(color = \"#224573\", face = \"bold\"),\n    legend.position = \"bottom\")"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#visualização-comparação-de-modeloscont",
    "href": "apresentações/posts/estatistica_basica.html#visualização-comparação-de-modeloscont",
    "title": "8. Estatística com R",
    "section": "Visualização: comparação de modelos(cont)",
    "text": "Visualização: comparação de modelos(cont)\n\ncomparacao_modelos"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#anova-de-medidas-repetidas",
    "href": "apresentações/posts/estatistica_basica.html#anova-de-medidas-repetidas",
    "title": "8. Estatística com R",
    "section": "ANOVA de medidas repetidas",
    "text": "ANOVA de medidas repetidas\nContexto: cada planta foi medida em 7 concentrações diferentes\nEstrutura dos dados:\n\nMedidas repetidas no mesmo sujeito (planta)\nViolação da independência\nNecessidade de ANOVA de medidas repetidas"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#modelo-misto",
    "href": "apresentações/posts/estatistica_basica.html#modelo-misto",
    "title": "8. Estatística com R",
    "section": "Modelo misto",
    "text": "Modelo misto\n\n# Preparar dados para análise\nlibrary(nlme)\n\n# Modelo misto com planta como efeito aleatório\nmodelo_misto &lt;- lme(uptake ~ Type * Treatment * conc,\n                    random = ~1|Plant,\n                    data = CO2)"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#modelo-mistocont",
    "href": "apresentações/posts/estatistica_basica.html#modelo-mistocont",
    "title": "8. Estatística com R",
    "section": "Modelo misto(cont)",
    "text": "Modelo misto(cont)\n\nsummary(modelo_misto)\n\nLinear mixed-effects model fit by REML\n  Data: CO2 \n      AIC      BIC   logLik\n  572.408 595.7153 -276.204\n\nRandom effects:\n Formula: ~1 | Plant\n        (Intercept) Residual\nStdDev:   0.5417416 5.770575\n\nFixed effects:  uptake ~ Type * Treatment * conc \n                                          Value Std.Error DF   t-value p-value\n(Intercept)                           25.585034  2.269624 68 11.272809  0.0000\nTypeMississippi                       -7.131741  3.209733  8 -2.221911  0.0570\nTreatmentchilled                      -4.163993  3.209733  8 -1.297302  0.2307\nconc                                   0.022410  0.004281 68  5.234918  0.0000\nTypeMississippi:Treatmentchilled      -1.747509  4.539247  8 -0.384978  0.7103\nTypeMississippi:conc                  -0.005171  0.006054 68 -0.854076  0.3961\nTreatmentchilled:conc                  0.001340  0.006054 68  0.221393  0.8254\nTypeMississippi:Treatmentchilled:conc -0.011057  0.008562 68 -1.291407  0.2009\n Correlation: \n                                      (Intr) TypMss Trtmnt conc   TypM:T TypMs:\nTypeMississippi                       -0.707                                   \nTreatmentchilled                      -0.707  0.500                            \nconc                                  -0.820  0.580  0.580                     \nTypeMississippi:Treatmentchilled       0.500 -0.707 -0.707 -0.410              \nTypeMississippi:conc                   0.580 -0.820 -0.410 -0.707  0.580       \nTreatmentchilled:conc                  0.580 -0.410 -0.820 -0.707  0.580  0.500\nTypeMississippi:Treatmentchilled:conc -0.410  0.580  0.580  0.500 -0.820 -0.707\n                                      Trtmn:\nTypeMississippi                             \nTreatmentchilled                            \nconc                                        \nTypeMississippi:Treatmentchilled            \nTypeMississippi:conc                        \nTreatmentchilled:conc                       \nTypeMississippi:Treatmentchilled:conc -0.707\n\nStandardized Within-Group Residuals:\n       Min         Q1        Med         Q3        Max \n-2.5010289 -0.4922569  0.1597821  0.6500850  1.8530185 \n\nNumber of Observations: 84\nNumber of Groups: 12"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#anova-do-modelo-misto",
    "href": "apresentações/posts/estatistica_basica.html#anova-do-modelo-misto",
    "title": "8. Estatística com R",
    "section": "ANOVA do modelo misto",
    "text": "ANOVA do modelo misto\n\n# ANOVA do modelo misto\nanova(modelo_misto)\n\n                    numDF denDF   F-value p-value\n(Intercept)             1    68 1759.5333  &lt;.0001\nType                    1     8   95.1955  &lt;.0001\nTreatment               1     8   27.9492  0.0007\nconc                    1    68   68.6194  &lt;.0001\nType:Treatment          1     8    6.3849  0.0354\nType:conc               1    68    6.2463  0.0149\nTreatment:conc          1    68    0.9571  0.3314\nType:Treatment:conc     1    68    1.6677  0.2009"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#intervalos-de-confiança",
    "href": "apresentações/posts/estatistica_basica.html#intervalos-de-confiança",
    "title": "8. Estatística com R",
    "section": "Intervalos de confiança",
    "text": "Intervalos de confiança\n\n# Intervalos de confiança\nintervals(modelo_misto)\n\nApproximate 95% confidence intervals\n\n Fixed effects:\n                                             lower         est.        upper\n(Intercept)                            21.05607021 25.585033845 30.113997476\nTypeMississippi                       -14.53339750 -7.131740725  0.269916049\nTreatmentchilled                      -11.56564944 -4.163992665  3.237664109\nconc                                    0.01386759  0.022409884  0.030952181\nTypeMississippi:Treatmentchilled      -12.21503277 -1.747509375  8.720014018\nTypeMississippi:conc                   -0.01725123 -0.005170602  0.006910031\nTreatmentchilled:conc                  -0.01074031  0.001340322  0.013420955\nTypeMississippi:Treatmentchilled:conc  -0.02814122 -0.011056629  0.006027966\n\n Random Effects:\n  Level: Plant \n                       lower      est.    upper\nsd((Intercept)) 9.464014e-06 0.5417416 31010.51\n\n Within-group standard error:\n   lower     est.    upper \n4.857472 5.770575 6.855323"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#correlação-intra-planta",
    "href": "apresentações/posts/estatistica_basica.html#correlação-intra-planta",
    "title": "8. Estatística com R",
    "section": "Correlação intra-planta",
    "text": "Correlação intra-planta\n\n# Verificar correlação intra-planta\nVarCorr(modelo_misto)\n\nPlant = pdLogChol(1) \n            Variance   StdDev   \n(Intercept)  0.2934839 0.5417416\nResidual    33.2995415 5.7705755"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#correlação-entre-variáveis",
    "href": "apresentações/posts/estatistica_basica.html#correlação-entre-variáveis",
    "title": "8. Estatística com R",
    "section": "Correlação entre variáveis",
    "text": "Correlação entre variáveis\n\n# Matriz de correlação\ncor_matrix &lt;- cor(CO2[, c(\"conc\", \"uptake\")])\ncor_matrix\n\n            conc    uptake\nconc   1.0000000 0.4851774\nuptake 0.4851774 1.0000000"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#correlação-entre-variáveiscont",
    "href": "apresentações/posts/estatistica_basica.html#correlação-entre-variáveiscont",
    "title": "8. Estatística com R",
    "section": "Correlação entre variáveis(cont)",
    "text": "Correlação entre variáveis(cont)\n\n# Teste de correlação\ncor.test(CO2$conc, CO2$uptake)\n\n\n    Pearson's product-moment correlation\n\ndata:  CO2$conc and CO2$uptake\nt = 5.0245, df = 82, p-value = 2.906e-06\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.3022189 0.6336595\nsample estimates:\n      cor \n0.4851774"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#visualização-da-correlação",
    "href": "apresentações/posts/estatistica_basica.html#visualização-da-correlação",
    "title": "8. Estatística com R",
    "section": "Visualização da correlação",
    "text": "Visualização da correlação\n\nlibrary(corrplot)\ncorrplot(cor_matrix, \n         method = \"color\",\n         col = colorRampPalette(c(\"#E5D3B3\", \"#4A6FA5\", \"#224573\"))(100),\n         addCoef.col = \"black\",\n         tl.col = \"#224573\",\n         tl.srt = 45)"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#calculando-coeficientes-de-correlação",
    "href": "apresentações/posts/estatistica_basica.html#calculando-coeficientes-de-correlação",
    "title": "8. Estatística com R",
    "section": "Calculando coeficientes de correlação",
    "text": "Calculando coeficientes de correlação\n\n# Calcular coeficiente de correlação\nr_value &lt;- cor(CO2$conc, CO2$uptake)\nr_squared &lt;- r_value^2\n\ndata.frame(\n  r = r_value,\n  r_squared = r_squared)\n\n          r r_squared\n1 0.4851774 0.2353971"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#gráfico-de-dispersão-com-correlação",
    "href": "apresentações/posts/estatistica_basica.html#gráfico-de-dispersão-com-correlação",
    "title": "8. Estatística com R",
    "section": "Gráfico de dispersão com correlação",
    "text": "Gráfico de dispersão com correlação\n\ndisp_cor &lt;- ggplot(CO2, aes(x = conc, y = uptake)) +\n  geom_point(aes(color = Type, shape = Treatment),\n             size = 3, alpha = 0.7) +\n  geom_smooth(method = \"lm\", \n              color = \"#224573\",\n              fill = \"#E5D3B3\") +\n  scale_color_manual(values = c(\"#224573\", \"#6B4F4F\")) +\n  annotate(\"text\", \n           x = max(CO2$conc) * 0.7, \n           y = min(CO2$uptake) * 1.2,\n           label = paste(\"r =\", round(r_value, 3), \n                        \"\\nR² =\", round(r_squared, 3)),\n           color = \"#224573\", \n           size = 5) +\n  labs(title = \"Correlação: concentração x absorção\",\n       x = \"Concentração de CO2 (mL/L)\",\n       y = \"Absorção de CO2 (μmol/m²s)\",\n       color = \"Origem\",\n       shape = \"Tratamento\") +\n  theme_classic(base_size = 14) +\n  theme(\n    plot.title = element_text(color = \"#224573\", face = \"bold\"),\n    legend.position = \"right\")"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#gráfico-de-dispersão-com-correlaçãocont",
    "href": "apresentações/posts/estatistica_basica.html#gráfico-de-dispersão-com-correlaçãocont",
    "title": "8. Estatística com R",
    "section": "Gráfico de dispersão com correlação(cont)",
    "text": "Gráfico de dispersão com correlação(cont)\n\ndisp_cor"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#análise-de-clusters",
    "href": "apresentações/posts/estatistica_basica.html#análise-de-clusters",
    "title": "8. Estatística com R",
    "section": "Análise de clusters",
    "text": "Análise de clusters\n\n# Preparar dados para clustering\ndados_cluster &lt;- CO2 %&gt;%\n  select(conc, uptake) %&gt;%\n  scale()\n\n# K-means clustering\nset.seed(123)\nkmeans_result &lt;- kmeans(dados_cluster, centers = 3)\n\n# Adicionar clusters ao dataset\nCO2$cluster &lt;- as.factor(kmeans_result$cluster)\n\n# Ver centros dos clusters\nkmeans_result$centers\n\n        conc     uptake\n1  1.3840211  0.5901899\n2 -0.7361121 -1.1022108\n3 -0.3144878  0.6287728"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#visualização-de-clusters",
    "href": "apresentações/posts/estatistica_basica.html#visualização-de-clusters",
    "title": "8. Estatística com R",
    "section": "Visualização de clusters",
    "text": "Visualização de clusters\n\ncluster &lt;- ggplot(CO2, aes(x = conc, y = uptake, color = cluster)) +\n  geom_point(size = 3, alpha = 0.7) +\n  scale_color_manual(values = c(\"#224573\", \"#6B4F4F\", \"#4A6FA5\")) +\n  labs(title = \"Análise de clusters K-means\",\n       subtitle = \"Agrupamento baseado em concentração e absorção\",\n       x = \"Concentração de CO2 (mL/L)\",\n       y = \"Absorção de CO2 (μmol/m²s)\",\n       color = \"Cluster\") +\n  theme_classic(base_size = 14) +\n  theme(\n    plot.title = element_text(color = \"#224573\", face = \"bold\"),\n    legend.position = \"bottom\")"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#visualização-de-clusterscont",
    "href": "apresentações/posts/estatistica_basica.html#visualização-de-clusterscont",
    "title": "8. Estatística com R",
    "section": "Visualização de clusters(cont)",
    "text": "Visualização de clusters(cont)\n\ncluster"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#gráfico-de-perfis-individuais",
    "href": "apresentações/posts/estatistica_basica.html#gráfico-de-perfis-individuais",
    "title": "8. Estatística com R",
    "section": "Gráfico de perfis individuais",
    "text": "Gráfico de perfis individuais\n\nperfis &lt;- ggplot(CO2, aes(x = conc, y = uptake, group = Plant)) +\n  geom_line(aes(color = Type), alpha = 0.5, linewidth = 0.8) +\n  geom_point(aes(color = Type), size = 1.5, alpha = 0.6) +\n  facet_wrap(~Treatment, labeller = labeller(\n    Treatment = c(\"nonchilled\" = \"Não resfriada\",\n                  \"chilled\" = \"Resfriada\"))) +\n  scale_color_manual(values = c(\"#224573\", \"#6B4F4F\"),\n                     labels = c(\"Quebec\", \"Mississippi\")) +\n  labs(title = \"Perfis de absorção por planta individual\",\n       x = \"Concentração de CO2 (mL/L)\",\n       y = \"Absorção de CO2 (μmol/m²s)\",\n       color = \"Origem\") +\n  theme_classic(base_size = 14) +\n  theme(\n    plot.title = element_text(color = \"#224573\", face = \"bold\"),\n    strip.background = element_rect(fill = \"#E5D3B3\", color = NA),\n    strip.text = element_text(color = \"#224573\", face = \"bold\"),\n    legend.position = \"bottom\")"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#gráfico-de-perfis-individuaiscont",
    "href": "apresentações/posts/estatistica_basica.html#gráfico-de-perfis-individuaiscont",
    "title": "8. Estatística com R",
    "section": "Gráfico de perfis individuais(cont)",
    "text": "Gráfico de perfis individuais(cont)\n\nperfis"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#preparando-dados-para-heatmap",
    "href": "apresentações/posts/estatistica_basica.html#preparando-dados-para-heatmap",
    "title": "8. Estatística com R",
    "section": "Preparando dados para heatmap",
    "text": "Preparando dados para heatmap\n\n# Calcular médias por grupo\nheatmap_data &lt;- CO2 %&gt;%\n  group_by(Type, Treatment, conc) %&gt;%\n  summarise(Media_uptake = mean(uptake), .groups = \"drop\")\n\nhead(heatmap_data)\n\n# A tibble: 6 × 4\n  Type   Treatment   conc Media_uptake\n  &lt;fct&gt;  &lt;fct&gt;      &lt;dbl&gt;        &lt;dbl&gt;\n1 Quebec nonchilled    95         15.3\n2 Quebec nonchilled   175         30.0\n3 Quebec nonchilled   250         37.4\n4 Quebec nonchilled   350         40.4\n5 Quebec nonchilled   500         39.6\n6 Quebec nonchilled   675         41.5"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#heatmap-de-médias",
    "href": "apresentações/posts/estatistica_basica.html#heatmap-de-médias",
    "title": "8. Estatística com R",
    "section": "Heatmap de médias",
    "text": "Heatmap de médias\n\nheatmap_media &lt;- ggplot(heatmap_data, aes(x = factor(conc), y = interaction(Type, Treatment),\n                         fill = Media_uptake)) +\n  geom_tile(color = \"white\", linewidth = 1) +\n  scale_fill_gradient2(low = \"#E5D3B3\", \n                       mid = \"#4A6FA5\", \n                       high = \"#224573\",\n                       midpoint = median(heatmap_data$Media_uptake)) +\n  geom_text(aes(label = round(Media_uptake, 1)), \n            color = \"white\", \n            size = 3,\n            fontface = \"bold\") +\n  labs(title = \"Heatmap: absorção média de CO2\",\n       x = \"Concentração de CO2 (mL/L)\",\n       y = \"Grupo (Origem.Tratamento)\",\n       fill = \"Absorção\\nmédia\") +\n  theme_classic(base_size = 14) +\n  theme(\n    plot.title = element_text(color = \"#224573\", face = \"bold\"),\n    axis.text.x = element_text(angle = 45, hjust = 1))"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#heatmap-de-médiascont",
    "href": "apresentações/posts/estatistica_basica.html#heatmap-de-médiascont",
    "title": "8. Estatística com R",
    "section": "Heatmap de médias(cont)",
    "text": "Heatmap de médias(cont)\n\nheatmap_media"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#preparando-estatísticas-para-gráfico-de-barras",
    "href": "apresentações/posts/estatistica_basica.html#preparando-estatísticas-para-gráfico-de-barras",
    "title": "8. Estatística com R",
    "section": "Preparando estatísticas para gráfico de barras",
    "text": "Preparando estatísticas para gráfico de barras\n\n# Calcular estatísticas\nstats_plot &lt;- CO2 %&gt;%\n  group_by(Type, Treatment) %&gt;%\n  summarise(\n    Media = mean(uptake),\n    EP = sd(uptake) / sqrt(n()),\n    .groups = \"drop\")\n\nstats_plot\n\n# A tibble: 4 × 4\n  Type        Treatment  Media    EP\n  &lt;fct&gt;       &lt;fct&gt;      &lt;dbl&gt; &lt;dbl&gt;\n1 Quebec      nonchilled  35.3 2.09 \n2 Quebec      chilled     31.8 2.10 \n3 Mississippi nonchilled  26.0 1.62 \n4 Mississippi chilled     15.8 0.886"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#gráfico-de-barras-com-erro-padrão",
    "href": "apresentações/posts/estatistica_basica.html#gráfico-de-barras-com-erro-padrão",
    "title": "8. Estatística com R",
    "section": "Gráfico de barras com erro padrão",
    "text": "Gráfico de barras com erro padrão\n\nbarras &lt;- ggplot(stats_plot, aes(x = Type, y = Media, fill = Treatment)) +\n  geom_col(position = position_dodge(width = 0.8),\n           alpha = 0.8,\n           color = \"#224573\") +\n  geom_errorbar(aes(ymin = Media - EP, ymax = Media + EP),\n                position = position_dodge(width = 0.8),\n                width = 0.25,\n                linewidth = 1) +\n  scale_fill_manual(values = c(\"#4A6FA5\", \"#E5D3B3\"),\n                    labels = c(\"Não resfriada\", \"Resfriada\")) +\n  labs(title = \"Absorção média por origem e tratamento\",\n       subtitle = \"Barras de erro: erro padrão da média\",\n       x = \"Origem da planta\",\n       y = \"Absorção média de CO2 (μmol/m²s)\",\n       fill = \"Tratamento\") +\n  theme_classic(base_size = 14) +\n  theme(\n    plot.title = element_text(color = \"#224573\", face = \"bold\"),\n    legend.position = \"bottom\")"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#gráfico-de-barras-com-erro-padrãocont",
    "href": "apresentações/posts/estatistica_basica.html#gráfico-de-barras-com-erro-padrãocont",
    "title": "8. Estatística com R",
    "section": "Gráfico de barras com erro padrão(cont)",
    "text": "Gráfico de barras com erro padrão(cont)\n\nbarras"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#gráfico-de-densidade-por-grupo",
    "href": "apresentações/posts/estatistica_basica.html#gráfico-de-densidade-por-grupo",
    "title": "8. Estatística com R",
    "section": "Gráfico de densidade por grupo",
    "text": "Gráfico de densidade por grupo\n\ndensidade &lt;- ggplot(CO2, aes(x = uptake, fill = interaction(Type, Treatment))) +\n  geom_density(alpha = 0.5) +\n  scale_fill_manual(values = c(\"#224573\", \"#4A6FA5\", \"#6B4F4F\", \"#E5D3B3\"),\n                    labels = c(\"Quebec.Não resfriada\",\n                              \"Quebec.Resfriada\",\n                              \"Mississippi.Não resfriada\",\n                              \"Mississippi.Resfriada\")) +\n  labs(title = \"Distribuição de densidade por grupo\",\n       x = \"Absorção de CO2 (μmol/m²s)\",\n       y = \"Densidade\",\n       fill = \"Grupo\") +\n  theme_classic(base_size = 14) +\n  theme(\n    plot.title = element_text(color = \"#224573\", face = \"bold\"),\n    legend.position = \"bottom\",\n    legend.text = element_text(size = 10))"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#gráfico-de-densidade-por-grupocont",
    "href": "apresentações/posts/estatistica_basica.html#gráfico-de-densidade-por-grupocont",
    "title": "8. Estatística com R",
    "section": "Gráfico de densidade por grupo(cont)",
    "text": "Gráfico de densidade por grupo(cont)\n\ndensidade"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#painel-de-diagnóstico-completo",
    "href": "apresentações/posts/estatistica_basica.html#painel-de-diagnóstico-completo",
    "title": "8. Estatística com R",
    "section": "Painel de diagnóstico completo",
    "text": "Painel de diagnóstico completo\n\npar(mfrow = c(2, 2))\nplot(anova_completa, col = \"#4A6FA5\", pch = 19)\n\npar(mfrow = c(1, 1))"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#estrutura-de-um-relatório-estatístico",
    "href": "apresentações/posts/estatistica_basica.html#estrutura-de-um-relatório-estatístico",
    "title": "8. Estatística com R",
    "section": "Estrutura de um relatório estatístico",
    "text": "Estrutura de um relatório estatístico\nComponentes essenciais:\n\nIntrodução\n\nContexto do estudo\nObjetivos\nHipóteses\n\nMétodos\n\nDescrição dos dados\nAnálises estatísticas aplicadas\nSoftware utilizado"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#estrutura-de-um-relatório-estatísticocont",
    "href": "apresentações/posts/estatistica_basica.html#estrutura-de-um-relatório-estatísticocont",
    "title": "8. Estatística com R",
    "section": "Estrutura de um relatório estatístico(cont)",
    "text": "Estrutura de um relatório estatístico(cont)\n\nResultados\n\nEstatísticas descritivas\nTestes estatísticos\nTabelas e gráficos\n\nDiscussão e conclusões"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#criando-tabela-de-estatísticas-descritivas",
    "href": "apresentações/posts/estatistica_basica.html#criando-tabela-de-estatísticas-descritivas",
    "title": "8. Estatística com R",
    "section": "Criando tabela de estatísticas descritivas",
    "text": "Criando tabela de estatísticas descritivas\n\nlibrary(knitr)\n\n# Criar tabela formatada\ntabela_descritiva &lt;- CO2 %&gt;%\n  group_by(Type, Treatment) %&gt;%\n  summarise(\n    n = n(),\n    Media = mean(uptake),\n    DP = sd(uptake),\n    Mediana = median(uptake),\n    Min = min(uptake),\n    Max = max(uptake),\n    .groups = \"drop\")"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#criando-tabela-de-estatísticas-descritivascont",
    "href": "apresentações/posts/estatistica_basica.html#criando-tabela-de-estatísticas-descritivascont",
    "title": "8. Estatística com R",
    "section": "Criando tabela de estatísticas descritivas(cont)",
    "text": "Criando tabela de estatísticas descritivas(cont)\n\nkable(tabela_descritiva, \n      digits = 2,\n      caption = \"Estatísticas descritivas da absorção de CO2\",\n      col.names = c(\"Origem\", \"Tratamento\", \"n\", \n                    \"Média\", \"DP\", \"Mediana\", \"Mín\", \"Máx\"))\n\n\nEstatísticas descritivas da absorção de CO2\n\n\nOrigem\nTratamento\nn\nMédia\nDP\nMediana\nMín\nMáx\n\n\n\n\nQuebec\nnonchilled\n21\n35.33\n9.60\n39.2\n13.6\n45.5\n\n\nQuebec\nchilled\n21\n31.75\n9.64\n35.0\n9.3\n42.4\n\n\nMississippi\nnonchilled\n21\n25.95\n7.40\n28.1\n10.6\n35.5\n\n\nMississippi\nchilled\n21\n15.81\n4.06\n17.9\n7.7\n22.2"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#tabela-de-resultados-anova",
    "href": "apresentações/posts/estatistica_basica.html#tabela-de-resultados-anova",
    "title": "8. Estatística com R",
    "section": "Tabela de resultados ANOVA",
    "text": "Tabela de resultados ANOVA\n\n# Extrair resultados ANOVA\nanova_table &lt;- as.data.frame(summary(anova_completa)[[1]])\nanova_table$Fator &lt;- rownames(anova_table)"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#tabela-de-resultados-anovacont",
    "href": "apresentações/posts/estatistica_basica.html#tabela-de-resultados-anovacont",
    "title": "8. Estatística com R",
    "section": "Tabela de resultados ANOVA(cont)",
    "text": "Tabela de resultados ANOVA(cont)\n\n# Formatar tabela\nkable(anova_table[, c(\"Fator\", \"Df\", \"Sum Sq\", \"Mean Sq\", \n                      \"F value\", \"Pr(&gt;F)\")],\n      digits = c(0, 0, 2, 2, 2, 4),\n      caption = \"Tabela ANOVA: efeitos de origem e tratamento\",\n      col.names = c(\"Fator\", \"GL\", \"SQ\", \"QM\", \"F\", \"p-valor\"))\n\n\nTabela ANOVA: efeitos de origem e tratamento\n\n\n\nFator\nGL\nSQ\nQM\nF\np-valor\n\n\n\n\nType\nType\n1\n3365.53\n3365.53\n52.51\n0.0000\n\n\nTreatment\nTreatment\n1\n988.11\n988.11\n15.42\n0.0002\n\n\nType:Treatment\nType:Treatment\n1\n225.73\n225.73\n3.52\n0.0642\n\n\nResiduals\nResiduals\n80\n5127.60\n64.09\nNA\nNA"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#interpretação-dos-resultados",
    "href": "apresentações/posts/estatistica_basica.html#interpretação-dos-resultados",
    "title": "8. Estatística com R",
    "section": "Interpretação dos resultados",
    "text": "Interpretação dos resultados\nPrincipais achados:\n\nEfeito da origem (Type):\n\nF(1,80) = 48.98, p &lt; 0.001\nPlantas de Quebec apresentam absorção significativamente maior que plantas de Mississippi\n\nEfeito do tratamento:\n\nF(1,80) = 14.38, p &lt; 0.001\nTratamento de resfriamento reduz significativamente a absorção"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#interpretação-dos-resultadoscont",
    "href": "apresentações/posts/estatistica_basica.html#interpretação-dos-resultadoscont",
    "title": "8. Estatística com R",
    "section": "Interpretação dos resultados(cont)",
    "text": "Interpretação dos resultados(cont)\n\nInteração:\n\nF(1,80) = 3.29, p = 0.073\nInteração marginalmente não significativa"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#exemplo-de-redação-de-resultados",
    "href": "apresentações/posts/estatistica_basica.html#exemplo-de-redação-de-resultados",
    "title": "8. Estatística com R",
    "section": "Exemplo de redação de resultados",
    "text": "Exemplo de redação de resultados\n“Foi realizada uma ANOVA two-way para avaliar os efeitos da origem (Quebec vs. Mississippi) e tratamento (resfriado vs. não resfriado) na absorção de CO2. Os pressupostos de normalidade e homocedasticidade foram verificados através do teste de Shapiro-Wilk (W = 0.98, p = 0.23) e teste de Levene (F = 1.85, p = 0.14), respectivamente."
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#exemplo-de-redação-de-resultadoscont",
    "href": "apresentações/posts/estatistica_basica.html#exemplo-de-redação-de-resultadoscont",
    "title": "8. Estatística com R",
    "section": "Exemplo de redação de resultados(cont)",
    "text": "Exemplo de redação de resultados(cont)\nOs resultados indicaram efeito principal significativo da origem (F(1,80) = 48.98, p &lt; 0.001, η² = 0.38) e do tratamento (F(1,80) = 14.38, p &lt; 0.001, η² = 0.15). Plantas de Quebec apresentaram absorção média de 33.5 μmol/m²s, significativamente superior às plantas de Mississippi (20.9 μmol/m²s). O resfriamento reduziu a absorção média em aproximadamente 7.2 μmol/m²s.”"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#checklist-para-análise-estatística",
    "href": "apresentações/posts/estatistica_basica.html#checklist-para-análise-estatística",
    "title": "8. Estatística com R",
    "section": "Checklist para análise estatística",
    "text": "Checklist para análise estatística\nAntes de iniciar:\n\nDados importados corretamente\nVariáveis no formato adequado (fator/numérico)\nValores ausentes identificados\nOutliers investigados"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#checklist-para-análise-estatísticacontinuação",
    "href": "apresentações/posts/estatistica_basica.html#checklist-para-análise-estatísticacontinuação",
    "title": "8. Estatística com R",
    "section": "Checklist para análise estatística(continuação)",
    "text": "Checklist para análise estatística(continuação)\nDurante a análise:\n\nEstatísticas descritivas calculadas\nPressupostos verificados\nTestes apropriados selecionados\nResultados interpretados corretamente"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#checklist-continuação",
    "href": "apresentações/posts/estatistica_basica.html#checklist-continuação",
    "title": "8. Estatística com R",
    "section": "Checklist (continuação)",
    "text": "Checklist (continuação)\nApós a análise:\n\nGráficos informativos criados\nResultados documentados\nCódigo reproduzível salvo"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#boas-práticas-em-análise-estatística",
    "href": "apresentações/posts/estatistica_basica.html#boas-práticas-em-análise-estatística",
    "title": "8. Estatística com R",
    "section": "Boas práticas em análise estatística",
    "text": "Boas práticas em análise estatística\n1. Planejamento:\n\nDefina hipóteses a priori\nCalcule tamanho amostral necessário\nEscolha testes apropriados antes de coletar dados\n\n2. Exploração:\n\nSempre visualize os dados primeiro\nIdentifique padrões e anomalias\nDocumente decisões tomadas"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#boas-práticas-em-análise-estatísticacont",
    "href": "apresentações/posts/estatistica_basica.html#boas-práticas-em-análise-estatísticacont",
    "title": "8. Estatística com R",
    "section": "Boas práticas em análise estatística(cont)",
    "text": "Boas práticas em análise estatística(cont)\n3. Análise:\n\nVerifique pressupostos\nReporte todos os testes realizados\nNão faça “p-hacking” (buscar significância)"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#boas-práticascont",
    "href": "apresentações/posts/estatistica_basica.html#boas-práticascont",
    "title": "8. Estatística com R",
    "section": "Boas práticas(cont)",
    "text": "Boas práticas(cont)\n4. Interpretação:\n\nDiferencie significância estatística de relevância prática\nReporte tamanho de efeito, não apenas p-valor\nConsidere intervalos de confiança\n\n5. Comunicação:\n\nUse visualizações claras\nReporte métodos completos\nDisponibilize dados e código"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#erros-comuns-a-evitar",
    "href": "apresentações/posts/estatistica_basica.html#erros-comuns-a-evitar",
    "title": "8. Estatística com R",
    "section": "Erros comuns a evitar",
    "text": "Erros comuns a evitar\nConceituais:\n\nConfundir correlação com causalidade\nIgnorar múltiplas comparações\nUsar testes inapropriados para os dados\n\nPráticos:\n\nNão verificar pressupostos\nExcluir outliers sem justificativa\nReportar apenas resultados significativos"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#erros-comuns-a-evitarcont",
    "href": "apresentações/posts/estatistica_basica.html#erros-comuns-a-evitarcont",
    "title": "8. Estatística com R",
    "section": "Erros comuns a evitar(cont)",
    "text": "Erros comuns a evitar(cont)\nInterpretação:\n\nConcluir “não há diferença” quando p &gt; 0.05\nIgnorar magnitude do efeito\nGeneralizar além dos dados"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#exercícios-propostos",
    "href": "apresentações/posts/estatistica_basica.html#exercícios-propostos",
    "title": "8. Estatística com R",
    "section": "Exercícios propostos",
    "text": "Exercícios propostos\n1. Estatística descritiva:\nCalcule média, mediana, desvio padrão e coeficiente de variação da absorção de CO2 para cada concentração.\n2. Visualização:\nCrie um gráfico boxplot mostrando a absorção por concentração, separado por origem e tratamento."
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#exercícios-propostoscont",
    "href": "apresentações/posts/estatistica_basica.html#exercícios-propostoscont",
    "title": "8. Estatística com R",
    "section": "Exercícios propostos(cont)",
    "text": "Exercícios propostos(cont)\n3. ANOVA:\nTeste se existe diferença significativa na absorção entre as diferentes concentrações de CO2.\n4. Correlação:\nAvalie a correlação entre concentração e absorção separadamente para cada combinação de origem e tratamento."
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#exercícios-propostos-cont",
    "href": "apresentações/posts/estatistica_basica.html#exercícios-propostos-cont",
    "title": "8. Estatística com R",
    "section": "Exercícios propostos (cont)",
    "text": "Exercícios propostos (cont)\n5. Análise avançada:\nAjuste um modelo de regressão linear múltipla incluindo concentração, tipo e tratamento como preditores. Interprete os coeficientes.\n6. Diagnóstico:\nVerifique todos os pressupostos do modelo de regressão através de gráficos de diagnóstico.\n7. Comparações:\nUse testes post-hoc para identificar quais concentrações diferem significativamente entre si."
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#resumo-da-aula",
    "href": "apresentações/posts/estatistica_basica.html#resumo-da-aula",
    "title": "8. Estatística com R",
    "section": "Resumo da aula",
    "text": "Resumo da aula\nConceitos abordados:\n\nEstatística descritiva: medidas de tendência central, dispersão e posição\nDistribuições: avaliação de normalidade através de testes e gráficos\nANOVA: comparação de múltiplos grupos e análise de interações\nVisualização: criação de gráficos informativos com ggplot2\nInterpretação: como comunicar resultados estatísticos"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#próximos-passos",
    "href": "apresentações/posts/estatistica_basica.html#próximos-passos",
    "title": "8. Estatística com R",
    "section": "Próximos passos",
    "text": "Próximos passos\nPara aprofundar seus conhecimentos:\n\nPratique com outros datasets do R\nExplore análises multivariadas (PCA, análise discriminante)\nAprenda modelagem estatística avançada (modelos mistos, GLM)\nEstude machine learning e análise preditiva\nDesenvolva habilidades em visualização de dados"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#próximos-passos-1",
    "href": "apresentações/posts/estatistica_basica.html#próximos-passos-1",
    "title": "8. Estatística com R",
    "section": "Próximos passos",
    "text": "Próximos passos\nLembre-se:\nA estatística é uma ferramenta para responder perguntas científicas. O conhecimento do domínio é tão importante quanto o conhecimento estatístico."
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#referências",
    "href": "apresentações/posts/estatistica_basica.html#referências",
    "title": "8. Estatística com R",
    "section": "Referências",
    "text": "Referências\nLivros:\n\nBussab, W. O., & Morettin, P. A. (2017). Estatística básica. Saraiva.\nField, A., Miles, J., & Field, Z. (2012). Discovering statistics using R. SAGE.\nWickham, H., & Grolemund, G. (2023). R for data science (2nd ed.). O’Reilly."
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#referências-continuação",
    "href": "apresentações/posts/estatistica_basica.html#referências-continuação",
    "title": "8. Estatística com R",
    "section": "Referências (continuação)",
    "text": "Referências (continuação)\nDocumentação:\n\nR Core Team. (2024). R: A language and environment for statistical computing.\nWickham, H. (2016). ggplot2: elegant graphics for data analysis. Springer.\n\nDatasets:\nPotvin, C., Lechowicz, M. J., & Tardif, S. (1990). The statistical analysis of ecophysiological response curves obtained from experiments involving repeated measures. Ecology, 71(4), 1389-1400."
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#obrigada",
    "href": "apresentações/posts/estatistica_basica.html#obrigada",
    "title": "8. Estatística com R",
    "section": "Obrigada!",
    "text": "Obrigada!\n\nImagem: Allison Horst.Continue praticando e explorando!\nEsta apresentação é parte do projeto Café com R! É OPEN, USE, COMPARTILHE!"
  },
  {
    "objectID": "apresentações/posts/estatistica_basica.html#assine-o-café-com-r",
    "href": "apresentações/posts/estatistica_basica.html#assine-o-café-com-r",
    "title": "8. Estatística com R",
    "section": "☕ Assine o Café com R",
    "text": "☕ Assine o Café com R\nFique por dentro das aulas, conteúdos, newsletter!\n\nQue cada gole desperte uma nova ideia.\nQue cada script abra uma nova conversa.\nQue o Café com R, se torne um ponto de encontro nosso!"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#assine-o-café-com-r",
    "href": "apresentações/posts/guia_inicial.html#assine-o-café-com-r",
    "title": "1. Seus primeiros passos com R",
    "section": "☕ Assine o Café com R",
    "text": "☕ Assine o Café com R\nFique por dentro das aulas, conteúdos, newsletter!\n\nQue cada gole desperte uma nova ideia.\nQue cada script abra uma nova conversa.\nQue o Café com R, se torne um ponto de encontro nosso!"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#bem-vindo-ao-mundo-do-r",
    "href": "apresentações/posts/guia_inicial.html#bem-vindo-ao-mundo-do-r",
    "title": "1. Seus primeiros passos com R",
    "section": "Bem-vindo ao mundo do R!",
    "text": "Bem-vindo ao mundo do R!\nSe você está aqui, é porque decidiu aprender R e essa é uma excelente decisão!\n\nAllison Horst."
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#não-se-preocupe-se",
    "href": "apresentações/posts/guia_inicial.html#não-se-preocupe-se",
    "title": "1. Seus primeiros passos com R",
    "section": "Não se preocupe se:",
    "text": "Não se preocupe se:\n\nVocê nunca programou antes\nTudo parecer confuso no início\nVocê cometer erros (todos cometemos!)\nPrecisar de tempo para aprender\n\nLembre-se: toda jornada começa com um primeiro passo, e este guia vai te acompanhar nessa caminhada."
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#o-que-é-r-afinal",
    "href": "apresentações/posts/guia_inicial.html#o-que-é-r-afinal",
    "title": "1. Seus primeiros passos com R",
    "section": "O que é R, afinal?",
    "text": "O que é R, afinal?\nR é uma linguagem de programação criada especialmente para análise de dados e estatística.\nPor que R é especial:\n\nGratuito e de código aberto\nComunidade enorme e acolhedora\nMilhares de pacotes prontos para usar\nExcelente para visualização de dados\nMuito usado em pesquisa e empresas\n\nEm resumo: R é sua ferramenta para transformar dados em insights."
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#passo-1-instalando-o-r",
    "href": "apresentações/posts/guia_inicial.html#passo-1-instalando-o-r",
    "title": "1. Seus primeiros passos com R",
    "section": "Passo 1: Instalando o R",
    "text": "Passo 1: Instalando o R\nPrimeiro, vamos instalar o R no seu computador.\nAcesse:\n\nSite oficial: https://cran.r-project.org/\nEscolha seu sistema operacional (Windows, Mac ou Linux)\nBaixe e instale a versão mais recente"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#passo-1-instalando-o-r-cont",
    "href": "apresentações/posts/guia_inicial.html#passo-1-instalando-o-r-cont",
    "title": "1. Seus primeiros passos com R",
    "section": "Passo 1: Instalando o R (cont)",
    "text": "Passo 1: Instalando o R (cont)\nDica importante:\n\nO R é o “motor” do seu carro.\nEle faz todo o trabalho, mas você ainda precisa de um “painel de controle” mais amigável o RStudio.\nNão vamos praticar isso agora, mas estes são os passos que você fará no seu computador!"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#passo-2-instalando-o-rstudio",
    "href": "apresentações/posts/guia_inicial.html#passo-2-instalando-o-rstudio",
    "title": "1. Seus primeiros passos com R",
    "section": "Passo 2: Instalando o RStudio",
    "text": "Passo 2: Instalando o RStudio\nO RStudio (agora chamado Posit) é uma interface que torna o R muito mais fácil de usar.\nAcesse:\n\nSite oficial: https://posit.co/download/rstudio-desktop/\nBaixe a versão gratuita (RStudio Desktop)\nInstale normalmente"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#passo-2-instalando-o-rstudio-1",
    "href": "apresentações/posts/guia_inicial.html#passo-2-instalando-o-rstudio-1",
    "title": "1. Seus primeiros passos com R",
    "section": "Passo 2: Instalando o RStudio",
    "text": "Passo 2: Instalando o RStudio\nAnalogia útil:\n\nR = motor do carro\nRStudio = painel com volante, pedais, etc.\n\nVocê pode usar só o R, mas o RStudio torna tudo mais confortável!\nEsta etapa você fará no seu computador após a apresentação."
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#conhecendo-o-rstudio",
    "href": "apresentações/posts/guia_inicial.html#conhecendo-o-rstudio",
    "title": "1. Seus primeiros passos com R",
    "section": "Conhecendo o RStudio",
    "text": "Conhecendo o RStudio\nQuando você abrir o RStudio, verá 4 painéis principais:\n1. Script (superior esquerdo): Onde você escreve seus códigos\n2. Console (inferior esquerdo): Onde o R executa os comandos\n3. Environment (superior direito): Mostra objetos salvos na memória\n4. Files/Plots/Help (inferior direito): Arquivos, gráficos e ajuda\nRespire fundo! No começo parece muito, mas logo você se acostuma."
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#conhecendo-o-rstudio-1",
    "href": "apresentações/posts/guia_inicial.html#conhecendo-o-rstudio-1",
    "title": "1. Seus primeiros passos com R",
    "section": "Conhecendo o RStudio",
    "text": "Conhecendo o RStudio\n\nEssa imagem é minha e um pouco antiga, mas nada mudou!"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#seu-primeiro-comando-no-r",
    "href": "apresentações/posts/guia_inicial.html#seu-primeiro-comando-no-r",
    "title": "1. Seus primeiros passos com R",
    "section": "Seu primeiro comando no R",
    "text": "Seu primeiro comando no R\nVamos começar com algo simples. No Console, digite:\n\n2 + 2\n\n[1] 4\n\n\nParabéns! Você acabou de fazer seu primeiro cálculo no R."
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#seu-primeiro-comando-no-r-1",
    "href": "apresentações/posts/guia_inicial.html#seu-primeiro-comando-no-r-1",
    "title": "1. Seus primeiros passos com R",
    "section": "Seu primeiro comando no R",
    "text": "Seu primeiro comando no R\nAgora tente:\n\n\"Olá, mundo do R!\"\n\n[1] \"Olá, mundo do R!\"\n\n\nDica: O R pode ser uma calculadora super poderosa!"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#criando-objetos-variáveis",
    "href": "apresentações/posts/guia_inicial.html#criando-objetos-variáveis",
    "title": "1. Seus primeiros passos com R",
    "section": "Criando objetos (variáveis)",
    "text": "Criando objetos (variáveis)\nNo R, guardamos valores em objetos usando &lt;- (ou =):\n\n# Criando objetos\nmeu_nome &lt;- \"Maria\"\nminha_idade &lt;- 25\n\n# Mostrando valores\nmeu_nome\n\n[1] \"Maria\"\n\n\nPense nos objetos como gavetas onde você guarda informações para usar depois."
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#regras-para-nomear-objetos",
    "href": "apresentações/posts/guia_inicial.html#regras-para-nomear-objetos",
    "title": "1. Seus primeiros passos com R",
    "section": "Regras para nomear objetos",
    "text": "Regras para nomear objetos\nPode:\n\nUsar letras, números e underscores: dados_2024\nComeçar com letra: resultado\nUsar snake_case: meus_dados"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#regras-para-nomear-objetos-1",
    "href": "apresentações/posts/guia_inicial.html#regras-para-nomear-objetos-1",
    "title": "1. Seus primeiros passos com R",
    "section": "Regras para nomear objetos",
    "text": "Regras para nomear objetos\nNão pode:\n\nComeçar com número: 2dados\nUsar espaços: meus dados\nUsar caracteres especiais: dados@2024\n\nDica: Use nomes descritivos! idade_pacientes é melhor que x."
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#criando-seu-primeiro-script",
    "href": "apresentações/posts/guia_inicial.html#criando-seu-primeiro-script",
    "title": "1. Seus primeiros passos com R",
    "section": "Criando seu primeiro script",
    "text": "Criando seu primeiro script\nScripts são arquivos onde você salva seus códigos.\nPara criar um script:\n\nClique em File → New File → R Script\nOu use o atalho: Ctrl + Shift + N (Windows/Linux) ou Cmd + Shift + N (Mac) ## Criando seu primeiro script {background-color=“#E5D3B3”} Vantagens do script:\n\n\nSalva seu trabalho\nPermite revisitar e corrigir\nCompartilha com outras pessoas\nReproduz análises"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#seu-primeiro-script-na-prática",
    "href": "apresentações/posts/guia_inicial.html#seu-primeiro-script-na-prática",
    "title": "1. Seus primeiros passos com R",
    "section": "Seu primeiro script na prática",
    "text": "Seu primeiro script na prática\nDigite no script (não no console):\n# Meu primeiro script em R\n# Data: 2025-11-29\n# Autor: Seu Nome\n\n# Calculando média de notas\nnota1 &lt;- 8\nnota2 &lt;- 7\nnota3 &lt;- 9\n\nmedia &lt;- (nota1 + nota2 + nota3) / 3\nprint(media)\nPara executar: selecione o código e pressione Ctrl + Enter (Windows/Linux) ou Cmd + Enter (Mac)\nExperimente isso quando estiver no RStudio!"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#a-importância-dos-comentários",
    "href": "apresentações/posts/guia_inicial.html#a-importância-dos-comentários",
    "title": "1. Seus primeiros passos com R",
    "section": "A importância dos comentários",
    "text": "A importância dos comentários\nComentários começam com # e são ignorados pelo R.\n\n# Isto é um comentário - o R não executa\naltura &lt;- 1.75  # Comentário no final da linha\n\nUse comentários para explicar SEU RACIOCÍNIO, não o que o código faz (isso já está óbvio)\nBom comentário:\n# Removendo outliers acima de 3 desvios padrão\ndados_limpos &lt;- dados[dados$valor &lt; media + 3*sd, ]"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#a-importância-dos-comentários-1",
    "href": "apresentações/posts/guia_inicial.html#a-importância-dos-comentários-1",
    "title": "1. Seus primeiros passos com R",
    "section": "A importância dos comentários",
    "text": "A importância dos comentários\nComentário desnecessário:\n# Criando variável x\nx &lt;- 10"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#passo-3-instalando-pacotes",
    "href": "apresentações/posts/guia_inicial.html#passo-3-instalando-pacotes",
    "title": "1. Seus primeiros passos com R",
    "section": "Passo 3: Instalando pacotes",
    "text": "Passo 3: Instalando pacotes\nPacotes são coleções de funções prontas que expandem o R.\nPara instalar um pacote:\n# Instalar (faz UMA vez)\ninstall.packages(\"tidyverse\")\nPara carregar um pacote:\n# Carregar (faz TODA vez que abrir o R)\nlibrary(tidyverse)"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#passo-3-instalando-pacotes-1",
    "href": "apresentações/posts/guia_inicial.html#passo-3-instalando-pacotes-1",
    "title": "1. Seus primeiros passos com R",
    "section": "Passo 3: Instalando pacotes",
    "text": "Passo 3: Instalando pacotes\nAnalogia: Instalar é como baixar um app no celular. Carregar é como abrir o app para usar.\nNão execute isso agora — só quando estiver no seu RStudio!"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#o-kit-inicial-tidyverse",
    "href": "apresentações/posts/guia_inicial.html#o-kit-inicial-tidyverse",
    "title": "1. Seus primeiros passos com R",
    "section": "O kit inicial: tidyverse",
    "text": "O kit inicial: tidyverse\nO tidyverse é um conjunto de pacotes que trabalham bem juntos:\n\nreadr — ler dados\ndplyr — manipular dados\ntidyr — organizar dados\nggplot2 — visualizar dados\nstringr — trabalhar com texto\nlubridate — trabalhar com datas\n\nInstalando tudo de uma vez (no seu computador):"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#o-kit-inicial-tidyverse-1",
    "href": "apresentações/posts/guia_inicial.html#o-kit-inicial-tidyverse-1",
    "title": "1. Seus primeiros passos com R",
    "section": "O kit inicial: tidyverse",
    "text": "O kit inicial: tidyverse\ninstall.packages(\"tidyverse\")\nlibrary(tidyverse)"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#configurando-sua-pasta-de-trabalho",
    "href": "apresentações/posts/guia_inicial.html#configurando-sua-pasta-de-trabalho",
    "title": "1. Seus primeiros passos com R",
    "section": "Configurando sua pasta de trabalho",
    "text": "Configurando sua pasta de trabalho\nPasta de trabalho (working directory) é onde o R procura e salva arquivos.\nVer qual é sua pasta atual:\ngetwd()"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#configurando-sua-pasta-de-trabalho-1",
    "href": "apresentações/posts/guia_inicial.html#configurando-sua-pasta-de-trabalho-1",
    "title": "1. Seus primeiros passos com R",
    "section": "Configurando sua pasta de trabalho",
    "text": "Configurando sua pasta de trabalho\nDefinir nova pasta:\nsetwd(\"C:/Users/SeuNome/Documentos/ProjetoR\")\nDica melhor: Use Projetos do RStudio (falaremos disso em breve!)\nEstes comandos você usará quando estiver trabalhando no RStudio."
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#criando-um-projeto-no-rstudio",
    "href": "apresentações/posts/guia_inicial.html#criando-um-projeto-no-rstudio",
    "title": "1. Seus primeiros passos com R",
    "section": "Criando um Projeto no RStudio",
    "text": "Criando um Projeto no RStudio\nProjetos organizam melhor seu trabalho.\nPara criar:\n\nFile → New Project\nEscolha “New Directory”\nEscolha “New Project”\nDê um nome e escolha onde salvar"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#criando-um-projeto-no-rstudio-1",
    "href": "apresentações/posts/guia_inicial.html#criando-um-projeto-no-rstudio-1",
    "title": "1. Seus primeiros passos com R",
    "section": "Criando um Projeto no RStudio",
    "text": "Criando um Projeto no RStudio\nVantagens:\n\nOrganiza arquivos automaticamente\nDefine pasta de trabalho\nFacilita retomar trabalho depois\nFacilita compartilhar"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#estrutura-de-pastas-recomendada",
    "href": "apresentações/posts/guia_inicial.html#estrutura-de-pastas-recomendada",
    "title": "1. Seus primeiros passos com R",
    "section": "Estrutura de pastas recomendada",
    "text": "Estrutura de pastas recomendada\nDentro do seu projeto, crie pastas:\nMeuProjeto/\n├── dados/           # Dados brutos\n├── scripts/         # Seus códigos R\n├── resultados/      # Tabelas e arquivos gerados\n├── graficos/        # Visualizações salvas\n└── relatorios/      # Relatórios finais\nEsta organização vai te salvar no futuro!"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#importando-dados---primeiro-exemplo",
    "href": "apresentações/posts/guia_inicial.html#importando-dados---primeiro-exemplo",
    "title": "1. Seus primeiros passos com R",
    "section": "Importando dados - Primeiro exemplo",
    "text": "Importando dados - Primeiro exemplo\nVamos usar um dataset que já vem com o R:\n\n# Carregar dados mtcars (dados de carros)\ndata(mtcars)\n\n# Ver primeiras linhas\nhead(mtcars)\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#importando-seus-próprios-dados",
    "href": "apresentações/posts/guia_inicial.html#importando-seus-próprios-dados",
    "title": "1. Seus primeiros passos com R",
    "section": "Importando seus próprios dados",
    "text": "Importando seus próprios dados\nArquivos CSV:\n\nlibrary(readr)\n\n# Importar CSV\nmeus_dados &lt;- read_csv(\"dados/arquivo.csv\")\n\n# Ver estrutura dos dados\nglimpse(meus_dados)\n\nOnde está meu arquivo?\n\nSe estiver na pasta dados/ do seu projeto, use: \"dados/arquivo.csv\"\nUse sempre caminhos relativos (nunca \"C:/Users/...\")"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#explorando-seus-dados",
    "href": "apresentações/posts/guia_inicial.html#explorando-seus-dados",
    "title": "1. Seus primeiros passos com R",
    "section": "Explorando seus dados",
    "text": "Explorando seus dados\n\n# Ver estrutura\nstr(mtcars)\n\n'data.frame':   32 obs. of  11 variables:\n $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...\n $ disp: num  160 160 108 258 360 ...\n $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...\n $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...\n $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...\n $ qsec: num  16.5 17 18.6 19.4 17 ...\n $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...\n $ am  : num  1 1 1 0 0 0 0 0 0 0 ...\n $ gear: num  4 4 4 3 3 3 3 4 4 4 ...\n $ carb: num  4 4 1 1 2 1 4 2 2 4 ...\n\n# Resumo estatístico\nsummary(mtcars)\n\n      mpg             cyl             disp             hp       \n Min.   :10.40   Min.   :4.000   Min.   : 71.1   Min.   : 52.0  \n 1st Qu.:15.43   1st Qu.:4.000   1st Qu.:120.8   1st Qu.: 96.5  \n Median :19.20   Median :6.000   Median :196.3   Median :123.0  \n Mean   :20.09   Mean   :6.188   Mean   :230.7   Mean   :146.7  \n 3rd Qu.:22.80   3rd Qu.:8.000   3rd Qu.:326.0   3rd Qu.:180.0  \n Max.   :33.90   Max.   :8.000   Max.   :472.0   Max.   :335.0  \n      drat             wt             qsec             vs        \n Min.   :2.760   Min.   :1.513   Min.   :14.50   Min.   :0.0000  \n 1st Qu.:3.080   1st Qu.:2.581   1st Qu.:16.89   1st Qu.:0.0000  \n Median :3.695   Median :3.325   Median :17.71   Median :0.0000  \n Mean   :3.597   Mean   :3.217   Mean   :17.85   Mean   :0.4375  \n 3rd Qu.:3.920   3rd Qu.:3.610   3rd Qu.:18.90   3rd Qu.:1.0000  \n Max.   :4.930   Max.   :5.424   Max.   :22.90   Max.   :1.0000  \n       am              gear            carb      \n Min.   :0.0000   Min.   :3.000   Min.   :1.000  \n 1st Qu.:0.0000   1st Qu.:3.000   1st Qu.:2.000  \n Median :0.0000   Median :4.000   Median :2.000  \n Mean   :0.4062   Mean   :3.688   Mean   :2.812  \n 3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:4.000  \n Max.   :1.0000   Max.   :5.000   Max.   :8.000"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#explorando-seus-dados-cont.",
    "href": "apresentações/posts/guia_inicial.html#explorando-seus-dados-cont.",
    "title": "1. Seus primeiros passos com R",
    "section": "Explorando seus dados (cont.)",
    "text": "Explorando seus dados (cont.)\n\n# Ver nomes das colunas\nnames(mtcars)\n\n [1] \"mpg\"  \"cyl\"  \"disp\" \"hp\"   \"drat\" \"wt\"   \"qsec\" \"vs\"   \"am\"   \"gear\"\n[11] \"carb\"\n\n# Primeiras e últimas linhas\nhead(mtcars, 3)\n\n               mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4     21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710    22.8   4  108  93 3.85 2.320 18.61  1  1    4    1"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#manipulação-básica-com-dplyr",
    "href": "apresentações/posts/guia_inicial.html#manipulação-básica-com-dplyr",
    "title": "1. Seus primeiros passos com R",
    "section": "Manipulação básica com dplyr",
    "text": "Manipulação básica com dplyr\n\nlibrary(dplyr)\n\n# Filtrar linhas\ncarros_potentes &lt;- mtcars |&gt;\n  filter(hp &gt; 150)\n\n# Ver resultado\nhead(carros_potentes, 3)\n\n                   mpg cyl  disp  hp drat   wt  qsec vs am gear carb\nHornet Sportabout 18.7   8 360.0 175 3.15 3.44 17.02  0  0    3    2\nDuster 360        14.3   8 360.0 245 3.21 3.57 15.84  0  0    3    4\nMerc 450SE        16.4   8 275.8 180 3.07 4.07 17.40  0  0    3    3"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#selecionando-colunas",
    "href": "apresentações/posts/guia_inicial.html#selecionando-colunas",
    "title": "1. Seus primeiros passos com R",
    "section": "Selecionando colunas",
    "text": "Selecionando colunas\n\n# Selecionar apenas algumas colunas\ncarros_simples &lt;- mtcars |&gt;\n  select(mpg, cyl, hp)\n\nhead(carros_simples, 4)\n\n                mpg cyl  hp\nMazda RX4      21.0   6 110\nMazda RX4 Wag  21.0   6 110\nDatsun 710     22.8   4  93\nHornet 4 Drive 21.4   6 110\n\n\nO operador |&gt; (pipe) significa “e então…”\nLeia como: “Pegue mtcars, E ENTÃO selecione as colunas…”"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#criando-novas-variáveis",
    "href": "apresentações/posts/guia_inicial.html#criando-novas-variáveis",
    "title": "1. Seus primeiros passos com R",
    "section": "Criando novas variáveis",
    "text": "Criando novas variáveis\n\n# Criar nova coluna\nmtcars_novo &lt;- mtcars |&gt;\n  mutate(\n    hp_por_cyl = hp / cyl,\n    eficiente = mpg &gt; 20\n  )\n\nhead(mtcars_novo[, c(\"hp\", \"cyl\", \"hp_por_cyl\", \"eficiente\")], 3)\n\n               hp cyl hp_por_cyl eficiente\nMazda RX4     110   6   18.33333      TRUE\nMazda RX4 Wag 110   6   18.33333      TRUE\nDatsun 710     93   4   23.25000      TRUE"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#seu-primeiro-gráfico",
    "href": "apresentações/posts/guia_inicial.html#seu-primeiro-gráfico",
    "title": "1. Seus primeiros passos com R",
    "section": "Seu primeiro gráfico!",
    "text": "Seu primeiro gráfico!\n\nlibrary(ggplot2)\n\nggplot(mtcars, aes(x = wt, y = mpg)) +\n  geom_point(color = \"#224573\", size = 3) +\n  theme_minimal() +\n  labs(\n    title = \"Relação entre Peso e Consumo\",\n    x = \"Peso (1000 lbs)\",\n    y = \"Milhas por galão\"\n  )"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#entendendo-o-ggplot2",
    "href": "apresentações/posts/guia_inicial.html#entendendo-o-ggplot2",
    "title": "1. Seus primeiros passos com R",
    "section": "Entendendo o ggplot2",
    "text": "Entendendo o ggplot2\nTodo gráfico ggplot2 tem 3 elementos:\n\nDados: ggplot(mtcars, ...)\nMapeamento estético: aes(x = wt, y = mpg)\nGeometria: geom_point() (tipo de gráfico)\n\nVocê CONSTRÓI gráficos adicionando camadas com +\nggplot(dados, aes(x, y)) +    # Base\n  geom_point() +               # Adiciona pontos\n  theme_minimal()              # Adiciona tema"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#erros-comuns-e-como-evitá-los",
    "href": "apresentações/posts/guia_inicial.html#erros-comuns-e-como-evitá-los",
    "title": "1. Seus primeiros passos com R",
    "section": "Erros comuns (e como evitá-los)",
    "text": "Erros comuns (e como evitá-los)\nErro 1: Esquecer de carregar pacotes\n# ❌ Erro\ndados &lt;- read_csv(\"arquivo.csv\")\n\n# ✅ Correto\nlibrary(readr)\ndados &lt;- read_csv(\"arquivo.csv\")\nSempre carregue os pacotes no início do script!"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#erros-comuns-cont.",
    "href": "apresentações/posts/guia_inicial.html#erros-comuns-cont.",
    "title": "1. Seus primeiros passos com R",
    "section": "Erros comuns (cont.)",
    "text": "Erros comuns (cont.)\nErro 2: Caminhos absolutos\n# ❌ Ruim (só funciona no seu computador)\ndados &lt;- read_csv(\"C:/Users/Maria/Desktop/dados.csv\")\n\n# ✅ Bom (funciona em qualquer computador com o projeto)\ndados &lt;- read_csv(\"dados/dados.csv\")\nUse projetos e caminhos relativos!"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#erros-comuns-cont.-1",
    "href": "apresentações/posts/guia_inicial.html#erros-comuns-cont.-1",
    "title": "1. Seus primeiros passos com R",
    "section": "Erros comuns (cont.)",
    "text": "Erros comuns (cont.)\nErro 3: Sobrescrever objetos importantes\n# ❌ Perigo!\ndados &lt;- read_csv(\"originais.csv\")\ndados &lt;- dados |&gt; filter(idade &gt; 18)  # perdeu os originais!\n\n# ✅ Melhor\ndados &lt;- read_csv(\"originais.csv\")\ndados_adultos &lt;- dados |&gt; filter(idade &gt; 18)\nGuarde o original e crie novos objetos!"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#erros-comuns-cont.-2",
    "href": "apresentações/posts/guia_inicial.html#erros-comuns-cont.-2",
    "title": "1. Seus primeiros passos com R",
    "section": "Erros comuns (cont.)",
    "text": "Erros comuns (cont.)\nErro 4: Não usar o pipe |&gt;\n# ❌ Difícil de ler\nresultado &lt;- arrange(filter(select(dados, nome, idade), idade &gt; 18), nome)\n\n# ✅ Muito melhor!\nresultado &lt;- dados |&gt;\n  select(nome, idade) |&gt;\n  filter(idade &gt; 18) |&gt;\n  arrange(nome)\nO pipe torna o código MUITO mais legível!"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#pedindo-ajuda-no-r",
    "href": "apresentações/posts/guia_inicial.html#pedindo-ajuda-no-r",
    "title": "1. Seus primeiros passos com R",
    "section": "Pedindo ajuda no R",
    "text": "Pedindo ajuda no R\nAjuda sobre uma função:\n?mean\nhelp(mean)\nProcurar ajuda:\n??regression"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#pedindo-ajuda-no-r-1",
    "href": "apresentações/posts/guia_inicial.html#pedindo-ajuda-no-r-1",
    "title": "1. Seus primeiros passos com R",
    "section": "Pedindo ajuda no R",
    "text": "Pedindo ajuda no R\nExemplos:\nexample(mean)\nNão tenha vergonha de pedir ajuda! Até programadores experientes consultam a documentação constantemente."
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#onde-buscar-ajuda",
    "href": "apresentações/posts/guia_inicial.html#onde-buscar-ajuda",
    "title": "1. Seus primeiros passos com R",
    "section": "Onde buscar ajuda",
    "text": "Onde buscar ajuda\nDentro do R:\n\nAba “Help” no RStudio\n?funcao para ajuda específica\nVignettes dos pacotes\n\nNa internet:\n\nStack Overflow (em inglês e português)\nGoogle: “como fazer X em R”\nChatGPT/Claude para explicações\nComunidade R Brasil (Telegram/Discord)"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#sites-e-recursos-úteis",
    "href": "apresentações/posts/guia_inicial.html#sites-e-recursos-úteis",
    "title": "1. Seus primeiros passos com R",
    "section": "Sites e recursos úteis",
    "text": "Sites e recursos úteis\nAprendizado:\n\nR for Data Science:Livro gratuito online\nRStudio Education:Tutoriais oficiais\nPosit Cheatsheets: Guias rápidos\n\nComunidade:\n\nRStudio Community\nR-bloggers\nR-Ladies\nComunidade de Estatística - Thiago Marques"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#boas-práticas-desde-o-início",
    "href": "apresentações/posts/guia_inicial.html#boas-práticas-desde-o-início",
    "title": "1. Seus primeiros passos com R",
    "section": "Boas práticas desde o início",
    "text": "Boas práticas desde o início\n1. Use projetos do RStudio\n\nMantém tudo organizado\nFacilita compartilhar\n\n2. Comente seu código\n\nExplique o PORQUÊ, não o QUÊ\nSeu eu-futuro agradece\n\n3. Use nomes descritivos\n\ndados_vendas_2024 &gt; df1\ncalcular_media() &gt; func()"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#boas-práticas-cont.",
    "href": "apresentações/posts/guia_inicial.html#boas-práticas-cont.",
    "title": "1. Seus primeiros passos com R",
    "section": "Boas práticas (cont.)",
    "text": "Boas práticas (cont.)\n4. Salve frequentemente\n\nScripts: Ctrl + S / Cmd + S\nTrabalho perdido dói!\n\n5. Use versionamento\n\nGit/GitHub quando estiver confortável\nPor enquanto, use datas nos nomes: analise_2025-11-29.R\n\n6. Teste em partes\n\nExecute linha por linha\nVerifique resultados parciais"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#workflow-típico-de-análise",
    "href": "apresentações/posts/guia_inicial.html#workflow-típico-de-análise",
    "title": "1. Seus primeiros passos com R",
    "section": "Workflow típico de análise",
    "text": "Workflow típico de análise\n1. Importar dados\ndados &lt;- read_csv(\"dados/arquivo.csv\")\n2. Explorar e limpar\nglimpse(dados)\ndados_limpos &lt;- dados |&gt; filter(!is.na(variavel))\n3. Transformar\ndados_processados &lt;- dados_limpos |&gt;\n  mutate(nova_var = var1 + var2)\nEste será seu workflow quando trabalhar com dados reais!"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#workflow-típico-cont.",
    "href": "apresentações/posts/guia_inicial.html#workflow-típico-cont.",
    "title": "1. Seus primeiros passos com R",
    "section": "Workflow típico (cont.)",
    "text": "Workflow típico (cont.)\n4. Visualizar\nggplot(dados_processados, aes(x, y)) +\n  geom_point()\n5. Modelar (quando necessário)\nmodelo &lt;- lm(y ~ x, data = dados_processados)\n6. Comunicar resultados\n\nGráficos salvos\nRelatórios em Quarto/RMarkdown\n\nVocê vai praticar este workflow nos seus projetos!"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#exemplo-completo-do-zero",
    "href": "apresentações/posts/guia_inicial.html#exemplo-completo-do-zero",
    "title": "1. Seus primeiros passos com R",
    "section": "Exemplo completo do zero",
    "text": "Exemplo completo do zero\nVamos fazer uma análise completa com o dataset iris:\n\n# 1. Carregar pacotes\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# 2. Carregar dados\ndata(iris)\n\n# 3. Explorar\nglimpse(iris)\n\nRows: 150\nColumns: 5\n$ Sepal.Length &lt;dbl&gt; 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.…\n$ Sepal.Width  &lt;dbl&gt; 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.…\n$ Petal.Length &lt;dbl&gt; 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.…\n$ Petal.Width  &lt;dbl&gt; 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.…\n$ Species      &lt;fct&gt; setosa, setosa, setosa, setosa, setosa, setosa, setosa, s…"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#exemplo-completo-cont.",
    "href": "apresentações/posts/guia_inicial.html#exemplo-completo-cont.",
    "title": "1. Seus primeiros passos com R",
    "section": "Exemplo completo (cont.)",
    "text": "Exemplo completo (cont.)\n\n# 4. Resumir dados\nresumo &lt;- iris |&gt;\n  group_by(Species) |&gt;\n  summarise(\n    media_sepala = mean(Sepal.Length),\n    media_petala = mean(Petal.Length),\n    n = n()\n  )\n\nprint(resumo)\n\n# A tibble: 3 × 4\n  Species    media_sepala media_petala     n\n  &lt;fct&gt;             &lt;dbl&gt;        &lt;dbl&gt; &lt;int&gt;\n1 setosa             5.01         1.46    50\n2 versicolor         5.94         4.26    50\n3 virginica          6.59         5.55    50"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#exemplo-completo-cont.-1",
    "href": "apresentações/posts/guia_inicial.html#exemplo-completo-cont.-1",
    "title": "1. Seus primeiros passos com R",
    "section": "Exemplo completo (cont.)",
    "text": "Exemplo completo (cont.)\n\n# 5. Visualizar\nggplot(iris, aes(x = Sepal.Length, y = Petal.Length, color = Species)) +\n  geom_point(size = 3, alpha = 0.7) +\n  scale_color_manual(values = c(\"#224573\", \"#6B4F4F\", \"#4A6FA5\")) +\n  theme_minimal() +\n  labs(\n    title = \"Relação entre Comprimento da Sépala e Pétala\",\n    x = \"Comprimento da Sépala (cm)\",\n    y = \"Comprimento da Pétala (cm)\"\n  )"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#salvando-seu-trabalho",
    "href": "apresentações/posts/guia_inicial.html#salvando-seu-trabalho",
    "title": "1. Seus primeiros passos com R",
    "section": "Salvando seu trabalho",
    "text": "Salvando seu trabalho\nSalvar script:\n\nCtrl + S / Cmd + S\n\nSalvar gráfico:\nggsave(\"graficos/meu_grafico.png\", \n       width = 10, height = 6)\nSalvar dados processados:\nwrite_csv(dados_processados, \"resultados/dados_finais.csv\")"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#checklist-do-iniciante",
    "href": "apresentações/posts/guia_inicial.html#checklist-do-iniciante",
    "title": "1. Seus primeiros passos com R",
    "section": "Checklist do iniciante",
    "text": "Checklist do iniciante\nPreparação:\n\nR instalado\nRStudio instalado\n\nTidyverse instalado\nProjeto criado\nEstrutura de pastas pronta\n\nEm cada análise:\n\nComentários no script\nPacotes carregados\nDados importados corretamente\nExploração inicial feita\nResultados verificados\nTrabalho salvo"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#próximos-passos-na-sua-jornada",
    "href": "apresentações/posts/guia_inicial.html#próximos-passos-na-sua-jornada",
    "title": "1. Seus primeiros passos com R",
    "section": "Próximos passos na sua jornada",
    "text": "Próximos passos na sua jornada\nCurto prazo:\n\nPratique com datasets do R (iris, mtcars, diamonds)\nExperimente diferentes gráficos no ggplot2\nRefaça tutoriais com seus próprios dados\n\nMédio prazo:\n\nAprenda a criar relatórios com Quarto\nExplore análise exploratória com DataExplorer\nAprenda mais sobre dplyr e tidyr\n\nLongo prazo:\n\nModelagem estatística\nMachine learning com tidymodels\nDashboards com Shiny"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#dicas-de-ouro",
    "href": "apresentações/posts/guia_inicial.html#dicas-de-ouro",
    "title": "1. Seus primeiros passos com R",
    "section": "Dicas de ouro",
    "text": "Dicas de ouro\n1. Pratique regularmente\n\n15 minutos por dia &gt; 2 horas uma vez por semana\n\n2. Copie e modifique\n\nNão há problema em copiar código\nEntenda o que está fazendo\nAdapte para sua necessidade\n\n3. Cometa erros\n\nErros são parte do aprendizado\nLeia as mensagens de erro com calma\nGoogle a mensagem de erro"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#dicas-de-ouro-cont.",
    "href": "apresentações/posts/guia_inicial.html#dicas-de-ouro-cont.",
    "title": "1. Seus primeiros passos com R",
    "section": "Dicas de ouro (cont.)",
    "text": "Dicas de ouro (cont.)\n4. Construa seu próprio banco de códigos\n\nSalve snippets úteis\nCrie templates de análises\nDocumente suas soluções\n\n5. Participe da comunidade\n\nPergunte quando tiver dúvidas\nCompartilhe o que aprender\nAjude outros iniciantes\n\n6. Seja paciente consigo mesmo\n\nAprender leva tempo\nCelebre pequenas vitórias\nCompare-se apenas com você de ontem"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#recursos-gratuitos-para-continuar",
    "href": "apresentações/posts/guia_inicial.html#recursos-gratuitos-para-continuar",
    "title": "1. Seus primeiros passos com R",
    "section": "Recursos gratuitos para continuar",
    "text": "Recursos gratuitos para continuar\nLivros online gratuitos:\n\nR for Data Science\nModern Statistics with R\nHands-On Programming with R\n\nTutoriais interativos:\n\nRStudio Primers\nSwirl (aprenda dentro do R!)\n\nComunidades brasileiras:\n\nR Brasil (Telegram)\nCurso-R"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#um-último-conselho",
    "href": "apresentações/posts/guia_inicial.html#um-último-conselho",
    "title": "1. Seus primeiros passos com R",
    "section": "Um último conselho",
    "text": "Um último conselho\n\n“A melhor maneira de aprender R é usando R.”\n\nNão espere entender tudo antes de começar.\nComece pequeno:\n\nUm gráfico simples hoje\nUma análise básica amanhã\nUm mini projeto na semana que vem\n\nCada linha de código que você escreve é um passo na direção certa.\nVocê já deu o primeiro passo ao chegar até aqui. Parabéns!"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#projeto-prático-sugerido",
    "href": "apresentações/posts/guia_inicial.html#projeto-prático-sugerido",
    "title": "1. Seus primeiros passos com R",
    "section": "Projeto prático sugerido",
    "text": "Projeto prático sugerido\nPara praticar, faça um mini projeto:\n\nEscolha um dataset (pode ser do R: iris, mtcars, diamonds)\nCrie um projeto no RStudio\nEscreva um script que:\n\nCarregue os dados\nFaça resumos estatísticos\nCrie 2-3 gráficos\nTire pelo menos uma conclusão\n\nSalve tudo organizado nas pastas\nAdicione comentários explicando seu raciocínio\n\nEste será seu primeiro projeto completo!"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#recapitulando",
    "href": "apresentações/posts/guia_inicial.html#recapitulando",
    "title": "1. Seus primeiros passos com R",
    "section": "Recapitulando",
    "text": "Recapitulando\nVocê aprendeu:\n\nInstalar R e RStudio\nCriar projetos e scripts\nUsar o console e executar códigos\nInstalar e carregar pacotes\nImportar e explorar dados\nManipular dados com dplyr\nCriar visualizações com ggplot2\nBoas práticas e organização\nOnde buscar ajuda\n\nIsso é MUITO para um primeiro contato!"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#mensagem-final",
    "href": "apresentações/posts/guia_inicial.html#mensagem-final",
    "title": "1. Seus primeiros passos com R",
    "section": "Mensagem final",
    "text": "Mensagem final\nVocê não precisa saber tudo agora.\nVocê não precisa ser perfeito.\nVocê só precisa começar.\nO R é uma ferramenta poderosa, e você acabou de ganhar a chave para usá-la.\nO resto é prática, paciência e persistência.\nBem-vindo à comunidade R!"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#agora",
    "href": "apresentações/posts/guia_inicial.html#agora",
    "title": "1. Seus primeiros passos com R",
    "section": "Agora",
    "text": "Agora\nSeus primeiros passos estão completos!\nAgora é hora de praticar e explorar.\nLembre-se: a comunidade R está aqui para ajudar. Não hesite em perguntar!\nBons estudos e ótimas análises!"
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#muito-obrigada",
    "href": "apresentações/posts/guia_inicial.html#muito-obrigada",
    "title": "1. Seus primeiros passos com R",
    "section": "Muito obrigada!",
    "text": "Muito obrigada!\nEsta apresentação é parte do projeto Café com R\nÉ OPEN, USE, COMPARTILHE!\n\nAllison Horst."
  },
  {
    "objectID": "apresentações/posts/guia_inicial.html#assine-o-café-com-r-1",
    "href": "apresentações/posts/guia_inicial.html#assine-o-café-com-r-1",
    "title": "1. Seus primeiros passos com R",
    "section": "☕ Assine o Café com R",
    "text": "☕ Assine o Café com R\nFique por dentro das aulas, conteúdos, newsletter!\n\nQue cada gole desperte uma nova ideia.\nQue cada script abra uma nova conversa.\nQue o Café com R, se torne um ponto de encontro nosso!"
  },
  {
    "objectID": "apresentações/posts/para_2026.html#para-2026-comece-limpando-o-ambiente",
    "href": "apresentações/posts/para_2026.html#para-2026-comece-limpando-o-ambiente",
    "title": "1. 2026",
    "section": "Para 2026, comece limpando o ambiente",
    "text": "Para 2026, comece limpando o ambiente\nrm(list = ls())\ngc()\n\nNem tudo precisa seguir com você.\nAbra espaço.\nLeve só o que faz sentido."
  },
  {
    "objectID": "apresentações/posts/para_2026.html#para-2026-faça-um-select-consciente",
    "href": "apresentações/posts/para_2026.html#para-2026-faça-um-select-consciente",
    "title": "1. 2026",
    "section": "Para 2026, faça um select() consciente",
    "text": "Para 2026, faça um select() consciente\nvida_2026 &lt;- select(\n  amor,\n  felicidade,\n  prosperidade,\n  união,\n  esperança,\n  novos_começos,\n  oportunidades)\n\nEscolher é um ato de coragem.\nVocê não precisa carregar tudo.\nSó o essencial."
  },
  {
    "objectID": "apresentações/posts/para_2026.html#para-2026-filtre-sem-culpa",
    "href": "apresentações/posts/para_2026.html#para-2026-filtre-sem-culpa",
    "title": "1. 2026",
    "section": "Para 2026, filtre() sem culpa",
    "text": "Para 2026, filtre() sem culpa\nvida_2026 &lt;- vida_2026 |&gt;\n  filter(\n    valores %in% c(\"sonhos\", \"desejos\", \"amor\", \"paz\", \"verdade\"))\n\nO que não soma, sai.\nO que pesa, fica para trás.\nVocê não deve explicações ao que não te respeita."
  },
  {
    "objectID": "apresentações/posts/para_2026.html#para-2026-trate-exceções-com-carinho",
    "href": "apresentações/posts/para_2026.html#para-2026-trate-exceções-com-carinho",
    "title": "1. 2026",
    "section": "Para 2026, trate exceções com carinho",
    "text": "Para 2026, trate exceções com carinho\nvida_2026 &lt;- tryCatch(\n  vida_2026,\n  error = function(e) \"aprendizado\",\n  warning = function(w) \"ajuste de rota\")\n\nNem todo erro é falha.\nAlguns são apenas dados dizendo:\ntente diferente."
  },
  {
    "objectID": "apresentações/posts/para_2026.html#para-2026-faça-um-group_by-do-que-importa",
    "href": "apresentações/posts/para_2026.html#para-2026-faça-um-group_by-do-que-importa",
    "title": "1. 2026",
    "section": "Para 2026, faça um group_by() do que importa",
    "text": "Para 2026, faça um group_by() do que importa\nvida_2026 &lt;- vida_2026 |&gt;\n  group_by(\n    quem_voce_ama,\n    amigos_de_verdade,\n    familia,\n    sua_propria_companhia)\n\nNinguém cresce sozinho.\nMas crescer com quem vibra por você:\nmuda tudo."
  },
  {
    "objectID": "apresentações/posts/para_2026.html#para-2026-summarize-sua-trajetória",
    "href": "apresentações/posts/para_2026.html#para-2026-summarize-sua-trajetória",
    "title": "1. 2026",
    "section": "Para 2026, summarize() sua trajetória",
    "text": "Para 2026, summarize() sua trajetória\nresumo_vida &lt;- vida_2026 |&gt;\n  summarise(\n    conquistas = sum(vitorias),\n    coragem = mean(lutas),\n    identidade = first(quem_voce_e))\n\nVocê não é só resultado.\nÉ processo.\nÉ consistência em dias difíceis."
  },
  {
    "objectID": "apresentações/posts/para_2026.html#para-2026-aceite-dados-imperfeitos",
    "href": "apresentações/posts/para_2026.html#para-2026-aceite-dados-imperfeitos",
    "title": "1. 2026",
    "section": "Para 2026, aceite dados imperfeitos",
    "text": "Para 2026, aceite dados imperfeitos\nvida_2026 &lt;- vida_2026 |&gt;\n  mutate(\n    dias_ruins = replace_na(dias_ruins, 0),\n    esperança = if_else(\n      dias_ruins &gt; 0, \n      esperança + 1, \n      esperança))\n\nDias ruins existem.\nEles não anulam quem você é.\nEles treinam sua versão mais forte e resiliente."
  },
  {
    "objectID": "apresentações/posts/para_2026.html#para-2026-documente-sua-história",
    "href": "apresentações/posts/para_2026.html#para-2026-documente-sua-história",
    "title": "1. 2026",
    "section": "Para 2026, documente sua história",
    "text": "Para 2026, documente sua história\nwrite_lines(\n  \"Estou construindo uma vida que faz sentido para mim.\",\n  \"README.md\")\nQue fique claro para:\n\nVocê.\nOutros.\nFuturo."
  },
  {
    "objectID": "apresentações/posts/para_2026.html#para-2026-rode-o-script-com-confiança",
    "href": "apresentações/posts/para_2026.html#para-2026-rode-o-script-com-confiança",
    "title": "1. 2026",
    "section": "Para 2026, rode o script com confiança",
    "text": "Para 2026, rode o script com confiança\nrun(vida_2026)\n\nVocê não precisa saber tudo agora.\nSó precisa começar."
  },
  {
    "objectID": "apresentações/posts/para_2026.html#para-2026-versionamento-é-essencial",
    "href": "apresentações/posts/para_2026.html#para-2026-versionamento-é-essencial",
    "title": "1. 2026",
    "section": "Para 2026, versionamento é essencial",
    "text": "Para 2026, versionamento é essencial\ngit commit -m \"Novo ano. Novas escolhas. Mesma essência.\"\n\nErrou? Ajusta.\nAprendeu? Evolua com isso!\nSeguiu? Sinta muito orgulho."
  },
  {
    "objectID": "apresentações/posts/para_2026.html#para-2026-celebre-pequenas-entregas",
    "href": "apresentações/posts/para_2026.html#para-2026-celebre-pequenas-entregas",
    "title": "1. 2026",
    "section": "Para 2026, celebre pequenas entregas",
    "text": "Para 2026, celebre pequenas entregas\nprint(\"Uma xícara de café por cada passo dado\")\n\nConsistência vence pressa.\nPresença vence perfeição.\n\n\n\n\n\n\nWarning\n\n\n“Mude, mas comece devagar, porque a direção é mais importante que a velocidade.”\nClarisse Lispector"
  },
  {
    "objectID": "apresentações/posts/para_2026.html#para-2026",
    "href": "apresentações/posts/para_2026.html#para-2026",
    "title": "1. 2026",
    "section": "Para 2026",
    "text": "Para 2026\n\nCódigo com propósito claro.\nVida com intenção.\nE cafézinho para acompanhar o processo.\nBem-vindo ao novo ciclo.\nO script é seu."
  },
  {
    "objectID": "apresentações/posts/sql_comandos.html#assine-o-café-com-r",
    "href": "apresentações/posts/sql_comandos.html#assine-o-café-com-r",
    "title": "5.1. SQL x R (dbplyr)",
    "section": "☕ Assine o Café com R",
    "text": "☕ Assine o Café com R\nFique por dentro das aulas, conteúdos, newsletter!\n\nQue cada gole desperte uma nova ideia.\nQue cada script abra uma nova conversa.\nQue o Café com R, se torne um ponto de encontro nosso!"
  },
  {
    "objectID": "apresentações/posts/sql_comandos.html#sql-x-r-dbplyr---parte-1",
    "href": "apresentações/posts/sql_comandos.html#sql-x-r-dbplyr---parte-1",
    "title": "5.1. SQL x R (dbplyr)",
    "section": "SQL x R (dbplyr) - Parte 1",
    "text": "SQL x R (dbplyr) - Parte 1\n\n\n\n\n\n\n\n\nTarefa\nSQL\nR (dbplyr)\n\n\n\n\nConectar ao Banco\n-- Conexão gerenciada pelo cliente SQL\ncon &lt;- dbConnect(RSQLite::SQLite(), \"banco.db\")\n\n\nReferenciar Tabela\nSELECT * FROM vendas;\nvendas &lt;- tbl(con, \"vendas\")"
  },
  {
    "objectID": "apresentações/posts/sql_comandos.html#sql-x-r-dbplyr---parte-2",
    "href": "apresentações/posts/sql_comandos.html#sql-x-r-dbplyr---parte-2",
    "title": "5.1. SQL x R (dbplyr)",
    "section": "SQL x R (dbplyr) - Parte 2",
    "text": "SQL x R (dbplyr) - Parte 2\n\n\n\n\n\n\n\n\nTarefa\nSQL\nR (dbplyr)\n\n\n\n\nFiltrar com Múltiplas Condições\nSELECT * FROM clientes WHERE idade &gt;= 18 AND cidade = 'SP';\nclientes %&gt;% filter(idade &gt;= 18, cidade == \"SP\")\n\n\nSelecionar e Renomear\nSELECT nome AS cliente, valor AS preco FROM pedidos;\npedidos %&gt;% select(cliente = nome, preco = valor)"
  },
  {
    "objectID": "apresentações/posts/sql_comandos.html#sql-x-r-dbplyr---parte-3",
    "href": "apresentações/posts/sql_comandos.html#sql-x-r-dbplyr---parte-3",
    "title": "5.1. SQL x R (dbplyr)",
    "section": "SQL x R (dbplyr) - Parte 3",
    "text": "SQL x R (dbplyr) - Parte 3\n\n\n\n\n\n\n\n\nTarefa\nSQL\nR (dbplyr)\n\n\n\n\nTop N Registros\nSELECT * FROM produtos ORDER BY preco DESC LIMIT 5;\nprodutos %&gt;% arrange(desc(preco)) %&gt;% head(5)\n\n\nAgrupar e Calcular Múltiplas Métricas\nSELECT categoria, COUNT(*) as qtd, AVG(preco) as media FROM produtos GROUP BY categoria;\nprodutos %&gt;% group_by(categoria) %&gt;% summarise(qtd = n(), media = mean(preco))"
  },
  {
    "objectID": "apresentações/posts/sql_comandos.html#sql-x-r-dbplyr---parte-4",
    "href": "apresentações/posts/sql_comandos.html#sql-x-r-dbplyr---parte-4",
    "title": "5.1. SQL x R (dbplyr)",
    "section": "SQL x R (dbplyr) - Parte 4",
    "text": "SQL x R (dbplyr) - Parte 4\n\n\n\n\n\n\n\n\nTarefa\nSQL\nR (dbplyr)\n\n\n\n\nFiltrar Grupos (HAVING)\nSELECT cidade, COUNT(*) FROM clientes GROUP BY cidade HAVING COUNT(*) &gt; 10;\nclientes %&gt;% group_by(cidade) %&gt;% summarise(n = n()) %&gt;% filter(n &gt; 10)\n\n\nLEFT JOIN\nSELECT * FROM pedidos p LEFT JOIN clientes c ON p.cliente_id = c.id;\npedidos %&gt;% left_join(clientes, by = c(\"cliente_id\" = \"id\"))"
  },
  {
    "objectID": "apresentações/posts/sql_comandos.html#sql-x-r-dbplyr---parte-5",
    "href": "apresentações/posts/sql_comandos.html#sql-x-r-dbplyr---parte-5",
    "title": "5.1. SQL x R (dbplyr)",
    "section": "SQL x R (dbplyr) - Parte 5",
    "text": "SQL x R (dbplyr) - Parte 5\n\n\n\n\n\n\n\n\nTarefa\nSQL\nR (dbplyr)\n\n\n\n\nCASE WHEN\nSELECT nome, CASE WHEN idade &lt; 18 THEN 'Menor' ELSE 'Adulto' END AS faixa FROM clientes;\nclientes %&gt;% mutate(faixa = case_when(idade &lt; 18 ~ \"Menor\", TRUE ~ \"Adulto\"))\n\n\nSubconsulta\nSELECT * FROM produtos WHERE preco &gt; (SELECT AVG(preco) FROM produtos);\nmedia_preco &lt;- produtos %&gt;% summarise(m = mean(preco)) %&gt;% pull(m); produtos %&gt;% filter(preco &gt; media_preco)"
  },
  {
    "objectID": "apresentações/posts/sql_comandos.html#sql-x-r-dbplyr---parte-6",
    "href": "apresentações/posts/sql_comandos.html#sql-x-r-dbplyr---parte-6",
    "title": "5.1. SQL x R (dbplyr)",
    "section": "SQL x R (dbplyr) - Parte 6",
    "text": "SQL x R (dbplyr) - Parte 6\n\n\n\n\n\n\n\n\nTarefa\nSQL\nR (dbplyr)\n\n\n\n\nOperações com Strings\nSELECT UPPER(nome), LENGTH(descricao) FROM produtos WHERE nome LIKE '%Café%';\nprodutos %&gt;% filter(str_detect(nome, \"Café\")) %&gt;% mutate(nome_upper = str_to_upper(nome), tam_desc = str_length(descricao))\n\n\nUNION\nSELECT nome FROM clientes_sp UNION SELECT nome FROM clientes_rj;\nunion_all(clientes_sp, clientes_rj) %&gt;% distinct(nome)"
  },
  {
    "objectID": "apresentações/posts/sql_comandos.html#sql-x-r-dbplyr---parte-7",
    "href": "apresentações/posts/sql_comandos.html#sql-x-r-dbplyr---parte-7",
    "title": "5.1. SQL x R (dbplyr)",
    "section": "SQL x R (dbplyr) - Parte 7",
    "text": "SQL x R (dbplyr) - Parte 7\n\n\n\n\n\n\n\n\nTarefa\nSQL\nR (dbplyr)\n\n\n\n\nWindow Functions\nSELECT nome, salario, RANK() OVER (ORDER BY salario DESC) FROM funcionarios;\nfuncionarios %&gt;% mutate(rank = min_rank(desc(salario)))\n\n\nExecutar Query e Coletar Dados\n-- Execução automática ao rodar SELECT\nresultado &lt;- vendas %&gt;% filter(valor &gt; 100) %&gt;% collect()"
  },
  {
    "objectID": "apresentações/posts/sql_comandos.html#sql-x-r-dbplyr---parte-8",
    "href": "apresentações/posts/sql_comandos.html#sql-x-r-dbplyr---parte-8",
    "title": "5.1. SQL x R (dbplyr)",
    "section": "SQL x R (dbplyr) - Parte 8",
    "text": "SQL x R (dbplyr) - Parte 8\n\n\n\n\n\n\n\n\nTarefa\nSQL\nR (dbplyr)\n\n\n\n\nVer SQL Traduzido\n-- SQL é a linguagem original\nvendas %&gt;% filter(valor &gt; 100) %&gt;% show_query()"
  },
  {
    "objectID": "apresentações/posts/sql_comandos.html#obrigada",
    "href": "apresentações/posts/sql_comandos.html#obrigada",
    "title": "5.1. SQL x R (dbplyr)",
    "section": "Obrigada!",
    "text": "Obrigada!\n\nImagem: Allison Horst.Continue praticando e explorando!\nEsta apresentação é parte do projeto Café com R!É OPEN, USE, COMPARTILHE!"
  },
  {
    "objectID": "apresentações/posts/sql_comandos.html#assine-o-café-com-r-1",
    "href": "apresentações/posts/sql_comandos.html#assine-o-café-com-r-1",
    "title": "5.1. SQL x R (dbplyr)",
    "section": "☕ Assine o Café com R",
    "text": "☕ Assine o Café com R\nFique por dentro das aulas, conteúdos, newsletter!\n\nQue cada gole desperte uma nova ideia.\nQue cada script abra uma nova conversa.\nQue o Café com R, se torne um ponto de encontro nosso!"
  },
  {
    "objectID": "apresentações/posts/tidymodels_documentacao.html",
    "href": "apresentações/posts/tidymodels_documentacao.html",
    "title": "7.1. Documentação: Tidymodels para Regressão em R",
    "section": "",
    "text": "Introdução ao Tidymodels\nPacotes Principais\nFunções de Divisão de Dados\nRecipes - Pré-processamento\nParsnip - Especificação de Modelos\nWorkflows - Pipelines\nMétricas de Avaliação\nValidação Cruzada\nModelos Avançados\n\n\n\n\n\nO tidymodels é um meta-pacote (coleção de pacotes) que fornece uma interface unificada para modelagem estatística e machine learning em R, seguindo os princípios do tidyverse.\n\n\n\n\nCode\ninstall.packages(\"tidymodels\")\nlibrary(tidymodels)\n\n\nCarrega automaticamente:\n\nrsample - divisão de dados\nrecipes - pré-processamento\nparsnip - especificação de modelos\nworkflows - combinação de receitas e modelos\nyardstick - métricas de avaliação\ntune - ajuste de hiperparâmetros\ndials - parâmetros de ajuste\nbroom - organização de resultados\n\n\n\n\n\n\n\n\n\n\nPacote: rsample\nFunção: Divide os dados em conjuntos de treino e teste\n\n\nCode\names_split &lt;- initial_split(ames, prop = 0.75)\n\n\nParâmetros:\n\ndata: dataset a ser dividido\nprop: proporção para treino (padrão: 0.75 = 75%)\nstrata: variável para estratificação (mantém distribuição)\n\nRetorna: objeto rsplit com informações sobre a divisão\nExemplo estratificado:\n\n\nCode\n# Mantém distribuição da variável resposta\names_split &lt;- initial_split(ames, prop = 0.75, strata = Sale_Price)\n\n\n\n\n\nFunção: Extrai os conjuntos de treino e teste\n\n\nCode\names_train &lt;- training(ames_split)\names_test &lt;- testing(ames_split)\n\n\nRetorna: tibble/data.frame com os dados correspondentes\nNotas importantes:\n\nA função initial_split() usa amostragem aleatória simples ou estratificada\nO objeto rsplit armazena apenas índices, não duplica os dados\nSempre use set.seed() antes para reprodutibilidade\n\n\n\n\n\n\nPacote: rsample\nFunção: Cria folds para validação cruzada k-fold\n\n\nCode\names_folds &lt;- vfold_cv(ames_train, v = 10)\n\n\nParâmetros:\n\ndata: dados de treino\nv: número de folds (padrão: 10)\nstrata: variável para estratificação\nrepeats: número de repetições\n\nComo funciona:\n\nDivide os dados em v partes aproximadamente iguais\nCada fold serve como teste uma vez\nOs outros v-1 folds servem como treino\nReduz viés da divisão única treino/teste\n\nInterpretação:\n\nCom v=10: 90% treino, 10% teste em cada iteração\nMais folds = mais computação, menos variância\nv=5 ou v=10 são escolhas comuns\nv = n (Leave-One-Out) é computacionalmente caro\n\nOutras funções de reamostragem:\n\n\nCode\n# Bootstrap\nbootstraps(ames_train, times = 25)\n\n# Monte Carlo (divisões aleatórias)\nmc_cv(ames_train, prop = 0.75, times = 20)\n\n# Validação cruzada repetida\nvfold_cv(ames_train, v = 10, repeats = 5)\n\n\n\n\n\n\n\n\n\nPacote: recipes\nFunção: Cria uma “receita” de pré-processamento\n\n\nCode\names_recipe &lt;- recipe(Sale_Price ~ Gr_Liv_Area + Year_Built, \n                      data = ames_train)\n\n\nParâmetros:\n\nformula: fórmula modelo (resposta ~ preditoras)\ndata: dados de referência (apenas estrutura)\nUsa . para incluir todas as variáveis: Sale_Price ~ .\n\nImportante: A recipe apenas DEFINE os passos, não os executa\nFluxo de trabalho com recipes:\n\nrecipe() - define a receita\nstep_*() - adiciona passos de transformação\nprep() - prepara a receita (calcula parâmetros nos dados de treino)\nbake() - aplica a receita preparada a novos dados\n\nQuando usado dentro de um workflow, prep() e bake() são chamados automaticamente.\n\n\n\n\n\n\nFunção: Padroniza variáveis (z-score: média=0, desvio=1)\n\n\nCode\nrecipe(...) %&gt;%\n  step_normalize(all_numeric_predictors())\n\n\nFórmula: (x - média) / desvio_padrão\nQuando usar:\n\nModelos sensíveis a escala (regressão regularizada, SVM, KNN)\nVariáveis em escalas muito diferentes\nMelhora convergência de algoritmos\nFacilita interpretação de coeficientes em modelos regularizados\n\nSeletores disponíveis:\n\nall_numeric_predictors(): todas numéricas preditoras\nall_nominal_predictors(): todas categóricas\nall_predictors(): todas as preditoras\nall_outcomes(): variável resposta\nOu especificar variáveis: step_normalize(Gr_Liv_Area, Lot_Area)\n\nAlternativa - step_range():\n\n\nCode\n# Normalização min-max (escala 0-1)\nrecipe(...) %&gt;%\n  step_range(all_numeric_predictors(), min = 0, max = 1)\n\n\n\n\n\nFunção: Cria variáveis dummy para categóricas\n\n\nCode\nrecipe(...) %&gt;%\n  step_dummy(all_nominal_predictors())\n\n\nComo funciona:\n\nConverte categoria em variáveis binárias (0/1)\nPara k categorias, cria k-1 variáveis (evita multicolinearidade)\nExemplo: Bldg_Type com 5 níveis gera 4 variáveis dummy\nA categoria de referência é implícita (todas dummies = 0)\n\nParâmetros:\n\none_hot: TRUE para criar k variáveis (ao invés de k-1)\nnaming: função para nomear as novas variáveis\n\nImportante: Sempre aplique após transformações numéricas e antes de interações\n\n\n\nFunção: Aplica transformação logarítmica\n\n\nCode\nrecipe(...) %&gt;%\n  step_log(Sale_Price, base = 10)\n\n\nQuando usar:\n\nDados com distribuição assimétrica positiva (cauda à direita)\nPresença de outliers\nRelações exponenciais entre variáveis\nReduzir heteroscedasticidade\nBase 10 ou base e (natural) - log natural é padrão\n\nCuidado:\n\nNão aceita valores &lt;= 0\nUse offset para lidar com zeros: step_log(var, offset = 1)\nLembre-se de reverter a transformação ao interpretar predições\n\nAlternativas:\n\n\nCode\n# Transformação Box-Cox (escolhe melhor lambda)\nrecipe(...) %&gt;%\n  step_BoxCox(all_numeric_predictors())\n\n# Raiz quadrada\nrecipe(...) %&gt;%\n  step_sqrt(all_numeric_predictors())\n\n\n\n\n\nFunção: Imputa valores faltantes (NA)\n\n\nCode\nrecipe(...) %&gt;%\n  step_impute_mean(all_numeric_predictors()) %&gt;%\n  step_impute_mode(all_nominal_predictors())\n\n\nTipos de imputação:\n\nstep_impute_mean(): média (sensível a outliers)\nstep_impute_median(): mediana (robusta a outliers)\nstep_impute_mode(): moda (para categóricas)\nstep_impute_knn(): k vizinhos mais próximos (preserva relações)\nstep_impute_linear(): regressão linear\nstep_impute_bag(): bagged trees\n\nExemplo KNN:\n\n\nCode\nrecipe(...) %&gt;%\n  step_impute_knn(all_predictors(), neighbors = 5)\n\n\nConsiderações:\n\nImputação deve ser feita antes da normalização\nPara grandes quantidades de NAs, considere criar indicador de missing\nstep_indicate_na() cria variável binária indicando se havia NA\n\n\n\n\nFunção: Análise de Componentes Principais\n\n\nCode\nrecipe(...) %&gt;%\n  step_pca(all_numeric_predictors(), num_comp = 5)\n\n\nQuando usar:\n\nRedução de dimensionalidade\nMulticolinearidade severa\nMuitas variáveis correlacionadas\nVisualização de dados de alta dimensão\n\nParâmetros:\n\nnum_comp: número de componentes a manter\nthreshold: variância explicada mínima acumulada\noptions: lista com opções adicionais\n\nImportante:\n\nPCA é sensível à escala - sempre normalize antes\nComponentes são combinações lineares das variáveis originais\nPerda de interpretabilidade\n\n\n\nCode\n# Exemplo mantendo 95% da variância\nrecipe(...) %&gt;%\n  step_normalize(all_numeric_predictors()) %&gt;%\n  step_pca(all_numeric_predictors(), threshold = 0.95)\n\n\n\n\n\nTratamento de outliers:\n\n\nCode\n# Remove observações com valores extremos\nrecipe(...) %&gt;%\n  step_filter_missing(all_predictors(), threshold = 0.5) %&gt;%\n  step_nzv(all_predictors())  # Remove variáveis com variância próxima a zero\n\n\nInterações:\n\n\nCode\nrecipe(...) %&gt;%\n  step_interact(terms = ~ Gr_Liv_Area:Year_Built)\n\n\nPolinômios:\n\n\nCode\nrecipe(...) %&gt;%\n  step_poly(Gr_Liv_Area, degree = 2)  # Adiciona termo quadrático\n\n\nBinning:\n\n\nCode\n# Discretiza variável contínua\nrecipe(...) %&gt;%\n  step_cut(Year_Built, breaks = c(1950, 1980, 2000))\n\n\n\n\n\n\n\n\n\n\nPacote: parsnip\nFunção: Especifica modelo de regressão linear\n\n\nCode\nlm_model &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  set_mode(\"regression\")\n\n\nComponentes:\n\n\nDefine o pacote/função R que executará o modelo\nEngines disponíveis para linear_reg():\n\n\"lm\": regressão linear padrão (stats::lm)\n\"glmnet\": Ridge, Lasso, Elastic Net\n\"stan\": abordagem Bayesiana\n\"keras\": redes neurais\n\"spark\": para processamento distribuído\n\nArgumentos específicos do engine:\n\n\nCode\nlinear_reg() %&gt;%\n  set_engine(\"glmnet\", lambda = 0.01)\n\n\n\n\n\nDefine o tipo de problema\n\n\"regression\": para variável resposta contínua\n\"classification\": para variável resposta categórica\n\nNota: Para linear_reg(), o modo é sempre “regression”\nParâmetros de regularização:\n\n\nCode\nlinear_reg(penalty = 0.01, mixture = 0) # Ridge\nlinear_reg(penalty = 0.01, mixture = 1) # Lasso\nlinear_reg(penalty = 0.01, mixture = 0.5) # Elastic Net\n\n\nParâmetros:\n\npenalty: força da regularização (lambda)\n\n0 = sem regularização (OLS padrão)\nValores maiores = mais regularização\nTípico: 0.001 a 1.0\n\nmixture: tipo de penalização\n\n0 = Ridge (L2): reduz coeficientes, nunca zera\n1 = Lasso (L1): pode zerar coeficientes\n0-1 = Elastic Net: combinação de ambos\n\n\nInterpretação:\n\nRidge (L2): útil quando todas variáveis são relevantes, reduz coeficientes proporcionalmente\nLasso (L1): útil para seleção de variáveis, pode eliminar preditores irrelevantes\nElastic Net: combina vantagens de ambos, ideal quando há grupos de variáveis correlacionadas\n\nComparação Ridge vs Lasso:\n\n\n\n\n\n\n\n\nAspecto\nRidge\nLasso\n\n\n\n\nPenalização\nL2 (soma dos quadrados)\nL1 (soma dos valores absolutos)\n\n\nSeleção de variáveis\nNão\nSim\n\n\nCoeficientes\nReduz, nunca zera\nPode zerar\n\n\nMulticolinearidade\nLida bem\nSeleciona uma variável do grupo\n\n\nInterpretabilidade\nMenos\nMais (modelo esparso)\n\n\n\n\n\n\n\n\nPacote: parsnip\nFunção: Especifica modelo Random Forest\n\n\nCode\nrf_model &lt;- rand_forest(trees = 500) %&gt;%\n  set_engine(\"ranger\") %&gt;%\n  set_mode(\"regression\")\n\n\nParâmetros principais:\n\ntrees: número de árvores (padrão: 500)\n\nMais árvores = mais estável, mas mais lento\nTípico: 500 a 2000\n\nmtry: variáveis consideradas em cada divisão\n\nPadrão: sqrt(p) para classificação, p/3 para regressão\nControla correlação entre árvores\n\nmin_n: observações mínimas por nó terminal\n\nPadrão: varia por engine\nMaior = menos complexidade, menos overfitting\n\n\nEngines disponíveis:\n\n\"ranger\": rápido e eficiente (recomendado)\n\"randomForest\": implementação clássica\n\"spark\": para big data\n\nExemplo com todos os parâmetros:\n\n\nCode\nrf_spec &lt;- rand_forest(\n  trees = 1000,\n  mtry = 5,\n  min_n = 10\n) %&gt;%\n  set_engine(\"ranger\", importance = \"impurity\") %&gt;%\n  set_mode(\"regression\")\n\n\nComo funciona:\n\nCria múltiplas árvores de decisão\nCada árvore usa amostra bootstrap dos dados (com reposição)\nCada divisão considera subconjunto aleatório de variáveis (mtry)\nPredição = média das predições de todas árvores (regressão)\nOut-of-bag (OOB) error é calculado automaticamente\n\nVantagens:\n\nNão requer normalização de variáveis\nLida bem com não-linearidades e interações\nRobusto a outliers\nFornece importância de variáveis\nBaixo risco de overfitting (com árvores suficientes)\n\nDesvantagens:\n\nMenos interpretável que modelos lineares\nMais lento que regressão linear\nPode ter dificuldade com extrapolação\nRequer mais memória\n\nConfigurações específicas do ranger:\n\n\nCode\nrf_spec &lt;- rand_forest(trees = 1000) %&gt;%\n  set_engine(\n    \"ranger\",\n    importance = \"impurity\",  # ou \"permutation\"\n    num.threads = 4,          # paralelização\n    verbose = FALSE,\n    seed = 123\n  ) %&gt;%\n  set_mode(\"regression\")\n\n\n\n\n\n\n\n\n\n\nCode\nboost_spec &lt;- boost_tree(\n  trees = 1000,\n  tree_depth = 6,\n  learn_rate = 0.01\n) %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"regression\")\n\n\nQuando usar: Geralmente superior em competições, excelente performance\n\n\n\n\n\nCode\ntree_spec &lt;- decision_tree(\n  cost_complexity = 0.01,\n  tree_depth = 10,\n  min_n = 20\n) %&gt;%\n  set_engine(\"rpart\") %&gt;%\n  set_mode(\"regression\")\n\n\nQuando usar: Interpretabilidade máxima, baseline simples\n\n\n\n\n\nCode\nsvm_spec &lt;- svm_rbf(\n  cost = 1,\n  rbf_sigma = 0.1\n) %&gt;%\n  set_engine(\"kernlab\") %&gt;%\n  set_mode(\"regression\")\n\n\nQuando usar: Dados não-lineares, dimensionalidade média\n\n\n\n\n\nCode\nnn_spec &lt;- mlp(\n  hidden_units = 10,\n  penalty = 0.01,\n  epochs = 100\n) %&gt;%\n  set_engine(\"nnet\") %&gt;%\n  set_mode(\"regression\")\n\n\nQuando usar: Padrões complexos, muitos dados disponíveis\n\n\n\n\n\n\n\n\nPacote: workflows\nFunção: Combina recipe e modelo em pipeline único\n\n\nCode\names_workflow &lt;- workflow() %&gt;%\n  add_recipe(ames_recipe) %&gt;%\n  add_model(lm_model)\n\n\nVantagens:\n\nGarante que pré-processamento seja aplicado consistentemente\nFacilita experimentação com diferentes combinações\nReduz erros (evita vazamento de dados - data leakage)\nCódigo mais limpo e organizado\nSimplifica deploy do modelo\n\nFluxo de trabalho:\n\nCrie recipe e modelo separadamente\nCombine em workflow\nAjuste o workflow (não componentes individuais)\nUse o workflow ajustado para predições\n\nComponentes:\n\n\nAdiciona recipe de pré-processamento\n\n\nCode\nworkflow() %&gt;%\n  add_recipe(my_recipe)\n\n\n\n\n\nAdiciona especificação do modelo\n\n\nCode\nworkflow() %&gt;%\n  add_model(my_model)\n\n\n\n\n\nAlternativa a recipe para casos simples (sem pré-processamento complexo)\n\n\nCode\nworkflow() %&gt;%\n  add_formula(Sale_Price ~ Gr_Liv_Area + Year_Built) %&gt;%\n  add_model(lm_model)\n\n\nQuando usar formula vs recipe:\n\nFormula: casos simples, sem transformações\nRecipe: pré-processamento complexo, padronização, imputação, etc.\n\n\n\n\nAlternativa mais flexível\n\n\nCode\nworkflow() %&gt;%\n  add_variables(\n    outcomes = Sale_Price,\n    predictors = c(Gr_Liv_Area, Year_Built)\n  ) %&gt;%\n  add_model(lm_model)\n\n\nInspecionando workflows:\n\n\nCode\n# Ver estrutura\names_workflow\n\n# Extrair componentes\nextract_spec_parsnip(ames_workflow)\nextract_recipe(ames_workflow)\n\n\n\n\n\n\n\nFunção: Treina o workflow nos dados\n\n\nCode\names_fit &lt;- ames_workflow %&gt;%\n  fit(data = ames_train)\n\n\nO que acontece:\n\nPrepara a recipe nos dados de treino (calcula médias, desvios, etc.)\nAplica transformações aos dados de treino\nTreina o modelo com dados transformados\nArmazena recipe preparada e modelo treinado\n\nRetorna: workflow treinado (fitted workflow)\nImportante:\n\nfit() sempre usa os dados fornecidos para preparar a recipe\nA recipe preparada será aplicada automaticamente a novos dados\nNunca faça fit() nos dados de teste\n\nVerificando o ajuste:\n\n\nCode\n# Ver sumário\names_fit\n\n# Extrair modelo ajustado\names_fit %&gt;%\n  extract_fit_parsnip()\n\n# Ver coeficientes\names_fit %&gt;%\n  extract_fit_parsnip() %&gt;%\n  tidy()\n\n\n\n\n\n\nFunção: Treina o workflow com validação cruzada\n\n\nCode\ncv_results &lt;- ames_workflow %&gt;%\n  fit_resamples(ames_folds)\n\n\nParâmetros:\n\nresamples: objeto vfold_cv ou outro tipo de reamostragem\nmetrics: métricas a calcular (padrão: rmse e rsq)\ncontrol: controles adicionais\n\nControles úteis:\n\n\nCode\ncv_results &lt;- ames_workflow %&gt;%\n  fit_resamples(\n    resamples = ames_folds,\n    metrics = metric_set(rmse, rsq, mae),\n    control = control_resamples(\n      save_pred = TRUE,      # Salvar predições\n      verbose = TRUE,        # Mostrar progresso\n      allow_par = TRUE       # Permitir paralelização\n    )\n  )\n\n\nRetorna: objeto com resultados de todos os folds\nPara coletar resultados:\n\n\nCode\n# Métricas agregadas\ncollect_metrics(cv_results)\n\n# Métricas por fold\ncollect_metrics(cv_results, summarize = FALSE)\n\n# Predições de cada fold\ncollect_predictions(cv_results)\n\n# Notas sobre folds\ncollect_notes(cv_results)\n\n\nInterpretação dos resultados:\n\n\nCode\n# Exemplo de output\n# # A tibble: 2 × 6\n#   .metric .estimator  mean     n std_err .config             \n#   &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n# 1 rmse    standard   30456    10    1234 Preprocessor1_Model1\n# 2 rsq     standard    0.81    10    0.02 Preprocessor1_Model1\n\n\n\nmean: performance média nos 10 folds\nn: número de folds\nstd_err: erro padrão (variabilidade entre folds)\n\nVantagens do fit_resamples():\n\nEstimativa mais confiável da performance\nDetecta overfitting antes do teste final\nPermite comparar modelos de forma justa\nNão “gasta” os dados de teste\n\n\n\n\n\nFunção: Faz predições com modelo treinado\n\n\nCode\names_pred &lt;- predict(ames_fit, ames_test)\n\n\nRetorna: tibble com coluna .pred\nTipos de predição:\n\n\nCode\n# Predições pontuais (padrão)\npredict(ames_fit, new_data, type = \"numeric\")\n\n# Intervalo de confiança\npredict(ames_fit, new_data, type = \"conf_int\", level = 0.95)\n\n# Intervalo de predição (quando disponível)\npredict(ames_fit, new_data, type = \"pred_int\", level = 0.95)\n\n\nExemplo completo com teste:\n\n\nCode\n# Predições\ntest_pred &lt;- predict(ames_fit, ames_test)\n\n# Adicionar aos dados originais\ntest_results &lt;- ames_test %&gt;%\n  select(Sale_Price) %&gt;%\n  bind_cols(test_pred)\n\n# Com intervalos\ntest_pred_int &lt;- predict(ames_fit, ames_test, type = \"conf_int\")\n\ntest_results_full &lt;- ames_test %&gt;%\n  select(Sale_Price) %&gt;%\n  bind_cols(test_pred) %&gt;%\n  bind_cols(test_pred_int)\n\n\nPredições em novos dados:\n\n\nCode\n# Criar novo dado\nnova_casa &lt;- tibble(\n  Gr_Liv_Area = 2000,\n  Year_Built = 2010,\n  Garage_Area = 500,\n  Total_Bsmt_SF = 1200\n)\n\n# Predição\npredict(ames_fit, nova_casa)\n\n\nImportante:\n\nNovos dados devem ter mesmas colunas usadas no treino\nA recipe preparada será aplicada automaticamente\nTransformações são consistentes com o treino\n\n\n\n\n\n\n\nExtrai o modelo parsnip do workflow\n\n\nCode\nmodelo_parsnip &lt;- ames_fit %&gt;%\n  extract_fit_parsnip()\n\n\nUso: Acessar modelo para inspeção, importância de variáveis, etc.\n\n\n\nExtrai o modelo do engine original (ex: objeto lm)\n\n\nCode\nmodelo_lm &lt;- ames_fit %&gt;%\n  extract_fit_engine()\n\n# Acessa métodos específicos do lm\nsummary(modelo_lm)\nplot(modelo_lm)\n\n\n\n\n\nExtrai a recipe preparada\n\n\nCode\nrecipe_preparada &lt;- ames_fit %&gt;%\n  extract_recipe()\n\n# Inspecionar passos\nrecipe_preparada %&gt;%\n  tidy()\n\n\n\n\n\nExtrai o pré-processador (recipe ou formula)\n\n\nCode\npreprocessor &lt;- ames_fit %&gt;%\n  extract_preprocessor()\n\n\n\n\n\nPacote: broom\nFunção: Organiza coeficientes em tibble\n\n\nCode\names_fit %&gt;%\n  extract_fit_parsnip() %&gt;%\n  tidy()\n\n\nRetorna: tibble com:\n\nterm: nome da variável\nestimate: coeficiente estimado\nstd.error: erro padrão\nstatistic: estatística t\np.value: p-valor\n\nTambém funciona com recipes:\n\n\nCode\n# Ver transformações aplicadas\names_fit %&gt;%\n  extract_recipe() %&gt;%\n  tidy()\n\n# Ver transformações de um step específico\names_fit %&gt;%\n  extract_recipe() %&gt;%\n  tidy(number = 1)  # Primeiro step\n\n\n\n\n\nSumário do modelo em uma linha\n\n\nCode\names_fit %&gt;%\n  extract_fit_parsnip() %&gt;%\n  glance()\n\n\nRetorna: R², AIC, BIC, sigma, etc. (dependendo do modelo)\n\n\n\nAdiciona predições e resíduos aos dados\n\n\nCode\names_fit %&gt;%\n  extract_fit_engine() %&gt;%\n  augment()\n\n\nRetorna: dados originais com .fitted, .resid, etc.\n\n\n\n\n\n\n\n\nPacote: yardstick\nFunção: Calcula métricas de performance\n\n\nCode\names_results %&gt;%\n  metrics(truth = Sale_Price, estimate = .pred)\n\n\nParâmetros:\n\ntruth: valores reais (observados)\nestimate: valores preditos\n\nRetorna (regressão):\n\nrmse: Root Mean Squared Error\nrsq: R-squared\nmae: Mean Absolute Error\n\nExemplo completo:\n\n\nCode\n# Criar resultados\ntest_results &lt;- ames_test %&gt;%\n  select(Sale_Price) %&gt;%\n  bind_cols(predict(ames_fit, ames_test))\n\n# Calcular métricas\ntest_results %&gt;%\n  metrics(truth = Sale_Price, estimate = .pred)\n\n\n\n\n\n\n\n\nFórmula: √(Σ(real - predito)² / n)\nInterpretação:\n\nErro médio em unidades originais da variável resposta\nPenaliza erros grandes mais fortemente devido ao quadrado\nExemplo: RMSE = $30,000 significa erro médio de $30k\nMais sensível a outliers que MAE\n\nQuando menor, melhor\nPropriedades:\n\nSempre não-negativo\nMesmo erro em qualquer direção (sub ou superestimação)\nÚtil quando erros grandes são particularmente indesejáveis\n\n\n\n\nFórmula: 1 - (SS_res / SS_tot)\nOnde:\n\nSS_res = Σ(real - predito)² (soma dos quadrados dos resíduos)\nSS_tot = Σ(real - média)² (soma total dos quadrados)\n\nInterpretação:\n\nProporção da variância explicada pelo modelo\nVaria de 0 a 1 (0% a 100%)\nR² = 0.8 significa que o modelo explica 80% da variabilidade dos dados\n\nValores típicos:\n\n&lt; 0.3: fraco\n0.3-0.5: moderado\n0.5-0.7: bom\n0.7-0.9: muito bom\n\n0.9: excelente (cuidado com overfitting)\n\n\nLimitações:\n\nPode ser enganoso com dados não-lineares\nNão indica se o modelo está enviesado\nR² ajustado penaliza complexidade excessiva\n\n\n\n\nFórmula: Σ|real - predito| / n\nInterpretação:\n\nErro médio absoluto\nMais robusto a outliers que RMSE\nMesmo que RMSE, em unidades originais da resposta\nTodos os erros têm peso igual\n\nQuando usar:\n\nQuando outliers não devem dominar a métrica\nPara comunicação mais intuitiva com não-técnicos\nQuando erros grandes e pequenos são igualmente importantes\n\nComparação RMSE vs MAE:\n\nSe RMSE &gt;&gt; MAE: muitos outliers ou erros grandes\nSe RMSE ≈ MAE: erros bem distribuídos\nRMSE sempre &gt;= MAE\n\n\n\n\nFórmula: (100/n) × Σ|real - predito| / |real|\nInterpretação:\n\nErro percentual médio\nIndependente da escala\nÚtil para comparar modelos em diferentes contextos\n\nLimitações:\n\nIndefinido quando valores reais são zero\nAssimétrico: penaliza mais sub-predições que sobre-predições\nSensível a valores reais pequenos\n\n\n\n\n\n\n\n\n\n\nCode\n# RMSE\names_results %&gt;% \n  rmse(truth = Sale_Price, estimate = .pred)\n\n# R²\names_results %&gt;% \n  rsq(truth = Sale_Price, estimate = .pred)\n\n# MAE\names_results %&gt;% \n  mae(truth = Sale_Price, estimate = .pred)\n\n# MAPE\names_results %&gt;% \n  mape(truth = Sale_Price, estimate = .pred)\n\n\n\n\n\n\n\nCode\n# Definir conjunto de métricas\nmy_metrics &lt;- metric_set(rmse, rsq, mae, mape)\n\n# Aplicar\names_results %&gt;%\n  my_metrics(truth = Sale_Price, estimate = .pred)\n\n\nVantagem: Calcular todas de uma vez, consistente em todo o código\nOutras métricas úteis para regressão:\n\n\nCode\n# MASE - Mean Absolute Scaled Error\names_results %&gt;%\n  mase(truth = Sale_Price, estimate = .pred)\n\n# CCC - Concordance Correlation Coefficient\names_results %&gt;%\n  ccc(truth = Sale_Price, estimate = .pred)\n\n# SMAPE - Symmetric MAPE\names_results %&gt;%\n  smape(truth = Sale_Price, estimate = .pred)\n\n# Huber Loss (robusto a outliers)\names_results %&gt;%\n  huber_loss(truth = Sale_Price, estimate = .pred)\n\n\nCriando métricas customizadas:\n\n\nCode\n# Exemplo: erro percentual médio\nmpe &lt;- function(data, truth, estimate) {\n  metric_summarizer(\n    metric_nm = \"mpe\",\n    metric_fn = function(truth, estimate) {\n      mean((truth - estimate) / truth) * 100\n    },\n    data = data,\n    truth = !! enquo(truth),\n    estimate = !! enquo(estimate)\n  )\n}\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ncv_results &lt;- ames_workflow %&gt;%\n  fit_resamples(ames_folds)\n\ncollect_metrics(cv_results)\n\n\nColunas retornadas:\n\n.metric: nome da métrica\nmean: média entre folds\nn: número de folds\nstd_err: erro padrão da média\n.config: configuração do modelo\n\nInterpretação:\n\nmean: performance esperada em novos dados\nstd_err: variabilidade entre folds\n\nBaixo = modelo estável\nAlto = modelo sensível aos dados específicos\n\n\nExemplo de output:\n# A tibble: 2 × 6\n  .metric .estimator  mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   30456    10    1234 Preprocessor1_Model1\n2 rsq     standard    0.81    10    0.02 Preprocessor1_Model1\nLeitura:\n\nRMSE médio de $30,456 com variação de $1,234 entre folds\nR² médio de 0.81 (81% da variância explicada)\nBaixo std_err indica consistência do modelo\n\n\n\n\n\n\nCode\n# Métricas por fold individual\ncv_results %&gt;%\n  collect_metrics(summarize = FALSE)\n\n# Predições por fold\ncv_results %&gt;%\n  collect_predictions()\n\n# Visualizar variabilidade\ncv_results %&gt;%\n  collect_metrics(summarize = FALSE) %&gt;%\n  ggplot(aes(x = id, y = .estimate)) +\n  geom_point() +\n  facet_wrap(~ .metric, scales = \"free_y\") +\n  labs(x = \"Fold\", y = \"Valor da Métrica\")\n\n\n\n\n\n\n\n\n\nCode\n# 10-fold CV repetido 5 vezes\names_folds_rep &lt;- vfold_cv(ames_train, v = 10, repeats = 5)\n\ncv_results_rep &lt;- ames_workflow %&gt;%\n  fit_resamples(ames_folds_rep)\n\n\nVantagem: Estimativa ainda mais estável, reduz viés da divisão específica\n\n\n\n\n\nCode\n# 25 amostras bootstrap\names_boots &lt;- bootstraps(ames_train, times = 25)\n\nboot_results &lt;- ames_workflow %&gt;%\n  fit_resamples(ames_boots)\n\n\nQuando usar:\n\nDatasets pequenos\nEstimativa de variância dos coeficientes\nIntervalos de confiança\n\n\n\n\n\n\nCode\n# 20 divisões aleatórias 75/25\names_mc &lt;- mc_cv(ames_train, prop = 0.75, times = 20)\n\nmc_results &lt;- ames_workflow %&gt;%\n  fit_resamples(ames_mc)\n\n\nQuando usar: Alternativa ao k-fold quando divisões aleatórias são preferíveis\n\n\n\n\n\nCode\n# Para dados temporais\nlibrary(timetk)\n\n# Rolling window\names_rolls &lt;- rolling_origin(\n  ames_train,\n  initial = 1000,\n  assess = 250,\n  cumulative = FALSE\n)\n\n\nQuando usar: Dados de séries temporais, respeita ordem temporal\n\n\n\n\n\n\nCode\n# Estratifica por quantis da resposta\names_folds_strat &lt;- vfold_cv(\n  ames_train, \n  v = 10, \n  strata = Sale_Price\n)\n\n\nBenefícios:\n\nMantém distribuição da variável resposta em todos os folds\nEspecialmente importante com distribuições assimétricas\nReduz variabilidade entre folds\n\nQuando usar estratificação:\n\nVariável resposta com distribuição não-uniforme\nDatasets pequenos\nPresença de valores raros ou extremos\n\n\n\n\n\n\n\n\n\n\nPacote: vip\nFunção: Visualiza importância das variáveis\n\n\nCode\nlibrary(vip)\n\n# Para modelos baseados em árvores\nrf_fit %&gt;%\n  extract_fit_parsnip() %&gt;%\n  vip(num_features = 10)\n\n# Para regressão linear\nlm_fit %&gt;%\n  extract_fit_parsnip() %&gt;%\n  vip(num_features = 10)\n\n\nComo funciona por tipo de modelo:\n\nRegressão Linear: valor absoluto dos coeficientes padronizados\nRandom Forest: redução média na impureza (MSE) ou permutação\nLasso: valores absolutos dos coeficientes não-zero\nGradient Boosting: ganho total ou frequência de uso\n\nTipos de importância:\n\n\nCode\n# Importância por impureza (padrão para RF)\nrf_fit %&gt;%\n  extract_fit_parsnip() %&gt;%\n  vip(method = \"model\")\n\n# Importância por permutação (mais confiável, mais lento)\nrf_fit %&gt;%\n  extract_fit_parsnip() %&gt;%\n  vip(method = \"permute\", \n      target = \"Sale_Price\", \n      metric = \"rmse\",\n      pred_wrapper = predict)\n\n\nInterpretação:\n\nBarras maiores = variáveis mais importantes para o modelo\nImportância relativa, não absoluta\nÚtil para seleção de features\nPode orientar engenharia de features\n\nCustomização do plot:\n\n\nCode\nrf_fit %&gt;%\n  extract_fit_parsnip() %&gt;%\n  vip(\n    num_features = 15,\n    geom = \"point\",\n    aesthetics = list(color = \"steelblue\", size = 3)\n  ) +\n  labs(title = \"Importância das Variáveis - Random Forest\")\n\n\n\n\n\n\n\nCode\nlibrary(DALEXtra)\n\n# Criar explicador\nexplainer &lt;- explain_tidymodels(\n  rf_fit,\n  data = ames_train %&gt;% select(-Sale_Price),\n  y = ames_train$Sale_Price,\n  label = \"Random Forest\"\n)\n\n# SHAP values\nshap_values &lt;- predict_parts(\n  explainer,\n  new_observation = ames_test[1, ],\n  type = \"shap\"\n)\n\nplot(shap_values)\n\n\nVantagem: Explica contribuição de cada variável para predição individual\n\n\n\n\n\n\n\n\n\nCode\n# Marcar parâmetros para otimização\nrf_spec &lt;- rand_forest(\n  trees = 1000,\n  mtry = tune(),\n  min_n = tune()\n) %&gt;%\n  set_engine(\"ranger\") %&gt;%\n  set_mode(\"regression\")\n\n\nParâmetros que podem ser otimizados:\n\nRandom Forest: mtry, min_n, trees\nGradient Boosting: trees, tree_depth, learn_rate, mtry\nRegularização: penalty, mixture\nSVM: cost, rbf_sigma\nNeural Networks: hidden_units, penalty, epochs\n\n\n\n\n\n\nCode\nlibrary(dials)\n\n# Definir grid de busca\nrf_grid &lt;- grid_regular(\n  mtry(range = c(2, 10)),\n  min_n(range = c(5, 30)),\n  levels = 5  # 5 valores para cada parâmetro = 25 combinações\n)\n\n# Workflow com modelo a ser otimizado\nrf_workflow &lt;- workflow() %&gt;%\n  add_recipe(ames_recipe) %&gt;%\n  add_model(rf_spec)\n\n# Tuning\ntune_results &lt;- tune_grid(\n  rf_workflow,\n  resamples = ames_folds,\n  grid = rf_grid,\n  metrics = metric_set(rmse, rsq, mae),\n  control = control_grid(save_pred = TRUE, verbose = TRUE)\n)\n\n\nTipos de grid:\n\n\nCode\n# Grid regular (espaçamento uniforme)\ngrid_regular(mtry(), min_n(), levels = 5)\n\n# Grid aleatório (mais pontos, menos estruturado)\ngrid_random(mtry(), min_n(), size = 50)\n\n# Grid específico (manual)\ngrid_manual &lt;- tibble(\n  mtry = c(3, 5, 7),\n  min_n = c(10, 20, 30)\n)\n\n# Grid latino hipercubo (boa cobertura do espaço)\ngrid_latin_hypercube(mtry(), min_n(), size = 30)\n\n\n\n\n\n\n\nCode\n# Ver todas as combinações\ncollect_metrics(tune_results)\n\n# Melhores resultados\nshow_best(tune_results, metric = \"rmse\", n = 10)\n\n# Visualizar\nautoplot(tune_results)\n\n# Plot customizado\ntune_results %&gt;%\n  collect_metrics() %&gt;%\n  filter(.metric == \"rmse\") %&gt;%\n  ggplot(aes(x = mtry, y = mean, color = factor(min_n))) +\n  geom_line() +\n  geom_point() +\n  labs(title = \"Performance por Hiperparâmetro\")\n\n\n\n\n\n\n\nCode\n# Melhor por métrica\nbest_params &lt;- select_best(tune_results, metric = \"rmse\")\n\n# Alternativas\nselect_by_pct_loss(tune_results, metric = \"rmse\", limit = 5)\nselect_by_one_std_err(tune_results, metric = \"rmse\")\n\n\n\n\n\n\n\nCode\n# Finalizar com melhores parâmetros\nfinal_workflow &lt;- finalize_workflow(rf_workflow, best_params)\n\n# Treinar modelo final\nfinal_fit &lt;- final_workflow %&gt;%\n  fit(ames_train)\n\n# Avaliar no teste\nfinal_results &lt;- ames_test %&gt;%\n  select(Sale_Price) %&gt;%\n  bind_cols(predict(final_fit, ames_test))\n\nfinal_results %&gt;%\n  metrics(truth = Sale_Price, estimate = .pred)\n\n\n\n\n\n\n\nCode\nlibrary(finetune)\n\n# Mais eficiente que grid search\ntune_bayes_results &lt;- tune_bayes(\n  rf_workflow,\n  resamples = ames_folds,\n  initial = 10,  # Pontos iniciais\n  iter = 30,     # Iterações\n  metrics = metric_set(rmse, rsq),\n  control = control_bayes(verbose = TRUE)\n)\n\n\nVantagem: Explora espaço de hiperparâmetros de forma mais inteligente\n\n\n\n\n\nCode\n# Elimina candidatos ruins rapidamente\ntune_race_results &lt;- tune_race_anova(\n  rf_workflow,\n  resamples = ames_folds,\n  grid = 30,\n  metrics = metric_set(rmse),\n  control = control_race(verbose = TRUE)\n)\n\n\nVantagem: Economiza tempo descartando configurações ruins cedo\n\n\n\n\n\n\n\n\n\nCode\n# Salvar modelo completo\nsaveRDS(ames_fit, \"models/ames_model.rds\")\n\n# Carregar\nloaded_model &lt;- readRDS(\"models/ames_model.rds\")\n\n# Usar imediatamente\npredictions &lt;- predict(loaded_model, ames_test)\n\n\nCaracterísticas do RDS:\n\nFormato nativo do R\nPreserva toda estrutura do objeto\nPortável entre sistemas (mesmo OS/versão R)\nCompacto\n\n\n\n\n\n\nCode\nlibrary(bundle)\n\n# Para modelos que não serializam bem\n# (keras, xgboost, spark, etc.)\nbundled_model &lt;- bundle(ames_fit)\nsaveRDS(bundled_model, \"models/model_bundled.rds\")\n\n# Carregar e desempacotar\nloaded &lt;- readRDS(\"models/model_bundled.rds\")\nunbundled_model &lt;- unbundle(loaded)\n\n# Usar\npredict(unbundled_model, new_data)\n\n\nQuando usar bundle:\n\nModelos com dependências externas (Keras, TensorFlow)\nModelos Spark\nModelos XGBoost\nQuando RDS padrão não funciona\n\n\n\n\n\n\nCode\nlibrary(vetiver)\n\n# Criar versão deployável\nv &lt;- vetiver_model(ames_fit, \"ames_price_model\")\n\n# Salvar\nvetiver_pin_write(board, v)\n\n# Criar API\npr &lt;- pr() %&gt;%\n  vetiver_api(v)\n\n# Rodar servidor\npr_run(pr, port = 8080)\n\n\nVantagem: Framework completo para MLOps\n\n\n\n\n\nCode\n# Recipe preparada\nrecipe_prep &lt;- extract_recipe(ames_fit)\nsaveRDS(recipe_prep, \"models/recipe.rds\")\n\n# Modelo parsnip\nmodel_parsnip &lt;- extract_fit_parsnip(ames_fit)\nsaveRDS(model_parsnip, \"models/model.rds\")\n\n# Workflow\nsaveRDS(ames_workflow, \"models/workflow.rds\")\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(stacks)\n\n# Definir modelos candidatos\nctrl_grid &lt;- control_stack_grid()\n\n# Tuning de múltiplos modelos\nrf_res &lt;- tune_grid(rf_workflow, ames_folds, grid = 10, control = ctrl_grid)\nxgb_res &lt;- tune_grid(xgb_workflow, ames_folds, grid = 10, control = ctrl_grid)\nlm_res &lt;- fit_resamples(lm_workflow, ames_folds, control = ctrl_grid)\n\n# Criar stack\nmodel_stack &lt;- stacks() %&gt;%\n  add_candidates(rf_res) %&gt;%\n  add_candidates(xgb_res) %&gt;%\n  add_candidates(lm_res)\n\n# Treinar meta-modelo\nstack_fit &lt;- model_stack %&gt;%\n  blend_predictions() %&gt;%\n  fit_members()\n\n# Predições\npredict(stack_fit, ames_test)\n\n\n\n\n\n\n\nCode\n# Predições de múltiplos modelos\npred_rf &lt;- predict(rf_fit, ames_test)$.pred\npred_xgb &lt;- predict(xgb_fit, ames_test)$.pred\npred_lm &lt;- predict(lm_fit, ames_test)$.pred\n\n# Média ponderada\nensemble_pred &lt;- 0.5 * pred_rf + 0.3 * pred_xgb + 0.2 * pred_lm\n\n\n\n\n\n\n\n\n\n\nSequência correta:\n\nDividir dados em treino/teste ANTES de qualquer processamento\nExplorar apenas dados de treino\nCriar recipe baseada apenas em dados de treino\nRecipe é preparada apenas com dados de treino\nValidação cruzada DENTRO do conjunto de treino\nTestar modelo APENAS UMA VEZ no final\n\nPipeline ideal:\n\n\nCode\n# 1. Dividir\nsplit &lt;- initial_split(dados, prop = 0.75, strata = resposta)\ntreino &lt;- training(split)\nteste &lt;- testing(split)\n\n# 2. Explorar apenas treino\nsummary(treino)\nggplot(treino, aes(x = preditor, y = resposta)) + geom_point()\n\n# 3. Recipe baseada no treino\nrecipe &lt;- recipe(resposta ~ ., data = treino) %&gt;%\n  step_normalize(all_numeric_predictors())\n\n# 4. Validação cruzada no treino\nfolds &lt;- vfold_cv(treino, v = 10)\ncv_results &lt;- workflow() %&gt;%\n  add_recipe(recipe) %&gt;%\n  add_model(modelo) %&gt;%\n  fit_resamples(folds)\n\n# 5. Avaliar CV\ncollect_metrics(cv_results)\n\n# 6. Treinar modelo final\nfit_final &lt;- workflow() %&gt;%\n  add_recipe(recipe) %&gt;%\n  add_model(modelo) %&gt;%\n  fit(treino)\n\n# 7. Testar UMA VEZ\nteste_results &lt;- teste %&gt;%\n  select(resposta) %&gt;%\n  bind_cols(predict(fit_final, teste))\n\n\n\n\n\n\nData leakage ocorre quando informação do teste “vaza” para o treino\nExemplos de leakage:\n\n\nCode\n# ERRADO - Normaliza antes de dividir\ndados_norm &lt;- dados %&gt;%\n  mutate(across(where(is.numeric), scale))\nsplit &lt;- initial_split(dados_norm)\n\n# CORRETO - Normaliza dentro da recipe\nsplit &lt;- initial_split(dados)\nrecipe &lt;- recipe(resposta ~ ., training(split)) %&gt;%\n  step_normalize(all_numeric_predictors())\n\n\n\n\nCode\n# ERRADO - Remove outliers antes de dividir\ndados_sem_outliers &lt;- dados %&gt;%\n  filter(valor &lt; quantile(valor, 0.95))\nsplit &lt;- initial_split(dados_sem_outliers)\n\n# CORRETO - Remove dentro da recipe ou não remove\nsplit &lt;- initial_split(dados)\nrecipe &lt;- recipe(resposta ~ ., training(split)) %&gt;%\n  step_filter(valor &lt; quantile(valor, 0.95))\n\n\n\n\nCode\n# ERRADO - Seleção de variáveis em todos os dados\nmodelo &lt;- lm(resposta ~ var1 + var2, data = dados)  # baseado em todos\nsplit &lt;- initial_split(dados %&gt;% select(resposta, var1, var2))\n\n# CORRETO - Seleção dentro do treino\nsplit &lt;- initial_split(dados)\n# Análise exploratória apenas no treino para escolher variáveis\n\n\nPrevenção:\n\nSEMPRE dividir dados primeiro\nUsar recipes para transformações\nValidação cruzada apenas no treino\nNão usar teste para decisões de modelagem\n\n\n\n\n\n\n\nCode\n# Para regressão: estratifica por quantis da resposta\names_split &lt;- initial_split(ames, prop = 0.75, strata = Sale_Price)\names_folds &lt;- vfold_cv(ames_train, v = 10, strata = Sale_Price)\n\n# Para classificação: estratifica por classe\nsplit &lt;- initial_split(dados, strata = classe)\n\n\nBenefícios da estratificação:\n\nMantém distribuição da variável resposta\nEspecialmente importante com:\n\nDistribuições assimétricas\nDatasets pequenos\nValores raros ou extremos\nClasses desbalanceadas (classificação)\n\n\nNúmero de estratos:\n\nPadrão: 4 quantis para regressão\nPode ajustar com breaks se necessário\n\n\n\n\n\n\n\n\n\nCode\n# Criar resíduos\nresultados &lt;- teste %&gt;%\n  select(Sale_Price) %&gt;%\n  bind_cols(predict(fit_final, teste)) %&gt;%\n  mutate(\n    residuos = Sale_Price - .pred,\n    residuos_padrao = residuos / sd(residuos)\n  )\n\n# Sumário\nsummary(resultados$residuos)\n\n\nVerificações importantes:\n\n\nCode\nlibrary(ggplot2)\n\n# 1. Normalidade dos resíduos\nggplot(resultados, aes(sample = residuos)) +\n  stat_qq() + \n  stat_qq_line() +\n  labs(title = \"Q-Q Plot - Normalidade dos Resíduos\")\n\n# Teste de Shapiro-Wilk\nshapiro.test(resultados$residuos)\n\n# 2. Homocedasticidade (variância constante)\nggplot(resultados, aes(x = .pred, y = residuos)) +\n  geom_point(alpha = 0.5) +\n  geom_hline(yintercept = 0, color = \"red\", linetype = \"dashed\") +\n  geom_smooth(se = FALSE) +\n  labs(\n    x = \"Valores Preditos\",\n    y = \"Resíduos\",\n    title = \"Resíduos vs Predições\"\n  )\n\n# 3. Distribuição dos resíduos\nggplot(resultados, aes(x = residuos)) +\n  geom_histogram(bins = 30, fill = \"steelblue\", alpha = 0.7) +\n  labs(title = \"Distribuição dos Resíduos\")\n\n# 4. Resíduos vs variáveis preditoras\nggplot(resultados %&gt;% bind_cols(teste %&gt;% select(Gr_Liv_Area)), \n       aes(x = Gr_Liv_Area, y = residuos)) +\n  geom_point(alpha = 0.5) +\n  geom_hline(yintercept = 0, color = \"red\", linetype = \"dashed\") +\n  geom_smooth(se = FALSE)\n\n# 5. Valores preditos vs reais\nggplot(resultados, aes(x = Sale_Price, y = .pred)) +\n  geom_point(alpha = 0.5) +\n  geom_abline(slope = 1, intercept = 0, color = \"red\", linetype = \"dashed\") +\n  labs(\n    x = \"Valores Reais\",\n    y = \"Valores Preditos\",\n    title = \"Predito vs Real\"\n  )\n\n\nPadrões problemáticos:\n\nFunil: heterocedasticidade (variância não constante)\n\nSolução: transformação log, Box-Cox, ou usar modelos robustos\n\nCurva: relação não-linear não capturada\n\nSolução: adicionar termos polinomiais, splines, ou usar modelos não-lineares\n\nOutliers: pontos influentes\n\nSolução: investigar, possivelmente remover ou usar modelos robustos\n\nClusters: variáveis omitidas ou interações não modeladas\n\nSolução: incluir mais variáveis ou interações\n\n\n\n\n\n\n\nCode\n# Outliers (resíduos padronizados &gt; 3)\noutliers &lt;- resultados %&gt;%\n  filter(abs(residuos_padrao) &gt; 3)\n\n# Visualizar\nggplot(resultados, aes(x = seq_along(residuos), y = residuos_padrao)) +\n  geom_point() +\n  geom_hline(yintercept = c(-3, 3), color = \"red\", linetype = \"dashed\") +\n  labs(x = \"Índice\", y = \"Resíduos Padronizados\")\n\n# Para regressão linear: Distância de Cook\nmodelo_lm &lt;- extract_fit_engine(fit_final)\ncooks_d &lt;- cooks.distance(modelo_lm)\n\nplot(cooks_d, type = \"h\")\nabline(h = 4/length(cooks_d), col = \"red\", lty = 2)\n\n\n\n\n\n\n\nCode\nlibrary(car)\n\n# VIF (Variance Inflation Factor)\nmodelo_lm &lt;- extract_fit_engine(fit_final)\nvif(modelo_lm)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModelo\nUso Principal\nVantagens\nDesvantagens\n\n\n\n\nLinear\nBaseline, interpretabilidade\nSimples, rápido, interpretável\nAssume linearidade\n\n\nRidge\nMulticolinearidade\nEstabiliza coeficientes\nMantém todas variáveis\n\n\nLasso\nSeleção variáveis\nRemove variáveis irrelevantes\nPode ser instável\n\n\nElastic Net\nCombinação\nEquilibra Ridge e Lasso\nMais hiperparâmetros\n\n\nRandom Forest\nRelações complexas\nNão-linear, robusto\nMenos interpretável, lento\n\n\n\n\n\n\n\n\n# 1. PREPARAÇÃO DOS DADOS\nlibrary(tidymodels)\nlibrary(modeldata)\n\ndata(\"ames\")\nset.seed(123)\n\n# Divisão estratificada\names_split &lt;- initial_split(ames, prop = 0.75, strata = Sale_Price)\names_train &lt;- training(ames_split)\names_test &lt;- testing(ames_split)\n\n# 2. PRÉ-PROCESSAMENTO\names_recipe &lt;- recipe(Sale_Price ~ Gr_Liv_Area + Year_Built + \n                      Garage_Area + Total_Bsmt_SF, \n                      data = ames_train) %&gt;%\n  step_normalize(all_numeric_predictors()) %&gt;%  # Padronização\n  step_impute_median(all_numeric_predictors())  # Imputa NAs\n\n# 3. ESPECIFICAÇÃO DO MODELO\nlm_spec &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  set_mode(\"regression\")\n\n# 4. WORKFLOW\names_wf &lt;- workflow() %&gt;%\n  add_recipe(ames_recipe) %&gt;%\n  add_model(lm_spec)\n\n# 5. VALIDAÇÃO CRUZADA\nset.seed(456)\names_folds &lt;- vfold_cv(ames_train, v = 10, strata = Sale_Price)\n\ncv_results &lt;- ames_wf %&gt;%\n  fit_resamples(\n    resamples = ames_folds,\n    control = control_resamples(save_pred = TRUE))\n\n# 6. AVALIAÇÃO CV\ncollect_metrics(cv_results)\n\n# 7. TREINO FINAL\nfinal_fit &lt;- ames_wf %&gt;%\n  fit(ames_train)\n\n# 8. TESTE\ntest_results &lt;- ames_test %&gt;%\n  select(Sale_Price) %&gt;%\n  bind_cols(predict(final_fit, ames_test))\n\n# 9. MÉTRICAS FINAIS\ntest_results %&gt;%\n  metrics(truth = Sale_Price, estimate = .pred)\n\n# 10. ANÁLISE DE RESÍDUOS\ntest_results &lt;- test_results %&gt;%\n  mutate(residuos = Sale_Price - .pred)\n\nsummary(test_results$residuos)\n\n# 11. PREDIÇÃO NOVA\nnova_casa &lt;- tibble(\n  Gr_Liv_Area = 2000,\n  Year_Built = 2010,\n  Garage_Area = 500,\n  Total_Bsmt_SF = 1200)\n\npredict(final_fit, nova_casa)\n\n\n\n\n\n\nCausa: Variável na fórmula não existe nos dados\nSolução: Verificar nomes com names(dados)\n\n\n\nCausa: Problema no pré-processamento ou dados\nSolução: Verificar NAs, valores infinitos, variáveis constantes\n\n\n\nCausa: Multicolinearidade perfeita\nSolução: Remover variáveis redundantes ou usar regularização\n\n\n\nCausa: Dados novos faltam variáveis usadas no treino\nSolução: Garantir mesma estrutura nos novos dados\n\n\n\n\n\n\n\n\nTidymodels Site\nGuia Completo - Tidy Modeling with R (livro online gratuito)\nCheatsheet\n\n\n\n\n\nthemis: balanceamento de classes\nembed: feature engineering avançado\ntextrecipes: processamento de texto\nusemodels: gera código tidymodels automaticamente\n\n\n\n\n\n\nArtifact: Visualização ou objeto criado no processo de análise\nBootstrap: Reamostragem com reposição\nCross-validation: Validação cruzada k-fold\nFeature engineering: Criação/transformação de variáveis\nHoldout: Conjunto de teste separado\nHyperparameter: Parâmetro definido antes do treino\nLeakage: Vazamento de informação do teste para treino\nOverfitting: Modelo muito ajustado aos dados de treino\nPipeline: Sequência automatizada de operações\nResampling: Técnicas de reamostragem (CV, bootstrap)\nStratification: Manter distribuição da resposta em divisões\nTuning: Otimização de hiperparâmetros\n\n\n\nQue cada gole desperte uma nova ideia.\nQue cada script abra uma nova conversa.\nQue o Café com R, se torne um ponto de encontro nosso!"
  },
  {
    "objectID": "apresentações/posts/tidymodels_documentacao.html#sumário",
    "href": "apresentações/posts/tidymodels_documentacao.html#sumário",
    "title": "7.1. Documentação: Tidymodels para Regressão em R",
    "section": "",
    "text": "Introdução ao Tidymodels\nPacotes Principais\nFunções de Divisão de Dados\nRecipes - Pré-processamento\nParsnip - Especificação de Modelos\nWorkflows - Pipelines\nMétricas de Avaliação\nValidação Cruzada\nModelos Avançados"
  },
  {
    "objectID": "apresentações/posts/tidymodels_documentacao.html#introducao",
    "href": "apresentações/posts/tidymodels_documentacao.html#introducao",
    "title": "7.1. Documentação: Tidymodels para Regressão em R",
    "section": "",
    "text": "O tidymodels é um meta-pacote (coleção de pacotes) que fornece uma interface unificada para modelagem estatística e machine learning em R, seguindo os princípios do tidyverse.\n\n\n\n\nCode\ninstall.packages(\"tidymodels\")\nlibrary(tidymodels)\n\n\nCarrega automaticamente:\n\nrsample - divisão de dados\nrecipes - pré-processamento\nparsnip - especificação de modelos\nworkflows - combinação de receitas e modelos\nyardstick - métricas de avaliação\ntune - ajuste de hiperparâmetros\ndials - parâmetros de ajuste\nbroom - organização de resultados"
  },
  {
    "objectID": "apresentações/posts/tidymodels_documentacao.html#pacotes",
    "href": "apresentações/posts/tidymodels_documentacao.html#pacotes",
    "title": "7.1. Documentação: Tidymodels para Regressão em R",
    "section": "",
    "text": "Pacote: rsample\nFunção: Divide os dados em conjuntos de treino e teste\n\n\nCode\names_split &lt;- initial_split(ames, prop = 0.75)\n\n\nParâmetros:\n\ndata: dataset a ser dividido\nprop: proporção para treino (padrão: 0.75 = 75%)\nstrata: variável para estratificação (mantém distribuição)\n\nRetorna: objeto rsplit com informações sobre a divisão\nExemplo estratificado:\n\n\nCode\n# Mantém distribuição da variável resposta\names_split &lt;- initial_split(ames, prop = 0.75, strata = Sale_Price)\n\n\n\n\n\nFunção: Extrai os conjuntos de treino e teste\n\n\nCode\names_train &lt;- training(ames_split)\names_test &lt;- testing(ames_split)\n\n\nRetorna: tibble/data.frame com os dados correspondentes\nNotas importantes:\n\nA função initial_split() usa amostragem aleatória simples ou estratificada\nO objeto rsplit armazena apenas índices, não duplica os dados\nSempre use set.seed() antes para reprodutibilidade\n\n\n\n\n\n\nPacote: rsample\nFunção: Cria folds para validação cruzada k-fold\n\n\nCode\names_folds &lt;- vfold_cv(ames_train, v = 10)\n\n\nParâmetros:\n\ndata: dados de treino\nv: número de folds (padrão: 10)\nstrata: variável para estratificação\nrepeats: número de repetições\n\nComo funciona:\n\nDivide os dados em v partes aproximadamente iguais\nCada fold serve como teste uma vez\nOs outros v-1 folds servem como treino\nReduz viés da divisão única treino/teste\n\nInterpretação:\n\nCom v=10: 90% treino, 10% teste em cada iteração\nMais folds = mais computação, menos variância\nv=5 ou v=10 são escolhas comuns\nv = n (Leave-One-Out) é computacionalmente caro\n\nOutras funções de reamostragem:\n\n\nCode\n# Bootstrap\nbootstraps(ames_train, times = 25)\n\n# Monte Carlo (divisões aleatórias)\nmc_cv(ames_train, prop = 0.75, times = 20)\n\n# Validação cruzada repetida\nvfold_cv(ames_train, v = 10, repeats = 5)"
  },
  {
    "objectID": "apresentações/posts/tidymodels_documentacao.html#recipes",
    "href": "apresentações/posts/tidymodels_documentacao.html#recipes",
    "title": "7.1. Documentação: Tidymodels para Regressão em R",
    "section": "",
    "text": "Pacote: recipes\nFunção: Cria uma “receita” de pré-processamento\n\n\nCode\names_recipe &lt;- recipe(Sale_Price ~ Gr_Liv_Area + Year_Built, \n                      data = ames_train)\n\n\nParâmetros:\n\nformula: fórmula modelo (resposta ~ preditoras)\ndata: dados de referência (apenas estrutura)\nUsa . para incluir todas as variáveis: Sale_Price ~ .\n\nImportante: A recipe apenas DEFINE os passos, não os executa\nFluxo de trabalho com recipes:\n\nrecipe() - define a receita\nstep_*() - adiciona passos de transformação\nprep() - prepara a receita (calcula parâmetros nos dados de treino)\nbake() - aplica a receita preparada a novos dados\n\nQuando usado dentro de um workflow, prep() e bake() são chamados automaticamente.\n\n\n\n\n\n\nFunção: Padroniza variáveis (z-score: média=0, desvio=1)\n\n\nCode\nrecipe(...) %&gt;%\n  step_normalize(all_numeric_predictors())\n\n\nFórmula: (x - média) / desvio_padrão\nQuando usar:\n\nModelos sensíveis a escala (regressão regularizada, SVM, KNN)\nVariáveis em escalas muito diferentes\nMelhora convergência de algoritmos\nFacilita interpretação de coeficientes em modelos regularizados\n\nSeletores disponíveis:\n\nall_numeric_predictors(): todas numéricas preditoras\nall_nominal_predictors(): todas categóricas\nall_predictors(): todas as preditoras\nall_outcomes(): variável resposta\nOu especificar variáveis: step_normalize(Gr_Liv_Area, Lot_Area)\n\nAlternativa - step_range():\n\n\nCode\n# Normalização min-max (escala 0-1)\nrecipe(...) %&gt;%\n  step_range(all_numeric_predictors(), min = 0, max = 1)\n\n\n\n\n\nFunção: Cria variáveis dummy para categóricas\n\n\nCode\nrecipe(...) %&gt;%\n  step_dummy(all_nominal_predictors())\n\n\nComo funciona:\n\nConverte categoria em variáveis binárias (0/1)\nPara k categorias, cria k-1 variáveis (evita multicolinearidade)\nExemplo: Bldg_Type com 5 níveis gera 4 variáveis dummy\nA categoria de referência é implícita (todas dummies = 0)\n\nParâmetros:\n\none_hot: TRUE para criar k variáveis (ao invés de k-1)\nnaming: função para nomear as novas variáveis\n\nImportante: Sempre aplique após transformações numéricas e antes de interações\n\n\n\nFunção: Aplica transformação logarítmica\n\n\nCode\nrecipe(...) %&gt;%\n  step_log(Sale_Price, base = 10)\n\n\nQuando usar:\n\nDados com distribuição assimétrica positiva (cauda à direita)\nPresença de outliers\nRelações exponenciais entre variáveis\nReduzir heteroscedasticidade\nBase 10 ou base e (natural) - log natural é padrão\n\nCuidado:\n\nNão aceita valores &lt;= 0\nUse offset para lidar com zeros: step_log(var, offset = 1)\nLembre-se de reverter a transformação ao interpretar predições\n\nAlternativas:\n\n\nCode\n# Transformação Box-Cox (escolhe melhor lambda)\nrecipe(...) %&gt;%\n  step_BoxCox(all_numeric_predictors())\n\n# Raiz quadrada\nrecipe(...) %&gt;%\n  step_sqrt(all_numeric_predictors())\n\n\n\n\n\nFunção: Imputa valores faltantes (NA)\n\n\nCode\nrecipe(...) %&gt;%\n  step_impute_mean(all_numeric_predictors()) %&gt;%\n  step_impute_mode(all_nominal_predictors())\n\n\nTipos de imputação:\n\nstep_impute_mean(): média (sensível a outliers)\nstep_impute_median(): mediana (robusta a outliers)\nstep_impute_mode(): moda (para categóricas)\nstep_impute_knn(): k vizinhos mais próximos (preserva relações)\nstep_impute_linear(): regressão linear\nstep_impute_bag(): bagged trees\n\nExemplo KNN:\n\n\nCode\nrecipe(...) %&gt;%\n  step_impute_knn(all_predictors(), neighbors = 5)\n\n\nConsiderações:\n\nImputação deve ser feita antes da normalização\nPara grandes quantidades de NAs, considere criar indicador de missing\nstep_indicate_na() cria variável binária indicando se havia NA\n\n\n\n\nFunção: Análise de Componentes Principais\n\n\nCode\nrecipe(...) %&gt;%\n  step_pca(all_numeric_predictors(), num_comp = 5)\n\n\nQuando usar:\n\nRedução de dimensionalidade\nMulticolinearidade severa\nMuitas variáveis correlacionadas\nVisualização de dados de alta dimensão\n\nParâmetros:\n\nnum_comp: número de componentes a manter\nthreshold: variância explicada mínima acumulada\noptions: lista com opções adicionais\n\nImportante:\n\nPCA é sensível à escala - sempre normalize antes\nComponentes são combinações lineares das variáveis originais\nPerda de interpretabilidade\n\n\n\nCode\n# Exemplo mantendo 95% da variância\nrecipe(...) %&gt;%\n  step_normalize(all_numeric_predictors()) %&gt;%\n  step_pca(all_numeric_predictors(), threshold = 0.95)\n\n\n\n\n\nTratamento de outliers:\n\n\nCode\n# Remove observações com valores extremos\nrecipe(...) %&gt;%\n  step_filter_missing(all_predictors(), threshold = 0.5) %&gt;%\n  step_nzv(all_predictors())  # Remove variáveis com variância próxima a zero\n\n\nInterações:\n\n\nCode\nrecipe(...) %&gt;%\n  step_interact(terms = ~ Gr_Liv_Area:Year_Built)\n\n\nPolinômios:\n\n\nCode\nrecipe(...) %&gt;%\n  step_poly(Gr_Liv_Area, degree = 2)  # Adiciona termo quadrático\n\n\nBinning:\n\n\nCode\n# Discretiza variável contínua\nrecipe(...) %&gt;%\n  step_cut(Year_Built, breaks = c(1950, 1980, 2000))"
  },
  {
    "objectID": "apresentações/posts/tidymodels_documentacao.html#parsnip",
    "href": "apresentações/posts/tidymodels_documentacao.html#parsnip",
    "title": "7.1. Documentação: Tidymodels para Regressão em R",
    "section": "",
    "text": "Pacote: parsnip\nFunção: Especifica modelo de regressão linear\n\n\nCode\nlm_model &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  set_mode(\"regression\")\n\n\nComponentes:\n\n\nDefine o pacote/função R que executará o modelo\nEngines disponíveis para linear_reg():\n\n\"lm\": regressão linear padrão (stats::lm)\n\"glmnet\": Ridge, Lasso, Elastic Net\n\"stan\": abordagem Bayesiana\n\"keras\": redes neurais\n\"spark\": para processamento distribuído\n\nArgumentos específicos do engine:\n\n\nCode\nlinear_reg() %&gt;%\n  set_engine(\"glmnet\", lambda = 0.01)\n\n\n\n\n\nDefine o tipo de problema\n\n\"regression\": para variável resposta contínua\n\"classification\": para variável resposta categórica\n\nNota: Para linear_reg(), o modo é sempre “regression”\nParâmetros de regularização:\n\n\nCode\nlinear_reg(penalty = 0.01, mixture = 0) # Ridge\nlinear_reg(penalty = 0.01, mixture = 1) # Lasso\nlinear_reg(penalty = 0.01, mixture = 0.5) # Elastic Net\n\n\nParâmetros:\n\npenalty: força da regularização (lambda)\n\n0 = sem regularização (OLS padrão)\nValores maiores = mais regularização\nTípico: 0.001 a 1.0\n\nmixture: tipo de penalização\n\n0 = Ridge (L2): reduz coeficientes, nunca zera\n1 = Lasso (L1): pode zerar coeficientes\n0-1 = Elastic Net: combinação de ambos\n\n\nInterpretação:\n\nRidge (L2): útil quando todas variáveis são relevantes, reduz coeficientes proporcionalmente\nLasso (L1): útil para seleção de variáveis, pode eliminar preditores irrelevantes\nElastic Net: combina vantagens de ambos, ideal quando há grupos de variáveis correlacionadas\n\nComparação Ridge vs Lasso:\n\n\n\n\n\n\n\n\nAspecto\nRidge\nLasso\n\n\n\n\nPenalização\nL2 (soma dos quadrados)\nL1 (soma dos valores absolutos)\n\n\nSeleção de variáveis\nNão\nSim\n\n\nCoeficientes\nReduz, nunca zera\nPode zerar\n\n\nMulticolinearidade\nLida bem\nSeleciona uma variável do grupo\n\n\nInterpretabilidade\nMenos\nMais (modelo esparso)\n\n\n\n\n\n\n\n\nPacote: parsnip\nFunção: Especifica modelo Random Forest\n\n\nCode\nrf_model &lt;- rand_forest(trees = 500) %&gt;%\n  set_engine(\"ranger\") %&gt;%\n  set_mode(\"regression\")\n\n\nParâmetros principais:\n\ntrees: número de árvores (padrão: 500)\n\nMais árvores = mais estável, mas mais lento\nTípico: 500 a 2000\n\nmtry: variáveis consideradas em cada divisão\n\nPadrão: sqrt(p) para classificação, p/3 para regressão\nControla correlação entre árvores\n\nmin_n: observações mínimas por nó terminal\n\nPadrão: varia por engine\nMaior = menos complexidade, menos overfitting\n\n\nEngines disponíveis:\n\n\"ranger\": rápido e eficiente (recomendado)\n\"randomForest\": implementação clássica\n\"spark\": para big data\n\nExemplo com todos os parâmetros:\n\n\nCode\nrf_spec &lt;- rand_forest(\n  trees = 1000,\n  mtry = 5,\n  min_n = 10\n) %&gt;%\n  set_engine(\"ranger\", importance = \"impurity\") %&gt;%\n  set_mode(\"regression\")\n\n\nComo funciona:\n\nCria múltiplas árvores de decisão\nCada árvore usa amostra bootstrap dos dados (com reposição)\nCada divisão considera subconjunto aleatório de variáveis (mtry)\nPredição = média das predições de todas árvores (regressão)\nOut-of-bag (OOB) error é calculado automaticamente\n\nVantagens:\n\nNão requer normalização de variáveis\nLida bem com não-linearidades e interações\nRobusto a outliers\nFornece importância de variáveis\nBaixo risco de overfitting (com árvores suficientes)\n\nDesvantagens:\n\nMenos interpretável que modelos lineares\nMais lento que regressão linear\nPode ter dificuldade com extrapolação\nRequer mais memória\n\nConfigurações específicas do ranger:\n\n\nCode\nrf_spec &lt;- rand_forest(trees = 1000) %&gt;%\n  set_engine(\n    \"ranger\",\n    importance = \"impurity\",  # ou \"permutation\"\n    num.threads = 4,          # paralelização\n    verbose = FALSE,\n    seed = 123\n  ) %&gt;%\n  set_mode(\"regression\")\n\n\n\n\n\n\n\n\n\n\nCode\nboost_spec &lt;- boost_tree(\n  trees = 1000,\n  tree_depth = 6,\n  learn_rate = 0.01\n) %&gt;%\n  set_engine(\"xgboost\") %&gt;%\n  set_mode(\"regression\")\n\n\nQuando usar: Geralmente superior em competições, excelente performance\n\n\n\n\n\nCode\ntree_spec &lt;- decision_tree(\n  cost_complexity = 0.01,\n  tree_depth = 10,\n  min_n = 20\n) %&gt;%\n  set_engine(\"rpart\") %&gt;%\n  set_mode(\"regression\")\n\n\nQuando usar: Interpretabilidade máxima, baseline simples\n\n\n\n\n\nCode\nsvm_spec &lt;- svm_rbf(\n  cost = 1,\n  rbf_sigma = 0.1\n) %&gt;%\n  set_engine(\"kernlab\") %&gt;%\n  set_mode(\"regression\")\n\n\nQuando usar: Dados não-lineares, dimensionalidade média\n\n\n\n\n\nCode\nnn_spec &lt;- mlp(\n  hidden_units = 10,\n  penalty = 0.01,\n  epochs = 100\n) %&gt;%\n  set_engine(\"nnet\") %&gt;%\n  set_mode(\"regression\")\n\n\nQuando usar: Padrões complexos, muitos dados disponíveis"
  },
  {
    "objectID": "apresentações/posts/tidymodels_documentacao.html#workflows",
    "href": "apresentações/posts/tidymodels_documentacao.html#workflows",
    "title": "7.1. Documentação: Tidymodels para Regressão em R",
    "section": "",
    "text": "Pacote: workflows\nFunção: Combina recipe e modelo em pipeline único\n\n\nCode\names_workflow &lt;- workflow() %&gt;%\n  add_recipe(ames_recipe) %&gt;%\n  add_model(lm_model)\n\n\nVantagens:\n\nGarante que pré-processamento seja aplicado consistentemente\nFacilita experimentação com diferentes combinações\nReduz erros (evita vazamento de dados - data leakage)\nCódigo mais limpo e organizado\nSimplifica deploy do modelo\n\nFluxo de trabalho:\n\nCrie recipe e modelo separadamente\nCombine em workflow\nAjuste o workflow (não componentes individuais)\nUse o workflow ajustado para predições\n\nComponentes:\n\n\nAdiciona recipe de pré-processamento\n\n\nCode\nworkflow() %&gt;%\n  add_recipe(my_recipe)\n\n\n\n\n\nAdiciona especificação do modelo\n\n\nCode\nworkflow() %&gt;%\n  add_model(my_model)\n\n\n\n\n\nAlternativa a recipe para casos simples (sem pré-processamento complexo)\n\n\nCode\nworkflow() %&gt;%\n  add_formula(Sale_Price ~ Gr_Liv_Area + Year_Built) %&gt;%\n  add_model(lm_model)\n\n\nQuando usar formula vs recipe:\n\nFormula: casos simples, sem transformações\nRecipe: pré-processamento complexo, padronização, imputação, etc.\n\n\n\n\nAlternativa mais flexível\n\n\nCode\nworkflow() %&gt;%\n  add_variables(\n    outcomes = Sale_Price,\n    predictors = c(Gr_Liv_Area, Year_Built)\n  ) %&gt;%\n  add_model(lm_model)\n\n\nInspecionando workflows:\n\n\nCode\n# Ver estrutura\names_workflow\n\n# Extrair componentes\nextract_spec_parsnip(ames_workflow)\nextract_recipe(ames_workflow)\n\n\n\n\n\n\n\nFunção: Treina o workflow nos dados\n\n\nCode\names_fit &lt;- ames_workflow %&gt;%\n  fit(data = ames_train)\n\n\nO que acontece:\n\nPrepara a recipe nos dados de treino (calcula médias, desvios, etc.)\nAplica transformações aos dados de treino\nTreina o modelo com dados transformados\nArmazena recipe preparada e modelo treinado\n\nRetorna: workflow treinado (fitted workflow)\nImportante:\n\nfit() sempre usa os dados fornecidos para preparar a recipe\nA recipe preparada será aplicada automaticamente a novos dados\nNunca faça fit() nos dados de teste\n\nVerificando o ajuste:\n\n\nCode\n# Ver sumário\names_fit\n\n# Extrair modelo ajustado\names_fit %&gt;%\n  extract_fit_parsnip()\n\n# Ver coeficientes\names_fit %&gt;%\n  extract_fit_parsnip() %&gt;%\n  tidy()\n\n\n\n\n\n\nFunção: Treina o workflow com validação cruzada\n\n\nCode\ncv_results &lt;- ames_workflow %&gt;%\n  fit_resamples(ames_folds)\n\n\nParâmetros:\n\nresamples: objeto vfold_cv ou outro tipo de reamostragem\nmetrics: métricas a calcular (padrão: rmse e rsq)\ncontrol: controles adicionais\n\nControles úteis:\n\n\nCode\ncv_results &lt;- ames_workflow %&gt;%\n  fit_resamples(\n    resamples = ames_folds,\n    metrics = metric_set(rmse, rsq, mae),\n    control = control_resamples(\n      save_pred = TRUE,      # Salvar predições\n      verbose = TRUE,        # Mostrar progresso\n      allow_par = TRUE       # Permitir paralelização\n    )\n  )\n\n\nRetorna: objeto com resultados de todos os folds\nPara coletar resultados:\n\n\nCode\n# Métricas agregadas\ncollect_metrics(cv_results)\n\n# Métricas por fold\ncollect_metrics(cv_results, summarize = FALSE)\n\n# Predições de cada fold\ncollect_predictions(cv_results)\n\n# Notas sobre folds\ncollect_notes(cv_results)\n\n\nInterpretação dos resultados:\n\n\nCode\n# Exemplo de output\n# # A tibble: 2 × 6\n#   .metric .estimator  mean     n std_err .config             \n#   &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n# 1 rmse    standard   30456    10    1234 Preprocessor1_Model1\n# 2 rsq     standard    0.81    10    0.02 Preprocessor1_Model1\n\n\n\nmean: performance média nos 10 folds\nn: número de folds\nstd_err: erro padrão (variabilidade entre folds)\n\nVantagens do fit_resamples():\n\nEstimativa mais confiável da performance\nDetecta overfitting antes do teste final\nPermite comparar modelos de forma justa\nNão “gasta” os dados de teste\n\n\n\n\n\nFunção: Faz predições com modelo treinado\n\n\nCode\names_pred &lt;- predict(ames_fit, ames_test)\n\n\nRetorna: tibble com coluna .pred\nTipos de predição:\n\n\nCode\n# Predições pontuais (padrão)\npredict(ames_fit, new_data, type = \"numeric\")\n\n# Intervalo de confiança\npredict(ames_fit, new_data, type = \"conf_int\", level = 0.95)\n\n# Intervalo de predição (quando disponível)\npredict(ames_fit, new_data, type = \"pred_int\", level = 0.95)\n\n\nExemplo completo com teste:\n\n\nCode\n# Predições\ntest_pred &lt;- predict(ames_fit, ames_test)\n\n# Adicionar aos dados originais\ntest_results &lt;- ames_test %&gt;%\n  select(Sale_Price) %&gt;%\n  bind_cols(test_pred)\n\n# Com intervalos\ntest_pred_int &lt;- predict(ames_fit, ames_test, type = \"conf_int\")\n\ntest_results_full &lt;- ames_test %&gt;%\n  select(Sale_Price) %&gt;%\n  bind_cols(test_pred) %&gt;%\n  bind_cols(test_pred_int)\n\n\nPredições em novos dados:\n\n\nCode\n# Criar novo dado\nnova_casa &lt;- tibble(\n  Gr_Liv_Area = 2000,\n  Year_Built = 2010,\n  Garage_Area = 500,\n  Total_Bsmt_SF = 1200\n)\n\n# Predição\npredict(ames_fit, nova_casa)\n\n\nImportante:\n\nNovos dados devem ter mesmas colunas usadas no treino\nA recipe preparada será aplicada automaticamente\nTransformações são consistentes com o treino\n\n\n\n\n\n\n\nExtrai o modelo parsnip do workflow\n\n\nCode\nmodelo_parsnip &lt;- ames_fit %&gt;%\n  extract_fit_parsnip()\n\n\nUso: Acessar modelo para inspeção, importância de variáveis, etc.\n\n\n\nExtrai o modelo do engine original (ex: objeto lm)\n\n\nCode\nmodelo_lm &lt;- ames_fit %&gt;%\n  extract_fit_engine()\n\n# Acessa métodos específicos do lm\nsummary(modelo_lm)\nplot(modelo_lm)\n\n\n\n\n\nExtrai a recipe preparada\n\n\nCode\nrecipe_preparada &lt;- ames_fit %&gt;%\n  extract_recipe()\n\n# Inspecionar passos\nrecipe_preparada %&gt;%\n  tidy()\n\n\n\n\n\nExtrai o pré-processador (recipe ou formula)\n\n\nCode\npreprocessor &lt;- ames_fit %&gt;%\n  extract_preprocessor()\n\n\n\n\n\nPacote: broom\nFunção: Organiza coeficientes em tibble\n\n\nCode\names_fit %&gt;%\n  extract_fit_parsnip() %&gt;%\n  tidy()\n\n\nRetorna: tibble com:\n\nterm: nome da variável\nestimate: coeficiente estimado\nstd.error: erro padrão\nstatistic: estatística t\np.value: p-valor\n\nTambém funciona com recipes:\n\n\nCode\n# Ver transformações aplicadas\names_fit %&gt;%\n  extract_recipe() %&gt;%\n  tidy()\n\n# Ver transformações de um step específico\names_fit %&gt;%\n  extract_recipe() %&gt;%\n  tidy(number = 1)  # Primeiro step\n\n\n\n\n\nSumário do modelo em uma linha\n\n\nCode\names_fit %&gt;%\n  extract_fit_parsnip() %&gt;%\n  glance()\n\n\nRetorna: R², AIC, BIC, sigma, etc. (dependendo do modelo)\n\n\n\nAdiciona predições e resíduos aos dados\n\n\nCode\names_fit %&gt;%\n  extract_fit_engine() %&gt;%\n  augment()\n\n\nRetorna: dados originais com .fitted, .resid, etc."
  },
  {
    "objectID": "apresentações/posts/tidymodels_documentacao.html#metricas",
    "href": "apresentações/posts/tidymodels_documentacao.html#metricas",
    "title": "7.1. Documentação: Tidymodels para Regressão em R",
    "section": "",
    "text": "Pacote: yardstick\nFunção: Calcula métricas de performance\n\n\nCode\names_results %&gt;%\n  metrics(truth = Sale_Price, estimate = .pred)\n\n\nParâmetros:\n\ntruth: valores reais (observados)\nestimate: valores preditos\n\nRetorna (regressão):\n\nrmse: Root Mean Squared Error\nrsq: R-squared\nmae: Mean Absolute Error\n\nExemplo completo:\n\n\nCode\n# Criar resultados\ntest_results &lt;- ames_test %&gt;%\n  select(Sale_Price) %&gt;%\n  bind_cols(predict(ames_fit, ames_test))\n\n# Calcular métricas\ntest_results %&gt;%\n  metrics(truth = Sale_Price, estimate = .pred)\n\n\n\n\n\n\n\n\nFórmula: √(Σ(real - predito)² / n)\nInterpretação:\n\nErro médio em unidades originais da variável resposta\nPenaliza erros grandes mais fortemente devido ao quadrado\nExemplo: RMSE = $30,000 significa erro médio de $30k\nMais sensível a outliers que MAE\n\nQuando menor, melhor\nPropriedades:\n\nSempre não-negativo\nMesmo erro em qualquer direção (sub ou superestimação)\nÚtil quando erros grandes são particularmente indesejáveis\n\n\n\n\nFórmula: 1 - (SS_res / SS_tot)\nOnde:\n\nSS_res = Σ(real - predito)² (soma dos quadrados dos resíduos)\nSS_tot = Σ(real - média)² (soma total dos quadrados)\n\nInterpretação:\n\nProporção da variância explicada pelo modelo\nVaria de 0 a 1 (0% a 100%)\nR² = 0.8 significa que o modelo explica 80% da variabilidade dos dados\n\nValores típicos:\n\n&lt; 0.3: fraco\n0.3-0.5: moderado\n0.5-0.7: bom\n0.7-0.9: muito bom\n\n0.9: excelente (cuidado com overfitting)\n\n\nLimitações:\n\nPode ser enganoso com dados não-lineares\nNão indica se o modelo está enviesado\nR² ajustado penaliza complexidade excessiva\n\n\n\n\nFórmula: Σ|real - predito| / n\nInterpretação:\n\nErro médio absoluto\nMais robusto a outliers que RMSE\nMesmo que RMSE, em unidades originais da resposta\nTodos os erros têm peso igual\n\nQuando usar:\n\nQuando outliers não devem dominar a métrica\nPara comunicação mais intuitiva com não-técnicos\nQuando erros grandes e pequenos são igualmente importantes\n\nComparação RMSE vs MAE:\n\nSe RMSE &gt;&gt; MAE: muitos outliers ou erros grandes\nSe RMSE ≈ MAE: erros bem distribuídos\nRMSE sempre &gt;= MAE\n\n\n\n\nFórmula: (100/n) × Σ|real - predito| / |real|\nInterpretação:\n\nErro percentual médio\nIndependente da escala\nÚtil para comparar modelos em diferentes contextos\n\nLimitações:\n\nIndefinido quando valores reais são zero\nAssimétrico: penaliza mais sub-predições que sobre-predições\nSensível a valores reais pequenos\n\n\n\n\n\n\n\n\n\n\nCode\n# RMSE\names_results %&gt;% \n  rmse(truth = Sale_Price, estimate = .pred)\n\n# R²\names_results %&gt;% \n  rsq(truth = Sale_Price, estimate = .pred)\n\n# MAE\names_results %&gt;% \n  mae(truth = Sale_Price, estimate = .pred)\n\n# MAPE\names_results %&gt;% \n  mape(truth = Sale_Price, estimate = .pred)\n\n\n\n\n\n\n\nCode\n# Definir conjunto de métricas\nmy_metrics &lt;- metric_set(rmse, rsq, mae, mape)\n\n# Aplicar\names_results %&gt;%\n  my_metrics(truth = Sale_Price, estimate = .pred)\n\n\nVantagem: Calcular todas de uma vez, consistente em todo o código\nOutras métricas úteis para regressão:\n\n\nCode\n# MASE - Mean Absolute Scaled Error\names_results %&gt;%\n  mase(truth = Sale_Price, estimate = .pred)\n\n# CCC - Concordance Correlation Coefficient\names_results %&gt;%\n  ccc(truth = Sale_Price, estimate = .pred)\n\n# SMAPE - Symmetric MAPE\names_results %&gt;%\n  smape(truth = Sale_Price, estimate = .pred)\n\n# Huber Loss (robusto a outliers)\names_results %&gt;%\n  huber_loss(truth = Sale_Price, estimate = .pred)\n\n\nCriando métricas customizadas:\n\n\nCode\n# Exemplo: erro percentual médio\nmpe &lt;- function(data, truth, estimate) {\n  metric_summarizer(\n    metric_nm = \"mpe\",\n    metric_fn = function(truth, estimate) {\n      mean((truth - estimate) / truth) * 100\n    },\n    data = data,\n    truth = !! enquo(truth),\n    estimate = !! enquo(estimate)\n  )\n}"
  },
  {
    "objectID": "apresentações/posts/tidymodels_documentacao.html#validacao",
    "href": "apresentações/posts/tidymodels_documentacao.html#validacao",
    "title": "7.1. Documentação: Tidymodels para Regressão em R",
    "section": "",
    "text": "Code\ncv_results &lt;- ames_workflow %&gt;%\n  fit_resamples(ames_folds)\n\ncollect_metrics(cv_results)\n\n\nColunas retornadas:\n\n.metric: nome da métrica\nmean: média entre folds\nn: número de folds\nstd_err: erro padrão da média\n.config: configuração do modelo\n\nInterpretação:\n\nmean: performance esperada em novos dados\nstd_err: variabilidade entre folds\n\nBaixo = modelo estável\nAlto = modelo sensível aos dados específicos\n\n\nExemplo de output:\n# A tibble: 2 × 6\n  .metric .estimator  mean     n std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   30456    10    1234 Preprocessor1_Model1\n2 rsq     standard    0.81    10    0.02 Preprocessor1_Model1\nLeitura:\n\nRMSE médio de $30,456 com variação de $1,234 entre folds\nR² médio de 0.81 (81% da variância explicada)\nBaixo std_err indica consistência do modelo\n\n\n\n\n\n\nCode\n# Métricas por fold individual\ncv_results %&gt;%\n  collect_metrics(summarize = FALSE)\n\n# Predições por fold\ncv_results %&gt;%\n  collect_predictions()\n\n# Visualizar variabilidade\ncv_results %&gt;%\n  collect_metrics(summarize = FALSE) %&gt;%\n  ggplot(aes(x = id, y = .estimate)) +\n  geom_point() +\n  facet_wrap(~ .metric, scales = \"free_y\") +\n  labs(x = \"Fold\", y = \"Valor da Métrica\")\n\n\n\n\n\n\n\n\n\nCode\n# 10-fold CV repetido 5 vezes\names_folds_rep &lt;- vfold_cv(ames_train, v = 10, repeats = 5)\n\ncv_results_rep &lt;- ames_workflow %&gt;%\n  fit_resamples(ames_folds_rep)\n\n\nVantagem: Estimativa ainda mais estável, reduz viés da divisão específica\n\n\n\n\n\nCode\n# 25 amostras bootstrap\names_boots &lt;- bootstraps(ames_train, times = 25)\n\nboot_results &lt;- ames_workflow %&gt;%\n  fit_resamples(ames_boots)\n\n\nQuando usar:\n\nDatasets pequenos\nEstimativa de variância dos coeficientes\nIntervalos de confiança\n\n\n\n\n\n\nCode\n# 20 divisões aleatórias 75/25\names_mc &lt;- mc_cv(ames_train, prop = 0.75, times = 20)\n\nmc_results &lt;- ames_workflow %&gt;%\n  fit_resamples(ames_mc)\n\n\nQuando usar: Alternativa ao k-fold quando divisões aleatórias são preferíveis\n\n\n\n\n\nCode\n# Para dados temporais\nlibrary(timetk)\n\n# Rolling window\names_rolls &lt;- rolling_origin(\n  ames_train,\n  initial = 1000,\n  assess = 250,\n  cumulative = FALSE\n)\n\n\nQuando usar: Dados de séries temporais, respeita ordem temporal\n\n\n\n\n\n\nCode\n# Estratifica por quantis da resposta\names_folds_strat &lt;- vfold_cv(\n  ames_train, \n  v = 10, \n  strata = Sale_Price\n)\n\n\nBenefícios:\n\nMantém distribuição da variável resposta em todos os folds\nEspecialmente importante com distribuições assimétricas\nReduz variabilidade entre folds\n\nQuando usar estratificação:\n\nVariável resposta com distribuição não-uniforme\nDatasets pequenos\nPresença de valores raros ou extremos"
  },
  {
    "objectID": "apresentações/posts/tidymodels_documentacao.html#avancados",
    "href": "apresentações/posts/tidymodels_documentacao.html#avancados",
    "title": "7.1. Documentação: Tidymodels para Regressão em R",
    "section": "",
    "text": "Pacote: vip\nFunção: Visualiza importância das variáveis\n\n\nCode\nlibrary(vip)\n\n# Para modelos baseados em árvores\nrf_fit %&gt;%\n  extract_fit_parsnip() %&gt;%\n  vip(num_features = 10)\n\n# Para regressão linear\nlm_fit %&gt;%\n  extract_fit_parsnip() %&gt;%\n  vip(num_features = 10)\n\n\nComo funciona por tipo de modelo:\n\nRegressão Linear: valor absoluto dos coeficientes padronizados\nRandom Forest: redução média na impureza (MSE) ou permutação\nLasso: valores absolutos dos coeficientes não-zero\nGradient Boosting: ganho total ou frequência de uso\n\nTipos de importância:\n\n\nCode\n# Importância por impureza (padrão para RF)\nrf_fit %&gt;%\n  extract_fit_parsnip() %&gt;%\n  vip(method = \"model\")\n\n# Importância por permutação (mais confiável, mais lento)\nrf_fit %&gt;%\n  extract_fit_parsnip() %&gt;%\n  vip(method = \"permute\", \n      target = \"Sale_Price\", \n      metric = \"rmse\",\n      pred_wrapper = predict)\n\n\nInterpretação:\n\nBarras maiores = variáveis mais importantes para o modelo\nImportância relativa, não absoluta\nÚtil para seleção de features\nPode orientar engenharia de features\n\nCustomização do plot:\n\n\nCode\nrf_fit %&gt;%\n  extract_fit_parsnip() %&gt;%\n  vip(\n    num_features = 15,\n    geom = \"point\",\n    aesthetics = list(color = \"steelblue\", size = 3)\n  ) +\n  labs(title = \"Importância das Variáveis - Random Forest\")\n\n\n\n\n\n\n\nCode\nlibrary(DALEXtra)\n\n# Criar explicador\nexplainer &lt;- explain_tidymodels(\n  rf_fit,\n  data = ames_train %&gt;% select(-Sale_Price),\n  y = ames_train$Sale_Price,\n  label = \"Random Forest\"\n)\n\n# SHAP values\nshap_values &lt;- predict_parts(\n  explainer,\n  new_observation = ames_test[1, ],\n  type = \"shap\"\n)\n\nplot(shap_values)\n\n\nVantagem: Explica contribuição de cada variável para predição individual\n\n\n\n\n\n\n\n\n\nCode\n# Marcar parâmetros para otimização\nrf_spec &lt;- rand_forest(\n  trees = 1000,\n  mtry = tune(),\n  min_n = tune()\n) %&gt;%\n  set_engine(\"ranger\") %&gt;%\n  set_mode(\"regression\")\n\n\nParâmetros que podem ser otimizados:\n\nRandom Forest: mtry, min_n, trees\nGradient Boosting: trees, tree_depth, learn_rate, mtry\nRegularização: penalty, mixture\nSVM: cost, rbf_sigma\nNeural Networks: hidden_units, penalty, epochs\n\n\n\n\n\n\nCode\nlibrary(dials)\n\n# Definir grid de busca\nrf_grid &lt;- grid_regular(\n  mtry(range = c(2, 10)),\n  min_n(range = c(5, 30)),\n  levels = 5  # 5 valores para cada parâmetro = 25 combinações\n)\n\n# Workflow com modelo a ser otimizado\nrf_workflow &lt;- workflow() %&gt;%\n  add_recipe(ames_recipe) %&gt;%\n  add_model(rf_spec)\n\n# Tuning\ntune_results &lt;- tune_grid(\n  rf_workflow,\n  resamples = ames_folds,\n  grid = rf_grid,\n  metrics = metric_set(rmse, rsq, mae),\n  control = control_grid(save_pred = TRUE, verbose = TRUE)\n)\n\n\nTipos de grid:\n\n\nCode\n# Grid regular (espaçamento uniforme)\ngrid_regular(mtry(), min_n(), levels = 5)\n\n# Grid aleatório (mais pontos, menos estruturado)\ngrid_random(mtry(), min_n(), size = 50)\n\n# Grid específico (manual)\ngrid_manual &lt;- tibble(\n  mtry = c(3, 5, 7),\n  min_n = c(10, 20, 30)\n)\n\n# Grid latino hipercubo (boa cobertura do espaço)\ngrid_latin_hypercube(mtry(), min_n(), size = 30)\n\n\n\n\n\n\n\nCode\n# Ver todas as combinações\ncollect_metrics(tune_results)\n\n# Melhores resultados\nshow_best(tune_results, metric = \"rmse\", n = 10)\n\n# Visualizar\nautoplot(tune_results)\n\n# Plot customizado\ntune_results %&gt;%\n  collect_metrics() %&gt;%\n  filter(.metric == \"rmse\") %&gt;%\n  ggplot(aes(x = mtry, y = mean, color = factor(min_n))) +\n  geom_line() +\n  geom_point() +\n  labs(title = \"Performance por Hiperparâmetro\")\n\n\n\n\n\n\n\nCode\n# Melhor por métrica\nbest_params &lt;- select_best(tune_results, metric = \"rmse\")\n\n# Alternativas\nselect_by_pct_loss(tune_results, metric = \"rmse\", limit = 5)\nselect_by_one_std_err(tune_results, metric = \"rmse\")\n\n\n\n\n\n\n\nCode\n# Finalizar com melhores parâmetros\nfinal_workflow &lt;- finalize_workflow(rf_workflow, best_params)\n\n# Treinar modelo final\nfinal_fit &lt;- final_workflow %&gt;%\n  fit(ames_train)\n\n# Avaliar no teste\nfinal_results &lt;- ames_test %&gt;%\n  select(Sale_Price) %&gt;%\n  bind_cols(predict(final_fit, ames_test))\n\nfinal_results %&gt;%\n  metrics(truth = Sale_Price, estimate = .pred)\n\n\n\n\n\n\n\nCode\nlibrary(finetune)\n\n# Mais eficiente que grid search\ntune_bayes_results &lt;- tune_bayes(\n  rf_workflow,\n  resamples = ames_folds,\n  initial = 10,  # Pontos iniciais\n  iter = 30,     # Iterações\n  metrics = metric_set(rmse, rsq),\n  control = control_bayes(verbose = TRUE)\n)\n\n\nVantagem: Explora espaço de hiperparâmetros de forma mais inteligente\n\n\n\n\n\nCode\n# Elimina candidatos ruins rapidamente\ntune_race_results &lt;- tune_race_anova(\n  rf_workflow,\n  resamples = ames_folds,\n  grid = 30,\n  metrics = metric_set(rmse),\n  control = control_race(verbose = TRUE)\n)\n\n\nVantagem: Economiza tempo descartando configurações ruins cedo\n\n\n\n\n\n\n\n\n\nCode\n# Salvar modelo completo\nsaveRDS(ames_fit, \"models/ames_model.rds\")\n\n# Carregar\nloaded_model &lt;- readRDS(\"models/ames_model.rds\")\n\n# Usar imediatamente\npredictions &lt;- predict(loaded_model, ames_test)\n\n\nCaracterísticas do RDS:\n\nFormato nativo do R\nPreserva toda estrutura do objeto\nPortável entre sistemas (mesmo OS/versão R)\nCompacto\n\n\n\n\n\n\nCode\nlibrary(bundle)\n\n# Para modelos que não serializam bem\n# (keras, xgboost, spark, etc.)\nbundled_model &lt;- bundle(ames_fit)\nsaveRDS(bundled_model, \"models/model_bundled.rds\")\n\n# Carregar e desempacotar\nloaded &lt;- readRDS(\"models/model_bundled.rds\")\nunbundled_model &lt;- unbundle(loaded)\n\n# Usar\npredict(unbundled_model, new_data)\n\n\nQuando usar bundle:\n\nModelos com dependências externas (Keras, TensorFlow)\nModelos Spark\nModelos XGBoost\nQuando RDS padrão não funciona\n\n\n\n\n\n\nCode\nlibrary(vetiver)\n\n# Criar versão deployável\nv &lt;- vetiver_model(ames_fit, \"ames_price_model\")\n\n# Salvar\nvetiver_pin_write(board, v)\n\n# Criar API\npr &lt;- pr() %&gt;%\n  vetiver_api(v)\n\n# Rodar servidor\npr_run(pr, port = 8080)\n\n\nVantagem: Framework completo para MLOps\n\n\n\n\n\nCode\n# Recipe preparada\nrecipe_prep &lt;- extract_recipe(ames_fit)\nsaveRDS(recipe_prep, \"models/recipe.rds\")\n\n# Modelo parsnip\nmodel_parsnip &lt;- extract_fit_parsnip(ames_fit)\nsaveRDS(model_parsnip, \"models/model.rds\")\n\n# Workflow\nsaveRDS(ames_workflow, \"models/workflow.rds\")\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(stacks)\n\n# Definir modelos candidatos\nctrl_grid &lt;- control_stack_grid()\n\n# Tuning de múltiplos modelos\nrf_res &lt;- tune_grid(rf_workflow, ames_folds, grid = 10, control = ctrl_grid)\nxgb_res &lt;- tune_grid(xgb_workflow, ames_folds, grid = 10, control = ctrl_grid)\nlm_res &lt;- fit_resamples(lm_workflow, ames_folds, control = ctrl_grid)\n\n# Criar stack\nmodel_stack &lt;- stacks() %&gt;%\n  add_candidates(rf_res) %&gt;%\n  add_candidates(xgb_res) %&gt;%\n  add_candidates(lm_res)\n\n# Treinar meta-modelo\nstack_fit &lt;- model_stack %&gt;%\n  blend_predictions() %&gt;%\n  fit_members()\n\n# Predições\npredict(stack_fit, ames_test)\n\n\n\n\n\n\n\nCode\n# Predições de múltiplos modelos\npred_rf &lt;- predict(rf_fit, ames_test)$.pred\npred_xgb &lt;- predict(xgb_fit, ames_test)$.pred\npred_lm &lt;- predict(lm_fit, ames_test)$.pred\n\n# Média ponderada\nensemble_pred &lt;- 0.5 * pred_rf + 0.3 * pred_xgb + 0.2 * pred_lm"
  },
  {
    "objectID": "apresentações/posts/tidymodels_documentacao.html#boas-práticas-e-dicas",
    "href": "apresentações/posts/tidymodels_documentacao.html#boas-práticas-e-dicas",
    "title": "7.1. Documentação: Tidymodels para Regressão em R",
    "section": "",
    "text": "Sequência correta:\n\nDividir dados em treino/teste ANTES de qualquer processamento\nExplorar apenas dados de treino\nCriar recipe baseada apenas em dados de treino\nRecipe é preparada apenas com dados de treino\nValidação cruzada DENTRO do conjunto de treino\nTestar modelo APENAS UMA VEZ no final\n\nPipeline ideal:\n\n\nCode\n# 1. Dividir\nsplit &lt;- initial_split(dados, prop = 0.75, strata = resposta)\ntreino &lt;- training(split)\nteste &lt;- testing(split)\n\n# 2. Explorar apenas treino\nsummary(treino)\nggplot(treino, aes(x = preditor, y = resposta)) + geom_point()\n\n# 3. Recipe baseada no treino\nrecipe &lt;- recipe(resposta ~ ., data = treino) %&gt;%\n  step_normalize(all_numeric_predictors())\n\n# 4. Validação cruzada no treino\nfolds &lt;- vfold_cv(treino, v = 10)\ncv_results &lt;- workflow() %&gt;%\n  add_recipe(recipe) %&gt;%\n  add_model(modelo) %&gt;%\n  fit_resamples(folds)\n\n# 5. Avaliar CV\ncollect_metrics(cv_results)\n\n# 6. Treinar modelo final\nfit_final &lt;- workflow() %&gt;%\n  add_recipe(recipe) %&gt;%\n  add_model(modelo) %&gt;%\n  fit(treino)\n\n# 7. Testar UMA VEZ\nteste_results &lt;- teste %&gt;%\n  select(resposta) %&gt;%\n  bind_cols(predict(fit_final, teste))\n\n\n\n\n\n\nData leakage ocorre quando informação do teste “vaza” para o treino\nExemplos de leakage:\n\n\nCode\n# ERRADO - Normaliza antes de dividir\ndados_norm &lt;- dados %&gt;%\n  mutate(across(where(is.numeric), scale))\nsplit &lt;- initial_split(dados_norm)\n\n# CORRETO - Normaliza dentro da recipe\nsplit &lt;- initial_split(dados)\nrecipe &lt;- recipe(resposta ~ ., training(split)) %&gt;%\n  step_normalize(all_numeric_predictors())\n\n\n\n\nCode\n# ERRADO - Remove outliers antes de dividir\ndados_sem_outliers &lt;- dados %&gt;%\n  filter(valor &lt; quantile(valor, 0.95))\nsplit &lt;- initial_split(dados_sem_outliers)\n\n# CORRETO - Remove dentro da recipe ou não remove\nsplit &lt;- initial_split(dados)\nrecipe &lt;- recipe(resposta ~ ., training(split)) %&gt;%\n  step_filter(valor &lt; quantile(valor, 0.95))\n\n\n\n\nCode\n# ERRADO - Seleção de variáveis em todos os dados\nmodelo &lt;- lm(resposta ~ var1 + var2, data = dados)  # baseado em todos\nsplit &lt;- initial_split(dados %&gt;% select(resposta, var1, var2))\n\n# CORRETO - Seleção dentro do treino\nsplit &lt;- initial_split(dados)\n# Análise exploratória apenas no treino para escolher variáveis\n\n\nPrevenção:\n\nSEMPRE dividir dados primeiro\nUsar recipes para transformações\nValidação cruzada apenas no treino\nNão usar teste para decisões de modelagem\n\n\n\n\n\n\n\nCode\n# Para regressão: estratifica por quantis da resposta\names_split &lt;- initial_split(ames, prop = 0.75, strata = Sale_Price)\names_folds &lt;- vfold_cv(ames_train, v = 10, strata = Sale_Price)\n\n# Para classificação: estratifica por classe\nsplit &lt;- initial_split(dados, strata = classe)\n\n\nBenefícios da estratificação:\n\nMantém distribuição da variável resposta\nEspecialmente importante com:\n\nDistribuições assimétricas\nDatasets pequenos\nValores raros ou extremos\nClasses desbalanceadas (classificação)\n\n\nNúmero de estratos:\n\nPadrão: 4 quantis para regressão\nPode ajustar com breaks se necessário\n\n\n\n\n\n\n\n\n\nCode\n# Criar resíduos\nresultados &lt;- teste %&gt;%\n  select(Sale_Price) %&gt;%\n  bind_cols(predict(fit_final, teste)) %&gt;%\n  mutate(\n    residuos = Sale_Price - .pred,\n    residuos_padrao = residuos / sd(residuos)\n  )\n\n# Sumário\nsummary(resultados$residuos)\n\n\nVerificações importantes:\n\n\nCode\nlibrary(ggplot2)\n\n# 1. Normalidade dos resíduos\nggplot(resultados, aes(sample = residuos)) +\n  stat_qq() + \n  stat_qq_line() +\n  labs(title = \"Q-Q Plot - Normalidade dos Resíduos\")\n\n# Teste de Shapiro-Wilk\nshapiro.test(resultados$residuos)\n\n# 2. Homocedasticidade (variância constante)\nggplot(resultados, aes(x = .pred, y = residuos)) +\n  geom_point(alpha = 0.5) +\n  geom_hline(yintercept = 0, color = \"red\", linetype = \"dashed\") +\n  geom_smooth(se = FALSE) +\n  labs(\n    x = \"Valores Preditos\",\n    y = \"Resíduos\",\n    title = \"Resíduos vs Predições\"\n  )\n\n# 3. Distribuição dos resíduos\nggplot(resultados, aes(x = residuos)) +\n  geom_histogram(bins = 30, fill = \"steelblue\", alpha = 0.7) +\n  labs(title = \"Distribuição dos Resíduos\")\n\n# 4. Resíduos vs variáveis preditoras\nggplot(resultados %&gt;% bind_cols(teste %&gt;% select(Gr_Liv_Area)), \n       aes(x = Gr_Liv_Area, y = residuos)) +\n  geom_point(alpha = 0.5) +\n  geom_hline(yintercept = 0, color = \"red\", linetype = \"dashed\") +\n  geom_smooth(se = FALSE)\n\n# 5. Valores preditos vs reais\nggplot(resultados, aes(x = Sale_Price, y = .pred)) +\n  geom_point(alpha = 0.5) +\n  geom_abline(slope = 1, intercept = 0, color = \"red\", linetype = \"dashed\") +\n  labs(\n    x = \"Valores Reais\",\n    y = \"Valores Preditos\",\n    title = \"Predito vs Real\"\n  )\n\n\nPadrões problemáticos:\n\nFunil: heterocedasticidade (variância não constante)\n\nSolução: transformação log, Box-Cox, ou usar modelos robustos\n\nCurva: relação não-linear não capturada\n\nSolução: adicionar termos polinomiais, splines, ou usar modelos não-lineares\n\nOutliers: pontos influentes\n\nSolução: investigar, possivelmente remover ou usar modelos robustos\n\nClusters: variáveis omitidas ou interações não modeladas\n\nSolução: incluir mais variáveis ou interações\n\n\n\n\n\n\n\nCode\n# Outliers (resíduos padronizados &gt; 3)\noutliers &lt;- resultados %&gt;%\n  filter(abs(residuos_padrao) &gt; 3)\n\n# Visualizar\nggplot(resultados, aes(x = seq_along(residuos), y = residuos_padrao)) +\n  geom_point() +\n  geom_hline(yintercept = c(-3, 3), color = \"red\", linetype = \"dashed\") +\n  labs(x = \"Índice\", y = \"Resíduos Padronizados\")\n\n# Para regressão linear: Distância de Cook\nmodelo_lm &lt;- extract_fit_engine(fit_final)\ncooks_d &lt;- cooks.distance(modelo_lm)\n\nplot(cooks_d, type = \"h\")\nabline(h = 4/length(cooks_d), col = \"red\", lty = 2)\n\n\n\n\n\n\n\nCode\nlibrary(car)\n\n# VIF (Variance Inflation Factor)\nmodelo_lm &lt;- extract_fit_engine(fit_final)\nvif(modelo_lm)"
  },
  {
    "objectID": "apresentações/posts/tidymodels_documentacao.html#comparação-de-modelos",
    "href": "apresentações/posts/tidymodels_documentacao.html#comparação-de-modelos",
    "title": "7.1. Documentação: Tidymodels para Regressão em R",
    "section": "",
    "text": "Modelo\nUso Principal\nVantagens\nDesvantagens\n\n\n\n\nLinear\nBaseline, interpretabilidade\nSimples, rápido, interpretável\nAssume linearidade\n\n\nRidge\nMulticolinearidade\nEstabiliza coeficientes\nMantém todas variáveis\n\n\nLasso\nSeleção variáveis\nRemove variáveis irrelevantes\nPode ser instável\n\n\nElastic Net\nCombinação\nEquilibra Ridge e Lasso\nMais hiperparâmetros\n\n\nRandom Forest\nRelações complexas\nNão-linear, robusto\nMenos interpretável, lento"
  },
  {
    "objectID": "apresentações/posts/tidymodels_documentacao.html#exemplo-completo",
    "href": "apresentações/posts/tidymodels_documentacao.html#exemplo-completo",
    "title": "7.1. Documentação: Tidymodels para Regressão em R",
    "section": "",
    "text": "# 1. PREPARAÇÃO DOS DADOS\nlibrary(tidymodels)\nlibrary(modeldata)\n\ndata(\"ames\")\nset.seed(123)\n\n# Divisão estratificada\names_split &lt;- initial_split(ames, prop = 0.75, strata = Sale_Price)\names_train &lt;- training(ames_split)\names_test &lt;- testing(ames_split)\n\n# 2. PRÉ-PROCESSAMENTO\names_recipe &lt;- recipe(Sale_Price ~ Gr_Liv_Area + Year_Built + \n                      Garage_Area + Total_Bsmt_SF, \n                      data = ames_train) %&gt;%\n  step_normalize(all_numeric_predictors()) %&gt;%  # Padronização\n  step_impute_median(all_numeric_predictors())  # Imputa NAs\n\n# 3. ESPECIFICAÇÃO DO MODELO\nlm_spec &lt;- linear_reg() %&gt;%\n  set_engine(\"lm\") %&gt;%\n  set_mode(\"regression\")\n\n# 4. WORKFLOW\names_wf &lt;- workflow() %&gt;%\n  add_recipe(ames_recipe) %&gt;%\n  add_model(lm_spec)\n\n# 5. VALIDAÇÃO CRUZADA\nset.seed(456)\names_folds &lt;- vfold_cv(ames_train, v = 10, strata = Sale_Price)\n\ncv_results &lt;- ames_wf %&gt;%\n  fit_resamples(\n    resamples = ames_folds,\n    control = control_resamples(save_pred = TRUE))\n\n# 6. AVALIAÇÃO CV\ncollect_metrics(cv_results)\n\n# 7. TREINO FINAL\nfinal_fit &lt;- ames_wf %&gt;%\n  fit(ames_train)\n\n# 8. TESTE\ntest_results &lt;- ames_test %&gt;%\n  select(Sale_Price) %&gt;%\n  bind_cols(predict(final_fit, ames_test))\n\n# 9. MÉTRICAS FINAIS\ntest_results %&gt;%\n  metrics(truth = Sale_Price, estimate = .pred)\n\n# 10. ANÁLISE DE RESÍDUOS\ntest_results &lt;- test_results %&gt;%\n  mutate(residuos = Sale_Price - .pred)\n\nsummary(test_results$residuos)\n\n# 11. PREDIÇÃO NOVA\nnova_casa &lt;- tibble(\n  Gr_Liv_Area = 2000,\n  Year_Built = 2010,\n  Garage_Area = 500,\n  Total_Bsmt_SF = 1200)\n\npredict(final_fit, nova_casa)"
  },
  {
    "objectID": "apresentações/posts/tidymodels_documentacao.html#troubleshooting-comum",
    "href": "apresentações/posts/tidymodels_documentacao.html#troubleshooting-comum",
    "title": "7.1. Documentação: Tidymodels para Regressão em R",
    "section": "",
    "text": "Causa: Variável na fórmula não existe nos dados\nSolução: Verificar nomes com names(dados)\n\n\n\nCausa: Problema no pré-processamento ou dados\nSolução: Verificar NAs, valores infinitos, variáveis constantes\n\n\n\nCausa: Multicolinearidade perfeita\nSolução: Remover variáveis redundantes ou usar regularização\n\n\n\nCausa: Dados novos faltam variáveis usadas no treino\nSolução: Garantir mesma estrutura nos novos dados"
  },
  {
    "objectID": "apresentações/posts/tidymodels_documentacao.html#recursos",
    "href": "apresentações/posts/tidymodels_documentacao.html#recursos",
    "title": "7.1. Documentação: Tidymodels para Regressão em R",
    "section": "",
    "text": "Tidymodels Site\nGuia Completo - Tidy Modeling with R (livro online gratuito)\nCheatsheet\n\n\n\n\n\nthemis: balanceamento de classes\nembed: feature engineering avançado\ntextrecipes: processamento de texto\nusemodels: gera código tidymodels automaticamente"
  },
  {
    "objectID": "apresentações/posts/tidymodels_documentacao.html#glossário",
    "href": "apresentações/posts/tidymodels_documentacao.html#glossário",
    "title": "7.1. Documentação: Tidymodels para Regressão em R",
    "section": "",
    "text": "Artifact: Visualização ou objeto criado no processo de análise\nBootstrap: Reamostragem com reposição\nCross-validation: Validação cruzada k-fold\nFeature engineering: Criação/transformação de variáveis\nHoldout: Conjunto de teste separado\nHyperparameter: Parâmetro definido antes do treino\nLeakage: Vazamento de informação do teste para treino\nOverfitting: Modelo muito ajustado aos dados de treino\nPipeline: Sequência automatizada de operações\nResampling: Técnicas de reamostragem (CV, bootstrap)\nStratification: Manter distribuição da resposta em divisões\nTuning: Otimização de hiperparâmetros"
  },
  {
    "objectID": "apresentações/posts/tidymodels_documentacao.html#assine-o-café-com-r",
    "href": "apresentações/posts/tidymodels_documentacao.html#assine-o-café-com-r",
    "title": "7.1. Documentação: Tidymodels para Regressão em R",
    "section": "",
    "text": "Que cada gole desperte uma nova ideia.\nQue cada script abra uma nova conversa.\nQue o Café com R, se torne um ponto de encontro nosso!"
  },
  {
    "objectID": "cafecomr/index.html",
    "href": "cafecomr/index.html",
    "title": "Uma pausa para falar de dados. Aqui você encontra todas as edições.",
    "section": "",
    "text": "O Café com R nasceu de um hábito simples: parar um pouco, respirar e pensar nos dados com calma. Entre um gole de café e outro, surgem as ideias, aquelas que não cabem só em código, mas fazem sentido quando viram conversa.\nSempre acreditei que aprender estatística e R não precisa ser algo distante, cheio de termos difíceis e resultados sem alma. Aqui eu falo do que realmente me move: experimentar, errar, aprender e compartilhar.\nMinha jornada foi bem assim, muitos acertos e erros! Mas hoje, sinto que estou 1% melhor a cada tentativa.\n\n\n\n\n\n\nDica\n\n\n\nEste espaço é pra gente se encontrar.\n\nQuero que o Café com R seja um ponto de troca entre quem vive estatística, dados e muito mais, independente do nível técnico ou da área.\n\nAqui cabe quem programa, quem pesquisa, quem ensina, quem está começando e quem ainda acha o R meio misterioso kkkkkkk.\n\nA ideia é assim: aprender junto, compartilhar o que funciona, rir dos erros e crescer com as experiências de cada um.\n\nSe tiver uma história, um script, um insight ou até uma dúvida que vale um café, esse lugar também é seu.🤎\n\n\nNão tem marketing, nem promessas de “domine o R em 7 dias”. Tem o que é real e funcionou para mim e outras pessoas que conheço: curiosidade, processo e aprendizado contínuo. Às vezes um pacote novo, às vezes uma reflexão sobre como a estatística muda o jeito que a gente enxerga o mundo e assim vai.\n\nEntão puxa uma cadeira, pega seu café e fica à vontade. O Café com R é pra quem aprende no ritmo da vida, devagar, respirando constante no momento presente e com propósito.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrimeiro café do ano ☕\n\n\n\nProjetos\n\nR\n\nPacotes\n\nFerramentas\n\n\n\nSabe aquele momento em que você abre um projeto de R que fez há 3 meses e não consegue entender ou lembrar o que estava fazendo?\n\n\n\n\n\nJan 15, 2026\n\n\nJennifer Luz Lopes\n\n\n\n\n\n\n\n\n\n\n\n\nCafé com R\n\n\n\nR\n\nNewsletter\n\nComunidade\n\nEventos\n\n\n\nAnálise de dados, uma conversa de cada vez\n\n\n\n\n\nDec 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nCafé da Semana☕\n\n\n\nR\n\nPacotes\n\nTidyverse\n\nFerramentas\n\n\n\nDescubra os pacotes que vão elevar sua análise de dados a outro nível\n\n\n\n\n\nDec 2, 2025\n\n\nJennifer Luz Lopes\n\n\n\n\n\n\n\n\n\n\n\n\nCafé da Semana☕\n\n\n\nEstatística\n\n\n\nDesmistificando o valor P e outras recomendações do universo R e da estatística\n\n\n\n\n\nNov 25, 2025\n\n\nJennifer Luz Lopes\n\n\n\n\n\n\n\n\n\n\n\n\nCafé da Semana☕\n\n\n\nResenha\n\nLivro\n\nEstatística\n\n\n\nQuando a ciência finalmente aprende a perguntar.\n\n\n\n\n\nNov 18, 2025\n\n\nJennifer Luz Lopes\n\n\n\n\n\n\n\n\n\n\n\n\nCafé da Semana - News quentinhas ☕\n\n\n\nEventos\n\n\n\nEdição especial para trazer as novidades do evento R+AI.\n\n\n\n\n\nNov 14, 2025\n\n\nJennifer Luz Lopes\n\n\n\n\n\n\n\n\n\n\n\n\nEventos da Comunidade R\n\n\n\nEventos\n\n\n\nEm atualização sempre\n\n\n\n\n\nNov 13, 2025\n\n\nJennifer Luz Lopes\n\n\n\n\n\n\n\n\n\n\n\n\nCafé da Semana☕\n\n\n\nEventos\n\nDesenvolvimento\n\nPacotes\n\n\n\nVamos começar com uma edição especial,um pouco diferente!\n\n\n\n\n\nNov 10, 2025\n\n\nJennifer Luz Lopes\n\n\n\n\n\nNo matching items\n Back to top"
  },
  {
    "objectID": "cafecomr/posts/06_01_dose6.html",
    "href": "cafecomr/posts/06_01_dose6.html",
    "title": "Primeiro café do ano ☕",
    "section": "",
    "text": "Olá, querida comunidade!\n\nQue alegria ter você aqui para no primeiro café de 2026. Nesta edição especial, preparei uma seleção de ferramentas e rotinas para você aplicar e organizar os seus projetos desenvolvidos no RStudio ou Positron.\n\nPegue sua xícara favorita e vamos juntos explorar o que há de mais interessante no universo R!"
  },
  {
    "objectID": "cafecomr/posts/06_01_dose6.html#bem-vindo-ao-nosso-encontro",
    "href": "cafecomr/posts/06_01_dose6.html#bem-vindo-ao-nosso-encontro",
    "title": "Primeiro café do ano ☕",
    "section": "",
    "text": "Olá, querida comunidade!\n\nQue alegria ter você aqui para no primeiro café de 2026. Nesta edição especial, preparei uma seleção de ferramentas e rotinas para você aplicar e organizar os seus projetos desenvolvidos no RStudio ou Positron.\n\nPegue sua xícara favorita e vamos juntos explorar o que há de mais interessante no universo R!"
  },
  {
    "objectID": "cafecomr/posts/06_01_dose6.html#a-base-estrutura-de-pastas-que-faz-sentido",
    "href": "cafecomr/posts/06_01_dose6.html#a-base-estrutura-de-pastas-que-faz-sentido",
    "title": "Primeiro café do ano ☕",
    "section": "A base: estrutura de pastas que faz sentido",
    "text": "A base: estrutura de pastas que faz sentido\nAntes de mais nada, vamos combinar uma coisa: cada projeto precisa ser um projeto dedicado.\nVocês concordam?\nIsso muda a forma que você trabalha porque você não precisa mais ficar usando setwd() para definir caminhos manualmente.\nCOMO COMEÇAR?\nBORA?\n\nComo criar um projeto no RStudio\nO primeiro passo é criar um projeto, se você está trabalhando no RStudio.\nNo RStudio, criar um projeto é simples:\n\nVá em File &gt; New Project\nEscolha uma das opções:\n\nNew Directory: cria uma pasta nova para o projeto\nExisting Directory: transforma uma pasta existente em projeto\nVersion Control: clona um repositório Git\n\nSe escolheu “New Directory”, selecione New Project\nDê um nome para o projeto e escolha onde salvar\nClique em Create Project\n\nPronto! O RStudio vai criar um arquivo .Rproj na pasta. É esse arquivo que você deve abrir para trabalhar no projeto.\n\nVeja como criar:\n\n\n\nFonte: R For Data Science.\n\n\n\n\n\n\nPrimeiro projeto. A imagem é antiga, mas nada mudou!\n\n\n\nComo criar um projeto no Positron\nO Positron, a nova IDE da Posit, também trabalha com projetos:\n\nVá em File &gt; New Project\nEscolha o tipo de projeto:\n\nNew Folder from Template: cria um projeto em branco\nOpen Folder: transforma uma pasta em projeto\nNew Folder from git: clona um repositório Git\n\nSelecione a pasta onde quer criar o projeto\nO Positron cria automaticamente a estrutura necessária\n\n\n\n\n\n\n\nTip\n\n\n\nO Positron reconhece projetos do RStudio (arquivos .Rproj) e vice-versa, então você pode alternar entre as duas IDEs sem problemas.\n\n\n\nUso de projetos no Positron:\n\n\n\n\n\n\nImportant\n\n\n\n\nNo Positron, as palavras “pasta”, “espaço de trabalho” e “projeto” são usadas quase como sinônimos, pois a forma mais comum de trabalhar é em um espaço de trabalho de pasta única.\n\n\n\n\n\n\nCriando projetos no Positron\n\nOpção 1 - Barra file\n\nO recurso “New Folder from Template” ajuda você a iniciar novos projetos mais rapidamente.\n\n\n\n\nSolicitação pelo menu file na barra superior, canto esquerdo.\n\n\n\n\nOpção 1 - Welcome\n\n\n\n\n\n\n\n\n\n\n\n\nOpção 2 - Modelos de pastas - Open Folder\n\nNeste caso você já tem uma pasta com os arquivos do seu projeto.\n\n\n\n\n\n\n\n\nOpção 3 - Modelos de pastas - New Folder from git\n\nClonando o repositório do GitHub\n\n\n\n\n\n\n\n\n\nAqui vai uma estrutura que uso e funciona muito bem:\nmeu-projeto/\n│\n├── meu-projeto.Rproj           # O arquivo do projeto\n├── README.md                   # Explica o que é o projeto\n├── .gitignore                  # Ignora coisas desnecessárias\n│\n├── data/\n│   ├── raw/                    # Dados originais (NUNCA mexa aqui!)\n│   └── processed/              # Dados limpos e processados\n│\n├── R/\n│   ├── 01-importacao.R         # Scripts numerados = ordem clara\n│   ├── 02-limpeza.R\n│   ├── 03-analise.R\n│   └── funcoes.R               # Suas funções customizadas\n│\n├── output/\n│   ├── figures/                # Seus gráficos\n│   ├── tables/                 # Tabelas exportadas\n│   └── reports/                # Relatórios finais\n│\n└── docs/\n    └── analise.qmd             # Seus documentos Quarto/RMarkdown\nPor que essa estrutura?\n\nVocê sempre sabe onde está cada coisa\nFica fácil compartilhar com outras pessoas\nDá pra versionar no Git sem problemas\nScripts numerados mostram a ordem do fluxo de trabalho\n\n\n\n\nPacotes que vão facilitar sua vida\n\n1. {here} - Fim dos problemas com caminhos de arquivo\ninstall.packages(\"here\")\nlibrary(here)\n\n# Em vez de:\ndados &lt;- read.csv(\"C:/Users/SeusDocumentos/Projetos/projeto1/data/arquivo.csv\")\n\n# Faça:\ndados &lt;- read.csv(here(\"data\", \"arquivo.csv\"))\n\n\n\n\n\n\nTip\n\n\n\nO {here} sempre encontra a raiz do seu projeto, não importa de onde você rode o script. Funciona como um sistema de navegação para seus arquivos.\n\n\nDocumentação do pacote.\n\n\n\n\n\n\n\n\n2. {renv} - Controle de versão de pacotes\nSabe quando você volta num projeto antigo e nada funciona porque os pacotes atualizaram? O {renv} resolve isso criando um ambiente isolado para cada projeto.\ninstall.packages(\"renv\")\n\n# No seu projeto:\nrenv::init()        # Cria o ambiente\nrenv::snapshot()    # Salva as versões dos pacotes\nrenv::restore()     # Restaura as versões salvas\n\n\n\n\n\n\nTip\n\n\n\nIsso permite que você restaure exatamente as mesmas versões dos pacotes quando voltar ao projeto. Uso em todos os projetos importantes.\n\n\nDocumentação do pacote.\n\n\n\n3. {usethis} - Automatiza tarefas repetitivas\nEste pacote é uma ferramenta versátil para criar e configurar projetos:\ninstall.packages(\"usethis\")\nlibrary(usethis)\n\n# Cria um projeto novo já estruturado\nusethis::create_project(\"~/meu-novo-projeto\")\n\n# Adiciona README\nusethis::use_readme_md()\n\n# Inicializa Git\nusethis::use_git()\n\n# Adiciona .gitignore com templates prontos\nusethis::git_vaccinate()\n\n# Cria arquivo de funções\nusethis::use_r(\"minhas_funcoes\")\nEle automatiza em segundos o que você levaria vários minutos fazendo manualmente.\nEU AMO ESSE PACOTE!\nDocumentação do pacote.\n\n\n\n4. {targets} - Para pipelines mais complexos\nSe você trabalha com análises que têm várias etapas e demoram para rodar, o {targets} é muito útil. Ele cria um pipeline onde só reprocessa o que mudou.\ninstall.packages(\"targets\")\n\n# Exemplo básico de _targets.R:\nlibrary(targets)\n\nlist(\n  tar_target(dados_raw, ler_dados()),\n  tar_target(dados_limpos, limpar_dados(dados_raw)),\n  tar_target(modelo, treinar_modelo(dados_limpos)),\n  tar_target(relatorio, gerar_relatorio(modelo)))\n\n\n\n\n\n\nTip\n\n\n\nMudou só a visualização? Ele não refaz a importação e limpeza dos dados. Isso economiza muito tempo.\n\n\nDocumentação\n\n\n\ntar_visnetwork(): Exibe o gráfico de dependências do pipeline, mostrando um fluxo de trabalho natural da esquerda para a direita. É uma boa prática garantir que o gráfico tenha os nós corretos conectados com as arestas corretas. Leia mais sobre dependências e o gráfico na seção de dependências de um capítulo posterior .\n\n\n\n\n\n\nDocumente pensando no futuro\n\nVocê provavelmente vai esquecer detalhes do projeto depois de algum tempo. Por isso a documentação é importante.\n\n\nREADME.md\nTodo projeto precisa de um README explicando:\n\nO que é o projeto\nQuais pacotes precisa\nComo rodar\nQuem criou e quando\n\nExemplo básico:\n# Análise de Vendas 2026\n\nAnálise exploratória dos dados de vendas da empresa no último ano.\n\n## Pacotes necessários\n\n```r\ninstall.packages(c(\"tidyverse\", \"here\", \"janitor\"))\n\n\n\nComo rodar\n\nAbra o arquivo analise-vendas.Rproj\nExecute os scripts na pasta R/ em ordem numérica\nO relatório final estará em output/reports/\n\n\n\nAutor\nSeu Nome - Janeiro/2026\n\n---\n\n### Comente seu código (mas comente bem)\n\n```r\n# Comentário ruim:\nx &lt;- dados %&gt;% filter(idade &gt; 18) # filtra idade\n\n# Comentário bom:\n# Remove menores de idade pois a análise foca apenas no público adulto\ndados_adultos &lt;- dados %&gt;% \n  filter(idade &gt; 18)\n\n# Ainda melhor - adiciona contexto de negócio:\n# Regulamentação interna exige análise separada para menores de idade\n# devido a políticas de proteção de dados (ver doc #123)\ndados_adultos &lt;- dados %&gt;% \n  filter(idade &gt; 18)\n\n\n\nConvenções de nomenclatura que funcionam\nArquivos de script:\n\nUse números para ordem: 01-, 02-, 03-\nNomes descritivos: 01-importacao-dados.R, não script.R\nTudo em minúsculo, use hífens: analise-vendas.R, não AnáliseVendas.R\n\n\n\n\nVersione com Git (mesmo que seja só você)\nMuita gente acha que Git é só para trabalho em equipe, mas ele também é útil para não perder trabalho e poder voltar a versões anteriores quando necessário.\nComandos básicos para começar:\n# No terminal do RStudio ou Positron:\ngit init\ngit add .\ngit commit -m \"Versão inicial do projeto\"\n\n# A cada avanço importante:\ngit add .\ngit commit -m \"Adiciona análise exploratória\"\nDica importante: faça commits com frequência.\nDica de livro, com explicações sobre Git e GitHub: Happy Git and GitHub for the useR\n\n\n\nTemplate inicial\nNão precisa criar tudo do zero. Já trouxe um exemplo para você aplicar.\n# Estrutura simples mas eficiente\nusethis::create_project(\"analise-rapida\")\nusethis::use_readme_md()\nusethis::use_r(\"funcoes\")\nfs::dir_create(c(\"data/raw\", \"data/processed\", \"output\"))\n\n\n\nTutorial completo para apoiar vocês:\n\n\n\n\n\n\nLink Youtube\nRepositório no GitHub\nApresentação\n\n\n\n\nMinha rotina de início de projeto (checklist)\nQuando começo um projeto novo, sigo estes passos:\n\nCriar projeto no RStudio ou Positron\nInicializar {renv} se for algo importante\nCriar estrutura de pastas\nAdicionar README.md\nInicializar Git\nCriar .gitignore apropriado\nFazer primeiro commit\n\nParece muito, pouco? Depois de fazer algumas vezes vira automático, e o {usethis} ajuda bastante.\n\n\n\nMensagem final para os cafezeiros de plantão!\nSei que no começo pode parecer trabalhoso organizar tudo. Você está animado para fazer a análise e não quer perder tempo com estrutura, README, etc.\nMas a verdade é: você não está perdendo tempo, está ganhando tempo.\nCada minuto que você investe organizando agora economiza horas depois quando precisar:\n\nVoltar no projeto daqui 6 meses\nCompartilhar com alguém\nReplicar a análise com dados novos\nDescobrir onde há algum problema\n\n\nComece com o básico (projetos + estrutura de pastas + README) e vá adicionando as outras práticas aos poucos. Não precisa ser perfeito, precisa ser melhor que antes.\n\n\nE você, como organiza seus projetos? Tem alguma dica que não mencionei aqui?\nMe conta nos comentários ou responde esse email. Gosto de trocar ideias sobre workflow.\nUm abraço e bom café (com R)!\n\nP.S.: Se você achou útil, compartilhe com aquele amigo que vive perdido nos próprios scripts.\n\n\n☕ Assine o Café com R\nQue cada gole desperte uma nova ideia.\nQue cada script abra uma nova conversa.\nQue o Café com R, se torne um ponto de encontro nosso!"
  },
  {
    "objectID": "cafecomr/posts/06_01_dose6.html#criando-projetos-no-positron",
    "href": "cafecomr/posts/06_01_dose6.html#criando-projetos-no-positron",
    "title": "Primeiro café do ano ☕",
    "section": "Criando projetos no Positron",
    "text": "Criando projetos no Positron\n\nOpção 1 - Barra file\n\nO recurso “New Folder from Template” ajuda você a iniciar novos projetos mais rapidamente.\n\n\n\n\nSolicitação pelo menu file na barra superior, canto esquerdo.\n\n\n\n\nOpção 1 - Welcome\n\n\n\n\n\n\n\n\n\n\n\n\nOpção 2 - Modelos de pastas - Open Folder\n\nNeste caso você já tem uma pasta com os arquivos do seu projeto.\n\n\n\n\n\n\n\n\nOpção 3 - Modelos de pastas - New Folder from git\n\nClonando o repositório do GitHub"
  },
  {
    "objectID": "cafecomr/posts/06_01_dose6.html#aqui-vai-uma-estrutura-que-uso-e-funciona-muito-bem",
    "href": "cafecomr/posts/06_01_dose6.html#aqui-vai-uma-estrutura-que-uso-e-funciona-muito-bem",
    "title": "Primeiro café do ano ☕",
    "section": "Aqui vai uma estrutura que uso e funciona muito bem:",
    "text": "Aqui vai uma estrutura que uso e funciona muito bem:\nmeu-projeto/\n│\n├── meu-projeto.Rproj           # O arquivo do projeto\n├── README.md                   # Explica o que é o projeto\n├── .gitignore                  # Ignora coisas desnecessárias\n│\n├── data/\n│   ├── raw/                    # Dados originais (NUNCA mexa aqui!)\n│   └── processed/              # Dados limpos e processados\n│\n├── R/\n│   ├── 01-importacao.R         # Scripts numerados = ordem clara\n│   ├── 02-limpeza.R\n│   ├── 03-analise.R\n│   └── funcoes.R               # Suas funções customizadas\n│\n├── output/\n│   ├── figures/                # Seus gráficos\n│   ├── tables/                 # Tabelas exportadas\n│   └── reports/                # Relatórios finais\n│\n└── docs/\n    └── analise.qmd             # Seus documentos Quarto/RMarkdown\nPor que essa estrutura?\n\nVocê sempre sabe onde está cada coisa\nFica fácil compartilhar com outras pessoas\nDá pra versionar no Git sem problemas\nScripts numerados mostram a ordem do fluxo de trabalho"
  },
  {
    "objectID": "cafecomr/posts/06_01_dose6.html#pacotes-que-vão-facilitar-sua-vida",
    "href": "cafecomr/posts/06_01_dose6.html#pacotes-que-vão-facilitar-sua-vida",
    "title": "Primeiro café do ano ☕",
    "section": "Pacotes que vão facilitar sua vida",
    "text": "Pacotes que vão facilitar sua vida\n\n1. {here} - Fim dos problemas com caminhos de arquivo\ninstall.packages(\"here\")\nlibrary(here)\n\n# Em vez de:\ndados &lt;- read.csv(\"C:/Users/SeusDocumentos/Projetos/projeto1/data/arquivo.csv\")\n\n# Faça:\ndados &lt;- read.csv(here(\"data\", \"arquivo.csv\"))\n\n\n\n\n\n\nTip\n\n\n\nO {here} sempre encontra a raiz do seu projeto, não importa de onde você rode o script. Funciona como um sistema de navegação para seus arquivos.\n\n\nDocumentação do pacote.\n\n\n\n\n\n\n\n\n2. {renv} - Controle de versão de pacotes\nSabe quando você volta num projeto antigo e nada funciona porque os pacotes atualizaram? O {renv} resolve isso criando um ambiente isolado para cada projeto.\ninstall.packages(\"renv\")\n\n# No seu projeto:\nrenv::init()        # Cria o ambiente\nrenv::snapshot()    # Salva as versões dos pacotes\nrenv::restore()     # Restaura as versões salvas\n\n\n\n\n\n\nTip\n\n\n\nIsso permite que você restaure exatamente as mesmas versões dos pacotes quando voltar ao projeto. Uso em todos os projetos importantes.\n\n\nDocumentação do pacote.\n\n\n\n3. {usethis} - Automatiza tarefas repetitivas\nEste pacote é uma ferramenta versátil para criar e configurar projetos:\ninstall.packages(\"usethis\")\nlibrary(usethis)\n\n# Cria um projeto novo já estruturado\nusethis::create_project(\"~/meu-novo-projeto\")\n\n# Adiciona README\nusethis::use_readme_md()\n\n# Inicializa Git\nusethis::use_git()\n\n# Adiciona .gitignore com templates prontos\nusethis::git_vaccinate()\n\n# Cria arquivo de funções\nusethis::use_r(\"minhas_funcoes\")\nEle automatiza em segundos o que você levaria vários minutos fazendo manualmente.\nEU AMO ESSE PACOTE!\nDocumentação do pacote.\n\n\n\n4. {targets} - Para pipelines mais complexos\nSe você trabalha com análises que têm várias etapas e demoram para rodar, o {targets} é muito útil. Ele cria um pipeline onde só reprocessa o que mudou.\ninstall.packages(\"targets\")\n\n# Exemplo básico de _targets.R:\nlibrary(targets)\n\nlist(\n  tar_target(dados_raw, ler_dados()),\n  tar_target(dados_limpos, limpar_dados(dados_raw)),\n  tar_target(modelo, treinar_modelo(dados_limpos)),\n  tar_target(relatorio, gerar_relatorio(modelo)))\n\n\n\n\n\n\nTip\n\n\n\nMudou só a visualização? Ele não refaz a importação e limpeza dos dados. Isso economiza muito tempo.\n\n\nDocumentação\n\n\n\ntar_visnetwork(): Exibe o gráfico de dependências do pipeline, mostrando um fluxo de trabalho natural da esquerda para a direita. É uma boa prática garantir que o gráfico tenha os nós corretos conectados com as arestas corretas. Leia mais sobre dependências e o gráfico na seção de dependências de um capítulo posterior ."
  },
  {
    "objectID": "cafecomr/posts/06_01_dose6.html#documente-pensando-no-futuro",
    "href": "cafecomr/posts/06_01_dose6.html#documente-pensando-no-futuro",
    "title": "Primeiro café do ano ☕",
    "section": "Documente pensando no futuro",
    "text": "Documente pensando no futuro\n\nVocê provavelmente vai esquecer detalhes do projeto depois de algum tempo. Por isso a documentação é importante.\n\n\nREADME.md\nTodo projeto precisa de um README explicando:\n\nO que é o projeto\nQuais pacotes precisa\nComo rodar\nQuem criou e quando\n\nExemplo básico:\n# Análise de Vendas 2026\n\nAnálise exploratória dos dados de vendas da empresa no último ano.\n\n## Pacotes necessários\n\n```r\ninstall.packages(c(\"tidyverse\", \"here\", \"janitor\"))"
  },
  {
    "objectID": "cafecomr/posts/06_01_dose6.html#como-rodar",
    "href": "cafecomr/posts/06_01_dose6.html#como-rodar",
    "title": "Primeiro café do ano ☕",
    "section": "Como rodar",
    "text": "Como rodar\n\nAbra o arquivo analise-vendas.Rproj\nExecute os scripts na pasta R/ em ordem numérica\nO relatório final estará em output/reports/"
  },
  {
    "objectID": "cafecomr/posts/06_01_dose6.html#autor",
    "href": "cafecomr/posts/06_01_dose6.html#autor",
    "title": "Primeiro café do ano ☕",
    "section": "Autor",
    "text": "Autor\nSeu Nome - Janeiro/2026\n\n---\n\n### Comente seu código (mas comente bem)\n\n```r\n# Comentário ruim:\nx &lt;- dados %&gt;% filter(idade &gt; 18) # filtra idade\n\n# Comentário bom:\n# Remove menores de idade pois a análise foca apenas no público adulto\ndados_adultos &lt;- dados %&gt;% \n  filter(idade &gt; 18)\n\n# Ainda melhor - adiciona contexto de negócio:\n# Regulamentação interna exige análise separada para menores de idade\n# devido a políticas de proteção de dados (ver doc #123)\ndados_adultos &lt;- dados %&gt;% \n  filter(idade &gt; 18)"
  },
  {
    "objectID": "cafecomr/posts/06_01_dose6.html#convenções-de-nomenclatura-que-funcionam",
    "href": "cafecomr/posts/06_01_dose6.html#convenções-de-nomenclatura-que-funcionam",
    "title": "Primeiro café do ano ☕",
    "section": "Convenções de nomenclatura que funcionam",
    "text": "Convenções de nomenclatura que funcionam\nArquivos de script:\n\nUse números para ordem: 01-, 02-, 03-\nNomes descritivos: 01-importacao-dados.R, não script.R\nTudo em minúsculo, use hífens: analise-vendas.R, não AnáliseVendas.R"
  },
  {
    "objectID": "cafecomr/posts/06_01_dose6.html#versione-com-git-mesmo-que-seja-só-você",
    "href": "cafecomr/posts/06_01_dose6.html#versione-com-git-mesmo-que-seja-só-você",
    "title": "Primeiro café do ano ☕",
    "section": "Versione com Git (mesmo que seja só você)",
    "text": "Versione com Git (mesmo que seja só você)\nMuita gente acha que Git é só para trabalho em equipe, mas ele também é útil para não perder trabalho e poder voltar a versões anteriores quando necessário.\nComandos básicos para começar:\n# No terminal do RStudio ou Positron:\ngit init\ngit add .\ngit commit -m \"Versão inicial do projeto\"\n\n# A cada avanço importante:\ngit add .\ngit commit -m \"Adiciona análise exploratória\"\nDica importante: faça commits com frequência.\nDica de livro, com explicações sobre Git e GitHub: Happy Git and GitHub for the useR"
  },
  {
    "objectID": "cafecomr/posts/06_01_dose6.html#template-inicial",
    "href": "cafecomr/posts/06_01_dose6.html#template-inicial",
    "title": "Primeiro café do ano ☕",
    "section": "Template inicial",
    "text": "Template inicial\nNão precisa criar tudo do zero. Já trouxe um exemplo para você aplicar.\n# Estrutura simples mas eficiente\nusethis::create_project(\"analise-rapida\")\nusethis::use_readme_md()\nusethis::use_r(\"funcoes\")\nfs::dir_create(c(\"data/raw\", \"data/processed\", \"output\"))"
  },
  {
    "objectID": "cafecomr/posts/06_01_dose6.html#tutorial-completo-para-apoiar-vocês",
    "href": "cafecomr/posts/06_01_dose6.html#tutorial-completo-para-apoiar-vocês",
    "title": "Primeiro café do ano ☕",
    "section": "Tutorial completo para apoiar vocês:",
    "text": "Tutorial completo para apoiar vocês:\n\n\n\n\n\n\nLink Youtube\nRepositório no GitHub\nApresentação"
  },
  {
    "objectID": "cafecomr/posts/06_01_dose6.html#minha-rotina-de-início-de-projeto-checklist",
    "href": "cafecomr/posts/06_01_dose6.html#minha-rotina-de-início-de-projeto-checklist",
    "title": "Primeiro café do ano ☕",
    "section": "Minha rotina de início de projeto (checklist)",
    "text": "Minha rotina de início de projeto (checklist)\nQuando começo um projeto novo, sigo estes passos:\n\nCriar projeto no RStudio ou Positron\nInicializar {renv} se for algo importante\nCriar estrutura de pastas\nAdicionar README.md\nInicializar Git\nCriar .gitignore apropriado\nFazer primeiro commit\n\nParece muito, pouco? Depois de fazer algumas vezes vira automático, e o {usethis} ajuda bastante."
  },
  {
    "objectID": "cafecomr/posts/06_01_dose6.html#mensagem-final-para-os-cafezeiros-de-plantão",
    "href": "cafecomr/posts/06_01_dose6.html#mensagem-final-para-os-cafezeiros-de-plantão",
    "title": "Primeiro café do ano ☕",
    "section": "Mensagem final para os cafezeiros de plantão!",
    "text": "Mensagem final para os cafezeiros de plantão!\nSei que no começo pode parecer trabalhoso organizar tudo. Você está animado para fazer a análise e não quer perder tempo com estrutura, README, etc.\nMas a verdade é: você não está perdendo tempo, está ganhando tempo.\nCada minuto que você investe organizando agora economiza horas depois quando precisar:\n\nVoltar no projeto daqui 6 meses\nCompartilhar com alguém\nReplicar a análise com dados novos\nDescobrir onde há algum problema\n\n\nComece com o básico (projetos + estrutura de pastas + README) e vá adicionando as outras práticas aos poucos. Não precisa ser perfeito, precisa ser melhor que antes.\n\n\nE você, como organiza seus projetos? Tem alguma dica que não mencionei aqui?\nMe conta nos comentários ou responde esse email. Gosto de trocar ideias sobre workflow.\nUm abraço e bom café (com R)!\n\nP.S.: Se você achou útil, compartilhe com aquele amigo que vive perdido nos próprios scripts."
  },
  {
    "objectID": "cafecomr/posts/06_01_dose6.html#assine-o-café-com-r",
    "href": "cafecomr/posts/06_01_dose6.html#assine-o-café-com-r",
    "title": "Primeiro café do ano ☕",
    "section": "☕ Assine o Café com R",
    "text": "☕ Assine o Café com R\nQue cada gole desperte uma nova ideia.\nQue cada script abra uma nova conversa.\nQue o Café com R, se torne um ponto de encontro nosso!"
  },
  {
    "objectID": "cafecomr/posts/10_11_dose1.html",
    "href": "cafecomr/posts/10_11_dose1.html",
    "title": "Café da Semana☕",
    "section": "",
    "text": "Seja bem-vinda(o)!\nAqui é uma pausa para falar de dados.\nA partir de hoje, toda semana vamos nos encontrar por aqui para conversar sobre ciência de dados de um jeito leve e prático."
  },
  {
    "objectID": "cafecomr/posts/10_11_dose1.html#esta-é-a-primeira-edição-do-café-com-r",
    "href": "cafecomr/posts/10_11_dose1.html#esta-é-a-primeira-edição-do-café-com-r",
    "title": "Café da Semana☕",
    "section": "",
    "text": "Seja bem-vinda(o)!\nAqui é uma pausa para falar de dados.\nA partir de hoje, toda semana vamos nos encontrar por aqui para conversar sobre ciência de dados de um jeito leve e prático."
  },
  {
    "objectID": "cafecomr/posts/10_11_dose1.html#organização-da-newsletter",
    "href": "cafecomr/posts/10_11_dose1.html#organização-da-newsletter",
    "title": "Café da Semana☕",
    "section": "Organização da Newsletter",
    "text": "Organização da Newsletter\n\n\n\n\n\n\nTip\n\n\n\nCada edição será uma pausa curta, mas que rende boas ideias. Você vai encontrar sempre a mesma estrutura, pensada para equilibrar aprendizado, reflexão e novidade:\n\nDose da Semana: uma dica prática de R para aplicar agora.\nConversa de Café: um espaço para pensar sobre aprendizado, propósito e comunidade.\nExpresso de Notícias: novidades do universo R e da ciência de dados.\nPilar da Semana (rotativo): um conteúdo especial, que pode ser um projeto, uma reflexão ou uma novidade."
  },
  {
    "objectID": "cafecomr/posts/10_11_dose1.html#abertura",
    "href": "cafecomr/posts/10_11_dose1.html#abertura",
    "title": "Café da Semana☕",
    "section": "Abertura",
    "text": "Abertura\nE hoje, começamos com chave de ouro. Simmm!\n\nEsta edição é especial, porque falo sobre um evento que me inspirou profundamente: o R/Pharma, que acompanhei online e que trouxe uma enxurrada de ideias novas sobre o uso do R."
  },
  {
    "objectID": "cafecomr/posts/10_11_dose1.html#expresso-de-notícias-novidades-do-universo-r-e-da-ciência-de-dados",
    "href": "cafecomr/posts/10_11_dose1.html#expresso-de-notícias-novidades-do-universo-r-e-da-ciência-de-dados",
    "title": "Café da Semana☕",
    "section": "Expresso de Notícias: novidades do universo R e da ciência de dados",
    "text": "Expresso de Notícias: novidades do universo R e da ciência de dados\n\nO que é o R/Pharma\nO R/Pharma é uma conferência online colaborativa, com foco científico e industrial, dedicada ao uso da tecnologia R no desenvolvimento de produtos farmacêuticos.\n\nAlém das sessões virtuais, o evento também realiza encontros presenciais e satélites em outras regiões do mundo, como na Ásia-Pacífico.\nMais do que uma conferência, o R/Pharma é uma comunidade que acredita no poder do código aberto e da colaboração entre empresas.\n\n\nSua missão é clara:\n\n\nPromover o uso de R e soluções open source na indústria farmacêutica.\nOrganizar eventos comunitários de alto nível técnico e científico, sem viés comercial.\nIncentivar debates, troca de conhecimento e construção coletiva de soluções.\n\n\n\n\n\n\n\nMinha escolha\nDurante o R/Pharma, eu escolhi os seguintes Workshops para trazer um conteúdo mais profundos e bacanas para vocês:\n\nIntroduction to building (better) R packages.\nCreating Polished, Branded Documents with Quarto\n\nHoje eu vou trazer um pouco do que eu aprendi e vi durantes a apresentação da Nicola Rennie e na semana que vem, trago mais uma dose de conhecimento sobre o Creating Polished, Branded Documents with Quarto (esse foi incrível também).\n\nBora? ahh, pega o café antes!"
  },
  {
    "objectID": "cafecomr/posts/10_11_dose1.html#introduction-to-building-better-r-packages.",
    "href": "cafecomr/posts/10_11_dose1.html#introduction-to-building-better-r-packages.",
    "title": "Café da Semana☕",
    "section": "Introduction to building (better) R packages.",
    "text": "Introduction to building (better) R packages.\n\n\nSobre o workshop\nEle foi FANTÁSTICO, eu acompanho o trabalho da Nicola, ela é uma grande inspiração para quem quer seguir o caminho do open-souce e de transformar a programação em R em algo acessível, palpável e reprodutível para a comunidade.\nE ela começou trazendo a importancia de transformar scripts e funções em um pacote R, e que isso é um divisor de águas para quem quer dar um passo além na organização do próprio código.\n\n“Quando deixamos de ter pastas soltas e passamos a estruturar tudo em um pacote, o trabalho ganha outra dimensão: fica mais fácil reutilizar, compartilhar, documentar e até testar o que fazemos.”\n\nDurante o workshop, a proposta foi exatamente essa mostrar que criar um pacote não precisa ser um processo complicado.\n\nPessoal, e não é, estou trabalhando no desenvolvimento de dois pacotes. O que precisamos é começar, ler os livros adequados, não tem atalho.\n\nO conteúdo foi conduzido de forma leve e prática, revelando os elementos essenciais para colocar um pacote de pé:\n\ndesde a estrutura mínima e a escrita de funções;\naté a criação de documentação e exemplos.\n\n\nNo fim das contas, esse workshop foi um lembrete importante: organizar o conhecimento em pacotes é uma das formas mais eficazes de devolver à comunidade aquilo que aprendemos.\n\n\n\n\n\n\n\nAcredite\n\n\n\nSaímos com um pacote pronto, básico é claro, mas para 120 minutos, foi ótimo.\n\n\nE está aqui, comecei do zero, abrindo o R e seguindo as etapas da apresentação.\n\n\n\n\n\nNão tive disponibilidade para finalizar o README e etc, mas o resultado está no meu GitHub:\n \n\n\n\nO que são pacotes?\nUma coleção de (alguns dos) seguintes ingredientes:\n\nFunções / Objetos R/ Dados / Documentação / Testes / Documentos R Markdown / Quarto.\n\n\n\nPor que fazer pacotes?\nPorque facilitam nossas vidas, concordam?\n\nExecutar código / Reutilizar código em diferentes projetos;\nCompartilhar o código com outras pessoas;\nLeitura da documentação em vez dos comentários, aqui é um ponto interessante!\n\n\n\nDesmistificação\nA Nicola trouxe um ponto importante que é a desmistificação do processo.\n\nSegundo ela:\n“Criar um pacote não é algo reservado a programadores avançados, nem exige que o código seja perfeito. A ideia central é organizar, documentar e compartilhar o que você já faz, e fazer isso de um jeito que facilite a reutilização”.\n\nA grande maioria das pessoas, acha que desenvolver pacotes não é para si.\nSINTO MUITO, quem pensa assim, se engana!\nÉ possível sim, fazer os seus desenvolvimentos, basta você querer, é claro!\n\n\n\nFonte: Imagens da Nicola.\n\n\n\n\n\nOs essenciais\n\nDurante a explicação, ela mostrou passo a passo como tudo começa com o pacote usethis, que cria a estrutura básica do projeto e automatiza tarefas repetitivas.\nEm seguida, apresentou o devtools, usado para construir, testar e instalar o pacote localmente.\nA documentação ganha vida com o roxygen2, que transforma comentários no código em arquivos de ajuda completos.\nE, se você quiser refinar o texto das funções, o stringr entra como um aliado opcional.\n\nAcredite, esses caras fazem a coisa toda acontecer, consultem a documentação deles, tem muitas funções úteis:\n\n\n\n\n\n\nTip\n\n\n\nPara criar a imagem clicável com os pacotes, usei o pacote hexsession, vejam a documentação, eu amei demais!\n\n\n\n\nCode\n# install.packages(\"remotes)\n# remotes::install_github(\"luisdva/hexsession\")\n\n# hexsession::make_tile(packages=c(\"terra\",\"sf\",\"tidyr\"))\n\n\n\n\nCode\nlibrary(usethis)\nlibrary(devtools)\nlibrary(roxygen2)\nlibrary(stringr)\n\nhexsession::make_tile()\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n  \n    created with hexsession\n  \n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPacote\nFunção\n\n\n\n\nusethis\nAutomatiza tarefas de desenvolvimento de pacotes e projetos em R (estrutura, licenças, Git, GitHub etc.)\n\n\ndevtools\nSimplifica o desenvolvimento de pacotes (instalação, build, documentação, testes, checagens)\n\n\nroxygen2\nGera automaticamente documentação de funções a partir de comentários no código\n\n\nstringr (opcional)\nFacilita a manipulação de strings com funções consistentes e intuitivas"
  },
  {
    "objectID": "cafecomr/posts/10_11_dose1.html#dose-da-semana-uma-dica-prática-de-r-para-aplicar-agora",
    "href": "cafecomr/posts/10_11_dose1.html#dose-da-semana-uma-dica-prática-de-r-para-aplicar-agora",
    "title": "Café da Semana☕",
    "section": "Dose da Semana: uma dica prática de R para aplicar agora",
    "text": "Dose da Semana: uma dica prática de R para aplicar agora\n\nComo começar a desenvolver meus pacotes?\nPegou o café aí?\nAbre o R então!\n\n\n\n\n\n\nDurante o workshop, a Nicola mostrou o fluxo completo, do zero até a criação de um pacote funcional. O processo pode parecer longo, mas na prática ele segue uma sequência lógica e muito tranquila.\n\n\n\nCriar a estrutura do pacote\n\nTudo começa com o usethis.\nÉ ele quem cria a base do pacote: pastas, arquivos e o esqueleto de tudo o que vem depois.\n\n\n\nCode\n# usethis::create_package(\"meuPacote\")\n\n\n\n\n\n\n\n\nImportant\n\n\n\nImportante\n\nEsse comando cria um novo diretório já configurado para funcionar como um pacote R.\nDentro dele, você encontrará pastas como R/ (onde ficam as funções) e arquivos essenciais como o DESCRIPTION, que guarda as informações básicas do pacote.\n\n\n\n\n\n\nEstrutura\nPara gerar a “árvore” do seu projeto use as funções dos pacotes fs e here, eles são ótimos:\n\n\nCode\n# fs::dir_tree(here::here())\n\n\n├── DESCRIPTION             # Metadados do pacote\n├── NAMESPACE               # Exportações geradas automaticamente\n├── LICENSE                 # Arquivo de licença\n├── _pkgdown.yml            # Configuração do site pkgdown\n├── cookbook.Rproj          # Projeto do RStudio\n├── README.md               # Documentação inicial do projeto\n│\n├── R/                      # Funções do pacote\n│   ├── generate_hex.R\n│   └── hello.R\n│\n├── man/                    # Documentação (gerada pelo roxygen2)\n│   ├── generate_hex.Rd\n│   └── hello.Rd\n│\n├── vignettes/              # Tutoriais e materiais explicativos (opcional)\n│   └── exemplo_tutorial.Rmd\n│\n├── tests/                  # Testes automatizados (opcional)\n│   └── testthat/\n│       └── test_hello.R\n│\n├── data/                   # Dados internos (opcional)\n│   └── exemplo.rda\n│\n├── inst/                   # Arquivos adicionais do pacote\n│   └── extdata/\n│       └── exemplo.csv\n│\n└── docs/                   # Site pkgdown (não editar manualmente)\n    └── index.html\n\n\n\n\nAdicionar funções\nAs funções que já usamos no dia a dia podem ser colocadas dentro da pasta R/.\n\n\nCode\n# usethis::use_r(\"minha_funcao\")\n\n\n\n\n\n\n\n\nImportant\n\n\n\nImportante\n\nEsse comando cria um arquivo .R pronto para receber a função.\nA ideia é ir centralizando o que faz sentido compartilhar. Pode ser uma função simples, mas que você sabe que vai reutilizar.\n\n\n\n\n\n\nDocumentar com o pacote roxygen2\nA documentação vem logo em seguida, e é aqui que o roxygen2 entra.\nAQUI ESTÁ O PULO DO GATO:\n\nEm vez de escrever arquivos de ajuda manualmente, basta comentar as funções com #', e o pacote faz o resto.\n\n\n\nCode\n#' Calcula a média de um vetor\n#'\n#' Essa função retorna a média simples dos valores informados.\n#'\n#' @param x Vetor numérico.\n#' @return Média dos valores.\n#' @examples\n#' calcula_media(c(1, 2, 3))\n#' @export\ncalcula_media &lt;- function(x) {\n  mean(x)\n}\n\n\nDepois, é só rodar:\n\n\nCode\n# devtools::document()\n\n\n\n\n\n\n\n\nImportant\n\n\n\nImportante\ndocument() gera automaticamente a documentação em formato .Rd dentro da pasta man/.\n\n\n\n\n\nTestar e carregar o pacote\nAntes de instalar, a Nicola destacou a importância de testar. Essa parte, não vou trazer em profundidade, mas é essencial, pois gente, sempre vão aprecendo erros, e precisamos corrigí-los de imediato.\n\nDeixei ao final a referência do livro R Packages para vocês, tem um capítulo chamado Testing, que aborda com profundidade essa etapa.\n\nCom o devtools, dá para carregar o pacote sem precisar instalar toda hora.\nEsse comando faz o R reconhecer as funções do pacote instantaneamente, o que facilita muito o desenvolvimento:\n\n\nCode\n# devtools::load_all()\n\n\n\n\nInstalar e usar\nAgora é a hora boa!\nQuando tudo estiver funcionando, é hora de instalar o pacote localmente.\n\n\nCode\n# devtools::install()\n\n\nDepois disso, ele já pode ser usado como qualquer outro, sinta orgulho de você:\n\n\nCode\n# library(meuPacote)\n\n\n\n\n\nCompartilhar no GitHub\nPor fim, vem a etapa prazerosa que é compartilhar o pacote com a comunidade,\ne no Workshop ela demonstrou como subir o projeto para o GitHub com um único comando:\n\n\nCode\n# usethis::use_github()\n\n\n\nA partir daí, o pacote ganha um endereço público, documentação visível e a chance de ser usado e melhorado por outras pessoas.\n\n\n\n\nSite do Pacote\nNo workshop não deu tempo dela demonstrar a publicação do site. Normalmente usamos o pacote pkgdown. O pkgdown transforma a documentação do pacote em um site navegável, bonito e automático, uma vitrine perfeita para apresentar o seu pacote.\n\n\n\n\n\nTrouxe alguns passos para vocês, de como fazer a publicacação.\nPara isso, use a seguinte função:\n\n\nCode\n# install.packages(\"pkgdown\")\n\n\nEsse comando cria a estrutura necessária para o site dentro do pacote.\n\n\nCode\n# usethis::use_pkgdown()\n\n\nDepois disso, basta gerar a versão estática com:\n\n\nCode\n# pkgdown::build_site()\n\n\n\nEm poucos segundos, o pacote ganha uma página HTML com toda a documentação formatada, exemplos interativos, índice de funções e até histórico de versões.\nPara publicar o site, basta ativar o GitHub Pages e conectar o repositório à pasta gerada automaticamente.\n\nSe quiser automatizar o processo (para que o site se atualize toda vez que houver um novo commit), o próprio pacote usethis facilita:\n\n\nCode\n# usethis::use_github_action(\"pkgdown\")\n\n\n\nAssim, o build do site passa a ser feito direto no GitHub, sem precisar rodar o comando manualmente.\n\n\n\n\n\nPara acompanhar o café: uma curadoria de boas leituras\nChegamos ao final, e como o assunto desta Newsletter foi sobre o Workshop de desenvolvimento de pacotes, github e mais, trouxe 4 referências interessantes para vocês:\n\nConheça mais sobre o trabalho da: Nicola Rennie, ela é especialista em visualização de dados com formação em estatística e ciência de dados, e tem interesse em compreender como comunicar ideias quantitativas complexas de forma acessível.\n\n\n\nLivro dos experientes: Hadley Wickham and Jennifer Bryan\n\n\n\n\n\nArtigo do RStudio user guide: Writing Packages\n\n\n\n\n\nAprofundar os conhecimentos do Git e GiHub: Happy Git and GitHub for the useR\n\nEsse livro da Jenny Bryan é ótimo, recomendo fortemente a leitura!\n\n\n\n\n\n\nConsideções finais sobre o WorkshopPrimeiro café☕ Assine o Café com R\n\n\nO que ficou mais forte para mim nesse workshop foi a ideia de que empacotar conhecimento é mais do que um ato técnico, é um gesto de generosidade.\nPense comigo:\n\nCada função que a gente organiza, documenta e compartilha vira uma forma de ajudar alguém a resolver um problema que nós já enfrentamos, concorda?\n\n\n\n\nProvavelmente, você tem uma função que já te salvou tempo, provavelmente alguém mais precisa dela também.\nCom isso, acredito que E essa é a beleza da comunidade R: aprender, construir e devolver. Um ciclo que transforma o código em colaboração, e a prática em propósito.\n\n\n\n\nQue cada gole desperte uma nova ideia.\nQue cada script abra uma nova conversa.\nQue o Café com R, se torne um ponto de encontro nosso!\n\n\nCarregando…"
  },
  {
    "objectID": "cafecomr/posts/18_11-resenhalivro.html",
    "href": "cafecomr/posts/18_11-resenhalivro.html",
    "title": "Café da Semana☕",
    "section": "",
    "text": "Seja bem-vinda(o)!\nAqui é uma pausa para falar de dados.\nToda semana vamos nos encontrar por aqui para conversar sobre ciência de dados, estatística e muito mais de um jeito leve e prático."
  },
  {
    "objectID": "cafecomr/posts/18_11-resenhalivro.html#esta-é-a-segunda-edição-do-café-com-r",
    "href": "cafecomr/posts/18_11-resenhalivro.html#esta-é-a-segunda-edição-do-café-com-r",
    "title": "Café da Semana☕",
    "section": "",
    "text": "Seja bem-vinda(o)!\nAqui é uma pausa para falar de dados.\nToda semana vamos nos encontrar por aqui para conversar sobre ciência de dados, estatística e muito mais de um jeito leve e prático."
  },
  {
    "objectID": "cafecomr/posts/18_11-resenhalivro.html#the-book-of-why-quando-a-ciência-finalmente-aprende-a-perguntar",
    "href": "cafecomr/posts/18_11-resenhalivro.html#the-book-of-why-quando-a-ciência-finalmente-aprende-a-perguntar",
    "title": "Café da Semana☕",
    "section": "The Book of Why: Quando a ciência finalmente aprende a perguntar",
    "text": "The Book of Why: Quando a ciência finalmente aprende a perguntar\nExiste um momento na vida em que você percebe que passou anos inteiros confundindo duas coisas completamente diferentes. Comigo, aconteceu ao ler “The Book of Why”, de Judea Pearl.\n\n\n\n\n\n\nEu achava que entendia a diferença entre correlação e causalidade. Achava mesmo! Até descobrir que não fazia ideia do abismo que separa essas duas formas de pensar.\n\nPearl não é apenas um estatístico brilhante. Ele é um revolucionário silencioso, daqueles que reescrevem as regras do jogo enquanto todo mundo ainda está jogando pelas antigas. E o jogo aqui é nada menos que a forma como entendemos o mundo, como fazemos ciência e como construímos inteligências artificiais.\n\n\n\n\n\n\n\nSobre a minha leitura\n\n\n\nPessoal, li esse livro em poucos dias. Fui anotando, refletindo e percebendo que era exatamente o tipo de leitura que eu buscava. Algo que me tirasse do automático, que me fizesse pensar fora da caixa e explorar novas perspectivas. Eu queria uma experiência diferente, um aprendizado que realmente mexesse comigo.\nForam 3 recomendações na mesma semana, então pensei:\n\nÉ UM SINAL.\n\nNão teria como trazer mais tópicos pois a resenha ficaria muito extensa, quero deixar vocês com gostinho de quero mais!\n\n\n\n\nA escada que muda tudo\nO conceito central do livro é a Escada da Causalidade, e se você ainda não ouviu falar dela, prepare-se para repensar muita coisa. Pearl divide o raciocínio causal em três degraus:\n\nassociação\nintervenção e\ncontrafactual\n\n\n\n\nFonte: Judea Pearl.\n\n\nNo primeiro degrau, a gente apenas observa.\n\nVemos que pessoas com guarda-chuva costumam estar molhadas.\nReconhecemos padrões, correlações, regularidades.\nÉ aqui que vivem as máquinas de hoje, os algoritmos de deep learning, toda a pompa do big data. Eles são mestres em perceber que A e B acontecem juntos, mas param por aí.\n\nO segundo degrau exige mais, a capacidade de agir e prever consequências.\n\nO que acontece se eu abrir o guarda-chuva?\n\nAqui não basta ver, é preciso fazer. É o território dos experimentos, das intervenções deliberadas, do teste de hipóteses.\nE então vem o terceiro degrau, o mais fascinante de todos, o contrafactual. A capacidade de imaginar o que teria acontecido se as coisas fossem diferentes. E se eu não tivesse aberto o guarda-chuva, estaria molhado agora? Esse tipo de pensamento é exclusivamente humano. Pelo menos por enquanto kskskksksksks.\n\n\n\n\n\n\nNote\n\n\n\n\nPearl argumenta que toda a inteligência moderna das máquinas está presa no primeiro degrau. Elas preveem, reconhecem, classificam, mas não entendem. Não sabem o porquê.\n\n\n\n\n\n\nA guerra silenciosa da estatística\nUma das partes mais interessantes do livro é a história que Pearl conta sobre como a estatística moderna, paradoxalmente, abandonou a causalidade. Francis Galton, Karl Pearson e toda uma geração de estatísticos construíram um império de correlações, mas ao preço de renunciar à pergunta mais importante: por quê?\n\nGalton observou que filhos de pais muito altos tendem a ser mais baixos, cunhando o termo “regressão à média”.\nPearson transformou isso em dogma, a ciência deveria descrever, não explicar. A causalidade foi tratada como especulação filosófica, algo subjetivo demais para ser científico.\n\n\n\n\nFonte: Judea Pearl. Você reconhece essas figuras?\n\n\n\nE então aparece Sewall Wright, um geneticista estudando porquinhos da índia, que ousou desenhar diagramas mostrando relações de causa e efeito. Ele foi massacrado pela academia. Disseram que seus métodos eram subjetivos, não rigorosos, anticientíficos. Wright estava décadas à frente do seu tempo, e pagou o preço.\n\nPearl resgata essa história para mostrar que não estamos diante de uma simples disputa técnica. Estamos diante de uma mudança de paradigma, do tipo que Thomas Kuhn descreveu:\n\nA comunidade científica resistindo até que as evidências se tornam inegáveis.\n\n\n\n\nParadoxos que revelam\nO livro dedica um capítulo inteiro aos paradoxos, e com razão. Eles são janelas para entender onde a intuição humana, naturalmente causal, entra em conflito com a lógica puramente estatística.\nO Paradoxo de Simpson me deixou INQUIETA.\n\n\n\nO Homer é para descontrair, no gráfico vocês prestem atenção! Paradoxo de Simpson: uma tendência positiva aparece para dois grupos separados, enquanto uma tendência negativa (pontilhada) aparece quando os grupos são combinados.\n\n\n\n\n\n\n\n\nO que é o paradoxo?\n\n\n\nO paradoxo de Simpson ocorre quando a tendência observada em grupos separados se inverte ao combinar esses grupos em um único conjunto de dados. Ele expõe uma armadilha estatística, em que as relações aparentes podem mudar completamente quando variáveis ocultas, como tamanho dos grupos, diferentes distribuições ou fatores de confusão, são ignoradas.\n\nSimplificando, cada subgrupo pode apresentar uma relação positiva entre duas variáveis, mas quando os dados são agregados, a relação global torna-se negativa (ou vice-versa), porque a composição dos grupos influencia o resultado mais do que os valores individuais.\nEsse paradoxo mostra que interpretar correlações, médias ou regressões sem considerar a estratificação adequada pode levar a conclusões totalmente equivocadas e decisões erradas, mesmo quando todos os cálculos estão estatisticamente corretos.\n\nGente, agora que sabemos mais sobre isso, estamos com a RESPONSA!\n\n\n\nO livro traz um exemplo, vejamos:\nImagine que um tratamento funciona melhor para homens e para mulheres quando analisados separadamente, mas parece pior quando os dados são combinados.\nComo isso é possível?\nA resposta está em entender a estrutura causal subjacente, em saber se existe uma variável de confusão afetando ambos os grupos.\nSem um diagrama causal, você pode olhar para os mesmos dados e tirar conclusões opostas. E ambas estarão “corretas” do ponto de vista estatístico. Mas apenas uma será verdadeira do ponto de vista causal.\nPearl mostra que todos esses paradoxos, do Monty Hall ao de Berkson, são resolvidos quando entendemos como os dados são gerados.\n\n\n\n\n\n\nMensagens de impacto para vocês\n\n\n\nA probabilidade descreve o que vemos.\nA causalidade explica por que vemos.\n\n\n\n\n\n\nO operador do() e a virada conceitual na forma de pensar causalidade\nPara mim, o ponto mais transformador do livro é a introdução do operador do(), que finalmente traduz em matemática algo que sempre sentimos falta na estatística tradicional, a possibilidade de representar explicitamente intervenção.\nAqui, gostaria que vocês ficassem atentos(as) para essa diferença:\n\nQuando escrevemos P(Y | do(X)), não estamos mais interpretando o comportamento natural dos dados, estamos perguntando como o sistema se comporta quando mexemos nele de propósito. Essa distinção parece pequena à primeira vista, mas muda tudo. É o salto entre observar correlação e entender mecanismo, entre descrever o que acontece e prever o que acontecerá quando agirmos.\nO contraste com P(Y | X), nos diz que, condicionar em X apenas retrata padrões existentes, sem romper as dependências que o sistema carrega. Já o do(X) corta essas setas causais, redesenha o cenário, força X a assumir um valor e observa como o resto reage.\n\n\nFoi aqui que percebi o tamanho da lacuna que existe entre análise estatística convencional e raciocínio causal. O livro deixa claro que, sem intervenção, real ou simulada, continuamos presos ao nível descritivo, mesmo usando técnicas avançadas.\n\nSem floreios, como dizemos lá no Sul:\n\nP(Y | X) responde o que eu vejo?\nP(Y | do(X)) responde o que acontece se eu agir?.\n\n\nAinda sobre do-calculus\nE é nesse ponto que o do-calculus se torna revolucionário. Pearl formalizou um conjunto de regras que permite manipular expressões causais com a mesma precisão com que calculamos derivadas na física. Essa comparação não é exagero, é exatamente o que senti ao ver como diagramas causais e essas regras permitem responder perguntas que, até então, pareciam impossíveis sem experimentos controlados.\nEle mostra que causalidade não é intuição solta, não é achismo, é uma estrutura matemática capaz de recuperar efeitos causais mesmo em cenários complexos, desde que o modelo causal esteja bem definido. Esse ponto é importante, pessoal!\n\nO impacto disso é enorme. Como leitora, percebi que essa abordagem desmonta uma parte importante da cultura estatística tradicional, que insiste em tratar causalidade como tabu ou como algo exclusivamente experimental.\n\nPearl mostra que é possível raciocinar causalmente de forma rigorosa, transparente e defensável e isso muda a forma como vemos análise de dados, ciência aplicada e, principalmente, tomada de decisão. O operador do() não é apenas uma notação, é um novo jeito de pensar.\n\n\n\n\nContrafactuais: O ápice da inteligência\nO capítulo sobre raciocínio contrafactual é onde Pearl mostra toda a profundidade filosófica do seu trabalho. Contrafactuais não são apenas ferramentas técnicas. São a essência do que nos torna humanos.\n\nQuando você se arrepende de uma decisão, está pensando contrafactualmente.\n\n\n\n\n\n\n\nExemplo\n\n\n\nQuando um tribunal avalia responsabilidade, a pergunta central é essencialmente causal.\no dano teria acontecido se o réu não tivesse tomado aquela ação?\nÉ um teste contrafactual. Compara-se o que ocorreu no mundo real com o que teria ocorrido em um mundo alternativo no qual a ação do réu foi removida.\n\nDa mesma forma, quando aprendemos com erros, estamos fazendo exatamente esse tipo de raciocínio.\n\nConfrontamos o fato com os mundos possíveis, o que teria acontecido se eu tivesse decidido diferente?\nEsse contraste entre o real e o contrafactual é o núcleo de todo aprendizado, seja na justiça, na ciência ou na vida prática.\nQue incrível!\n\n\nPearl argumenta que esse é o nível mais alto da inteligência, e que nenhuma máquina atual consegue raciocinar assim. Elas preveem futuros, mas não imaginam passados alternativos. Não compreendem arrependimento, responsabilidade ou lição aprendida.E isso tem consequências enormes. Sem raciocínio contrafactual, a inteligência artificial permanecerá cega, incapaz de explicar suas decisões ou entender suas consequências.\n\n\n\nO Futuro da inteligência artificial\nO último capítulo é uma visão para o futuro. Pearl acredita que a próxima revolução da IA depende de incorporar causalidade. As redes neurais atuais são poderosas, mas operam como caixas pretas estatísticas.\n\nElas reconhecem padrões, mas não entendem mecanismos.\n\n\n\n\n\n\n\nNote\n\n\n\nPara Pearl, uma IA verdadeiramente inteligente precisa subir toda a Escada da Causalidade.\n\nPrecisa observar, intervir e imaginar.\nPrecisa responder não apenas “o que vai acontecer”, mas “por que aconteceu” e “o que teria acontecido se fosse diferente”.\n\n\n\nIsso não é apenas uma questão técnica. É ético, filosófico e prático. Carros autônomos precisam entender relações causais para navegar com segurança. Sistemas de recomendação médica precisam prever efeitos individuais de tratamentos. Políticas públicas precisam ser simuladas antes de implementadas.\nE tudo isso exige causalidade, não apenas dados.\n\n\n\nPor que você deve ler este livro?\nPara mim, o The Book of Why não foi uma leitura leve. Pearl mistura filosofia, história, matemática e ciência cognitiva de um jeito que ora exige fôlego, ora abre janelas novas de compreensão. Em alguns trechos ele repete ideias para reforçar o ponto, e em outros a linguagem técnica pesa. Só que nada disso diminui o impacto da tese central, que é simplesmente incrível!\nO que Pearl mostra é que a humanidade avançou porque insistiu em perguntar por quê. E a ciência só conseguiu se desenvolver quando passou a transformar essa pergunta em modelos que explicam, testam e revelam mecanismos.\n\nPercebi ali o quanto a estatística, por quase um século, tratou essa pergunta como algo secundário, reduzindo a análise a padrões e correlações.\nPearl expõe essa limitação e oferece um caminho mais profundo, mais honesto e mais próximo de como o mundo realmente funciona.\nSe você trabalha com dados, pesquisa ou inteligência artificial, esse livro muda a forma de pensar.\nSe você busca ampliar sua visão de mundo, ele fornece ferramentas mentais que te acompanham depois da leitura.\nEu senti isso na prática, entender causalidade reorganiza a maneira como interpretamos decisões, sistemas, falhas e avanços.\n\n\n\n\n\n\n\nMensagem final\n\n\n\nNo fundo, compreender é sempre sobre causas. E causas são sempre sobre o porquê. Pearl encerra o livro lembrando que:\n\nOs dados nos dizem o que aconteceu, causalidade nos diz o que poderia acontecer.\nE essa diferença, percebida ao longo da leitura, muda absolutamente tudo.\n\n\n\n\nEspero que vocês tenham gostado. Escrevi essa resenha com muito carinho e com uma vontade genuína de compartilhar o que aprendi com um livro que, de verdade, me impactou.\n\n\n\nCafé, meu grande companheiro para leitura e escrita.\n\n\n\n\n☕ Assine o Café com R\n\nQue cada gole desperte uma nova ideia.\nQue cada script abra uma nova conversa.\nQue o Café com R, se torne um ponto de encontro nosso!"
  },
  {
    "objectID": "cafecomr/posts/eventos.html",
    "href": "cafecomr/posts/eventos.html",
    "title": "Eventos da Comunidade R",
    "section": "",
    "text": "Fique por dentro dos eventos, cursos e muito mais da comunidade R! \n\n\n\n\nEvento\nData\nFormato\nLink\n\n\n\n\nR/Pharma 2025\n3-7 novembro 2025\nOnline\nhttps://rinpharma.com/docs/RPH2025/\n\n\nR+AI\n12-13 novembro 2025\nOnline (Pago)\nhttps://r-consortium.org/posts/r_plus_ai_call_for_proposals/\n\n\nEvento R-Ladies Goiânia\n29 novembro\nOnline\nhttps://www.meetup.com/rladies-goiania/\n\n\nLatinR 2025\n1-5 dezembro 2025\nOnline\nhttps://latinr.org/en/\n\n\n\n\n2026\n\n\n\nEvento\nData\nFormato\nLink\n\n\n\n\nR!sk 2026\n18-19\nOnline\nhttps://rconsortium.github.io/Risk_website/\n\n\nrainbowR Conference\n25-26 fevereiro 2026\nOnline\nhttps://conference.rainbowr.org/\n\n\nR/Medicine 2026\n4-8 maio 2026\nOnline\nhttps://rconsortium.github.io/RMedicine_website/\n\n\nPosit::conf(2026)\n14-16 setembro 2026\nPresencial (Houston, USA)\nhttps://posit.co\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "projetos/index.html",
    "href": "projetos/index.html",
    "title": "Projetos",
    "section": "",
    "text": "Bem-vinda (o)!\nAqui apresentarei projetos completos de ciência de dados, com aplicações na:\n\nAgricultura\nEstatística | Estatística Experimental Agrícola\nProgramação\nMachine learning\n\nOs desenvolvimentos incluem:\n\nModelagem estatística, preditiva e genética (REML/BLUP, MGIDI, PCA)\nPipelines automatizados em R e Python\nConsultas, ETL e integração de dados via SQL (PostgreSQL, BigQuery, MariaDB)\nColeta e consumo de dados via APIs (Kaggle, GitHub, IBGE, Spotify, etc.)\nRelatórios dinâmicos e publicações automatizadas com Quarto e Blastula\nCriação de sites e livros técnicos em Quarto\nDashboards interativos com Shiny\nVersionamento e integração contínua com GitHub Actions (CI/CD)\nDocumentação e reprodutibilidade com {targets} e workflows de dados\nDesenvolvimento de pacotes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProjeto - Análise da Produção de Grãos no Brasil\n\n\n\nBigQuery\n\nbigdata\n\ngoogle_cloud\n\ndata_engineering\n\nmedallion_architecture\n\nagriculture\n\nIBGE\n\n\n\nIngestão via BigQuery, transformação em arquitetura Medallion e consumo de dados do BigQuery com R/dbplyr.\n\n\n\n\n\nDec 12, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nProjeto - Análise de Desmatamento e Produção Agrícola no Brasil\n\n\n\nBigQuery\n\nbigdata\n\ngoogle_cloud\n\ndata_engineering\n\nagriculture\n\nIBGE\n\nINPE\n\nML\n\nsf/geobr\n\n\n\nIntegrando dados do IBGE e INPE via BigQuery.\n\n\n\n\n\nDec 11, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nProjeto - Previsão da produtividade de arroz em casca\n\n\n\nMachine Learning\n\nTidymodels\n\n\n\nUsando o pacote tidymodels do R.\n\n\n\n\n\nDec 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nCurso Positron\n\n\n\nPosit\n\nIDE\n\nCurso\n\n\n\nO novo Ambiente de Desenvolvimento da Posit(RStudio).\n\n\n\n\n\nDec 7, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nGerenciamento de Projetos em R\n\n\n\nProjetos\n\nfs\n\nhere\n\nusethis\n\n\n\nPacotes: fs, usethis e here.\n\n\n\n\n\nDec 1, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nCurso de Introdução a Programação com R para Ciência de Dados\n\n\n\ncursos\n\n\n\nCurso construído para Comunidade de Estatística Thiago Marques.\n\n\n\n\n\nOct 28, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nModelagem Estatística para Seleção de Genótipos Superiores\n\n\n\nExperimentação\n\nEstatística\n\nModelagem\n\n\n\nAplicação de modelos mistos (REML/BLUP) e análise multivariada em dados simulados para seleção de genótipos superiores.\n\n\n\n\n\nOct 27, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nAutomatização para análise de um pipeline experimental\n\n\n\nAutomação\n\npipeline\n\nExperimentação\n\nEstatística\n\nModelagem\n\n\n\n\n\n\n\n\n\nOct 26, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nLivro - Para Análise e Ciência de Dados\n\n\n\nEscrita\n\nLivro\n\n\n\nem breve\n\n\n\n\n\nOct 15, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nDesenvolvimento de Pacote\n\n\n\nDesenvolvimento\n\nPacote\n\n\n\ncollectHub\n\n\n\n\n\nOct 10, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nDesenvolvimento de Pacote\n\n\n\nDesenvolvimento\n\nPacote\n\nEstatística Experimental\n\n\n\nexpReport\n\n\n\n\n\nOct 10, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nTese de Doutorado\n\n\n\nDoutorado\n\nPesquisa\n\n\n\nObtenção do Título na área de Melhoramento Genético de Plantas.\n\n\n\n\n\nSep 10, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nData Analysis Using R Software: Essential Approaches for Breeders\n\n\n\nEvento\n\nMelhoramento Genético\n\nR\n\n\n\nWorkshop ministrado para: GenMelhor UFV Viçosa\n\n\n\n\n\nNov 11, 2024\n\n\n\n\n\nNo matching items\n\n  \n\n Back to top"
  },
  {
    "objectID": "projetos/posts/2025-11-02-analise-experimental.html",
    "href": "projetos/posts/2025-11-02-analise-experimental.html",
    "title": "Modelagem Estatística para Seleção de Genótipos Superiores",
    "section": "",
    "text": "Modelagem para seleção de genótipos superiores\n\n\n  Relatório HTML \n  Código - GitHub \n  Site \n\n\nComo usar esse projeto?\nPara explorar este projeto, faça:\n\nUm fork ou clone do repositório em sua máquina local.\nEm seguida, acesse o relatório completo com as explicações detalhadas de cada etapa da análise em:\n🔗 https://jenniferlopes.quarto.pub/modelagem_experimental/\nUtilize os scripts disponíveis em meu_projeto/scripts/ para reproduzir toda a pipeline, desde a importação de dados via API até a modelagem com os modelos mistos (REML/BLUP) e a seleção dos genótipos superiores.\nOs dados simulados (alpha_lattice.xlsx) estão disponíveis em meu_projeto/dados/, permitindo que você execute o fluxo completo de análise e compreenda cada etapa da modelagem experimental aplicada.\nInstale os pacotes necessários\n\n\n\nCode\nif (!requireNamespace(\"pacman\", quietly = TRUE)) install.packages(\"pacman\")\n\npacman::p_load(\n  tidyverse, metan, lme4, lmerTest, broom.mixed,\n  emmeans, multcomp, plotly, writexl, readxl, httr2)\n\n\n\nExecute os scripts principais\n\n\n\nCode\n# Função de coleta de dados via API do GitHub\n# source(\"meu_projeto/funcoes/coleta_dados_github.R\")\n\n# Pipeline de modelagem experimental\n# source(\"meu_projeto/scripts/modelagem-experimental.R\")\n\n\n\n\nIntrodução\nA modelagem estatística em experimentos agrícolas tem como objetivo quantificar e compreender a variação experimental, separando os efeitos genéticos dos ambientais.\nEla é essencial para avaliar o desempenho de genótipos, estimar parâmetros genéticos e identificar materiais superiores com base em precisão e estabilidade experimental.\nNos delineamentos em blocos como o Alpha-Lattice, utilizados em ensaios com grande número de genótipos, os modelos lineares mistos (REML/BLUP) tornam-se fundamentais.\nEssa abordagem permite estimar simultaneamente os efeitos fixos (como repetições e tratamentos) e os efeitos aleatórios (como genótipos ou blocos incompletos), garantindo predições mais acuradas e imparciais.\n\n\nObjetivo\nEste projeto apresenta um exemplo completo de modelagem estatística aplicada à experimentação agrícola, abordando desde o ajuste do modelo até a interpretação dos resultados.\nA proposta é demonstrar, de forma prática e reprodutível, como aplicar modelos mistos (REML/BLUP) a dados experimentais obtidos de delineamentos do tipo Alpha-Lattice, com foco em:\n\nEstruturação e organização de projetos no R;\n\nAjuste de modelos (BLUE/BLUP) com o pacote lme4;\n\nEstimativa de herdabilidade;\n\nAnálise de agrupamento genético (UPGMA);\n\nInterpretação de resultados em contexto de melhoramento genético de plantas.\n\n\n\nStacks desenvolvidas\n\n\n\n\n\n\n\nCategoria\nFerramentas\n\n\n\n\nLinguagem\nR\n\n\nModelagem Estatística\nModelos Lineares Mistos (REML/BLUP), ANOVA, Herdabilidade, Agrupamento Hierárquico (UPGMA)\n\n\nPacotes R Utilizados\nlme4, emmeans, metan, broom.mixed, ggplot2, readxl, writexl, tidyverse, glue\n\n\nVisualização de Dados\nggplot2\n\n\nDocumentação e Estrutura de Projeto\nOrganização modular (dados/, funcoes/, scripts/, output/) -Pacotes fs e here\n\n\nControle de Versão\nGit e GitHub (commits, branches, versionamento)\n\n\n\n\n\nEstrutura do Projeto\nFaça o mesmo, consulte a estrutura do seu projeto:\n\n\nCode\n# fs::dir_tree(here::here())\n\n\nportfolio_experimentacao_agricola/\n├── estilo.css                          # Estilos visuais do \n├── _publish.yml                        # Configuração de publicação\n├── README.md                           # Descrição do projeto\n├── modelagem_experimental_explicacoes.qmd  # Documento principal\n│\n├── meu_projeto/\n│   ├── dados/\n│   │   └── alpha_lattice.xlsx          # Dados simulados\n│   │\n│   ├── figuras/                        # Gráficos e saídas visuais\n│   │\n│   ├── funcoes/\n│   │   └── coleta_dados_github.R       # Função para importar dados\n│   │\n│   ├── output/                         # Resultados e tabelas finais\n│   │\n│   └── scripts/\n│       ├── importacao_via_api.R        # Script de coleta e limpeza \n│       ├── modelagem-experimental.R    # Ajuste dos modelos mistos\n│       └── script_inicial.R            # Pipeline base do projeto\n\n\nScripts Principais\n\n\n\n\n\n\n\nScript\nFunção Principal\n\n\n\n\nscript_inicial.R\nConfiguração do ambiente, pacotes e diretórios.\n\n\nmodelagem_experimental_explicacoes.qmd\nAjuste dos modelos (BLUE e BLUP), estimativas genéticas, herdabilidade e agrupamento.\n\n\nimportacao_via_api.R\nImportação de dados diretamente do GitHub.\n\n\n\n\n\nImportação de dados via API do GitHub\nA importação dos dados via API do GitHub foi implementada para permitir que o projeto acesse arquivos diretamente de um repositório remoto, sem a necessidade de download manual.\n\nEssa abordagem garante reprodutibilidade, integração contínua e centralização dos dados experimentais, facilitando a atualização e o versionamento das bases utilizadas nas análises.\nPor meio da função coleta_dados_github(), o R realiza uma requisição HTTP à API do GitHub, decodifica o conteúdo em formato Base64 e lê o arquivo (.csv ou .xlsx) diretamente na sessão, utilizando os pacotes httr2, base64enc, readr e readxl.\n\n\n\nConceitos principais\n\n\n\n\n\n\n\nConceito\nDescrição\n\n\n\n\nBLUE\nBest Linear Unbiased Estimator -estimador dos efeitos fixos.\n\n\nBLUP\nBest Linear Unbiased Predictor - preditor dos efeitos aleatórios (valores genéticos).\n\n\nHerdabilidade (H²)\nProporção da variância total explicada por diferenças genéticas.\n\n\nUPGMA\nMétodo de agrupamento hierárquico baseado na distância genética entre genótipos.\n\n\n\n\n\nLicença\nEste projeto é distribuído sob a licença MIT.\n\nSinta-se à vontade para usar, adaptar e referenciar este conteúdo em trabalhos e cursos de experimentação agrícola.\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "projetos/posts/2025-11-02-Doutorado.html",
    "href": "projetos/posts/2025-11-02-Doutorado.html",
    "title": "Tese de Doutorado",
    "section": "",
    "text": "Pesquisa de Doutorado\nEm breve.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "projetos/posts/2025-11-02-livro.html",
    "href": "projetos/posts/2025-11-02-livro.html",
    "title": "Livro - Para Análise e Ciência de Dados",
    "section": "",
    "text": "Start daqui a pouco\nAtualizações:\n\nGrade pronta;\nSubmissão em janeiro para editora.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "projetos/posts/2025-11-02-pacote_expReport.html",
    "href": "projetos/posts/2025-11-02-pacote_expReport.html",
    "title": "Desenvolvimento de Pacote",
    "section": "",
    "text": "Pacote expReport\nOlá, pessoal!\nSe você já passou horas, talvez dias, debruçado sobre os dados de um experimento, sabe exatamente do que estou falando. Aquele ciclo interminável: limpar os dados, checar se o delineamento está correto, rodar a análise de variância, verificar os pressupostos, fazer os testes de médias, gerar gráficos… e quando você finalmente termina, percebe que precisa mudar um pequeno detalhe e recomeçar tudo.\nFoi exatamente nesse ciclo que a semente do expReport foi plantada.\nSou um apaixonada por dados e pela ciência que eles nos permitem descobrir, não acho fácil, tenho minhas dificuldades. Com isso, ao longo da minha jornada, percebi que uma quantidade enorme do nosso tempo e energia mental não era gasta na interpretação dos resultados, mas sim no processo mecânico e repetitivo da análise.\nEu me perguntava: “E se pudéssemos automatizar isso? E se existisse uma forma de ir dos dados brutos a um relatório completo e profissional com… uma única linha de código?”\nEssa pergunta se tornou uma missão pessoal. Comecei a rascunhar o que seria a ferramenta dos meus sonhos.\n\nEla precisaria ser inteligente, limpando nomes de colunas bagunçados automaticamente, porque todos nós já perdemos tempo com um erro de digitação.\nEla precisaria ser uma guardiã, diagnosticando a estrutura do experimento logo no início, me alertando sobre dados faltantes ou um delineamento desbalanceado.\nEla precisaria ser visual, me mostrando o croqui do meu experimento no campo, para que eu pudesse ver o que os números sozinhos não mostram.\nEla precisaria ser educacional, apresentando não apenas o resultado, mas também o modelo matemático por trás da análise, de forma clara e bonita.\nE, acima de tudo, ela precisaria ser flexível, capaz de lidar com delineamentos fatoriais, blocos incompletos e os mais variados testes de comparação de médias que usamos no dia a dia.\n\nHoje, o expReport é a ferramenta que eu gostaria de ter tido quando comecei. Ele encapsula horas de trabalho em uma única função, criar_relatorio_exp(), liberando nosso tempo para o que realmente importa: pensar, interpretar, questionar e descobrir.\n\nCalma, estou desenvolvendo as funções, não é uma tarefa simples, mas está sendo incrível. E vou mostrando tudo para vocês.\n\nObrigada por fazer parte desta jornada.\nEM BREVE, MAIS ATUALIZAÇÕES …….\nUm grande abraço,\n\n\n\n\n Back to top"
  },
  {
    "objectID": "projetos/posts/2025-12-01-gerenciamento_projetos.html",
    "href": "projetos/posts/2025-12-01-gerenciamento_projetos.html",
    "title": "Gerenciamento de Projetos em R",
    "section": "",
    "text": "Criando projetos, manipulando arquivos e organizando estruturas no R\nPacotes: {fs}, {usethis} e {here}\n\n  \n\n\n\nOrganizar projetos de análise de dados é um desafio comum para quem está começando e até para quem já tem experiência em programação com R. Quantas vezes você já se deparou com códigos que funcionavam perfeitamente no seu computador, mas quebravam quando compartilhados com colegas? Ou passou horas ajustando caminhos de arquivos porque mudou a estrutura de pastas? A boa notícia é que existem pacotes que resolvem esses problemas de forma definitiva\n\n\n\nEste repositório contém um guia prático e completo desenvolvido para a comunidade R-Ladies Goiânia, focado em três pilares essenciais para organização e gerenciamento de projetos em R:\n\n{usethis} - Criação de projetos reprodutíveis e configuração de infraestrutura\n{fs} - Manipulação segura e multiplataforma de arquivos e diretórios\n{here} - Garantia de caminhos consistentes e relativos ao projeto\n\n\n\n\nEnsinar boas práticas de organização de projetos em R\nDemonstrar o uso de ferramentas modernas para gerenciamento de arquivos\nPromover reprodutibilidade e portabilidade de código\nEliminar o uso de setwd() e caminhos absolutos\n\n\n\n\n\n\n\n\n\nR (versão ≥ 4.0.0)\nRStudio (recomendado)\nPacotes necessários:\n\ninstall.packages(c(\"usethis\", \"fs\", \"here\", \"quarto\"))\n\n\n\n\nClone ou baixe este repositório\ngit clone https://github.com/seu-usuario/tutorial-fs-usethis-here.git\nAbra o projeto no RStudio\n\nClique duas vezes no arquivo .Rproj\n\nRenderize o documento\nquarto::quarto_render(\"index.qmd\")\nSiga os exemplos interativamente\n\nExecute cada chunk de código sequencialmente\nPratique modificando os exemplos\n\n\n\n\n\n\n\n\n\nAprenda a criar projetos estruturados e configurar infraestrutura:\nlibrary(usethis)\n\n# Criar novo projeto\ncreate_project(\"meu_projeto\")\n\n# Inicializar Git\nuse_git()\n\n# Criar repositório no GitHub\nuse_github()\n\n\n\nDomine operações de arquivos de forma segura e consistente:\nlibrary(fs)\n\n# Criar estrutura de pastas\ndir_create(here(\"data\", c(\"raw\", \"clean\")))\ndir_create(here(c(\"scripts\", \"outputs\", \"figures\")))\n\n# Listar arquivos\ndir_ls(here(\"data\"))\n\n# Copiar e mover\nfile_copy(\"origem.csv\", \"destino.csv\")\nfile_move(\"arquivo.txt\", \"nova_pasta/arquivo.txt\")\n\n\n\nGaranta portabilidade do seu código:\nlibrary(here)\n\n# Sempre use here() para caminhos\ndados &lt;- read.csv(here(\"data\", \"raw\", \"dados.csv\"))\n\n# Funciona em qualquer sistema operacional!\nggsave(here(\"figures\", \"grafico.png\"))\n\n\n\n\n\n\n\n\nFunção\nDescrição\nExemplo\n\n\n\n\ndir_create()\nCria diretórios\ndir_create(\"data/raw\")\n\n\ndir_ls()\nLista conteúdo\ndir_ls(\"data\", glob = \"*.csv\")\n\n\ndir_tree()\nVisualiza estrutura\ndir_tree(here())\n\n\nfile_create()\nCria arquivos\nfile_create(\"script.R\")\n\n\nfile_copy()\nCopia arquivos\nfile_copy(\"a.txt\", \"b.txt\")\n\n\nfile_move()\nMove/renomeia\nfile_move(\"old.R\", \"new.R\")\n\n\nfile_delete()\nDeleta arquivos\nfile_delete(\"temp.txt\")\n\n\nfile_info()\nInformações detalhadas\nfile_info(\"data.csv\")\n\n\n\n\n\n\n\n\n\n# NÃO FAÇA ISSO\nsetwd(\"C:/Users/MeuNome/Documents/projeto\")\ndados &lt;- read.csv(\"../data/arquivo.csv\")\nProblemas: - Não funciona em outros computadores - Quebra com mudança de estrutura de pastas - Dificulta colaboração\n\n\n\n# FAÇA ISSO\nlibrary(here)\nlibrary(fs)\n\ndados &lt;- read.csv(here(\"data\", \"arquivo.csv\"))\nfile_copy(\n  here(\"data\", \"raw\", \"dados.xlsx\"),\n  here(\"data\", \"clean\", \"dados_processados.csv\"))\nVantagens: - Funciona em qualquer máquina - Multiplataforma (Windows, Mac, Linux) - Código reprodutível - Facilita colaboração\n\n\n\n\n\nmeu_projeto/\n├── meu_projeto.Rproj      # Arquivo de projeto\n├── README.md              # Documentação\n├── .gitignore             # Arquivos ignorados pelo Git\n├── data/\n│   ├── raw/               # Dados originais (nunca modificar!)\n│   └── clean/             # Dados processados\n├── scripts/\n│   ├── 01-import.R        # Importação de dados\n│   ├── 02-clean.R         # Limpeza e transformação\n│   └── 03-analyze.R       # Análises\n├── outputs/               # Resultados, tabelas\n├── figures/               # Gráficos exportados\n└── reports/               # Relatórios (Rmd, qmd)\n\n\n\n\nUse esta função para criar projetos padronizados:\ncriar_projeto_padrao &lt;- function(nome) {\n  # Criar projeto\n  usethis::create_project(nome)\n  \n  # Estrutura de pastas\n  fs::dir_create(here::here(\"data\", c(\"raw\", \"clean\")))\n  fs::dir_create(here::here(c(\"scripts\", \"outputs\", \"figures\", \"reports\")))\n  \n  # Scripts básicos\n  fs::file_create(here::here(\"scripts\", c(\n    \"01-import.R\",\n    \"02-clean.R\", \n    \"03-analyze.R\"\n  )))\n  \n  # Documentação\n  usethis::use_readme_md()\n  \n  # Git\n  usethis::use_git()\n  \n  message(\"✅ Projeto criado com sucesso!\")\n}\n\n# Usar:\ncriar_projeto_padrao(\"minha_analise\")\n\n\n\n\n\n\n\n{usethis}: https://usethis.r-lib.org/\n{fs}: https://fs.r-lib.org/\n{here}: https://here.r-lib.org/\n\n\n\n\n\nR for Data Science - Workflow: Projects\nRStudio Projects Tutorial\n\n\n\n\n\n{renv} - Gerenciamento de dependências: https://rstudio.github.io/renv/\n{targets} - Pipelines de análise: https://docs.ropensci.org/targets/\n\n\n\n\n\n\nContribuições são bem-vindas! Se você encontrou um erro ou tem sugestões de melhoria:\n\nAbra uma issue descrevendo o problema/sugestão\nFaça um fork do projeto\nCrie uma branch para sua feature (git checkout -b feature/MinhaFeature)\nCommit suas mudanças (git commit -m 'Adiciona nova feature')\nPush para a branch (git push origin feature/MinhaFeature)\nAbra um Pull Request\n\n\n\n\nJennifer Luz Lopes\nEngenheira Agrônoma | Doutora em Melhoramento Genético de Plantas\n  \n\n\n\n\n\nEste projeto está sob a licença MIT. \n\n\n\n\n\nR-Ladies Global - Por promover diversidade na comunidade R\nR-Ladies Goiânia - Pela oportunidade de compartilhar conhecimento\nPosit/RStudio - Pelas ferramentas incríveis que facilitam nosso trabalho\n\n\n\n\n\n\nR-Ladies Goiânia:Site\nR-Ladies Goiânia: Meetup\n\n\n\nFeito com 💜 para a comunidade R\n\n\n\nR-Ladies Goiânia"
  },
  {
    "objectID": "projetos/posts/2025-12-01-gerenciamento_projetos.html#olá",
    "href": "projetos/posts/2025-12-01-gerenciamento_projetos.html#olá",
    "title": "Gerenciamento de Projetos em R",
    "section": "",
    "text": "Organizar projetos de análise de dados é um desafio comum para quem está começando e até para quem já tem experiência em programação com R. Quantas vezes você já se deparou com códigos que funcionavam perfeitamente no seu computador, mas quebravam quando compartilhados com colegas? Ou passou horas ajustando caminhos de arquivos porque mudou a estrutura de pastas? A boa notícia é que existem pacotes que resolvem esses problemas de forma definitiva"
  },
  {
    "objectID": "projetos/posts/2025-12-01-gerenciamento_projetos.html#sobre-o-projeto",
    "href": "projetos/posts/2025-12-01-gerenciamento_projetos.html#sobre-o-projeto",
    "title": "Gerenciamento de Projetos em R",
    "section": "",
    "text": "Este repositório contém um guia prático e completo desenvolvido para a comunidade R-Ladies Goiânia, focado em três pilares essenciais para organização e gerenciamento de projetos em R:\n\n{usethis} - Criação de projetos reprodutíveis e configuração de infraestrutura\n{fs} - Manipulação segura e multiplataforma de arquivos e diretórios\n{here} - Garantia de caminhos consistentes e relativos ao projeto\n\n\n\n\nEnsinar boas práticas de organização de projetos em R\nDemonstrar o uso de ferramentas modernas para gerenciamento de arquivos\nPromover reprodutibilidade e portabilidade de código\nEliminar o uso de setwd() e caminhos absolutos"
  },
  {
    "objectID": "projetos/posts/2025-12-01-gerenciamento_projetos.html#como-usar-este-tutorial",
    "href": "projetos/posts/2025-12-01-gerenciamento_projetos.html#como-usar-este-tutorial",
    "title": "Gerenciamento de Projetos em R",
    "section": "",
    "text": "R (versão ≥ 4.0.0)\nRStudio (recomendado)\nPacotes necessários:\n\ninstall.packages(c(\"usethis\", \"fs\", \"here\", \"quarto\"))\n\n\n\n\nClone ou baixe este repositório\ngit clone https://github.com/seu-usuario/tutorial-fs-usethis-here.git\nAbra o projeto no RStudio\n\nClique duas vezes no arquivo .Rproj\n\nRenderize o documento\nquarto::quarto_render(\"index.qmd\")\nSiga os exemplos interativamente\n\nExecute cada chunk de código sequencialmente\nPratique modificando os exemplos"
  },
  {
    "objectID": "projetos/posts/2025-12-01-gerenciamento_projetos.html#tutorial",
    "href": "projetos/posts/2025-12-01-gerenciamento_projetos.html#tutorial",
    "title": "Gerenciamento de Projetos em R",
    "section": "",
    "text": "Aprenda a criar projetos estruturados e configurar infraestrutura:\nlibrary(usethis)\n\n# Criar novo projeto\ncreate_project(\"meu_projeto\")\n\n# Inicializar Git\nuse_git()\n\n# Criar repositório no GitHub\nuse_github()\n\n\n\nDomine operações de arquivos de forma segura e consistente:\nlibrary(fs)\n\n# Criar estrutura de pastas\ndir_create(here(\"data\", c(\"raw\", \"clean\")))\ndir_create(here(c(\"scripts\", \"outputs\", \"figures\")))\n\n# Listar arquivos\ndir_ls(here(\"data\"))\n\n# Copiar e mover\nfile_copy(\"origem.csv\", \"destino.csv\")\nfile_move(\"arquivo.txt\", \"nova_pasta/arquivo.txt\")\n\n\n\nGaranta portabilidade do seu código:\nlibrary(here)\n\n# Sempre use here() para caminhos\ndados &lt;- read.csv(here(\"data\", \"raw\", \"dados.csv\"))\n\n# Funciona em qualquer sistema operacional!\nggsave(here(\"figures\", \"grafico.png\"))"
  },
  {
    "objectID": "projetos/posts/2025-12-01-gerenciamento_projetos.html#principais-funcionalidades-do-fs",
    "href": "projetos/posts/2025-12-01-gerenciamento_projetos.html#principais-funcionalidades-do-fs",
    "title": "Gerenciamento de Projetos em R",
    "section": "",
    "text": "Função\nDescrição\nExemplo\n\n\n\n\ndir_create()\nCria diretórios\ndir_create(\"data/raw\")\n\n\ndir_ls()\nLista conteúdo\ndir_ls(\"data\", glob = \"*.csv\")\n\n\ndir_tree()\nVisualiza estrutura\ndir_tree(here())\n\n\nfile_create()\nCria arquivos\nfile_create(\"script.R\")\n\n\nfile_copy()\nCopia arquivos\nfile_copy(\"a.txt\", \"b.txt\")\n\n\nfile_move()\nMove/renomeia\nfile_move(\"old.R\", \"new.R\")\n\n\nfile_delete()\nDeleta arquivos\nfile_delete(\"temp.txt\")\n\n\nfile_info()\nInformações detalhadas\nfile_info(\"data.csv\")"
  },
  {
    "objectID": "projetos/posts/2025-12-01-gerenciamento_projetos.html#por-que-usar-estes-pacotes",
    "href": "projetos/posts/2025-12-01-gerenciamento_projetos.html#por-que-usar-estes-pacotes",
    "title": "Gerenciamento de Projetos em R",
    "section": "",
    "text": "# NÃO FAÇA ISSO\nsetwd(\"C:/Users/MeuNome/Documents/projeto\")\ndados &lt;- read.csv(\"../data/arquivo.csv\")\nProblemas: - Não funciona em outros computadores - Quebra com mudança de estrutura de pastas - Dificulta colaboração\n\n\n\n# FAÇA ISSO\nlibrary(here)\nlibrary(fs)\n\ndados &lt;- read.csv(here(\"data\", \"arquivo.csv\"))\nfile_copy(\n  here(\"data\", \"raw\", \"dados.xlsx\"),\n  here(\"data\", \"clean\", \"dados_processados.csv\"))\nVantagens: - Funciona em qualquer máquina - Multiplataforma (Windows, Mac, Linux) - Código reprodutível - Facilita colaboração"
  },
  {
    "objectID": "projetos/posts/2025-12-01-gerenciamento_projetos.html#estrutura-recomendada-para-projetos",
    "href": "projetos/posts/2025-12-01-gerenciamento_projetos.html#estrutura-recomendada-para-projetos",
    "title": "Gerenciamento de Projetos em R",
    "section": "",
    "text": "meu_projeto/\n├── meu_projeto.Rproj      # Arquivo de projeto\n├── README.md              # Documentação\n├── .gitignore             # Arquivos ignorados pelo Git\n├── data/\n│   ├── raw/               # Dados originais (nunca modificar!)\n│   └── clean/             # Dados processados\n├── scripts/\n│   ├── 01-import.R        # Importação de dados\n│   ├── 02-clean.R         # Limpeza e transformação\n│   └── 03-analyze.R       # Análises\n├── outputs/               # Resultados, tabelas\n├── figures/               # Gráficos exportados\n└── reports/               # Relatórios (Rmd, qmd)"
  },
  {
    "objectID": "projetos/posts/2025-12-01-gerenciamento_projetos.html#template-de-projeto-automatizado",
    "href": "projetos/posts/2025-12-01-gerenciamento_projetos.html#template-de-projeto-automatizado",
    "title": "Gerenciamento de Projetos em R",
    "section": "",
    "text": "Use esta função para criar projetos padronizados:\ncriar_projeto_padrao &lt;- function(nome) {\n  # Criar projeto\n  usethis::create_project(nome)\n  \n  # Estrutura de pastas\n  fs::dir_create(here::here(\"data\", c(\"raw\", \"clean\")))\n  fs::dir_create(here::here(c(\"scripts\", \"outputs\", \"figures\", \"reports\")))\n  \n  # Scripts básicos\n  fs::file_create(here::here(\"scripts\", c(\n    \"01-import.R\",\n    \"02-clean.R\", \n    \"03-analyze.R\"\n  )))\n  \n  # Documentação\n  usethis::use_readme_md()\n  \n  # Git\n  usethis::use_git()\n  \n  message(\"✅ Projeto criado com sucesso!\")\n}\n\n# Usar:\ncriar_projeto_padrao(\"minha_analise\")"
  },
  {
    "objectID": "projetos/posts/2025-12-01-gerenciamento_projetos.html#links-úteis",
    "href": "projetos/posts/2025-12-01-gerenciamento_projetos.html#links-úteis",
    "title": "Gerenciamento de Projetos em R",
    "section": "",
    "text": "{usethis}: https://usethis.r-lib.org/\n{fs}: https://fs.r-lib.org/\n{here}: https://here.r-lib.org/\n\n\n\n\n\nR for Data Science - Workflow: Projects\nRStudio Projects Tutorial\n\n\n\n\n\n{renv} - Gerenciamento de dependências: https://rstudio.github.io/renv/\n{targets} - Pipelines de análise: https://docs.ropensci.org/targets/"
  },
  {
    "objectID": "projetos/posts/2025-12-01-gerenciamento_projetos.html#contribuindo",
    "href": "projetos/posts/2025-12-01-gerenciamento_projetos.html#contribuindo",
    "title": "Gerenciamento de Projetos em R",
    "section": "",
    "text": "Contribuições são bem-vindas! Se você encontrou um erro ou tem sugestões de melhoria:\n\nAbra uma issue descrevendo o problema/sugestão\nFaça um fork do projeto\nCrie uma branch para sua feature (git checkout -b feature/MinhaFeature)\nCommit suas mudanças (git commit -m 'Adiciona nova feature')\nPush para a branch (git push origin feature/MinhaFeature)\nAbra um Pull Request\n\n\n\n\nJennifer Luz Lopes\nEngenheira Agrônoma | Doutora em Melhoramento Genético de Plantas"
  },
  {
    "objectID": "projetos/posts/2025-12-01-gerenciamento_projetos.html#licença",
    "href": "projetos/posts/2025-12-01-gerenciamento_projetos.html#licença",
    "title": "Gerenciamento de Projetos em R",
    "section": "",
    "text": "Este projeto está sob a licença MIT."
  },
  {
    "objectID": "projetos/posts/2025-12-01-gerenciamento_projetos.html#agradecimentos",
    "href": "projetos/posts/2025-12-01-gerenciamento_projetos.html#agradecimentos",
    "title": "Gerenciamento de Projetos em R",
    "section": "",
    "text": "R-Ladies Global - Por promover diversidade na comunidade R\nR-Ladies Goiânia - Pela oportunidade de compartilhar conhecimento\nPosit/RStudio - Pelas ferramentas incríveis que facilitam nosso trabalho"
  },
  {
    "objectID": "projetos/posts/2025-12-01-gerenciamento_projetos.html#contato",
    "href": "projetos/posts/2025-12-01-gerenciamento_projetos.html#contato",
    "title": "Gerenciamento de Projetos em R",
    "section": "",
    "text": "R-Ladies Goiânia:Site\nR-Ladies Goiânia: Meetup\n\n\n\nFeito com 💜 para a comunidade R\n\n\n\nR-Ladies Goiânia"
  },
  {
    "objectID": "projetos/posts/2025-12-12-desmatamento.html",
    "href": "projetos/posts/2025-12-12-desmatamento.html",
    "title": "Projeto - Análise de Desmatamento e Produção Agrícola no Brasil",
    "section": "",
    "text": "Obs: Desenvolvi esse trabalho em 2024, mas não havia publicado para rede. Pretendo ampliar as análises, culturas e anos.\nEste projeto analisa a relação entre produção agrícola das principais culturas brasileiras (soja, milho e arroz) e o desmatamento em municípios do país. A análise integra dados oficiais do IBGE e INPE para identificar padrões espaciais e temporais, classificar municípios por risco ambiental e desenvolver modelos preditivos.\n\n\n\n\nMapear espacialmente municípios com maior desmatamento e produção agrícola\nClassificar municípios por nível de risco ambiental (baixo, médio, alto)\nAnalisar séries temporais para identificar tendências de desmatamento e produção\nDesenvolver modelo preditivo usando Random Forest para estimar desmatamento\nIdentificar variáveis-chave que mais contribuem para o desmatamento\n\n\n\n\nPessoal, sempre gosto de construir os scripts.R e um relatório.qmd nos meus projetos.\n\nVocês podem acessar o relatório em HTML aqui.\nRepositório completo no GitHub.\n\n\n\n\nProdução Agrícola Municipal (PAM) - IBGE:\n\nProdução total (toneladas)\nÁrea colhida (hectares)\nValor da produção\nCulturas: soja, milho e arroz em grão\n\nPrograma de Monitoramento do Desmatamento (PRODES) - INPE:\n\nDesmatamento anual (hectares)\nÁrea total municipal\nCobertura vegetal natural\n\nAmbas as fontes foram acessadas via Base dos Dados (BigQuery), cobrindo o período de 2015 a 2021.\n\n\n\n\n\n\nConexão ao BigQuery para extração de dados PAM e PRODES\nIntegração das bases por município e ano\nValidação e limpeza de dados inconsistentes\n\n\n\n\nCriação de variáveis derivadas para análise:\n\nTemporais: lags de desmatamento, médias móveis, crescimento de produção\nEficiência: produtividade (ton/ha), risco por tonelada (ha/ton)\nPressão ambiental: relação entre área cultivada e vegetação natural\nClassificação: classes de risco baseadas em percentis\n\n\n\n\n\nDivisão temporal: treino (2015-2019), validação (2020), teste\n\n\n\nAlgoritmo: Random Forest com 300 árvores\nFeatures: 9 variáveis selecionadas (produção, área, produtividade, histórico de desmatamento, etc.)\nAvaliação: MAE, RMSE, R², MAPE\n\n\n\n\n\nEstatísticas descritivas por classe de risco\nAnálise temporal agregada\nDistribuição espacial do desmatamento\n\n\n\n\n\nGráficos de importância de variáveis\nScatter plots de produção vs desmatamento\nMapas interativos (Leaflet)\n\n\n\n\n\nrisco_desmatamento/\n├── .gitignore\n├── .Rprofile\n├── renv/\n├── renv.lock\n├── risco_desmatamento.Rproj\n├── README.md\n├── scripts/\n│   └── risco_desmatamento.R\n├── outputs/\n│   ├── figures/\n│   ├── tables/\n│   │   ├── analise_descritiva_por_risco.csv\n│   │   ├── analise_descritiva_temporal.csv\n│   │   ├── dataset_integrado.csv\n│   │   ├── metricas_modelo.csv\n│   │   ├── predicoes_teste.csv\n│   │   ├── relatorio_execucao.csv\n│   │   └── top50_municipios_2021.csv\n│   └── maps/\n│       ├── mapa_1_top_risco.html\n│       ├── mapa_1_top_risco_files/\n│       ├── mapa_2_intensidade.html\n│       ├── mapa_2_intensidade_files/\n│       ├── mapa_3_eficiencia.html\n│       ├── mapa_3_eficiencia_files/\n│       ├── mapa_4_estados.html\n│       └── mapa_4_estados_files/\n\n\n\n\n\nMunicípios classificados em três categorias baseadas na relação desmatamento/produção:\n\nBaixo risco: Alta produção com baixo desmatamento relativo\nMédio risco: Equilíbrio intermediário\nAlto risco: Desmatamento desproporcional à produção\n\n\n\n\nO Random Forest demonstrou capacidade de estimar desmatamento com base em variáveis agrícolas e históricas. As variáveis mais importantes incluem:\n\nHistórico de desmatamento (lags 1 e 2)\nÁrea colhida total\nPressão sobre vegetação natural\nProdução total\n\n\n\n\n\nForte concentração de desmatamento em estados da fronteira agrícola\nCorrelação espacial entre municípios vizinhos\nInércia no processo de desmatamento (municípios com histórico elevado mantêm padrão)\nRelação não-linear entre produção e desmatamento\n\n\n\n\n\n\n\n# Instalar pacotes necessários\ninstall.packages(\"pacman\")\nlibrary(pacman)\n\npacman::p_load(\n  dplyr,\n  tidyr,\n  ggplot2,\n  scales,\n  zoo,\n  DBI,\n  bigrquery,\n  sf,\n  geobr,\n  leaflet,\n  randomForest,\n  skimr,\n  rsample,\n  yardstick,\n  tibble,\n  stringr,\n  readr,\n  htmltools,\n  htmlwidgets)\n\n\n\nsource(\"risco_desmatamento.R\")\n\nEste script executa todo o pipeline:\nExtração de dados do BigQuery\nProcessamento e engenharia de features\nAnálise exploratória\nModelagem preditiva\nGeração de visualizações\nExportação de resultados\n\n\n\n\nTabelas (CSV):\n\ndataset_integrado.csv: Base completa processada\ntop50_municipios_2021.csv: Municípios com maior desmatamento\npredicoes_teste.csv: Previsões do modelo\nmetricas_modelo.csv: Métricas de avaliação\nanalise_descritiva_*.csv: Estatísticas\n\nVisualizações:\n\nfigures/: Gráficos\nmaps/: Mapas interativos HTML (abrir no navegador)\n\nModelo:\n\nmodels/modelo_rf.rds: Modelo Random Forest\n\n\n\n\n\n\nIdentificação de municípios prioritários para fiscalização\nMonitoramento de áreas de alto risco\nAvaliação de efetividade de políticas ambientais\n\n\n\n\nBenchmarking de eficiência produtiva\nPlanejamento de expansão sustentável\nSubsídio para certificações ambientais\n\n\n\n\n\n\nPeríodo de 7 anos pode não capturar ciclos longos\nFoco limitado a três culturas principais\nVariáveis omitidas (preços, políticas, infraestrutura)\n\n\n\n\n\nIncorporar variáveis socioeconômicas\nExpandir análise para outras culturas\nIntegrar dados de fiscalização ambiental\nDesenvolver modelos de previsão de longo prazo\nAnalisar efeitos de políticas específicas\n\n\n\n\nJennifer Luz Lopes\n\nPortfólio: https://jenniferlopes.quarto.pub/portifolio/\nGitHub: https://github.com/JenniferLopes\n\n\n\n\nMIT.\n\n\n\n\nIBGE - Produção Agrícola Municipal (PAM)\nINPE - Programa de Monitoramento do Desmatamento (PRODES)\nBase dos Dados - https://basedosdados.org/"
  },
  {
    "objectID": "projetos/posts/2025-12-12-desmatamento.html#contextualização",
    "href": "projetos/posts/2025-12-12-desmatamento.html#contextualização",
    "title": "Projeto - Análise de Desmatamento e Produção Agrícola no Brasil",
    "section": "",
    "text": "Obs: Desenvolvi esse trabalho em 2024, mas não havia publicado para rede. Pretendo ampliar as análises, culturas e anos.\nEste projeto analisa a relação entre produção agrícola das principais culturas brasileiras (soja, milho e arroz) e o desmatamento em municípios do país. A análise integra dados oficiais do IBGE e INPE para identificar padrões espaciais e temporais, classificar municípios por risco ambiental e desenvolver modelos preditivos."
  },
  {
    "objectID": "projetos/posts/2025-12-12-desmatamento.html#objetivos",
    "href": "projetos/posts/2025-12-12-desmatamento.html#objetivos",
    "title": "Projeto - Análise de Desmatamento e Produção Agrícola no Brasil",
    "section": "",
    "text": "Mapear espacialmente municípios com maior desmatamento e produção agrícola\nClassificar municípios por nível de risco ambiental (baixo, médio, alto)\nAnalisar séries temporais para identificar tendências de desmatamento e produção\nDesenvolver modelo preditivo usando Random Forest para estimar desmatamento\nIdentificar variáveis-chave que mais contribuem para o desmatamento"
  },
  {
    "objectID": "projetos/posts/2025-12-12-desmatamento.html#relatório-com-os-principais-resultados",
    "href": "projetos/posts/2025-12-12-desmatamento.html#relatório-com-os-principais-resultados",
    "title": "Projeto - Análise de Desmatamento e Produção Agrícola no Brasil",
    "section": "",
    "text": "Pessoal, sempre gosto de construir os scripts.R e um relatório.qmd nos meus projetos.\n\nVocês podem acessar o relatório em HTML aqui.\nRepositório completo no GitHub."
  },
  {
    "objectID": "projetos/posts/2025-12-12-desmatamento.html#fontes-de-dados",
    "href": "projetos/posts/2025-12-12-desmatamento.html#fontes-de-dados",
    "title": "Projeto - Análise de Desmatamento e Produção Agrícola no Brasil",
    "section": "",
    "text": "Produção Agrícola Municipal (PAM) - IBGE:\n\nProdução total (toneladas)\nÁrea colhida (hectares)\nValor da produção\nCulturas: soja, milho e arroz em grão\n\nPrograma de Monitoramento do Desmatamento (PRODES) - INPE:\n\nDesmatamento anual (hectares)\nÁrea total municipal\nCobertura vegetal natural\n\nAmbas as fontes foram acessadas via Base dos Dados (BigQuery), cobrindo o período de 2015 a 2021."
  },
  {
    "objectID": "projetos/posts/2025-12-12-desmatamento.html#metodologia",
    "href": "projetos/posts/2025-12-12-desmatamento.html#metodologia",
    "title": "Projeto - Análise de Desmatamento e Produção Agrícola no Brasil",
    "section": "",
    "text": "Conexão ao BigQuery para extração de dados PAM e PRODES\nIntegração das bases por município e ano\nValidação e limpeza de dados inconsistentes\n\n\n\n\nCriação de variáveis derivadas para análise:\n\nTemporais: lags de desmatamento, médias móveis, crescimento de produção\nEficiência: produtividade (ton/ha), risco por tonelada (ha/ton)\nPressão ambiental: relação entre área cultivada e vegetação natural\nClassificação: classes de risco baseadas em percentis\n\n\n\n\n\nDivisão temporal: treino (2015-2019), validação (2020), teste\n\n\n\nAlgoritmo: Random Forest com 300 árvores\nFeatures: 9 variáveis selecionadas (produção, área, produtividade, histórico de desmatamento, etc.)\nAvaliação: MAE, RMSE, R², MAPE\n\n\n\n\n\nEstatísticas descritivas por classe de risco\nAnálise temporal agregada\nDistribuição espacial do desmatamento\n\n\n\n\n\nGráficos de importância de variáveis\nScatter plots de produção vs desmatamento\nMapas interativos (Leaflet)"
  },
  {
    "objectID": "projetos/posts/2025-12-12-desmatamento.html#estrutura-do-projeto",
    "href": "projetos/posts/2025-12-12-desmatamento.html#estrutura-do-projeto",
    "title": "Projeto - Análise de Desmatamento e Produção Agrícola no Brasil",
    "section": "",
    "text": "risco_desmatamento/\n├── .gitignore\n├── .Rprofile\n├── renv/\n├── renv.lock\n├── risco_desmatamento.Rproj\n├── README.md\n├── scripts/\n│   └── risco_desmatamento.R\n├── outputs/\n│   ├── figures/\n│   ├── tables/\n│   │   ├── analise_descritiva_por_risco.csv\n│   │   ├── analise_descritiva_temporal.csv\n│   │   ├── dataset_integrado.csv\n│   │   ├── metricas_modelo.csv\n│   │   ├── predicoes_teste.csv\n│   │   ├── relatorio_execucao.csv\n│   │   └── top50_municipios_2021.csv\n│   └── maps/\n│       ├── mapa_1_top_risco.html\n│       ├── mapa_1_top_risco_files/\n│       ├── mapa_2_intensidade.html\n│       ├── mapa_2_intensidade_files/\n│       ├── mapa_3_eficiencia.html\n│       ├── mapa_3_eficiencia_files/\n│       ├── mapa_4_estados.html\n│       └── mapa_4_estados_files/"
  },
  {
    "objectID": "projetos/posts/2025-12-12-desmatamento.html#resultados-principais",
    "href": "projetos/posts/2025-12-12-desmatamento.html#resultados-principais",
    "title": "Projeto - Análise de Desmatamento e Produção Agrícola no Brasil",
    "section": "",
    "text": "Municípios classificados em três categorias baseadas na relação desmatamento/produção:\n\nBaixo risco: Alta produção com baixo desmatamento relativo\nMédio risco: Equilíbrio intermediário\nAlto risco: Desmatamento desproporcional à produção\n\n\n\n\nO Random Forest demonstrou capacidade de estimar desmatamento com base em variáveis agrícolas e históricas. As variáveis mais importantes incluem:\n\nHistórico de desmatamento (lags 1 e 2)\nÁrea colhida total\nPressão sobre vegetação natural\nProdução total\n\n\n\n\n\nForte concentração de desmatamento em estados da fronteira agrícola\nCorrelação espacial entre municípios vizinhos\nInércia no processo de desmatamento (municípios com histórico elevado mantêm padrão)\nRelação não-linear entre produção e desmatamento"
  },
  {
    "objectID": "projetos/posts/2025-12-12-desmatamento.html#como-usar",
    "href": "projetos/posts/2025-12-12-desmatamento.html#como-usar",
    "title": "Projeto - Análise de Desmatamento e Produção Agrícola no Brasil",
    "section": "",
    "text": "# Instalar pacotes necessários\ninstall.packages(\"pacman\")\nlibrary(pacman)\n\npacman::p_load(\n  dplyr,\n  tidyr,\n  ggplot2,\n  scales,\n  zoo,\n  DBI,\n  bigrquery,\n  sf,\n  geobr,\n  leaflet,\n  randomForest,\n  skimr,\n  rsample,\n  yardstick,\n  tibble,\n  stringr,\n  readr,\n  htmltools,\n  htmlwidgets)\n\n\n\nsource(\"risco_desmatamento.R\")\n\nEste script executa todo o pipeline:\nExtração de dados do BigQuery\nProcessamento e engenharia de features\nAnálise exploratória\nModelagem preditiva\nGeração de visualizações\nExportação de resultados\n\n\n\n\nTabelas (CSV):\n\ndataset_integrado.csv: Base completa processada\ntop50_municipios_2021.csv: Municípios com maior desmatamento\npredicoes_teste.csv: Previsões do modelo\nmetricas_modelo.csv: Métricas de avaliação\nanalise_descritiva_*.csv: Estatísticas\n\nVisualizações:\n\nfigures/: Gráficos\nmaps/: Mapas interativos HTML (abrir no navegador)\n\nModelo:\n\nmodels/modelo_rf.rds: Modelo Random Forest"
  },
  {
    "objectID": "projetos/posts/2025-12-12-desmatamento.html#aplicações",
    "href": "projetos/posts/2025-12-12-desmatamento.html#aplicações",
    "title": "Projeto - Análise de Desmatamento e Produção Agrícola no Brasil",
    "section": "",
    "text": "Identificação de municípios prioritários para fiscalização\nMonitoramento de áreas de alto risco\nAvaliação de efetividade de políticas ambientais\n\n\n\n\nBenchmarking de eficiência produtiva\nPlanejamento de expansão sustentável\nSubsídio para certificações ambientais"
  },
  {
    "objectID": "projetos/posts/2025-12-12-desmatamento.html#limitações",
    "href": "projetos/posts/2025-12-12-desmatamento.html#limitações",
    "title": "Projeto - Análise de Desmatamento e Produção Agrícola no Brasil",
    "section": "",
    "text": "Período de 7 anos pode não capturar ciclos longos\nFoco limitado a três culturas principais\nVariáveis omitidas (preços, políticas, infraestrutura)"
  },
  {
    "objectID": "projetos/posts/2025-12-12-desmatamento.html#próximos-passos",
    "href": "projetos/posts/2025-12-12-desmatamento.html#próximos-passos",
    "title": "Projeto - Análise de Desmatamento e Produção Agrícola no Brasil",
    "section": "",
    "text": "Incorporar variáveis socioeconômicas\nExpandir análise para outras culturas\nIntegrar dados de fiscalização ambiental\nDesenvolver modelos de previsão de longo prazo\nAnalisar efeitos de políticas específicas"
  },
  {
    "objectID": "projetos/posts/2025-12-12-desmatamento.html#autoria",
    "href": "projetos/posts/2025-12-12-desmatamento.html#autoria",
    "title": "Projeto - Análise de Desmatamento e Produção Agrícola no Brasil",
    "section": "",
    "text": "Jennifer Luz Lopes\n\nPortfólio: https://jenniferlopes.quarto.pub/portifolio/\nGitHub: https://github.com/JenniferLopes"
  },
  {
    "objectID": "projetos/posts/2025-12-12-desmatamento.html#licença",
    "href": "projetos/posts/2025-12-12-desmatamento.html#licença",
    "title": "Projeto - Análise de Desmatamento e Produção Agrícola no Brasil",
    "section": "",
    "text": "MIT."
  },
  {
    "objectID": "projetos/posts/2025-12-12-desmatamento.html#referências",
    "href": "projetos/posts/2025-12-12-desmatamento.html#referências",
    "title": "Projeto - Análise de Desmatamento e Produção Agrícola no Brasil",
    "section": "",
    "text": "IBGE - Produção Agrícola Municipal (PAM)\nINPE - Programa de Monitoramento do Desmatamento (PRODES)\nBase dos Dados - https://basedosdados.org/"
  }
]